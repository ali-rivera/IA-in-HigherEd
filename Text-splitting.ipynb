{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing with chunking/embedding code from https://huggingface.co/learn/cookbook/advanced_rag on PythonDSHandbook.txt, Week7-lecture.txt, Week9-lecture.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "from tqdm.notebook import tqdm #progress bar\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Tuple #type hinting\n",
    "# from datasets import Dataset #to load in premade example datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)  # This will be helpful when visualizing retriever outputs\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter #splitter\n",
    "\n",
    "#langsmith setup\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "#load in Documents\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter #alt import\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# embedding and searching\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "#plotting\n",
    "import pacmap\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKDOWN_SEPARATORS = [\n",
    "    \"\\n#{1,6} \",\n",
    "    \"```\\n\",\n",
    "    \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
    "    \"\\n---+\\n\",\n",
    "    \"\\n___+\\n\",\n",
    "    \"\\n\\n\",\n",
    "    \"\\n\",\n",
    "    \" \",\n",
    "    \"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:25<00:00,  2.80s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c92fd5127f41e2adc1ad03bcfbed6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## load in docs (must be in IA-in-HigherEd dir)\n",
    "loader = DirectoryLoader('./RAG-docs/processed/', glob=\"**/*.txt\", show_progress = True) #all .txt files in processed folder\n",
    "docs = loader.load()\n",
    "docs\n",
    "\n",
    "# save as LC docs\n",
    "RAW_KNOWLEDGE_BASE = [\n",
    "    LangchainDocument(page_content=doc.page_content, metadata= doc.metadata) for doc in tqdm(docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wat6sv\\AppData\\Local\\miniconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's maximum sequence length: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2cfd69c82c438d916fcda450174760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1485 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split (chunk) docs with chunk size = max seq length()\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "seq_len = SentenceTransformer(EMBEDDING_MODEL_NAME).max_seq_length\n",
    "print(f\"Model's maximum sequence length: {seq_len}\")\n",
    "\n",
    "\n",
    "def split_documents(\n",
    "    chunk_size: int,\n",
    "    knowledge_base: List[LangchainDocument],\n",
    "    tokenizer_name: Optional[str] = EMBEDDING_MODEL_NAME,\n",
    ") -> List[LangchainDocument]:\n",
    "    \"\"\"\n",
    "    Split documents into chunks of maximum size `chunk_size` tokens and return a list of documents.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "        AutoTokenizer.from_pretrained(tokenizer_name),\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=int(chunk_size / 10),\n",
    "        add_start_index=True,\n",
    "        strip_whitespace=True,\n",
    "        separators=MARKDOWN_SEPARATORS,\n",
    "    )\n",
    "\n",
    "    docs_processed = []\n",
    "    for doc in knowledge_base:\n",
    "        docs_processed += text_splitter.split_documents([doc])\n",
    "\n",
    "    # Remove duplicates\n",
    "    unique_texts = {}\n",
    "    docs_processed_unique = []\n",
    "    for doc in docs_processed:\n",
    "        if doc.page_content not in unique_texts:\n",
    "            unique_texts[doc.page_content] = True\n",
    "            docs_processed_unique.append(doc)\n",
    "\n",
    "    return docs_processed_unique\n",
    "\n",
    "\n",
    "docs_processed = split_documents(\n",
    "    seq_len,  # We choose a chunk size adapted to our model\n",
    "    RAW_KNOWLEDGE_BASE,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
    ")\n",
    "\n",
    "# Let's visualize the chunk sizes we would have in tokens from a common model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME)\n",
    "lengths = [len(tokenizer.encode(doc.page_content)) for doc in tqdm(docs_processed)]\n",
    "fig = pd.Series(lengths).hist()\n",
    "plt.title(\"Distribution of document lengths in the knowledge base (in count of tokens)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings for docs \n",
    "## Takes a while to run loacally (~6 min w/ PythonDS, Week7, Week9)\n",
    "\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    multi_process=True,\n",
    "    # model_kwargs={\"device\": \"cuda\"}, #using cpu when running locally - change if connecting to GPU for more speed\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
    ")\n",
    "\n",
    "#edit distance strategy for use case\n",
    "KNOWLEDGE_VECTOR_DATABASE = FAISS.from_documents(\n",
    "    docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try chroma for vector storage\n",
    "\n",
    "\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# text_splitter  = RecursiveCharacterTextSplitter(chunk_size=seq_len,chunk_overlap=20)\n",
    "# text_chunks = text_splitter.split_documents(RAW_KNOWLEDGE_BASE)\n",
    "\n",
    "\n",
    "# vectorstore = Chroma.from_documents(documents=text_chunks, \n",
    "#                                     embedding=embedding_model)#,\n",
    "#                                     # persist_directory=\"data/vectorstore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_docs = vectorstore.similarity_search(\"What is a decision tree?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in sim_docs:\n",
    "#     print(doc.metadata['source'], \"\\n\", doc.page_content, \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWLEDGE_VECTOR_DATABASE.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed a user query in the same space\n",
    "user_query = \"What is a decision tree?\"\n",
    "query_vector = embedding_model.embed_query(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wat6sv\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pacmap\\pacmap.py:822: UserWarning: Warning: random state is set to 1\n",
      "  warnings.warn(f'Warning: random state is set to {_RANDOM_STATE}')\n"
     ]
    }
   ],
   "source": [
    "# create pca projection of embeddings for visualization\n",
    "\n",
    "embedding_projector = pacmap.PaCMAP(n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0, random_state=1)\n",
    "\n",
    "embeddings_2d = [\n",
    "    list(KNOWLEDGE_VECTOR_DATABASE.index.reconstruct_n(idx, 1)[0]) for idx in range(len(docs_processed))\n",
    "] + [query_vector]\n",
    "\n",
    "# Fit the data (the index of transformed data corresponds to the index of the original data)\n",
    "documents_projected = embedding_projector.fit_transform(np.array(embeddings_2d), init=\"pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Chapter 1: Introducing Active Machine Learning - Active Machine Learning with Python [Book]\n\nSkip to..."
          ],
          [
           "Get Active Machine Learning with Python now with the O’Reilly learning platform. O’Reilly members ex..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n2 Designing Query Strategy Frameworks Query strategies act as the engine that..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Answers\n\nInsights reporting\n\nBlog\n\nContent sponsorship\n\nActive Machine Learning with Python by Marga..."
          ],
          [
           "Affiliate program\n\nSubmit an RFP\n\nDiversity\n\nO’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletter..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Start your free trial\n\nAbout O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nC..."
          ],
          [
           "Close\n\nChapter 5: Leveraging Active Learning for Big Data - Active Machine Learning with Python [Boo..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n6 Evaluating and Enhancing Efficiency In this chapter, we will explore the im..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Answers\n\nInsights reporting\n\nBlog\n\nContent sponsorship\n\nActive Machine Learning with Python by Marga..."
          ],
          [
           "Submit an RFP\n\nDiversity\n\nO’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\n..."
          ],
          [
           "Sign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividuals\n\nFeatures\n\nAll fea..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\ActiveMLwithPython-Masson-Forsythe.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\ActiveMLwithPython-Masson-Forsythe.txt, circle",
         "marker": {
          "color": "#EF553B",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\ActiveMLwithPython-Masson-Forsythe.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          10.515769,
          11.538707,
          10.7647505,
          10.378728,
          14.371646,
          10.225103,
          14.253117,
          10.187541,
          14.675078,
          10.174853,
          10.625165,
          10.50332,
          14.311891,
          10.559434,
          14.608761,
          10.488484
         ],
         "xaxis": "x",
         "y": [
          -3.0018935,
          -3.1153286,
          -2.8632429,
          -2.8858583,
          -2.7997544,
          -3.0484526,
          -3.452688,
          -3.1920874,
          -3.4599962,
          -2.9029346,
          -2.8368068,
          -2.9988084,
          -2.9295118,
          -2.9009986,
          -3.4161036,
          -3.0085652
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "1. The Machine Learning Landscape - Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFl..."
          ],
          [
           "Start your free trial\n\nChapter 1. The Machine Learning Landscape When most people hear “Machine Lear..."
          ],
          [
           "Then we will look at the workflow of a typical ML project, discuss the main challenges you may face,..."
          ],
          [
           "Your spam filter is a Machine Learning program that, given examples of spam emails (e.g., flagged by..."
          ],
          [
           "You would test your program and repeat steps 1 and 2 until it was good enough to launch.\n\nFigure 1\n\n..."
          ],
          [
           "Figure 1-2. The Machine Learning approach\n\nFigure 1-3. Automatically adapting to change\n\nAnother are..."
          ],
          [
           "Problems for which existing solutions require a lot of fine-tuning or long lists of rules: one Machi..."
          ],
          [
           "Creating a chatbot or a personal assistant\n\nThis involves many NLP components, including natural lan..."
          ],
          [
           "Recommending a product that a client may be interested in, based on past purchases\n\nThis is a recomm..."
          ],
          [
           "These criteria are not exclusive; you can combine them in any way you like. For example, a state-of-..."
          ],
          [
           "Figure 1-5. A labeled training set for spam classification (an example of supervised learning)\n\nA ty..."
          ],
          [
           "k\n\nNearest Neighbors\n\nLinear Regression\n\nLogistic Regression\n\nSupport Vector Machines (SVMs)\n\nDecisi..."
          ],
          [
           "t-Distributed Stochastic Neighbor Embedding (t-SNE)\n\nAssociation rule learning\n\nApriori\n\nEclat\n\nFor ..."
          ],
          [
           "Figure 1-9. Example of a t-SNE visualization highlighting semantic clusters3\n\nA related task is dime..."
          ],
          [
           "Yet another important unsupervised task is anomaly detection—for example, detecting unusual credit c..."
          ],
          [
           "Semisupervised learning Since labeling data is usually time-consuming and costly, you will often hav..."
          ],
          [
           "Reinforcement Learning Reinforcement Learning is a very different beast. The learning system, called..."
          ],
          [
           "Batch and Online Learning Another criterion used to classify Machine Learning systems is whether or ..."
          ],
          [
           "If you have a lot of data and you automate your system to train from scratch every day, it will end ..."
          ],
          [
           "Figure 1-13. In online learning, a model is trained and launched into production, and then it keeps ..."
          ],
          [
           "One important parameter of online learning systems is how fast they should adapt to changing data: t..."
          ],
          [
           "Instance-Based Versus Model-Based Learning One more way to categorize Machine Learning systems is by..."
          ],
          [
           "Figure 1\n\n15. Instance\n\nbased learning\n\nModel-based learning Another way to generalize from a set of..."
          ],
          [
           "Let’s plot the data for these countries (Figure 1-17).\n\nFigure 1-17. Do you see a trend here?\n\nThere..."
          ],
          [
           "Figure 1-18. A few possible linear models\n\nBefore you can use your model, you need to define the par..."
          ],
          [
           "Now the model fits the training data as closely as possible (for a linear model), as you can see in ..."
          ],
          [
           "encoding='latin1', na_values=\"n/a\")\n\n# Prepare the data country_stats = prepare_country_stats(oecd_b..."
          ],
          [
           "# Train the model\n\nmodel.fit(X, y)\n\n# Make a prediction for Cyprus X_new = [[22587]]  # Cyprus's GDP..."
          ],
          [
           "You studied the data.\n\nYou selected a model.\n\nYou trained it on the training data (i.e., the learnin..."
          ],
          [
           "The Unreasonable Effectiveness of Data In a famous paper published in 2001, Microsoft researchers Mi..."
          ],
          [
           "Figure 1-21. A more representative training sample\n\nIf you train a linear model on this data, you ge..."
          ],
          [
           "First, to obtain the addresses to send the polls to, the Literary Digest used telephone directories,..."
          ],
          [
           "If some instances are clearly outliers, it may help to simply discard them or try to fix the errors ..."
          ],
          [
           "Creating new features by gathering new data\n\nNow that we have looked at many examples of bad data, l..."
          ],
          [
           "Figure 1-22. Overfitting the training data\n\nComplex models such as deep neural networks can detect s..."
          ],
          [
           "Gather more training data.\n\nReduce the noise in the training data (e.g., fix data errors and remove ..."
          ],
          [
           "You can see that regularization forced the model to have a smaller slope: this model does not fit th..."
          ],
          [
           "Reduce the constraints on the model (e.g., reduce the regularization hyperparameter).\n\nStepping Back..."
          ],
          [
           "Testing and Validating The only way to know how well a model will generalize to new cases is to actu..."
          ],
          [
           "Hyperparameter Tuning and Model Selection Evaluating a model is simple enough: just use a test set. ..."
          ],
          [
           "More specifically, you train multiple models with various hyperparameters on the reduced training se..."
          ],
          [
           "Data Mismatch In some cases, it’s easy to get a large amount of data for training, but this data pro..."
          ],
          [
           "After the model is trained (on the training set, not on the train-dev set), you can evaluate it on t..."
          ],
          [
           "No Free Lunch Theorem A model is a simplified version of the observations. The simplifications are m..."
          ],
          [
           "What is a labeled training set?\n\nWhat are the two most common supervised tasks?\n\nCan you name four c..."
          ],
          [
           "What can go wrong if you tune hyperparameters using the test set?\n\nSolutions to these exercises are ..."
          ],
          [
           "It’s just boring pandas code that joins the life satisfaction data from the OECD with the GDP per ca..."
          ],
          [
           "Support\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAust..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Fine\n\ntune your model.\n\nPresent your solution.\n\nLaunch, monitor, and maintain your system.\n\nWorking ..."
          ],
          [
           "Start your free trial\n\nAbout O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nC..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 3. Classification In Chapter 1 I mentioned that the most common super..."
          ],
          [
           "A DESCR key describing the dataset\n\nA data key containing an array with one ...\n\nGet Hands-On Machin..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "Start your free trial\n\nChapter 4. Training Models So far we have treated Machine Learning models and..."
          ],
          [
           "Using an iterative optimization approach called Gradient Descent (GD) that gradually tweaks the mode..."
          ],
          [
           "Linear Regression In Chapter 1 we looked at a simple regression model of life satisfaction: life_sat..."
          ],
          [
           "In this equation:\n\nθ is the model’s parameter vector, containing the bias term θ0 and the feature we..."
          ],
          [
           "OK, that’s the Linear Regression model—but how do we train it? Well, recall that training a model me..."
          ],
          [
           "The Normal Equation To find the value of θ that minimizes the cost function, there is a closed-form ..."
          ],
          [
           "Now let’s compute θ^ using the Normal Equation. We will use the inv() function from NumPy’s linear a..."
          ],
          [
           "we used to generate the data is y = 4 + 3x1 + Gaussian noise. Let’s see what the equation found: >>>..."
          ],
          [
           "original function. Now we can make predictions using θ^: >>> X_new = np.array([[0], [2]]) >>> X_new_..."
          ],
          [
           "y, \"b.\") plt.axis([0, 2, 0, 15]) plt.show()..."
          ],
          [
           "Figure 4-2. Linear Regression model predictions..."
          ],
          [
           "Performing Linear Regression using Scikit-Learn is simple:2 >>> from sklearn.linear_model import Lin..."
          ],
          [
           "you could call directly: >>> theta_best_svd, residuals, rank, s = np.linalg.lstsq(X_b, y, rcond=1e-6..."
          ],
          [
           "The pseudoinverse itself is computed using a standard matrix factorization technique called Singular..."
          ],
          [
           "then it replaces all the nonzero values with their inverse, and finally it transposes the resulting ..."
          ],
          [
           "This approach is more efficient than computing the Normal Equation, plus it handles edge cases nicel..."
          ],
          [
           "Also, once you have trained your Linear Regression model (using the Normal Equation or any other alg..."
          ],
          [
           "Figure 4-3. In this depiction of Gradient Descent, the model parameters are initialized randomly and..."
          ],
          [
           "Figure 4\n\n6. Gradient Descent pitfalls\n\nFortunately, the MSE cost function for a Linear Regression m..."
          ],
          [
           "This diagram also illustrates the fact that training a model means searching for a combination of mo..."
          ],
          [
           "θ ⊺\n\nx (i)\n\ny (i)\n\n)\n\nx j (i)\n\nInstead of computing these partial derivatives individually, you can ..."
          ],
          [
           "2 m\n\nX ⊺\n\n(\n\nX\n\nθ\n\ny\n\n)\n\nWarning Notice that this formula involves calculations over the full traini..."
          ],
          [
           "theta = np.random.randn(2,1)  # random initialization\n\nfor iteration in range(n_iterations): gradien..."
          ],
          [
           "Figure 4-8. Gradient Descent with various learning rates\n\nOn the left, the learning rate is too low:..."
          ],
          [
           "Stochastic Gradient Descent The main problem with Batch Gradient Descent is the fact that it uses th..."
          ],
          [
           "Figure 4-9. With Stochastic Gradient Descent, each training step is much faster but also much more s..."
          ],
          [
           "theta = np.random.randn(2,1)  # random initialization\n\nfor epoch in range(n_epochs): for i in range(..."
          ],
          [
           "Figure 4-10. The first 20 steps of Stochastic Gradient Descent\n\nNote that since instances are picked..."
          ],
          [
           "To perform Linear Regression using Stochastic GD with Scikit-Learn, you can use the SGDRegressor cla..."
          ],
          [
           "Mini-batch Gradient Descent The last Gradient Descent algorithm we will look at is called Mini-batch..."
          ],
          [
           "Figure 4-11. Gradient Descent paths in parameter space\n\nLet’s compare the algorithms we’ve discussed..."
          ],
          [
           "SGDRegressor\n\nNote There is almost no difference after training: all these algorithms end up with ve..."
          ],
          [
           "Figure 4-12. Generated nonlinear and noisy dataset\n\nClearly, a straight line will never fit this dat..."
          ],
          [
           "0.56\n\nx 1  2\n\n+\n\n0.93\n\nx 1\n\n+\n\n1.78\n\nwhen in fact the original function was\n\ny\n\n=\n\n0.5\n\nx 1  2\n\n+\n\n1..."
          ],
          [
           "Learning Curves If you perform high-degree Polynomial Regression, you will likely fit the training d..."
          ],
          [
           "Figure 4\n\n14. High\n\ndegree Polynomial Regression\n\nThis high-degree Polynomial Regression model is se..."
          ],
          [
           "def plot_learning_curves(model, X, y): X_train, X_val, y_train, y_val = train_test_split(X, y, test_..."
          ],
          [
           "Figure 4\n\n15. Learning curves\n\nThis model that’s underfitting deserves a bit of explanation. First, ..."
          ],
          [
           "polynomial_regression = Pipeline([\n\n(\"poly_features\", PolynomialFeatures(degree=10, include_bias=Fal..."
          ],
          [
           "Variance\n\nThis part is due to the model’s excessive sensitivity to small variations in the training ..."
          ],
          [
           "Ridge Regression Ridge Regression (also called Tikhonov regularization) is a regularized version of ..."
          ],
          [
           "The hyperparameter α controls how much you want to regularize the model. If α = 0, then Ridge Regres..."
          ],
          [
           "Figure 4-17. A linear model (left) and a polynomial model (right), both with various levels of Ridge..."
          ],
          [
           "θ ^\n\n=\n\n(X ⊺ X+αA)\n\n1\n\nX ⊺\n\ny\n\nHere is how to perform Ridge Regression with Scikit-Learn using a clo..."
          ],
          [
           "Lasso Regression Least Absolute Shrinkage and Selection Operator Regression (usually simply called L..."
          ],
          [
           "Figure 4-18. A linear model (left) and a polynomial model (right), both using various levels of Lass..."
          ],
          [
           "The small white circles show the path that Gradient Descent takes to optimize some model parameters ..."
          ],
          [
           "The Lasso cost function is not differentiable at θi = 0 (for i = 1, 2, ⋯, n), but Gradient Descent s..."
          ],
          [
           "Elastic Net Elastic Net is a middle ground between Ridge Regression and Lasso Regression. The regula..."
          ],
          [
           "Early Stopping A very different way to regularize iterative learning algorithms such as Gradient Des..."
          ],
          [
           "(\"std_scaler\", StandardScaler())\n\n])\n\nX_train_poly_scaled = poly_scaler.fit_transform(X_train)\n\nX_va..."
          ],
          [
           "Logistic Regression As we discussed in Chapter 1, some regression algorithms can be used for classif..."
          ],
          [
           "Equation 4\n\n14. Logistic function\n\nσ\n\n(\n\nt\n\n)\n\n=\n\n1 1+exp(\n\nt)\n\nFigure 4\n\n21. Logistic function\n\nOnc..."
          ],
          [
           "Training and Cost Function Now you know how a Logistic Regression model estimates probabilities and ..."
          ],
          [
           "Logistic Regression cost function (log loss)J(θ)=-1m∑i=1my(i)logp^(i)+(1-y(i))log1-p^(i) The bad new..."
          ],
          [
           "Decision Boundaries Let’s use the iris dataset to illustrate Logistic Regression. This is a famous d..."
          ],
          [
           "log_reg = LogisticRegression() log_reg.fit(X, y) Let’s look at the model’s estimated probabilities f..."
          ],
          [
           "Figure 4-23. Estimated probabilities and decision boundary\n\nThe petal width of Iris virginica flower..."
          ],
          [
           "Note that it is a linear boundary.16 Each parallel line represents the points where the model output..."
          ],
          [
           "(\n\nx\n\n)\n\n=\n\n(θ (k) ) ⊺\n\nx\n\nNote that each class has its own dedicated parameter vector θ(k). All the..."
          ],
          [
           "y ^\n\n=\n\nargmax k\n\nσ\n\ns(x) k\n\n=\n\nargmax k\n\ns k\n\n(\n\nx\n\n)\n\n=\n\nargmax k\n\n(θ (k) ) ⊺\n\nx\n\nThe argmax opera..."
          ],
          [
           "yk(i) is the target probability that the ith instance belongs to class k. In general, it is either e..."
          ],
          [
           "∇ θ (k)\n\nJ\n\n(\n\nΘ\n\n)\n\n=\n\n1 m\n\n∑ i=1 m\n\np ^ k (i)\n\ny k (i)\n\nx (i)\n\nNow you can compute the gradient ve..."
          ],
          [
           "softmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=10) softmax_reg.fit(X, ..."
          ],
          [
           "Exercises\n\nWhich Linear Regression training algorithm can you use if you have a training set with mi..."
          ],
          [
           "Lasso instead of Ridge Regression?\n\nElastic Net instead of Lasso?\n\nSuppose you want to classify pict..."
          ],
          [
           "Implement Batch Gradient Descent with early stopping for Softmax Regression (without using Scikit-Le..."
          ],
          [
           "Stochastic Average GD is a variant of Stochastic GD. For more details, see the presentation “Minimiz..."
          ],
          [
           "O’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nl..."
          ],
          [
           "Close\n\n5. Support Vector Machines - Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFl..."
          ],
          [
           "Linear SVM Classification The fundamental idea behind SVMs is best explained with some pictures. Fig..."
          ],
          [
           "Newsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\n..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Start your free trial\n\nChapter 6. Decision Trees Like SVMs, Decision Trees are versatile Machine Lea..."
          ],
          [
           "Get Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition now with the O’R..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 7. Ensemble Learning and Random Forests Suppose you pose a complex qu..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 8. Dimensionality Reduction Many Machine Learning problems involve th..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 9. Unsupervised Learning Techniques Although most of the applications..."
          ],
          [
           "As a result, the labeled dataset will be quite small, ...\n\nGet Hands-On Machine Learning with Scikit..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nChapter 10. Introduction to Artificial Neural Networks with Keras Birds inspi..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 11. Training Deep Neural Networks In Chapter 10 we introduced artific..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 12. Custom Models and Training with TensorFlow Up until now, we’ve us..."
          ],
          [
           "A Quick Tour of TensorFlow As you know, TensorFlow is a powerful library for numerical ...\n\nGet Hand..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nChapter 13. Loading and Preprocessing Data with TensorFlow So far we have use..."
          ],
          [
           "These need to be encoded, for example using one-hot encoding, bag-of-words encoding, ...\n\nGet Hands-..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nChapter 14. Deep Computer Vision Using Convolutional Neural Networks Although..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 15. Processing Sequences Using RNNs and CNNs The batter hits the ball..."
          ],
          [
           "A (very) limited ...\n\nGet Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Ed..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 16. Natural Language Processing with RNNs and Attention When Alan Tur..."
          ],
          [
           "This will allow us to generate some original text, and in the process we ...\n\nGet Hands-On Machine L..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nChapter 17. Representation Learning and Generative Learning Using Autoencoder..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 18. Reinforcement Learning Reinforcement Learning (RL) is one of the ..."
          ],
          [
           "In this chapter we will first explain what Reinforcement Learning is and what it’s good at, then pre..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nChapter 19. Training and Deploying TensorFlow Models at Scale Once you have a..."
          ],
          [
           "If you use the cloud platform, you will also get many ...\n\nGet Hands-On Machine Learning with Scikit..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nAppendix A. Exercise Solutions Note Solutions to the coding exercises are ava..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nAppendix B. Machine Learning Project Checklist This checklist can guide you t..."
          ],
          [
           "Get the Data Note: automate as much as possible so you can easily get fresh data.\n\nList the data you..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Appendix C. SVM Dual Problem To understand duality, you first need to understand the Lagrange multip..."
          ],
          [
           "2y, subject to an equality constraint: 3x + 2y + 1 = 0. Using the Lagrange multipliers method, we st..."
          ],
          [
           "called a Lagrange multiplier. Joseph-Louis Lagrange showed that if (x^,y^) is a solution to the cons..."
          ],
          [
           "regard to x, y, and α; we can find the points where these derivatives are all equal to zero; and the..."
          ],
          [
           "2\n\nx ^\n\n3\n\nα ^\n\n=\n\n2\n\n2\n\nα ^\n\n=\n\n3\n\nx ^\n\n2\n\nGet Hands-On Machine Learning with Scikit-Learn, Keras, ..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "The derivative of a constant is 0.\n\nThe derivative of λx is λ (where λ is a constant).\n\nThe derivati..."
          ],
          [
           "0\n\n=\n\nx 2\n\n+\n\n1\n\nThis approach can ...\n\nGet Hands-On Machine Learning with Scikit-Learn, Keras, and ..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "Hopfield Networks Hopfield networks were first introduced by W. A. Little in 1974, then popularized ..."
          ],
          [
           "logo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJ..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Strings Tensors can hold byte strings, which is useful in particular for natural language processing..."
          ],
          [
           "The tf.strings package contains several functions to manipulate string tensors, such as length() to ..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "TF Functions and Concrete Functions TF Functions are polymorphic, meaning they support inputs of dif..."
          ],
          [
           "Such a combination of argument types and shapes is called an input signature. If you call the TF Fun..."
          ],
          [
           "But it will generate a new concrete function if you call tf_cube(tf.constant([2.0])) or tf_cube(tf.c..."
          ],
          [
           "method. It can then be called like a regular function, but it will only support one input signature ..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\HandsOnML-Geron.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\HandsOnML-Geron.txt, circle",
         "marker": {
          "color": "#00cc96",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\HandsOnML-Geron.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          9.452413,
          8.26465,
          8.254679,
          5.769631,
          5.474367,
          7.036949,
          6.949524,
          7.1660995,
          6.9197965,
          6.651284,
          6.657452,
          6.531563,
          6.525899,
          6.6135325,
          6.7430215,
          6.5310526,
          7.0742245,
          6.585272,
          7.0844836,
          6.960207,
          7.005075,
          6.266415,
          6.6156583,
          4.4142227,
          4.2051635,
          4.132354,
          3.287036,
          4.2883067,
          7.6148715,
          6.284949,
          5.3738556,
          6.2457576,
          6.7202625,
          6.6495304,
          5.655266,
          5.102933,
          5.0261,
          5.6628785,
          5.7787285,
          5.4358435,
          5.6957965,
          5.943915,
          5.6186585,
          7.7115073,
          7.6355605,
          5.670427,
          10.017788,
          14.123176,
          9.536347,
          7.1499324,
          14.785868,
          9.464521,
          7.942484,
          8.466179,
          14.227192,
          9.39878,
          7.709532,
          5.227064,
          4.593051,
          3.886767,
          4.71919,
          4.270265,
          4.211853,
          3.807861,
          3.8205388,
          -9.377196,
          4.30414,
          3.628707,
          3.9984272,
          3.5237658,
          -5.1882787,
          4.127225,
          4.978967,
          5.1670117,
          5.1876683,
          5.1175127,
          4.633578,
          4.705587,
          4.841312,
          5.1887474,
          5.2062106,
          5.1527023,
          5.0927753,
          5.188246,
          4.6237707,
          5.159519,
          5.062439,
          4.6085825,
          3.6271744,
          3.244701,
          4.079579,
          3.8265638,
          3.4082665,
          3.5788684,
          3.425195,
          5.098783,
          4.908926,
          5.0493536,
          5.0352182,
          4.462593,
          5.207597,
          5.138284,
          5.1056356,
          4.8075876,
          5.1339393,
          5.1580644,
          1.2635093,
          2.5428057,
          2.624976,
          3.2129517,
          5.0065374,
          2.5833325,
          2.2516408,
          2.2929008,
          2.3167224,
          2.203635,
          2.515521,
          2.5233722,
          1.7778134,
          2.375206,
          5.203763,
          5.395283,
          4.842462,
          5.1152887,
          14.359266,
          8.829683,
          1.0890862,
          13.701275,
          9.634944,
          7.1544614,
          9.4744,
          13.77523,
          9.053676,
          9.3885,
          6.8178153,
          9.485879,
          6.8203263,
          9.55381,
          14.1576,
          8.248771,
          13.790426,
          8.249848,
          13.768912,
          8.274891,
          8.733649,
          14.188652,
          7.330923,
          5.9604044,
          14.160506,
          8.271701,
          8.971084,
          8.169536,
          9.675538,
          13.857526,
          7.817979,
          9.681589,
          14.142386,
          7.705527,
          13.828812,
          8.15066,
          8.734722,
          14.078193,
          7.435153,
          9.394651,
          13.855567,
          7.13869,
          13.800383,
          7.9451756,
          9.765244,
          14.14309,
          2.8472826,
          4.194811,
          4.442481,
          4.526745,
          7.8985167,
          14.159376,
          8.461293,
          4.360077,
          9.539281,
          14.112106,
          8.356737,
          8.1599245,
          13.965382,
          8.430886,
          -1.459807,
          -1.2024817,
          14.182523,
          9.106537,
          -1.2292417,
          -1.3385468,
          -1.4374359,
          -1.3540857,
          13.551042
         ],
         "xaxis": "x",
         "y": [
          -3.9983273,
          -2.1186562,
          -2.1248887,
          -3.3344047,
          -3.751438,
          -2.4076612,
          -2.5159285,
          -2.630597,
          -2.8045406,
          -2.203994,
          -2.402567,
          -1.8408822,
          -1.7210586,
          -1.3837655,
          -1.487113,
          -1.7291367,
          -2.58082,
          -2.4144669,
          -1.7924857,
          -1.7585406,
          -0.8612191,
          -2.8973687,
          0.34613532,
          3.6005528,
          4.5182853,
          3.6175332,
          4.0000887,
          3.5131557,
          -2.1334717,
          0.7273961,
          2.4294333,
          0.43114692,
          -0.29285455,
          -0.007185752,
          2.6024365,
          3.570348,
          4.331554,
          3.4289474,
          3.2602243,
          3.6327398,
          3.508715,
          3.3446548,
          3.272888,
          -1.8882473,
          -2.3043327,
          1.8473828,
          -2.697382,
          -3.8649163,
          -2.939244,
          -0.6732345,
          -3.4983902,
          -4.048952,
          -1.7379518,
          -2.077148,
          -5.3188534,
          -4.1036987,
          -2.0563548,
          4.561209,
          4.538404,
          5.0605626,
          5.1698194,
          5.3856544,
          5.548754,
          4.983215,
          4.957864,
          5.7395396,
          4.4259777,
          4.3182883,
          5.37304,
          5.5003767,
          -6.364432,
          5.5708294,
          5.3428597,
          5.928908,
          5.379611,
          5.8804884,
          5.611649,
          5.687706,
          5.800038,
          5.9076567,
          5.9558935,
          6.0149727,
          5.981911,
          5.9947286,
          5.3603334,
          5.9531054,
          5.4451804,
          4.6768103,
          4.1300397,
          3.6442506,
          4.4297013,
          4.953644,
          4.629382,
          5.109465,
          5.061693,
          4.172648,
          4.548061,
          4.77824,
          4.8207617,
          5.109295,
          4.783521,
          4.7450495,
          4.926193,
          5.4530354,
          4.7520094,
          5.314513,
          6.24162,
          4.9778924,
          5.0071263,
          5.1533937,
          5.852809,
          4.776511,
          4.895313,
          5.0291185,
          4.901376,
          4.8406005,
          5.134643,
          5.0615654,
          4.218734,
          4.9405904,
          5.249948,
          4.6692123,
          5.3541265,
          5.9364266,
          -3.4872894,
          -1.3086993,
          5.5553513,
          -3.6619987,
          -3.9303782,
          3.8764153,
          -3.9156382,
          -4.9054465,
          -0.98707867,
          -4.111239,
          -1.5430816,
          -4.1464863,
          -1.8217391,
          -3.0416033,
          -5.216886,
          -3.9310849,
          -4.920374,
          -3.7103858,
          -5.00224,
          -3.6395235,
          -4.0028224,
          -5.2458506,
          -2.4667647,
          -2.2593281,
          -5.1800456,
          -3.9203815,
          -4.0816603,
          -3.9873574,
          -3.5148017,
          -5.0230203,
          -3.7786064,
          -3.3646977,
          -5.1112614,
          -2.782141,
          -5.1192384,
          -3.572917,
          -3.7449625,
          -5.20838,
          -1.9747438,
          -3.262245,
          -4.9988966,
          -2.1592112,
          -4.9238644,
          -2.1328442,
          -3.039357,
          -5.3119917,
          5.5904193,
          5.672967,
          5.688885,
          5.6788416,
          -2.9805572,
          -5.272223,
          -3.7997785,
          5.5393653,
          -3.5455074,
          -5.197468,
          -4.0626655,
          -3.7528055,
          -3.25672,
          -3.8488333,
          -6.2327065,
          -6.1912985,
          -5.194829,
          -4.161157,
          -6.3553214,
          -6.1050634,
          -6.22413,
          -6.4023123,
          -4.1105413
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "1. Introduction - Introduction to Machine Learning with Python [Book]\n\nSkip to main content\n\nSign In..."
          ],
          [
           "Outside of commercial applications, machine learning has had a tremendous influence on the way data-..."
          ],
          [
           "Designing rules requires a deep understanding of how a decision should be made by a human expert.\n\nO..."
          ],
          [
           "1.1.1 Problems Machine Learning Can Solve\n\nThe most successful kinds of machine learning algorithms ..."
          ],
          [
           "Determining whether a tumor is benign based on a medical image\n\nHere the input is the image, and the..."
          ],
          [
           "An interesting thing to note about these examples is that although the inputs and outputs look fairl..."
          ],
          [
           "Detecting abnormal access patterns to a website\n\nTo identify abuse or bugs, it is often helpful to f..."
          ],
          [
           "Each entity or row here is known as a sample (or data point) in machine learning, while the columns—..."
          ],
          [
           "What is the best way to phrase my question(s) as a machine learning problem?\n\nHave I collected enoug..."
          ],
          [
           "1.2 Why Python?\n\nPython has become the lingua franca for many data science applications. It combines..."
          ],
          [
           "1.3 scikit-learn scikit-learn is an open source project, meaning that it is free to use and distribu..."
          ],
          [
           "Anaconda\n\nA Python distribution made for large-scale data processing, predictive analytics, and scie..."
          ],
          [
           "1.4 Essential Libraries and Tools\n\nUnderstanding what scikit-learn is and how to use it is important..."
          ],
          [
           "1.4.2 NumPy\n\nNumPy is one of the fundamental packages for scientific computing in Python. It contain..."
          ],
          [
           "1.4.3 SciPy\n\nSciPy is a collection of functions for scientific computing in Python. It provides, amo..."
          ],
          [
           "# Create a 2D NumPy array with a diagonal of ones, and zeros everywhere else eye = np.eye(4) print(\"..."
          ],
          [
           "the nonzero entries are stored sparse_matrix = sparse.csr_matrix(eye) print(\"\\nSciPy sparse CSR matr..."
          ],
          [
           "way to create the same sparse matrix as before, using the COO format: In[4]: data = np.ones(4) row_i..."
          ],
          [
           "1.4.4 matplotlib matplotlib is the primary scientific plotting library in Python. It provides functi..."
          ],
          [
           "Figure 1-1. Simple line plot of the sine function using matplotlib\n\n1.4.5 pandas pandas is a Python ..."
          ],
          [
           "data_pandas = pd.DataFrame(data) # IPython.display allows \"pretty printing\" of dataframes # in the J..."
          ],
          [
           "London\n\nLinda\n\n1.4.6 mglearn\n\nThis book comes with accompanying code, which you can find on https://..."
          ],
          [
           "1.5 Python 2 Versus Python 3\n\nThere are two major versions of Python that are widely used at the mom..."
          ],
          [
           "import pandas as pd\n\nprint(\"pandas version:\", pd.__version__)\n\nimport matplotlib\n\nprint(\"matplotlib ..."
          ],
          [
           "import IPython\n\nprint(\"IPython version:\", IPython.__version__)\n\nimport sklearn print(\"scikit-learn v..."
          ],
          [
           "Now that we have everything set up, let’s dive into our first application of machine learning.\n\n1.7 ..."
          ],
          [
           "1.7.1 Meet the Data\n\nThe data we will use for this example is the Iris dataset, a classical dataset ..."
          ],
          [
           "Notes ---- Data Set Characteristics: :Number of Instances: 150 (50 in each of three classes) :Number..."
          ],
          [
           "We see that the array contains measurements for 150 different flowers. Remember that the individual ..."
          ],
          [
           "The target array contains the species of each of the flowers that were measured, also as a NumPy arr..."
          ],
          [
           "1.7.2 Measuring Success: Training and Testing Data\n\nWe want to build a machine learning model from t..."
          ],
          [
           "In scikit-learn, data is usually denoted with a capital X, while labels are denoted by a lowercase y..."
          ],
          [
           "To make sure that we will get the same output if we run the same function several times, we provide ..."
          ],
          [
           "One of the best ways to inspect data is to visualize it. One way to do this is by using a scatter pl..."
          ],
          [
           "The diagonal of this matrix is filled with histograms of each feature: In[23]: # create dataframe fr..."
          ],
          [
           "1.7.4 Building Your First Model: k-Nearest Neighbors\n\nNow we can start building the actual machine l..."
          ],
          [
           "The knn object encapsulates the algorithm that will be used to build the model from the training dat..."
          ],
          [
           "In the remainder of this book, we will not usually show the output of fit because it doesn’t contain..."
          ],
          [
           "1.7.5 Making Predictions\n\nWe can now make predictions using this model on new data for which we migh..."
          ],
          [
           "1.7.6 Evaluating the Model\n\nThis is where the test set that we created earlier comes in. This data w..."
          ],
          [
           "We can also use the score method of the knn object, which will compute the test set accuracy for us:..."
          ],
          [
           "1.8 Summary and Outlook\n\nLet’s summarize what we learned in this chapter. We started with a brief in..."
          ],
          [
           "We chose the k-nearest neighbors classification algorithm, which makes predictions for a new data po..."
          ],
          [
           "knn = KNeighborsClassifier(n_neighbors=1)\n\nknn.fit(X_train, y_train)\n\nprint(\"Test set score: {:.2f}\"..."
          ],
          [
           "Support\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAust..."
          ],
          [
           "For business\n\nFor government\n\nFor higher ed\n\nIndividuals\n\nFeatures\n\nAll features\n\nCourses\n\nCertifica..."
          ],
          [
           "2.1 Classification and Regression\n\nThere are two major types of supervised machine learning problems..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Answers\n\nInsights reporting\n\nBlog\n\nContent sponsorship\n\nIntroduction to Machine Learning with Python..."
          ],
          [
           "3.1 Types of Unsupervised Learning We will look into two kinds of unsupervised learning in this chap..."
          ],
          [
           "Contact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & N..."
          ],
          [
           "For business\n\nFor government\n\nFor higher ed\n\nIndividuals\n\nFeatures\n\nAll features\n\nCourses\n\nCertifica..."
          ],
          [
           "Start your free trial\n\nChapter 4. Representing Data and Engineering Features\n\nSo far, we’ve assumed ..."
          ],
          [
           "The question of how to represent your data best for a particular application is known as feature eng..."
          ],
          [
           "clerical\n\n<=50K\n\n1\n\n50\n\nSelf\n\nemp\n\nnot\n\ninc\n\nBachelors\n\nMale\n\n13\n\nExec\n\nmanagerial\n\n<=50K\n\n2\n\n38\n\nPr..."
          ],
          [
           "emp\n\nnot\n\ninc\n\nHS\n\ngrad\n\nMale\n\n45\n\nExec\n\nmanagerial\n\n>50K\n\n8\n\n31\n\nPrivate\n\nMasters\n\nFemale\n\n50\n\nProf..."
          ],
          [
           "Some\n\ncollege\n\nMale\n\n80\n\nExec\n\nmanagerial\n\n>50K\n\nThe task is phrased as a classification task with t..."
          ],
          [
           "4.1.1 One\n\nHot\n\nEncoding (Dummy Variables)\n\nBy far the most common way to represent categorical vari..."
          ],
          [
           "Self Employed\n\nSelf Employed Incorporated\n\nGovernment Employee\n\n1\n\n0\n\n0\n\n0\n\nPrivate Employee\n\n0\n\n1\n\n..."
          ],
          [
           "There are two ways to convert your data to a one-hot encoding of categorical variables, using either..."
          ],
          [
           "education\n\ngender\n\nhours\n\nper\n\nweek\n\noccupation\n\nincome\n\n0\n\n39\n\nState\n\ngov\n\nBachelors\n\nMale\n\n40\n\nAdm..."
          ],
          [
           "40\n\nProf\n\nspecialty\n\n<=50K\n\nChecking string\n\nencoded categorical data\n\nAfter reading a dataset like ..."
          ],
          [
           "The get_dummies function automatically transforms all columns that have object type (like strings) o..."
          ],
          [
           "Features after get_dummies: ['age', 'hours-per-week', 'workclass_ ? ', 'workclass_ Federal-gov', 'wo..."
          ],
          [
           "workclass_ Federal\n\ngov\n\nworkclass_\n\nLocal\n\ngov\n\n…\n\noccupation_ Tech\n\nsupport\n\noccupation_\n\nTranspor..."
          ],
          [
           "1.0\n\n0.0\n\n4\n\n28\n\n40\n\n0.0\n\n0.0\n\n0.0\n\n…\n\n0.0\n\n0.0\n\n1.0\n\n0.0\n\n5 rows × 46 columns We can now use the va..."
          ],
          [
           "In this case, we extract only the columns containing features—that is, all columns from age to occup..."
          ],
          [
           "In this example, we called get_dummies on a DataFrame containing both the training and the test data..."
          ],
          [
           "4.1.2 Numbers Can Encode Categoricals\n\nIn the example of the adult dataset, the categorical variable..."
          ],
          [
           "The get_dummies function in pandas treats all numbers as continuous and will not create dummy variab..."
          ],
          [
           "Categorical Feature_socks\n\n0\n\n0\n\n0.0\n\n0.0\n\n1.0\n\n1\n\n1\n\n0.0\n\n1.0\n\n0.0\n\n2\n\n2\n\n0.0\n\n0.0\n\n1.0\n\n3\n\n1\n\n1.0\n..."
          ],
          [
           "0.0\n\n0.0\n\n0.0\n\n0.0\n\n1.0\n\n1\n\n0.0\n\n1.0\n\n0.0\n\n0.0\n\n1.0\n\n0.0\n\n2\n\n0.0\n\n0.0\n\n1.0\n\n0.0\n\n0.0\n\n1.0\n\n3\n\n0.0\n\n1..."
          ],
          [
           "4.2 OneHotEncoder and ColumnTransformer: Categorical Variables with scikit-learn As mentioned before..."
          ],
          [
           "# Setting sparse=False means OneHotEncode will return a numpy array, # not a sparse matrix ohe = One..."
          ],
          [
           "transformed. As usual for scikit-learn, the output is not a DataFrame, so there are no column names...."
          ],
          [
           "and 2 of the first original feature (called x0 here), while the last three columns correspond to the..."
          ],
          [
           "This is where the ColumnTransformer class comes in handy: it allows you to apply different transform..."
          ],
          [
           "Out[12]: [cols=\",,,,,,,\",options=\"header\",] |=======================================================..."
          ],
          [
           "|53 |Private |11th |Male |40 |Handlers-cleaners |<=50K |4 |28 |Private |Bachelors |Female |40 |Prof-..."
          ],
          [
           "age and hours-per-week. This is exactly what ColumnTransformer can do for us. Each transformation in..."
          ],
          [
           "Each transformer is applied to the corresponding columns, and the result of the transformations are ..."
          ],
          [
           "ct.fit(X_train) X_train_trans = ct.transform(X_train) print(X_train_trans.shape) Out[14]: (24420, 44..."
          ],
          [
           "4.3 Convenient ColumnTransformer creation with make_columntransformer Creating a ColumnTransformer u..."
          ],
          [
           "4.4 Binning, Discretization, Linear Models, and Trees\n\nThe best way to represent data depends not on..."
          ],
          [
           "plt.plot(line, reg.predict(line), label=\"linear regression\")\n\nplt.plot(X[:, 0], y, 'o', c='k') plt.y..."
          ],
          [
           "We imagine a partition of the input range for the feature (in this case, the numbers from –3 to 3) i..."
          ],
          [
           "of the data (i.e., having smaller bins where there’s more data). Both of these strategies are implem..."
          ],
          [
           "1.155, 1.744,  2.333,  2.921])] Here, the first bin contains all data points with feature values fro..."
          ],
          [
           "per feature. This is why they are a list of length one in this case. Using transform, we can encode ..."
          ],
          [
           "In[21]: X_binned = kb.transform(X) X_binned Out[21]: <120x10 sparse matrix of type '<class 'numpy.fl..."
          ],
          [
           "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0. ], [0., 0., 0., 0., 0., 0., 0., 0., 0., 1. ], [0., 0...."
          ],
          [
           "0., 0., 0., 0., 0. ], [0., 1., 0., 0., 0., 0., 0., 0., 0., 0. ], [1., 0., 0., 0., 0., 0., 0., 0., 0...."
          ],
          [
           "[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]) We can see that the first data point with value -0.753 wa..."
          ],
          [
           "categorical feature which encodes which bin a data point is in. You can forego the one-hot-encoding ..."
          ],
          [
           "= kb.transform(X) Now we build a new linear regression model and a new decision tree model on the on..."
          ],
          [
           "reg = LinearRegression().fit(X_binned, y) plt.plot(line, reg.predict(line_binned), label='linear reg..."
          ],
          [
           "reg = DecisionTreeRegressor(min_samples_split=3).fit(X_binned, y) plt.plot(line, reg.predict(line_bi..."
          ],
          [
           "If there are good reasons to use a linear model for a particular dataset—say, because it is very lar..."
          ],
          [
           "plt.vlines(kb.bin_edges_[0], -3, 3, linewidth=1, alpha=.2) plt.legend(loc=\"best\") plt.ylabel(\"Regres..."
          ],
          [
           "Figure 4-3. Linear regression using binned features and a single global slope\n\nIn this example, the ..."
          ],
          [
           "plt.vlines(kb.bin_edges_[0],\n\n3, 3, linewidth=1, alpha=.2)\n\nplt.plot(X[:, 0], y, 'o', c='k') plt.yla..."
          ],
          [
           "# include polynomials up to x ** 10: # the default \"include_bias=True\" adds a feature that's constan..."
          ],
          [
           "20918.278] [    1.392     1.938     2.697     3.754     5.226     7.274    10.125 14.094    19.618  ..."
          ],
          [
           "line_poly = poly.transform(line) plt.plot(line, reg.predict(line_poly), label='polynomial linear reg..."
          ],
          [
           "Figure 4-6. Comparison of different gamma parameters for an SVM with RBF kernel\n\nUsing a more comple..."
          ],
          [
           "# rescale data scaler = MinMaxScaler() X_train_scaled = scaler.fit_transform(X_train) X_test_scaled ..."
          ],
          [
           "The exact correspondence between input and output features can be found using the get_feature_names ..."
          ],
          [
           "'x0 x5', 'x0 x6', 'x0 x7', 'x0 x8', 'x0 x9', 'x0 x10', 'x0 x11', 'x0 x12', 'x1^2', 'x1 x2', 'x1 x3',..."
          ],
          [
           "x5', 'x2 x6', 'x2 x7', 'x2 x8', 'x2 x9', 'x2 x10', 'x2 x11', 'x2 x12', 'x3^2', 'x3 x4', 'x3 x5', 'x3..."
          ],
          [
           "'x4 x10', 'x4 x11', 'x4 x12', 'x5^2', 'x5 x6', 'x5 x7', 'x5 x8', 'x5 x9', 'x5 x10', 'x5 x11', 'x5 x1..."
          ],
          [
           "'x8^2', 'x8 x9', 'x8 x10', 'x8 x11', 'x8 x12', 'x9^2', 'x9 x10', 'x9 x11', 'x9 x12', 'x10^2', 'x10 x..."
          ],
          [
           "first feature squared (\"x0^2\") and combinations of the first and the other features...."
          ],
          [
           "Let’s compare the performance using Ridge on the data with and without interactions: In[38]: from sk..."
          ],
          [
           "Clearly, the interactions and polynomial features gave us a good boost in performance when using Rid..."
          ],
          [
           "4.6 Univariate Nonlinear Transformations\n\nWe just saw that adding squared or cubed features can help..."
          ],
          [
           "X = rnd.poisson(10 * np.exp(X_org)) y = np.dot(X_org, w) Let’s look at the first 10 entries of the f..."
          ],
          [
           "0]))) Out[41]: Number of feature appearances: [28 38 68 48 61 59 45 56 37 40 35 34 36 26 23 26 27 21..."
          ],
          [
           "2  5  2  1 2  3  3  2  2  3  3  0  1  2  1  0  0  3  1  0  0  0  1  3  0  1  0  2  0 1  1  0  0  0  ..."
          ],
          [
           "2  0  1  1  0  0  0  0  1  1  0  0  0  0  0 0  0  1  0  0  0  0  0  1  1  0  0  1  0  0  0  0  0  0 ..."
          ],
          [
           "0 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1] The value 2 seems to be the most common, with 68 a..."
          ],
          [
           "are appearing twice. We visualize the counts in Figure 4-7: In[42]: bins = np.bincount(X[:, 0]) plt...."
          ],
          [
           "Figure 4-7. Histogram of feature values for X[0]..."
          ],
          [
           "Features X[:, 1] and X[:, 2] have similar properties. This kind of distribution of values (many smal..."
          ],
          [
           "train_test_split(X, y, random_state=0) score = Ridge().fit(X_train, y_train).score(X_test, y_test) p..."
          ],
          [
           "logarithm is not defined at 0), we can’t actually just apply log, but we have to compute log(X + 1):..."
          ],
          [
           "color='gray') plt.ylabel(\"Number of appearances\") plt.xlabel(\"Value\")..."
          ],
          [
           "Figure 4-8. Histogram of feature values for X[0] after logarithmic transformation\n\nBuilding a ridge ..."
          ],
          [
           "4.7 Automatic Feature Selection\n\nWith so many ways to create new features, you might get tempted to ..."
          ],
          [
           "To use univariate feature selection in scikit-learn, you need to choose a test, usually either f_cla..."
          ],
          [
           "X_train, X_test, y_train, y_test = train_test_split( X_w_noise, cancer.target, random_state=0, test_..."
          ],
          [
           "X_train.shape: (284, 80)\n\nX_train_selected.shape: (284, 40)\n\nAs you can see, the number of features ..."
          ],
          [
           "# transform test data\n\nX_test_selected = select.transform(X_test)\n\nlr = LogisticRegression() lr.fit(..."
          ],
          [
           "4.7.2 Model\n\nBased Feature Selection\n\nModel-based feature selection uses a supervised machine learni..."
          ],
          [
           "To use model-based feature selection, we need to use the SelectFromModel transformer: In[50]: from s..."
          ],
          [
           "result to what we got with univariate feature selection, we used the median as a threshold, so that ..."
          ],
          [
           "X_train_l1 = select.transform(X_train) print(\"X_train.shape: {}\".format(X_train.shape)) print(\"X_tra..."
          ],
          [
           "Figure 4-10. Features selected by SelectFromModel using the RandomForestClassifier\n\nThis time, all b..."
          ],
          [
           "4.7.3 Iterative Feature Selection\n\nIn univariate testing we used no model, while in model-based sele..."
          ],
          [
           "Figure 4-11. Features selected by recursive feature elimination with the random forest classifier mo..."
          ],
          [
           "score = LogisticRegression().fit(X_train_rfe, y_train).score(X_test_rfe, y_test) print(\"Test score: ..."
          ],
          [
           "4.8 Utilizing Expert Knowledge\n\nFeature engineering is often an important place to use expert knowle..."
          ],
          [
           "Adding a feature does not force a machine learning algorithm to use it, and even if the holiday info..."
          ],
          [
           "We resample the data into three-hour intervals to obtain the main trends for each day: In[57]: citib..."
          ],
          [
           "Figure 4-12. Number of bike rentals over time for a selected Citi Bike station\n\nLooking at the data,..."
          ],
          [
           "A (surprisingly) common way that dates are stored on computers is using POSIX time, which is the num..."
          ],
          [
           "plt.xticks(range(0, len(X), 8), xticks.strftime(\"%a %m-%d\"), rotation=90, ha=\"left\")\n\nplt.plot(range..."
          ],
          [
           "Figure 4-13. Predictions made by a random forest using only the POSIX time\n\nThe predictions on the t..."
          ],
          [
           "Figure 4-14. Predictions made by a random forest using only the hour of the day\n\nThe R2 is already m..."
          ],
          [
           "Figure 4-16. Predictions made by linear regression using day of week and hour of day as features\n\nLi..."
          ],
          [
           "Using interaction features, we can allow the model to learn one coefficient for each combination of ..."
          ],
          [
           "This transformation finally yields a model that performs similarly well to the random forest. A big ..."
          ],
          [
           "Figure 4-19. Coefficients of the linear regression model using a product of hour and day\n\n4.9 Summar..."
          ],
          [
           "Close\n\n5. Model Evaluation and Improvement - Introduction to Machine Learning with Python [Book]\n\nSk..."
          ],
          [
           "To evaluate our supervised models, so far we have split our dataset into a training set and a test s..."
          ],
          [
           "Close\n\n6. Algorithm Chains and Pipelines - Introduction to Machine Learning with Python [Book]\n\nSkip..."
          ],
          [
           "As an example of the importance of chaining models, we noticed that we can greatly improve the perfo..."
          ],
          [
           "Privacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & T..."
          ],
          [
           "For higher ed\n\nIndividuals\n\nFeatures\n\nAll features\n\nCourses\n\nCertifications\n\nInteractive learning\n\nL..."
          ],
          [
           "Start your free trial\n\nChapter 7. Working with Text Data\n\nIn Chapter 4, we talked about two kinds of..."
          ],
          [
           "Close\n\n8. Wrapping Up - Introduction to Machine Learning with Python [Book]\n\nSkip to main content\n\nS..."
          ],
          [
           "8.1 Approaching a Machine Learning Problem With all the great methods that we introduced in this boo..."
          ],
          [
           "Newsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\n..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\IntroToMLwithPython-MullerGuido.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\IntroToMLwithPython-MullerGuido.txt, circle",
         "marker": {
          "color": "#ab63fa",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\IntroToMLwithPython-MullerGuido.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          9.8186,
          8.415892,
          7.451424,
          6.870999,
          6.455871,
          6.642355,
          6.372021,
          6.1564217,
          8.0886345,
          -1.9025906,
          9.6626625,
          -2.1630871,
          9.861024,
          -3.388058,
          -3.8599348,
          -4.422069,
          -4.244637,
          -4.4655447,
          -8.119989,
          -8.299438,
          -2.1269963,
          -0.8103399,
          -2.48702,
          -8.93558,
          0.9536188,
          6.799785,
          0.91814315,
          0.9442417,
          0.6706135,
          0.8378857,
          1.1631914,
          1.3176987,
          1.4102954,
          0.74816245,
          0.8200584,
          1.1447067,
          1.383314,
          3.8693256,
          1.2805024,
          1.0964255,
          1.0587486,
          1.0153195,
          1.6154994,
          1.6419754,
          14.43593,
          8.320029,
          8.204737,
          13.033228,
          9.442693,
          6.765225,
          14.444718,
          10.535497,
          6.081703,
          3.9669135,
          3.1178775,
          3.093127,
          3.3873355,
          3.212722,
          3.2530975,
          3.1323562,
          3.1528444,
          3.3850954,
          3.0220528,
          3.077982,
          3.1112833,
          3.0139358,
          3.3429723,
          3.0787487,
          3.3767219,
          3.049908,
          3.068545,
          -4.722898,
          3.0298674,
          2.811475,
          3.1050997,
          2.9078846,
          3.1521606,
          3.0680413,
          3.22028,
          3.1346116,
          3.2692437,
          3.2022347,
          3.0509117,
          3.1444356,
          2.8730786,
          2.6840353,
          2.6179104,
          2.4377499,
          2.5691411,
          2.414469,
          -4.6852,
          -4.666914,
          2.6405413,
          2.4973724,
          2.7971692,
          2.6770158,
          2.7052667,
          2.9808853,
          2.728352,
          2.7445807,
          2.7626276,
          3.1944551,
          3.1614254,
          3.511162,
          3.288837,
          3.1675303,
          3.2420073,
          -4.652386,
          -4.654323,
          -4.6620183,
          3.1316543,
          3.2348247,
          3.9023037,
          4.2448916,
          3.306923,
          -4.8467317,
          -4.4413424,
          -4.652785,
          -4.6784163,
          -4.705902,
          -5.46225,
          1.9264493,
          4.1721044,
          3.0397701,
          -5.0563498,
          -8.8855295,
          3.55374,
          6.5304832,
          3.883598,
          2.7882144,
          3.6446104,
          3.9476008,
          4.353082,
          4.193271,
          3.9103255,
          2.014975,
          3.9441764,
          4.158169,
          4.2485323,
          4.3454757,
          6.295637,
          6.3531737,
          -11.326978,
          5.524006,
          5.3253136,
          5.2991934,
          5.192255,
          5.386969,
          5.5098386,
          5.4583554,
          5.1389685,
          6.105691,
          9.780618,
          2.0606604,
          10.0886965,
          1.698341,
          14.026779,
          10.799391,
          6.320142,
          10.121653,
          8.633591,
          14.455765
         ],
         "xaxis": "x",
         "y": [
          -2.2873397,
          -1.9121528,
          -1.4509345,
          -2.5898724,
          -1.6497902,
          -1.6662617,
          -1.4116247,
          -1.6855257,
          -2.119949,
          -8.95028,
          -2.1264415,
          -8.656511,
          -2.0555167,
          -6.6514664,
          -6.836357,
          -6.398862,
          -6.5793433,
          -6.530103,
          6.0744724,
          4.757757,
          -7.386101,
          6.388796,
          -8.390104,
          5.8017316,
          3.245403,
          -1.9479878,
          3.1953745,
          3.262437,
          3.0720682,
          3.2241647,
          3.5124025,
          3.3438911,
          3.4620333,
          3.4510517,
          3.8122888,
          3.9033077,
          4.1739044,
          4.442913,
          3.669704,
          3.464638,
          3.4696212,
          3.3701031,
          3.7123232,
          3.7086627,
          -3.4603164,
          -2.036193,
          -1.8275778,
          -3.919806,
          -2.275998,
          -1.6769811,
          -3.4702451,
          -2.7949808,
          -1.023664,
          -0.68650836,
          -0.81853795,
          -0.8125339,
          -0.5522703,
          -0.39482263,
          -0.66761667,
          -0.5479025,
          -0.7976322,
          -0.87141824,
          -0.185934,
          -0.40802437,
          -0.7377719,
          -0.46011108,
          2.9272168,
          -0.35038304,
          -0.57903475,
          -0.3300494,
          -0.45306742,
          1.785922,
          0.025986146,
          0.5176392,
          0.57606137,
          0.37071985,
          -0.41381958,
          -0.81316775,
          -0.67974716,
          -0.536156,
          0.82305723,
          1.539816,
          0.15059586,
          2.1617281,
          2.3220282,
          1.7704921,
          1.4849424,
          1.5843762,
          1.0501177,
          0.8817169,
          1.7939866,
          1.7786782,
          1.6246202,
          1.0377929,
          1.5408285,
          2.136831,
          2.0474668,
          2.1555684,
          2.0501368,
          1.875294,
          1.9667397,
          3.5607069,
          3.5916862,
          4.317897,
          4.062209,
          3.279141,
          3.2574744,
          1.8439407,
          1.8583298,
          1.7960658,
          3.1308525,
          3.0808897,
          3.2449312,
          2.7904258,
          2.3426402,
          3.6272995,
          2.4904878,
          1.7672935,
          1.8050325,
          2.1459324,
          3.7730963,
          2.4305983,
          3.206256,
          3.399045,
          3.9939604,
          5.670876,
          2.3510242,
          -0.5088644,
          2.2805157,
          2.8514938,
          2.4481409,
          2.1831238,
          2.1730855,
          2.1913066,
          2.1165018,
          3.0948045,
          2.168104,
          2.03206,
          1.9842342,
          2.1715813,
          -0.33806202,
          -0.0024932409,
          3.5101776,
          1.108997,
          1.312004,
          1.8015151,
          1.5392933,
          1.2240086,
          1.1109426,
          1.1661011,
          1.4783776,
          0.45579514,
          -1.9385186,
          3.8206816,
          -1.2697213,
          5.0826383,
          -3.6639755,
          -2.729539,
          -1.9101999,
          -2.2638175,
          -2.1981664,
          -3.456115
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Archives | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAbout\n\nArchive\n\nArchives and ..."
          ],
          [
           "4. Visualization with Matplotlib¶ Simple Line Plots Simple Scatter Plots Visualizing Errors Density ..."
          ],
          [
           "Preface\n\n| Contents | IPython: Beyond Normal Python >\n\nWhat Is Data Science?¶This is a book about do..."
          ],
          [
           "data\n\nscience\n\nvenn\n\ndiagram). Used by permission.)\n\nWhile some of the intersection labels are a bit..."
          ],
          [
           "Who Is This Book For?¶In my teaching both at the University of Washington and at various tech-focuse..."
          ],
          [
           "Why Python?¶Python has emerged over the last couple decades as a first-class tool for scientific com..."
          ],
          [
           "Python 2 vs Python 3¶This book uses the syntax of Python 3, which contains language enhancements tha..."
          ],
          [
           "The PyData world is certainly much larger than these five packages, and is growing every day. With t..."
          ],
          [
           "If you feel your use of code examples falls outside fair use or the per‐ mission given above, feel f..."
          ],
          [
           "Any of the packages included with Anaconda can also be installed manually on top of Miniconda; for t..."
          ],
          [
           "2. Introduction to NumPy¶ Understanding Data Types in Python The Basics of NumPy Arrays Computation ..."
          ],
          [
           "Appendix: Figure Code¶\n\nIPython: Beyond Normal Python | Python Data Science Handbook\n\nPython Data Sc..."
          ],
          [
           "IPython: Beyond Normal Python\n\n< Preface | Contents | Help and Documentation in IPython >\n\nThere are..."
          ],
          [
           "This chapter will start by stepping through some of the IPython features that are useful to the prac..."
          ],
          [
           "Launching the IPython Shell¶This chapter, like most of this book, is not designed to be absorbed pas..."
          ],
          [
           "Launching the Jupyter Notebook¶The Jupyter notebook is a browser-based graphical interface to the IP..."
          ],
          [
           "< Preface | Contents | Help and Documentation in IPython >\n\nPython Data Science Handbook | Python Da..."
          ],
          [
           "4. Visualization with Matplotlib¶ Simple Line Plots Simple Scatter Plots Visualizing Errors Density ..."
          ],
          [
           "Help and Documentation in IPython\n\n< IPython: Beyond Normal Python | Contents | Keyboard Shortcuts i..."
          ],
          [
           "Here we'll discuss IPython's tools to quickly access this information, namely the ? character to exp..."
          ],
          [
           "Return the number of items of a sequence or mapping.\n\nThis notation works for just about anything, i..."
          ],
          [
           "This quick access to documentation via docstrings is one reason you should get in the habit of alway..."
          ],
          [
           "Using ? and/or ? ? gives a powerful and quick interface for finding information about what any Pytho..."
          ],
          [
           "Though Python has no strictly-enforced distinction between public/external attributes and private/in..."
          ],
          [
           "Beyond tab completion: wildcard matching¶Tab completion is useful if you know the first few characte..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "Keyboard Shortcuts in the IPython Shell\n\n< Help and Documentation in IPython | Contents | IPython Ma..."
          ],
          [
           "Navigation shortcuts¶While the use of the left and right arrow keys to move backward and forward in ..."
          ],
          [
           "Ctrl-t Transpose (i.e., switch) previous two characters\n\nCommand History Shortcuts¶Perhaps the most ..."
          ],
          [
           "At any point, you can add more characters to refine the search, or press Ctrl-r again to search furt..."
          ],
          [
           "Ctrl\n\nc\n\nInterrupt current Python command\n\nCtrl\n\nd\n\nExit IPython session\n\nThe Ctrl-c in particular c..."
          ],
          [
           "IPython Magic Commands\n\n< Keyboard Shortcuts in the IPython Shell | Contents | Input and Output Hist..."
          ],
          [
           "The code is formatted as it would appear in the Python interpreter, and if you copy and paste this d..."
          ],
          [
           "These magic commands, like others we'll see, make available functionality that would be difficult or..."
          ],
          [
           "There are several options to fine-tune how your code is run; you can see the documentation in the no..."
          ],
          [
           "Help on Magic Functions: ?, %magic, and %lsmagic¶Like normal Python functions, IPython magic functio..."
          ],
          [
           "Input and Output History\n\n< IPython Magic Commands | Contents | IPython and Shell Commands >\n\nPrevio..."
          ],
          [
           "Out[3]:\n\n0.4161468365471424\n\nWe've imported the built-in math package, then computed the sine and th..."
          ],
          [
           "Note that not all operations have outputs: for example, import statements and print statements don't..."
          ],
          [
           "In [11]: print(___)\n\n0.9092974268256817\n\nIPython stops there: more than three underscores starts to ..."
          ],
          [
           "Related Magic Commands¶For accessing a batch of previous inputs at once, the %history magic command ..."
          ],
          [
           "IPython and Shell Commands\n\n< Input and Output History | Contents | Errors and Debugging >\n\nWhen wor..."
          ],
          [
           "Quick Introduction to the Shell¶A full intro to using the shell/terminal/command-line is well beyond..."
          ],
          [
           "osx:~ $ pwd                            # pwd = print working directory /home/jake                   ..."
          ],
          [
           "Shell Commands in IPython¶Any command that works at the command-line can be used in IPython by prefi..."
          ],
          [
           "Communication in the other direction–passing Python variables into the shell–is possible using the {..."
          ],
          [
           "In fact, by default you can even use this without the % sign: In [15]: cd myproject /home/jake/proje..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "1\n\nreturn func1(a, b)\n\nIn [2]:\n\nfunc2(1)\n\n----------------------------------------------------------..."
          ],
          [
           "ZeroDivisionError: division by zero\n\nCalling func2 results in an error, and reading the printed trac..."
          ],
          [
           "In [5]:\n\n%xmode Verbose\n\nException reporting mode: Verbose\n\nIn [6]:\n\nfunc2(1)\n\n---------------------..."
          ],
          [
           "ZeroDivisionError: division by zero\n\nThis extra information can help narrow-in on why the exception ..."
          ],
          [
           "ipdb> print(a)\n\n1\n\nipdb> print(b)\n\n0\n\nipdb> quit\n\nThe interactive debugger allows much more than thi..."
          ],
          [
           "ipdb> quit\n\nThis allows you to quickly find out not only what caused the error, but what function ca..."
          ],
          [
           "ipdb> print(b)\n\n0\n\nipdb> quit\n\nFinally, if you have a script that you'd like to run from the beginni..."
          ],
          [
           "Profiling and Timing Code | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAbout\n\nArchi..."
          ],
          [
           "%time: Time the execution of a single statement %timeit: Time repeated execution of a single stateme..."
          ],
          [
           "total += i\n\n(\n\n1) *\n\nj\n\n1 loops, best of 3: 407 ms per loop\n\nSometimes repeating an operation is not..."
          ],
          [
           "In [5]:\n\nprint(\"sorting an already sorted list:\") %time L.sort()\n\nsorting an already sorted list: CP..."
          ],
          [
           "Profiling Full Scripts: %prun¶A program is made of many single statements, and sometimes timing thes..."
          ],
          [
           "Ordered by: internal time\n\nncalls  tottime  percall  cumtime  percall filename:lineno(function) 5   ..."
          ],
          [
           "Line-By-Line Profiling with %lprun¶The function-by-function profiling of %prun is useful, but someti..."
          ],
          [
           "Line #      Hits         Time  Per Hit   % Time  Line Contents =====================================..."
          ],
          [
           "In [12]:\n\n%load_ext memory_profiler\n\nThe memory profiler extension contains two useful magic functio..."
          ],
          [
           "In [15]:\n\nfrom mprun_demo import sum_of_lists\n\n%mprun\n\nf sum_of_lists sum_of_lists(1000000)\n\nThe res..."
          ],
          [
           "Filename: ./mprun_demo.py\n\nLine #    Mem usage    Increment   Line Contents ========================..."
          ],
          [
           "More IPython Resources | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAbout\n\nArchive\n..."
          ],
          [
           "Web Resources¶ The IPython website: The IPython website links to documentation, examples, tutorials,..."
          ],
          [
           "Finally, a reminder that you can find help on your own: IPython's ?-based help functionality (discus..."
          ],
          [
           "Introduction to NumPy\n\n< More IPython Resources | Contents | Understanding Data Types in Python >\n\nT..."
          ],
          [
           "NumPy (short for Numerical Python) provides an efficient interface to store and operate on dense dat..."
          ],
          [
           "Throughout this chapter, and indeed the rest of the book, you'll find that this is the way we will i..."
          ],
          [
           "Table of Contents¶Preface¶1. IPython: Beyond Normal Python¶ Help and Documentation in IPython Keyboa..."
          ],
          [
           "5. Machine Learning¶ What Is Machine Learning? Introducing Scikit-Learn Hyperparameters and Model Va..."
          ],
          [
           "Understanding Data Types in Python\n\n< Introduction to NumPy | Contents | The Basics of NumPy Arrays ..."
          ],
          [
           "This sort of flexibility is one piece that makes Python and other dynamically-typed languages conven..."
          ],
          [
           "This means that there is some overhead in storing an integer in Python as compared to an integer in ..."
          ],
          [
           "In [3]:\n\nL2 = [str(c) for c in L] L2\n\nOut[3]:\n\n['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n\nI..."
          ],
          [
           "At the implementation level, the array essentially contains a single pointer to one contiguous block..."
          ],
          [
           "In [7]:\n\nimport numpy as np\n\nCreating Arrays from Python Lists¶First, we can use np.array to create ..."
          ],
          [
           "In [11]:\n\n# nested lists result in multi-dimensional arrays np.array([range(i, i + 3) for i in [2, 4..."
          ],
          [
           "# Create a 3x5 array filled with 3.14 np.full((3, 5), 3.14)\n\nOut[14]:\n\narray([[ 3.14,  3.14,  3.14, ..."
          ],
          [
           "Out[17]:\n\narray([[ 0.99844933,  0.52183819,  0.22421193], [ 0.08007488,  0.45429293,  0.20941444], [..."
          ],
          [
           "In [20]:\n\n# Create a 3x3 identity matrix np.eye(3)\n\nOut[20]:\n\narray([[ 1.,  0.,  0. ], [ 0.,  1.,  0..."
          ],
          [
           "intp Integer used for indexing (same as C ssize_t; normally either int32 or int64)\n\nint8\n\nByte (\n\n12..."
          ],
          [
           "complex64 Complex number, represented by two 32-bit floats\n\ncomplex128 Complex number, represented b..."
          ],
          [
           "Attributes of arrays: Determining the size, shape, memory consumption, and data types of arrays Inde..."
          ],
          [
           "print(\"x3 shape:\", x3.shape)\n\nprint(\"x3 size: \", x3.size)\n\nx3 ndim:  3 x3 shape: (3, 4, 5) x3 size: ..."
          ],
          [
           "In [5]:\n\nx1\n\nOut[5]:\n\narray([5, 0, 3, 3, 7, 9])\n\nIn [6]:\n\nx1[0]\n\nOut[6]:\n\n5\n\nIn [7]:\n\nx1[4]\n\nOut[7]:..."
          ],
          [
           "Out[12]:\n\n1\n\nIn [13]:\n\nx2[2,\n\n1]\n\nOut[13]:\n\n7\n\nValues can also be modified using any of the above in..."
          ],
          [
           "If any of these are unspecified, they default to the values start=0, stop=size of dimension, step=1...."
          ],
          [
           "Out[21]:\n\narray([1, 3, 5, 7, 9])\n\nA potentially confusing case is when the step value is negative. I..."
          ],
          [
           "In [26]:\n\nx2[:3, ::2]  # all rows, every other column\n\nOut[26]:\n\narray([[12,  2],\n\n[ 7,  8],\n\n[ 1,  ..."
          ],
          [
           "print(x2[0])  # equivalent to x2[0, :]\n\n[12  5  2  4]\n\nSubarrays as no-copy views¶One important–and ..."
          ],
          [
           "print(x2)\n\n[[99  5  2  4] [ 7  6  8  8] [ 1  6  7  7]]\n\nThis default behavior is actually quite usef..."
          ],
          [
           "In [38]:\n\ngrid = np.arange(1, 10).reshape((3, 3)) print(grid)\n\n[[1 2 3]\n\n[4 5 6]\n\n[7 8 9]]\n\nNote tha..."
          ],
          [
           "Out[41]:\n\narray([[1],\n\n[2],\n\n[3]])\n\nIn [42]:\n\n# column vector via newaxis x[:, np.newaxis]\n\nOut[42]:..."
          ],
          [
           "You can also concatenate more than two arrays at once:\n\nIn [44]:\n\nz = [99, 99, 99] print(np.concaten..."
          ],
          [
           "In [48]:\n\nx = np.array([1, 2, 3]) grid = np.array([[9, 8, 7], [6, 5, 4]])\n\n# vertically stack the ar..."
          ],
          [
           "[1 2 3] [99 99] [3 2 1]\n\nNotice that N split-points, leads to N + 1 subarrays. The related functions..."
          ],
          [
           "Computation on NumPy Arrays: Universal Functions | Python Data Science Handbook\n\nPython Data Science..."
          ],
          [
           "The Slowness of Loops¶Python's default implementation (known as CPython) does some operations very s..."
          ],
          [
           "values = np.random.randint(1, 10, size=5) compute_reciprocals(values)\n\nOut[1]:\n\narray([ 0.16666667, ..."
          ],
          [
           "Introducing UFuncs¶For many types of operations, NumPy provides a convenient interface into just thi..."
          ],
          [
           "Out[5]:\n\narray([ 0.        ,  0.5       ,  0.66666667,  0.75      ,  0.8       ])\n\nAnd ufunc operati..."
          ],
          [
           "In [7]:\n\nx = np.arange(4) print(\"x     =\", x) print(\"x + 5 =\", x + 5) print(\"x - 5 =\", x - 5) print(..."
          ],
          [
           "(0.5\n\nx + 1)\n\n** 2\n\nOut[9]:\n\narray([\n\n1.  ,\n\n2.25,\n\n4.  ,\n\n6.25])\n\nEach of these arithmetic operatio..."
          ],
          [
           "np.power\n\nExponentiation (e.g., 2 *\n\n3 = 8)\n\n% np.mod Modulus/remainder (e.g., 9 % 4 = 1)\n\nAdditiona..."
          ],
          [
           "x = np.array([3 - 4j, 4 - 3j, 2 + 0j, 0 + 1j]) np.abs(x)\n\nOut[14]:\n\narray([ 5.,  5.,  2.,  1.])\n\nTri..."
          ],
          [
           "The values are computed to within machine precision, which is why values that should be zero do not ..."
          ],
          [
           "x     = [1, 2, 3] e^x   = [  2.71828183   7.3890561   20.08553692] 2^x   = [ 2. 4. 8.] 3^x   = [ 3  ..."
          ],
          [
           "There are also some specialized versions that are useful for maintaining precision with very small i..."
          ],
          [
           "In [21]:\n\nfrom scipy import special\n\nIn [22]:\n\n# Gamma functions (generalized factorials) and relate..."
          ],
          [
           "erf(x)  = [ 0. 0.32862676  0.67780119  0.84270079] erfc(x) = [ 1. 0.67137324  0.32219881  0.15729921..."
          ],
          [
           "This can even be used with array views. For example, we can write the results of a computation to ev..."
          ],
          [
           "15\n\nSimilarly, calling reduce on the multiply ufunc results in the product of all array elements:\n\nI..."
          ],
          [
           "x = np.arange(1, 6)\n\nnp.multiply.outer(x, x)\n\nOut[30]:\n\narray([[ 1,  2,  3,  4,  5], [ 2,  4,  6,  8..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "The syntax is quite similar to that of NumPy's sum function, and the result is the same in the simpl..."
          ],
          [
           "NumPy's corresponding functions have similar syntax, and again operate much more quickly:\n\nIn [6]:\n\n..."
          ],
          [
           "In [9]:\n\nM = np.random.random((3, 4))\n\nprint(M)\n\n[[ 0.8967576   0.03783739  0.75952519  0.06682827] ..."
          ],
          [
           "In [12]:\n\nM.max(axis=1)\n\nOut[12]:\n\narray([ 0.8967576 ,  0.99196818,  0.6687194 ])\n\nThe way the axis ..."
          ],
          [
           "Compute mean of elements\n\nnp.std\n\nnp.nanstd\n\nCompute standard deviation\n\nnp.var\n\nnp.nanvar\n\nCompute ..."
          ],
          [
           "order,name,height(cm)\n\n1,George Washington,189\n\n2,John Adams,170\n\n3,Thomas Jefferson,189\n\nWe'll use ..."
          ],
          [
           "In [16]:\n\nprint(\"25th percentile:   \", np.percentile(heights, 25)) print(\"Median:            \", np.m..."
          ],
          [
           "Computation on Arrays: Broadcasting | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAb..."
          ],
          [
           "Out[2]:\n\narray([5, 6, 7])\n\nBroadcasting allows these types of binary operations to be performed on a..."
          ],
          [
           "Here the one-dimensional array a is stretched, or broadcast across the second dimension in order to ..."
          ],
          [
           "Rules of Broadcasting¶Broadcasting in NumPy follows a strict set of rules to determine the interacti..."
          ],
          [
           "M.shape\n\n> (2, 3)\n\na.shape\n\n> (2, 3)\n\nThe shapes match, and we see that the final shape will be (2, ..."
          ],
          [
           "In [11]:\n\na + b\n\nOut[11]:\n\narray([[0, 1, 2],\n\n[1, 2, 3],\n\n[2, 3, 4]])\n\nBroadcasting example 3¶Now le..."
          ],
          [
           "In [13]:\n\nM + a\n\n--------------------------------------------------------------------------- ValueEr..."
          ],
          [
           "M + a[:, np.newaxis]\n\nOut[15]:\n\narray([[ 1.,  1. ],\n\n[ 2.,  2. ],\n\n[ 3.,  3.]])\n\nAlso note that whil..."
          ],
          [
           "Centering an array¶\n\nIn the previous section, we saw that ufuncs allow a NumPy user to remove the ne..."
          ],
          [
           "17,\n\n7.77156117e\n\n17,\n\n1.66533454e\n\n17])\n\nTo within machine precision, the mean is now zero.\n\nPlotti..."
          ],
          [
           "The result is a compelling visualization of the two-dimensional function.\n\n< Aggregations: Min, Max,..."
          ],
          [
           "In [1]:\n\nimport numpy as np\n\nimport pandas as pd\n\n# use pandas to extract rainfall inches as a NumPy..."
          ],
          [
           "Digging into the data¶One approach to this would be to answer these questions by hand: loop through ..."
          ],
          [
           "Out[5]:\n\narray([ True,  True, False, False, False], dtype=bool)\n\nIn [6]:\n\nx > 3  # greater than\n\nOut..."
          ],
          [
           "(2\n\nx) == (x *\n\n2)\n\nOut[11]:\n\narray([False,  True, False, False, False], dtype=bool)\n\nAs in the case..."
          ],
          [
           "[2, 4, 7, 6]])\n\nIn [13]:\n\nx < 6\n\nOut[13]:\n\narray([[ True,  True,  True,  True], [False, False,  True..."
          ],
          [
           "In [16]:\n\nnp.sum(x < 6)\n\nOut[16]:\n\n8\n\nThe benefit of sum() is that like with other NumPy aggregation..."
          ],
          [
           "Out[21]:\n\nFalse\n\nnp.all and np.any can be used along particular axes as well. For example:\n\nIn [22]:..."
          ],
          [
           "In [23]:\n\nnp.sum((inches > 0.5) & (inches < 1))\n\nOut[23]:\n\n29\n\nSo we see that there are 29 days with..."
          ],
          [
           "In [25]:\n\nprint(\"Number days without rain:      \", np.sum(inches == 0)) print(\"Number days with rain..."
          ],
          [
           "Now to select these values from the array, we can simply index on this Boolean array; this is known ..."
          ],
          [
           "Median precip on rainy days in 2014 (inches):    0.194881889764 Median precip on summer days in 2014..."
          ],
          [
           "False\n\nIn [32]:\n\nbool(42 or 0)\n\nOut[32]:\n\nTrue\n\nWhen you use & and | on integers, the expression ope..."
          ],
          [
           "Out[37]:\n\narray([ True,  True,  True, False,  True,  True], dtype=bool)\n\nUsing or on these arrays wi..."
          ],
          [
           "Trying to evaluate the truth or falsehood of the entire array will give the same ValueError we saw p..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "[51 92 14 71 60 20 82 86 74 74]\n\nSuppose we want to access three different elements. We could do it ..."
          ],
          [
           "array([[ 0,  1,  2,  3], [ 4,  5,  6,  7], [ 8,  9, 10, 11]])\n\nLike with standard indexing, the firs..."
          ],
          [
           "Out[8]:\n\narray([[0, 0, 0],\n\n[2, 1, 3],\n\n[4, 2, 6]])\n\nIt is always important to remember with fancy i..."
          ],
          [
           "Out[12]:\n\narray([[ 0,  2],\n\n[ 4,  6],\n\n[ 8, 10]])\n\nAll of these indexing options combined lead to a ..."
          ],
          [
           "In [15]:\n\nindices = np.random.choice(X.shape[0], 20, replace=False) indices\n\nOut[15]:\n\narray([93, 45..."
          ],
          [
           "In [18]:\n\nx = np.arange(10) i = np.array([2, 1, 8, 4]) x[i] = 99 print(x)\n\n[ 0 99 99  3 99  5  6  7 ..."
          ],
          [
           "array([ 6.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.])\n\nYou might expect that x[3] would contain ..."
          ],
          [
           "Example: Binning Data¶You can use these ideas to efficiently bin data to create a histogram by hand...."
          ],
          [
           "This function will create a nearly identical plot to the one seen here. To compute the binning, matp..."
          ],
          [
           "print(\"Custom routine:\") %timeit np.add.at(counts, np.searchsorted(bins, x), 1)\n\nNumPy routine: 10 l..."
          ],
          [
           "Sorting Arrays\n\n< Fancy Indexing | Contents | Structured Data: NumPy's Structured Arrays >\n\nUp to th..."
          ],
          [
           "Out[2]:\n\narray([1, 2, 3, 4, 5])\n\nAs any first-year computer science major will tell you, the selecti..."
          ],
          [
           "Out[4]:\n\narray([1, 2, 3, 4, 5])\n\nThis silly sorting method relies on pure chance: it repeatedly appl..."
          ],
          [
           "Out[5]:\n\narray([1, 2, 3, 4, 5])\n\nIf you prefer to sort the array in-place, you can instead use the s..."
          ],
          [
           "rand = np.random.RandomState(42) X = rand.randint(0, 10, (4, 6)) print(X)\n\n[[6 3 7 4 6 9] [2 6 7 4 3..."
          ],
          [
           "Keep in mind that this treats each row or column as an independent array, and any relationships betw..."
          ],
          [
           "The result is an array where the first two slots in each row contain the smallest values from that r..."
          ],
          [
           "In [16]:\n\ndist_sq = np.sum((X[:, np.newaxis, :] - X[np.newaxis, :, :]) ** 2, axis=-1)\n\nThis operatio..."
          ],
          [
           "In [20]:\n\ndist_sq.diagonal()\n\nOut[20]:\n\narray([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n\nI..."
          ],
          [
           "Notice that the first column gives the numbers 0 through 9 in order: this is due to the fact that ea..."
          ],
          [
           "Each point in the plot has lines drawn to its two nearest neighbors. At first glance, it might seem ..."
          ],
          [
           "Aside: Big-O Notation¶Big-O notation is a means of describing how the number of operations required ..."
          ],
          [
           "When trying to analyze billions or trillions of samples, the difference between $\\mathcal{O}[N]$ and..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "But this is a bit clumsy. There's nothing here that tells us that the three arrays are related; it w..."
          ],
          [
           "In [5]:\n\ndata['name'] = name\n\ndata['age'] = age\n\ndata['weight'] = weight\n\nprint(data)\n\n[('Alice', 25..."
          ],
          [
           "# Get names where age is under 30 data[data['age'] < 30]['name']\n\nOut[9]:\n\narray(['Alice', 'Doug'],\n..."
          ],
          [
           "In [11]:\n\nnp.dtype({'names':('name', 'age', 'weight'),\n\n'formats':((np.str_, 10), int, np.float32)})..."
          ],
          [
           "The shortened string format codes may seem confusing, but they are built on simple principles. The f..."
          ],
          [
           "'V'\n\nRaw data (void)\n\nnp.dtype('V') == np.void\n\nMore Advanced Compound Types¶It is possible to defin..."
          ],
          [
           "RecordArrays: Structured Arrays with a Twist¶NumPy also provides the np.recarray class, which is alm..."
          ],
          [
           "Whether the more convenient notation is worth the additional overhead will depend on your own applic..."
          ],
          [
           "Data Manipulation with Pandas\n\n< Structured Data: NumPy's Structured Arrays | Contents | Introducing..."
          ],
          [
           "In this chapter, we will focus on the mechanics of using Series, DataFrame, and related structures e..."
          ],
          [
           "And to display Pandas's built-in documentation, you can use this: In [4]: pd?\n\nMore detailed documen..."
          ],
          [
           "3. Data Manipulation with Pandas¶ Introducing Pandas Objects Data Indexing and Selection Operating o..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "Out[2]:\n\n0    0.25 1    0.50 2    0.75 3    1.00 dtype: float64\n\nAs we see in the output, the Series..."
          ],
          [
           "Series as generalized NumPy array¶\n\nFrom what we've seen so far, it may look like the Series object ..."
          ],
          [
           "2    0.25 5    0.50 3    0.75 7    1.00 dtype: float64\n\nIn [10]:\n\ndata[5]\n\nOut[10]:\n\n0.5\n\nSeries as ..."
          ],
          [
           "In [12]:\n\npopulation['California']\n\nOut[12]:\n\n38332521\n\nUnlike a dictionary, though, the Series also..."
          ],
          [
           "data can be a dictionary, in which index defaults to the sorted dictionary keys:\n\nIn [16]:\n\npd.Serie..."
          ],
          [
           "DataFrame as a generalized NumPy array¶If a Series is an analog of a one-dimensional array with flex..."
          ],
          [
           "423967\n\n38332521\n\nFlorida\n\n170312\n\n19552860\n\nIllinois\n\n149995\n\n12882135\n\nNew York\n\n141297\n\n19651127\n..."
          ],
          [
           "In [22]:\n\nstates['area']\n\nOut[22]:\n\nCalifornia    423967 Florida       170312 Illinois      149995 N..."
          ],
          [
           "From a list of dicts¶Any list of dictionaries can be made into a DataFrame. We'll use a simple list ..."
          ],
          [
           "'area': area})\n\nOut[26]:\n\narea\n\npopulation\n\nCalifornia\n\n423967\n\n38332521\n\nFlorida\n\n170312\n\n19552860\n..."
          ],
          [
           "In [28]:\n\nA = np.zeros(3, dtype=[('A', 'i8'), ('B', 'f8')]) A\n\nOut[28]:\n\narray([(0, 0.0), (0, 0.0), ..."
          ],
          [
           "ind = pd.Index([2, 3, 5, 7, 11]) ind\n\nOut[30]:\n\nInt64Index([2, 3, 5, 7, 11], dtype='int64')\n\nIndex a..."
          ],
          [
           "In [34]:\n\nind[1] = 0\n\n--------------------------------------------------------------------------- Ty..."
          ],
          [
           "In [35]:\n\nindA = pd.Index([1, 3, 5, 7, 9]) indB = pd.Index([2, 3, 5, 7, 11])\n\nIn [36]:\n\nindA & indB ..."
          ],
          [
           "Data Indexing and Selection\n\n< Introducing Pandas Objects | Contents | Operating on Data in Pandas >..."
          ],
          [
           "Series as dictionary¶Like a dictionary, the Series object provides a mapping from a collection of ke..."
          ],
          [
           "Series objects can even be modified with a dictionary-like syntax. Just as you can extend a dictiona..."
          ],
          [
           "# masking data[(data > 0.3) & (data < 0.8)]\n\nOut[9]:\n\nb    0.50 c    0.75 dtype: float64\n\nIn [10]:\n\n..."
          ],
          [
           "# explicit index when indexing data[1]\n\nOut[12]:\n\n'a'\n\nIn [13]:\n\n# implicit index when slicing data[..."
          ],
          [
           "data.iloc[1:3]\n\nOut[17]:\n\n3    b 5    c dtype: object\n\nA third indexing attribute, ix, is a hybrid o..."
          ],
          [
           "In [18]:\n\narea = pd.Series({'California': 423967, 'Texas': 695662, 'New York': 141297, 'Florida': 17..."
          ],
          [
           "Equivalently, we can use attribute-style access with column names that are strings:\n\nIn [20]:\n\ndata...."
          ],
          [
           "data['density'] = data['pop'] / data['area'] data\n\nOut[23]:\n\narea\n\npop\n\ndensity\n\nCalifornia\n\n423967\n..."
          ],
          [
           "In [24]:\n\ndata.values\n\nOut[24]:\n\narray([[  4.23967000e+05,   3.83325210e+07,   9.04139261e+01], [  1..."
          ],
          [
           "6.956620e+05\n\npop\n\n3.833252e+07\n\n1.955286e+07\n\n1.288214e+07\n\n1.965113e+07\n\n2.644819e+07\n\ndensity\n\n9...."
          ],
          [
           "California    423967 Florida       170312 Illinois      149995 New York      141297 Texas         69..."
          ],
          [
           "Illinois\n\n149995\n\n12882135\n\nThe ix indexer allows a hybrid of these two approaches:\n\nIn [30]:\n\ndata...."
          ],
          [
           "In [32]:\n\ndata.iloc[0, 2] = 90\n\ndata\n\nOut[32]:\n\narea\n\npop\n\ndensity\n\nCalifornia\n\n423967\n\n38332521\n\n90..."
          ],
          [
           "density\n\nFlorida\n\n170312\n\n19552860\n\n114.806121\n\nIllinois\n\n149995\n\n12882135\n\n85.883763\n\nSuch slices c..."
          ],
          [
           "< Introducing Pandas Objects | Contents | Operating on Data in Pandas >\n\nOperating on Data in Pandas..."
          ],
          [
           "Ufuncs: Index Preservation¶Because Pandas is designed to work with NumPy, any NumPy ufunc will work ..."
          ],
          [
           "In [4]:\n\nnp.exp(ser)\n\nOut[4]:\n\n0     403.428793 1      20.085537 2    1096.633158 3      54.598150 d..."
          ],
          [
           "Index alignment in Series¶As an example, suppose we are combining two different data sources, and fi..."
          ],
          [
           "In [9]:\n\nA = pd.Series([2, 4, 6], index=[0, 1, 2]) B = pd.Series([1, 3, 5], index=[1, 2, 3]) A + B\n\n..."
          ],
          [
           "0\n\n1\n\n11\n\n1\n\n5\n\n1\n\nIn [12]:\n\nB = pd.DataFrame(rng.randint(0, 10, (3, 3)), columns=list('BAC')) B\n\nOu..."
          ],
          [
           "In [14]:\n\nfill = A.stack().mean()\n\nA.add(B, fill_value=fill)\n\nOut[14]:\n\nA\n\nB\n\nC\n\n0\n\n1.0\n\n15.0\n\n13.5\n..."
          ],
          [
           "In [15]:\n\nA = rng.randint(10, size=(3, 4)) A\n\nOut[15]:\n\narray([[3, 8, 2, 4],\n\n[2, 6, 4, 8],\n\n[6, 1, ..."
          ],
          [
           "2\n\n2\n\n4\n\n2\n\n3\n\n7\n\n1\n\n4\n\nIf you would instead like to operate column-wise, you can use the object met..."
          ],
          [
           "T\n\n0\n\n0.0\n\nNaN\n\n0.0\n\nNaN\n\n1\n\n1.0\n\nNaN\n\n2.0\n\nNaN\n\n2\n\n3.0\n\nNaN\n\n1.0\n\nNaN\n\nThis preservation and alignm..."
          ],
          [
           "Handling Missing Data\n\n< Operating on Data in Pandas | Contents | Hierarchical Indexing >\n\nThe diffe..."
          ],
          [
           "Trade-Offs in Missing Data Conventions¶There are a number of schemes that have been developed to ind..."
          ],
          [
           "Missing Data in Pandas¶The way in which Pandas handles missing values is constrained by its reliance..."
          ],
          [
           "None: Pythonic missing data¶The first sentinel value used by Pandas is None, a Python singleton obje..."
          ],
          [
           "dtype = int 100 loops, best of 3: 3.06 ms per loop\n\nThe use of Python objects in an array also means..."
          ],
          [
           "TypeError: unsupported operand type(s) for +: 'int' and 'NoneType'\n\nThis reflects the fact that addi..."
          ],
          [
           "In [8]:\n\nvals2.sum(), vals2.min(), vals2.max()\n\nOut[8]:\n\n(nan, nan, nan)\n\nNumPy does provide some sp..."
          ],
          [
           "x = pd.Series(range(2), dtype=int)\n\nx\n\nOut[11]:\n\n0    0 1    1 dtype: int64\n\nIn [12]:\n\nx[0] = None\n\n..."
          ],
          [
           "Cast to object\n\nNone or np.nan\n\nKeep in mind that in Pandas, string data is always stored with an ob..."
          ],
          [
           "data[data.notnull()]\n\nOut[15]:\n\n0        1 2    hello dtype: object\n\nThe isnull() and notnull() meth..."
          ],
          [
           "3.0\n\n5\n\n2\n\nNaN\n\n4.0\n\n6\n\nWe cannot drop single values from a DataFrame; we can only drop full rows or..."
          ],
          [
           "In [20]:\n\ndf[3] = np.nan\n\ndf\n\nOut[20]:\n\n0\n\n1\n\n2\n\n3\n\n0\n\n1.0\n\nNaN\n\n2\n\nNaN\n\n1\n\n2.0\n\n3.0\n\n5\n\nNaN\n\n2\n\nNaN..."
          ],
          [
           "2\n\n3\n\n1\n\n2.0\n\n3.0\n\n5\n\nNaN\n\nHere the first and last row have been dropped, because they contain only ..."
          ],
          [
           "In [25]:\n\n# forward\n\nfill\n\ndata.fillna(method='ffill')\n\nOut[25]:\n\na    1.0 b    1.0 c    2.0 d    2...."
          ],
          [
           "Out[28]:\n\n0\n\n1\n\n2\n\n3\n\n0\n\n1.0\n\n1.0\n\n2.0\n\n2.0\n\n1\n\n2.0\n\n3.0\n\n5.0\n\n5.0\n\n2\n\nNaN\n\n4.0\n\n6.0\n\n6.0\n\nNotice th..."
          ],
          [
           "Hierarchical Indexing\n\n< Handling Missing Data | Contents | Combining Datasets: Concat and Append >\n..."
          ],
          [
           "In [2]:\n\nindex = [('California', 2000), ('California', 2010), ('New York', 2000), ('New York', 2010)..."
          ],
          [
           "pop[[i for i in pop.index if i[1] == 2010]]\n\nOut[4]:\n\n(California, 2010)    37253956 (New York, 2010..."
          ],
          [
           "In [6]:\n\npop = pop.reindex(index)\n\npop\n\nOut[6]:\n\nCalifornia  2000    33871648 2010    37253956 New Y..."
          ],
          [
           "In [8]:\n\npop_df = pop.unstack()\n\npop_df\n\nOut[8]:\n\n2000\n\n2010\n\nCalifornia\n\n33871648\n\n37253956\n\nNew Yo..."
          ],
          [
           "In [10]:\n\npop_df = pd.DataFrame({'total': pop,\n\n'under18': [9267089, 9284094,\n\n4687374, 4318033,\n\n59..."
          ],
          [
           "Out[11]:\n\n2000\n\n2010\n\nCalifornia\n\n0.273594\n\n0.249211\n\nNew York\n\n0.247010\n\n0.222831\n\nTexas\n\n0.283251\n..."
          ],
          [
           "0.610054\n\n2\n\n0.171495\n\n0.886688\n\nThe work of creating the MultiIndex is done in the background. Simi..."
          ],
          [
           "Out[14]:\n\nMultiIndex(levels=[['a', 'b'], [1, 2]], labels=[[0, 0, 1, 1], [0, 1, 0, 1]])\n\nYou can cons..."
          ],
          [
           "In [17]:\n\npd.MultiIndex(levels=[['a', 'b'], [1, 2]], labels=[[0, 0, 1, 1], [0, 1, 0, 1]])\n\nOut[17]:\n..."
          ],
          [
           "With more involved datasets, this can be a useful way to keep track of the meaning of various index ..."
          ],
          [
           "visit\n\n2013\n\n1\n\n31.0\n\n38.7\n\n32.0\n\n36.7\n\n35.0\n\n37.2\n\n2\n\n44.0\n\n37.7\n\n50.0\n\n35.0\n\n29.0\n\n36.7\n\n2014\n\n1\n\n..."
          ],
          [
           "2013\n\n1\n\n32.0\n\n36.7\n\n2\n\n50.0\n\n35.0\n\n2014\n\n1\n\n39.0\n\n37.8\n\n2\n\n48.0\n\n37.3\n\nFor complicated records cont..."
          ],
          [
           "In [23]:\n\npop['California']\n\nOut[23]:\n\nyear 2000    33871648 2010    37253956 dtype: int64\n\nPartial ..."
          ],
          [
           "In [27]:\n\npop[['California', 'Texas']]\n\nOut[27]:\n\nstate       year California  2000    33871648 2010..."
          ],
          [
           "2\n\n47.0\n\n37.8\n\n48.0\n\n37.3\n\n51.0\n\n36.5\n\nRemember that columns are primary in a DataFrame, and the syn..."
          ],
          [
           "In [31]:\n\nhealth_data.loc[:, ('Bob', 'HR')]\n\nOut[31]:\n\nyear  visit 2013  1        31.0 2        44.0..."
          ],
          [
           "Bob\n\nGuido\n\nSue\n\ntype\n\nHR\n\nHR\n\nHR\n\nyear\n\nvisit\n\n2013\n\n1\n\n31.0\n\n32.0\n\n35.0\n\n2014\n\n1\n\n30.0\n\n39.0\n\n61.0..."
          ],
          [
           "In [34]:\n\nindex = pd.MultiIndex.from_product([['a', 'c', 'b'], [1, 2]]) data = pd.Series(np.random.r..."
          ],
          [
           "In [36]:\n\ndata = data.sort_index()\n\ndata\n\nOut[36]:\n\nchar  int a     1      0.003001 2      0.164974 ..."
          ],
          [
           "pop.unstack(level=1)\n\nOut[39]:\n\nyear\n\n2000\n\n2010\n\nstate\n\nCalifornia\n\n33871648\n\n37253956\n\nNew York\n\n1..."
          ],
          [
           "year\n\npopulation\n\n0\n\nCalifornia\n\n2000\n\n33871648\n\n1\n\nCalifornia\n\n2010\n\n37253956\n\n2\n\nNew York\n\n2000\n\n1..."
          ],
          [
           "19378102\n\nTexas\n\n2000\n\n20851820\n\n2010\n\n25145561\n\nIn practice, I find this type of reindexing to be o..."
          ],
          [
           "2014\n\n1\n\n30.0\n\n37.4\n\n39.0\n\n37.8\n\n61.0\n\n36.9\n\n2\n\n47.0\n\n37.8\n\n48.0\n\n37.3\n\n51.0\n\n36.5\n\nPerhaps we'd lik..."
          ],
          [
           "By further making use of the axis keyword, we can take the mean among levels on the columns as well:..."
          ],
          [
           "Aside: Panel Data¶Pandas has a few other fundamental data structures that we have not yet discussed,..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "For convenience, we'll define this function which creates a DataFrame of a particular form that will..."
          ],
          [
           "def _repr_html_(self):\n\nreturn '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n\nfor a in se..."
          ],
          [
           "In [5]:\n\nx = [[1, 2],\n\n[3, 4]]\n\nnp.concatenate([x, x], axis=1)\n\nOut[5]:\n\narray([[1, 2, 1, 2],\n\n[3, 4..."
          ],
          [
           "Out[6]:\n\n1    A 2    B 3    C 4    D 5    E 6    F dtype: object\n\nIt also works to concatenate highe..."
          ],
          [
           "B2\n\n3\n\nA3\n\nB3\n\n4\n\nA4\n\nB4\n\nBy default, the concatenation takes place row-wise within the DataFrame (i..."
          ],
          [
           "0\n\nA0\n\nB0\n\nC0\n\nD0\n\n1\n\nA1\n\nB1\n\nC1\n\nD1\n\nWe could have equivalently specified axis=1; here we've used t..."
          ],
          [
           "A0\n\nB0\n\n1\n\nA1\n\nB1\n\n0\n\nA2\n\nB2\n\n1\n\nA3\n\nB3\n\nNotice the repeated indices in the result. While this is va..."
          ],
          [
           "Out[11]:\n\nx\n\nA\n\nB\n\n0\n\nA0\n\nB0\n\n1\n\nA1\n\nB1\n\ny\n\nA\n\nB\n\n0\n\nA2\n\nB2\n\n1\n\nA3\n\nB3\n\npd.concat([x, y], ignore_ind..."
          ],
          [
           "y\n\nA\n\nB\n\n0\n\nA2\n\nB2\n\n1\n\nA3\n\nB3\n\npd.concat([x, y], keys=['x', 'y'])\n\nA\n\nB\n\nx\n\n0\n\nA0\n\nB0\n\n1\n\nA1\n\nB1\n\ny\n..."
          ],
          [
           "Out[13]:\n\ndf5\n\nA\n\nB\n\nC\n\n1\n\nA1\n\nB1\n\nC1\n\n2\n\nA2\n\nB2\n\nC2\n\ndf6\n\nB\n\nC\n\nD\n\n3\n\nB3\n\nC3\n\nD3\n\n4\n\nB4\n\nC4\n\nD4\n\npd..."
          ],
          [
           "In [14]:\n\ndisplay('df5', 'df6',\n\n\"pd.concat([df5, df6], join='inner')\")\n\nOut[14]:\n\ndf5\n\nA\n\nB\n\nC\n\n1\n\n..."
          ],
          [
           "In [15]:\n\ndisplay('df5', 'df6',\n\n\"pd.concat([df5, df6], join_axes=[df5.columns])\")\n\nOut[15]:\n\ndf5\n\nA..."
          ],
          [
           "The append() method¶Because direct array concatenation is so common, Series and DataFrame objects ha..."
          ],
          [
           "B2\n\n3\n\nA3\n\nB3\n\n4\n\nA4\n\nB4\n\nKeep in mind that unlike the append() and extend() methods of Python lists..."
          ],
          [
           "Combining Datasets: Merge and Join\n\n< Combining Datasets: Concat and Append | Contents | Aggregation..."
          ],
          [
           "Relational Algebra¶The behavior implemented in pd.merge() is a subset of what is known as relational..."
          ],
          [
           "In [2]:\n\ndf1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'], 'group': ['Accounting', 'En..."
          ],
          [
           "df3\n\nOut[3]:\n\nemployee\n\ngroup\n\nhire_date\n\n0\n\nBob\n\nAccounting\n\n2008\n\n1\n\nJake\n\nEngineering\n\n2012\n\n2\n\nL..."
          ],
          [
           "In [4]:\n\ndf4 = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'], 'supervisor': ['Carly', '..."
          ],
          [
           "2012\n\nGuido\n\n2\n\nLisa\n\nEngineering\n\n2004\n\nGuido\n\n3\n\nSue\n\nHR\n\n2014\n\nSteve\n\nThe resulting DataFrame has..."
          ],
          [
           "employee\n\ngroup\n\n0\n\nBob\n\nAccounting\n\n1\n\nJake\n\nEngineering\n\n2\n\nLisa\n\nEngineering\n\n3\n\nSue\n\nHR\n\ndf5\n\ngr..."
          ],
          [
           "Sue\n\nHR\n\nspreadsheets\n\n7\n\nSue\n\nHR\n\norganization\n\nThese three types of joins can be used with other P..."
          ],
          [
           "Engineering\n\n3\n\nSue\n\nHR\n\ndf2\n\nemployee\n\nhire_date\n\n0\n\nLisa\n\n2004\n\n1\n\nBob\n\n2008\n\n2\n\nJake\n\n2012\n\n3\n\nSu..."
          ],
          [
           "In [7]:\n\ndf3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'], 'salary': [70000, 80000, 120000..."
          ],
          [
           "70000\n\n1\n\nJake\n\nEngineering\n\nJake\n\n80000\n\n2\n\nLisa\n\nEngineering\n\nLisa\n\n120000\n\n3\n\nSue\n\nHR\n\nSue\n\n90000..."
          ],
          [
           "df2a = df2.set_index('employee')\n\ndisplay('df1a', 'df2a')\n\nOut[9]:\n\ndf1a\n\ngroup\n\nemployee\n\nBob\n\nAcco..."
          ],
          [
           "employee\n\nLisa\n\n2004\n\nBob\n\n2008\n\nJake\n\n2012\n\nSue\n\n2014\n\npd.merge(df1a, df2a, left_index=True, right_..."
          ],
          [
           "2014\n\ndf1a.join(df2a)\n\ngroup\n\nhire_date\n\nemployee\n\nBob\n\nAccounting\n\n2008\n\nJake\n\nEngineering\n\n2012\n\nL..."
          ],
          [
           "group\n\nname\n\nsalary\n\n0\n\nAccounting\n\nBob\n\n70000\n\n1\n\nEngineering\n\nJake\n\n80000\n\n2\n\nEngineering\n\nLisa\n\n1..."
          ],
          [
           "Out[13]:\n\ndf6\n\nname\n\nfood\n\n0\n\nPeter\n\nfish\n\n1\n\nPaul\n\nbeans\n\n2\n\nMary\n\nbread\n\ndf7\n\nname\n\ndrink\n\n0\n\nMary..."
          ],
          [
           "In [15]:\n\ndisplay('df6', 'df7', \"pd.merge(df6, df7, how='outer')\")\n\nOut[15]:\n\ndf6\n\nname\n\nfood\n\n0\n\nPe..."
          ],
          [
           "Out[16]:\n\ndf6\n\nname\n\nfood\n\n0\n\nPeter\n\nfish\n\n1\n\nPaul\n\nbeans\n\n2\n\nMary\n\nbread\n\ndf7\n\nname\n\ndrink\n\n0\n\nMary..."
          ],
          [
           "Finally, you may end up in a case where your two input DataFrames have conflicting column names. Con..."
          ],
          [
           "name\n\nrank_x\n\nrank_y\n\n0\n\nBob\n\n1\n\n3\n\n1\n\nJake\n\n2\n\n1\n\n2\n\nLisa\n\n3\n\n4\n\n3\n\nSue\n\n4\n\n2\n\nBecause the output w..."
          ],
          [
           "Jake\n\n1\n\n2\n\nLisa\n\n4\n\n3\n\nSue\n\n2\n\npd.merge(df8, df9, on=\"name\", suffixes=[\"_L\", \"_R\"])\n\nname\n\nrank_L\n\n..."
          ],
          [
           "In [19]:\n\n# Following are shell commands to download the data # !curl -O https://raw.githubuserconte..."
          ],
          [
           "under18\n\n2012\n\n1117489.0\n\n1\n\nAL\n\ntotal\n\n2012\n\n4817528.0\n\n2\n\nAL\n\nunder18\n\n2010\n\n1130966.0\n\n3\n\nAL\n\ntot..."
          ],
          [
           "Arizona\n\nAZ\n\n3\n\nArkansas\n\nAR\n\n4\n\nCalifornia\n\nCA\n\nGiven this information, say we want to compute a re..."
          ],
          [
           "2\n\nAL\n\nunder18\n\n2010\n\n1130966.0\n\nAlabama\n\n3\n\nAL\n\ntotal\n\n2010\n\n4785570.0\n\nAlabama\n\n4\n\nAL\n\nunder18\n\n20..."
          ],
          [
           "PR\n\ntotal\n\n1991\n\nNaN\n\nNaN\n\n2451\n\nPR\n\nunder18\n\n1991\n\nNaN\n\nNaN\n\n2452\n\nPR\n\ntotal\n\n1993\n\nNaN\n\nNaN\n\nIt ap..."
          ],
          [
           "Out[25]:\n\nstate/region    False ages            False year            False population       True st..."
          ],
          [
           "4\n\nAL\n\nunder18\n\n2011\n\n1125763.0\n\nAlabama\n\n52423.0\n\nAgain, let's check for nulls to see if there were..."
          ],
          [
           "ages\n\nyear\n\npopulation\n\nstate\n\narea (sq. mi)\n\n0\n\nAL\n\nunder18\n\n2012\n\n1117489.0\n\nAlabama\n\n52423.0\n\n1\n\n..."
          ],
          [
           "data2010 = final.query(\"year == 2010 & ages == 'total'\") data2010.head()\n\nOut[30]:\n\nstate/region\n\nag..."
          ],
          [
           "In [31]:\n\ndata2010.set_index('state', inplace=True) density = data2010['population'] / data2010['are..."
          ],
          [
           "We see that the least dense state, by far, is Alaska, averaging slightly over one resident per squar..."
          ],
          [
           "In [1]:\n\nimport numpy as np\n\nimport pandas as pd\n\nclass display(object): \"\"\"Display HTML representat..."
          ],
          [
           "planets.shape\n\nOut[2]:\n\n(1035, 6)\n\nIn [3]:\n\nplanets.head()\n\nOut[3]:\n\nmethod\n\nnumber\n\norbital_period\n..."
          ],
          [
           "2009\n\nThis has some details on the 1,000+ extrasolar planets discovered up to 2014.\n\nSimple Aggregat..."
          ],
          [
           "df\n\nOut[7]:\n\nA\n\nB\n\n0\n\n0.155995\n\n0.020584\n\n1\n\n0.058084\n\n0.969910\n\n2\n\n0.866176\n\n0.832443\n\n3\n\n0.601115\n..."
          ],
          [
           "In [10]:\n\nplanets.dropna().describe()\n\nOut[10]:\n\nnumber\n\norbital_period\n\nmass\n\ndistance\n\nyear\n\ncount..."
          ],
          [
           "39.940000\n\n2009.000000\n\n75%\n\n2.00000\n\n999.600000\n\n2.867500\n\n59.332500\n\n2011.000000\n\nmax\n\n6.00000\n\n17..."
          ],
          [
           "Product of all items\n\nsum()\n\nSum of all items\n\nThese are all methods of DataFrame and Series objects..."
          ],
          [
           "While this could certainly be done manually using some combination of the masking, aggregation, and ..."
          ],
          [
           "The most basic split-apply-combine operation can be computed with the groupby() method of DataFrames..."
          ],
          [
           "The GroupBy object¶The GroupBy object is a very flexible abstraction. In many ways, you can simply t..."
          ],
          [
           "planets.groupby('method')['orbital_period'].median()\n\nOut[16]:\n\nmethod Astrometry                   ..."
          ],
          [
           "This can be useful for doing certain things manually, though it is often much faster to use the buil..."
          ],
          [
           "2009.131579\n\n2.781901\n\n2004.0\n\n2008.00\n\n2009.0\n\n2011.00\n\n2013.0\n\nMicrolensing\n\n23.0\n\n2009.782609\n\n2...."
          ],
          [
           "4.249052\n\n1989.0\n\n2005.00\n\n2009.0\n\n2011.00\n\n2014.0\n\nTransit\n\n397.0\n\n2011.236776\n\n2.077867\n\n2002.0\n\n2..."
          ],
          [
           "Aggregate, filter, transform, apply¶The preceding discussion focused on aggregation for the combine ..."
          ],
          [
           "4\n\nB\n\n4\n\n7\n\n5\n\nC\n\n5\n\n9\n\nAggregation¶We're now familiar with GroupBy aggregations with sum(), median(..."
          ],
          [
           "In [21]:\n\ndf.groupby('key').aggregate({'data1': 'min',\n\n'data2': 'max'})\n\nOut[21]:\n\ndata1\n\ndata2\n\nke..."
          ],
          [
           "3\n\nA\n\n3\n\n3\n\n4\n\nB\n\n4\n\n7\n\n5\n\nC\n\n5\n\n9\n\ndf.groupby('key').std()\n\ndata1\n\ndata2\n\nkey\n\nA\n\n2.12132\n\n1.414214..."
          ],
          [
           "Transformation¶While aggregation must return a reduced version of the data, transformation can retur..."
          ],
          [
           "In [24]:\n\ndef norm_by_data2(x): # x is a DataFrame of group values x['data1'] /= x['data2'].sum() re..."
          ],
          [
           "3\n\n3\n\nA\n\n0.375000\n\n3\n\n4\n\nB\n\n0.571429\n\n7\n\n5\n\nC\n\n0.416667\n\n9\n\napply() within a GroupBy is quite flexib..."
          ],
          [
           "2\n\nC\n\n2\n\n3\n\n3\n\nA\n\n3\n\n3\n\n4\n\nB\n\n4\n\n7\n\n5\n\nC\n\n5\n\n9\n\ndf.groupby(L).sum()\n\ndata1\n\ndata2\n\n0\n\n7\n\n17\n\n1\n\n4\n\n3..."
          ],
          [
           "4\n\nB\n\n4\n\n7\n\n5\n\nC\n\n5\n\n9\n\ndf.groupby(df['key']).sum()\n\ndata1\n\ndata2\n\nkey\n\nA\n\n3\n\n8\n\nB\n\n5\n\n7\n\nC\n\n7\n\n12\n\n..."
          ],
          [
           "5\n\n9\n\ndf2.groupby(mapping).sum()\n\ndata1\n\ndata2\n\nconsonant\n\n12\n\n19\n\nvowel\n\n3\n\n8\n\nAny Python function¶..."
          ],
          [
           "6.0\n\nA list of valid keys¶Further, any of the preceding key choices can be combined to group on a mu..."
          ],
          [
           "2.0\n\nEclipse Timing Variations\n\n0.0\n\n0.0\n\n5.0\n\n10.0\n\nImaging\n\n0.0\n\n0.0\n\n29.0\n\n21.0\n\nMicrolensing\n\n0...."
          ],
          [
           "Transit Timing Variations\n\n0.0\n\n0.0\n\n0.0\n\n9.0\n\nThis shows the power of combining many of the operati..."
          ],
          [
           "Pivot Tables\n\n< Aggregation and Grouping | Contents | Vectorized String Operations >\n\nWe have seen h..."
          ],
          [
           "embarked\n\nclass\n\nwho\n\nadult_male\n\ndeck\n\nembark_town\n\nalive\n\nalone\n\n0\n\n0\n\n3\n\nmale\n\n22.0\n\n1\n\n0\n\n7.2500..."
          ],
          [
           "S\n\nFirst\n\nwoman\n\nFalse\n\nC\n\nSouthampton\n\nyes\n\nFalse\n\n4\n\n0\n\n3\n\nmale\n\n35.0\n\n0\n\n0\n\n8.0500\n\nS\n\nThird\n\nman..."
          ],
          [
           "survived\n\nsex\n\nfemale\n\n0.742038\n\nmale\n\n0.188908\n\nThis immediately gives us some insight: overall, th..."
          ],
          [
           "male\n\n0.368852\n\n0.157407\n\n0.135447\n\nThis gives us a better idea of how both gender and class affecte..."
          ],
          [
           "Multi-level pivot tables¶Just as in the GroupBy, the grouping in pivot tables can be specified with ..."
          ],
          [
           "In [7]:\n\nfare = pd.qcut(titanic['fare'], 2) titanic.pivot_table('survived', ['sex', age], [fare, 'cl..."
          ],
          [
           "0.098039\n\n0.125000\n\n0.391304\n\n0.030303\n\n0.192308\n\nThe result is a four-dimensional aggregation with ..."
          ],
          [
           "In [8]:\n\ntitanic.pivot_table(index='sex', columns='class',\n\naggfunc={'survived':sum, 'fare':'mean'})..."
          ],
          [
           "Third\n\nAll\n\nsex\n\nfemale\n\n0.968085\n\n0.921053\n\n0.500000\n\n0.742038\n\nmale\n\n0.368852\n\n0.157407\n\n0.135447\n..."
          ],
          [
           "In [11]:\n\nbirths = pd.read_csv('data/births.csv')\n\nTaking a look at the data, we see that it's relat..."
          ],
          [
           "births.pivot_table('births', index='decade', columns='gender', aggfunc='sum')\n\nOut[13]:\n\ngender\n\nF\n\n..."
          ],
          [
           "Further data exploration¶Though this doesn't necessarily relate to the pivot table, there are a few ..."
          ],
          [
           "births = births.query('(births > @mu - 5 * @sig) & (births < @mu + 5 * @sig)')\n\nNext we set the day ..."
          ],
          [
           "In [19]:\n\nimport matplotlib.pyplot as plt\n\nimport matplotlib as mpl\n\nbirths.pivot_table('births', in..."
          ],
          [
           "In [21]:\n\nbirths_by_date.index = [pd.datetime(2012, month, day) for (month, day) in births_by_date.i..."
          ],
          [
           "In particular, the striking feature of this graph is the dip in birthrate on US holidays (e.g., Inde..."
          ],
          [
           "Vectorized String Operations\n\n< Pivot Tables | Contents | Working with Time Series >\n\nOne strength o..."
          ],
          [
           "Out[2]:\n\n['Peter', 'Paul', 'Mary', 'Guido']\n\nThis is perhaps sufficient to work with some data, but ..."
          ],
          [
           "AttributeError: 'NoneType' object has no attribute 'capitalize'\n\nPandas includes features to address..."
          ],
          [
           "Methods similar to Python string methods¶Nearly all Python's built-in string methods are mirrored by..."
          ],
          [
           "In [7]:\n\nmonte.str.lower()\n\nOut[7]:\n\n0    graham chapman 1       john cleese 2     terry gilliam 3  ..."
          ],
          [
           "Method\n\nDescription\n\nmatch() Call re.match() on each element, returning a boolean.\n\nextract() Call r..."
          ],
          [
           "monte.str.findall(r'^[^AEIOU].\n\n[^aeiou]$')\n\nOut[12]:\n\n0    [Graham Chapman] 1                  [] 2..."
          ],
          [
           "join() Join strings in each element of the Series with passed separator\n\nget_dummies() extract dummy..."
          ],
          [
           "1)\n\nOut[14]:\n\n0    Chapman 1     Cleese 2    Gilliam 3       Idle 4      Jones 5      Palin dtype: o..."
          ],
          [
           "4\n\nB|C\n\nTerry Jones\n\n5\n\nB|C|D\n\nMichael Palin\n\nThe get_dummies() routine lets you quickly split-out t..."
          ],
          [
           "Example: Recipe Database¶These vectorized string operations become most useful in the process of cle..."
          ],
          [
           "except ValueError as e:\n\nprint(\"ValueError:\", e)\n\nValueError: Trailing data\n\nOops! We get a ValueErr..."
          ],
          [
           "In [21]:\n\nrecipes.shape\n\nOut[21]:\n\n(173278, 17)\n\nWe see there are nearly 200,000 recipes, and 17 col..."
          ],
          [
           "In [23]:\n\nrecipes.ingredients.str.len().describe()\n\nOut[23]:\n\ncount    173278.000000 mean        244..."
          ],
          [
           "Out[26]:\n\n10526\n\nWe could even look to see whether any recipes misspell the ingredient as \"cinamon\":..."
          ],
          [
           "We can then build a Boolean DataFrame consisting of True and False values, indicating whether this i..."
          ],
          [
           "False\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\n4\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n..."
          ],
          [
           "In [31]:\n\nrecipes.name[selection.index]\n\nOut[31]:\n\n2069      All cremat with a Little Gem, dandelion..."
          ],
          [
           "< Pivot Tables | Contents | Working with Time Series >\n\nWorking with Time Series | Python Data Scien..."
          ],
          [
           "In this section, we will introduce how to work with each of these types of date/time data in Pandas...."
          ],
          [
           "Or, using the dateutil module, you can parse dates from a variety of string formats:\n\nIn [2]:\n\nfrom ..."
          ],
          [
           "Typed arrays of times: NumPy's datetime64¶The weaknesses of Python's datetime format inspired the Nu..."
          ],
          [
           "07\n\n11',\n\n'2015\n\n07\n\n12', '2015\n\n07\n\n13', '2015\n\n07\n\n14', '2015\n\n07\n\n15'], dtype='datetime64[D]')\n\nB..."
          ],
          [
           "07\n\n04')\n\nHere is a minute\n\nbased datetime:\n\nIn [7]:\n\nnp.datetime64('2015\n\n07\n\n04 12:00')\n\nOut[7]:\n\n..."
          ],
          [
           "[9.2e18 BC, 9.2e18 AD]\n\nM\n\nMonth\n\n± 7.6e17 years\n\n[7.6e17 BC, 7.6e17 AD]\n\nW\n\nWeek\n\n± 1.7e17 years\n\n[..."
          ],
          [
           "fs Femtosecond ± 2.6 hours [ 1969 AD, 1970 AD]\n\nas Attosecond ± 9.2 seconds [ 1969 AD, 1970 AD]\n\nFor..."
          ],
          [
           "Timestamp('2015\n\n07\n\n04 00:00:00')\n\nIn [10]:\n\ndate.strftime('%A')\n\nOut[10]:\n\n'Saturday'\n\nAdditionall..."
          ],
          [
           "In the next section, we will take a closer look at manipulating time series data with the tools prov..."
          ],
          [
           "In [14]:\n\ndata['2015']\n\nOut[14]:\n\n2015-07-04    2 2015-08-04    3 dtype: int64\n\nLater, we will see a..."
          ],
          [
           "In [15]:\n\ndates = pd.to_datetime([datetime(2015, 7, 3), '4th of July, 2015', '2015-Jul-6', '07-07-20..."
          ],
          [
           "'2015\n\n07\n\n08'],\n\ndtype='int64', freq='D')\n\nA TimedeltaIndex is created, for example, when a date is..."
          ],
          [
           "Out[18]:\n\nDatetimeIndex(['2015\n\n07\n\n03', '2015\n\n07\n\n04', '2015\n\n07\n\n05', '2015\n\n07\n\n06',\n\n'2015\n\n07\n..."
          ],
          [
           "08', '2015\n\n07\n\n09', '2015\n\n07\n\n10'],\n\ndtype='datetime64[ns]', freq='D')\n\nThe spacing can be modifie..."
          ],
          [
           "03 07:00:00'],\n\ndtype='datetime64[ns]', freq='H')\n\nTo create regular sequences of Period or Timedelt..."
          ],
          [
           "pd.timedelta_range(0, periods=10, freq='H')\n\nOut[22]:\n\nTimedeltaIndex(['00:00:00', '01:00:00', '02:0..."
          ],
          [
           "A\n\nYear end\n\nBA\n\nBusiness year end\n\nH\n\nHours\n\nBH\n\nBusiness hours\n\nT\n\nMinutes\n\nS\n\nSeconds\n\nL\n\nMillise..."
          ],
          [
           "W\n\nSUN, W\n\nMON, W\n\nTUE, W\n\nWED, etc.\n\nOn top of this, codes can be combined with numbers to specify ..."
          ],
          [
           "Out[24]:\n\nDatetimeIndex(['2015\n\n07\n\n01', '2015\n\n07\n\n02', '2015\n\n07\n\n03', '2015\n\n07\n\n06',\n\n'2015\n\n07\n..."
          ],
          [
           "In [25]:\n\nfrom pandas_datareader import data\n\ngoog = data.DataReader('GOOG', start='2004', end='2016..."
          ],
          [
           "For simplicity, we'll use just the closing price:\n\nIn [26]:\n\ngoog = goog['Close']\n\nWe can visualize ..."
          ],
          [
           "');\n\nplt.legend(['input', 'resample', 'asfreq'],\n\nloc='upper left');\n\nNotice the difference: at each..."
          ],
          [
           "o')\n\nax[1].legend([\"back\n\nfill\", \"forward\n\nfill\"]);\n\nThe top panel is the default: non-business days..."
          ],
          [
           "11\n\n05')\n\noffset = pd.Timedelta(900, 'D')\n\nax[0].legend(['input'], loc=2)\n\nax[0].get_xticklabels()[2..."
          ],
          [
           "In [32]:\n\nROI = 100\n\n(goog.tshift(\n\n365) / goog\n\n1)\n\nROI.plot()\n\nplt.ylabel('% Return on Investment'..."
          ],
          [
           "', '-\n\n', ':'])\n\nax.lines[0].set_alpha(0.3)\n\nAs with group-by operations, the aggregate() and apply(..."
          ],
          [
           "In [34]:\n\n# !curl\n\no FremontBridge.csv https://data.seattle.gov/api/views/65db\n\nxm6k/rows.csv?access..."
          ],
          [
           "2012\n\n10\n\n03 04:00:00\n\n6.0\n\n1.0\n\nFor convenience, we'll further process this dataset by shortening t..."
          ],
          [
           "50%\n\n33.000000\n\n28.000000\n\n65.000000\n\n75%\n\n79.000000\n\n67.000000\n\n151.000000\n\nmax\n\n825.000000\n\n717.00..."
          ],
          [
           "', '\n\n'])\n\nplt.ylabel('Weekly bicycle count');\n\nThis shows us some interesting seasonal trends: as y..."
          ],
          [
           "', '\n\n']);\n\nDigging into the data¶While these smoothed data views are useful to get an idea of the g..."
          ],
          [
           "In [44]:\n\nby_weekday = data.groupby(data.index.dayofweek).mean() by_weekday.index = ['Mon', 'Tues', ..."
          ],
          [
           "Now we'll use some of the Matplotlib tools described in Multiple Subplots to plot two panels side by..."
          ],
          [
           "Python Data Science Handbook\n\nAbout\n\nArchive\n\nThis is an excerpt from the Python Data Science Handbo..."
          ],
          [
           "In [1]:\n\nimport numpy as np\n\nrng = np.random.RandomState(42)\n\nx = rng.rand(1000000)\n\ny = rng.rand(10..."
          ],
          [
           "tmp1 = (x > 0.5) tmp2 = (y < 0.5) mask = tmp1 & tmp2\n\nIn other words, every intermediate step is exp..."
          ],
          [
           "In [6]:\n\nimport pandas as pd nrows, ncols = 100000, 100 rng = np.random.RandomState(42) df1, df2, df..."
          ],
          [
           "Out[9]:\n\nTrue\n\nOperations supported by pd.eval()¶As of Pandas v0.16, pd.eval() supports a wide range..."
          ],
          [
           "Out[12]:\n\nTrue\n\nBitwise operators¶pd.eval() supports the & and | bitwise operators:\n\nIn [13]:\n\nresul..."
          ],
          [
           "Out[15]:\n\nTrue\n\nOther operations¶Other operations such as function calls, conditional statements, lo..."
          ],
          [
           "0.808055\n\n0.347197\n\n4\n\n0.589161\n\n0.252418\n\n0.557789\n\nUsing pd.eval() as above, we can compute expres..."
          ],
          [
           "In [19]:\n\ndf.head()\n\nOut[19]:\n\nA\n\nB\n\nC\n\n0\n\n0.375506\n\n0.406939\n\n0.069938\n\n1\n\n0.069087\n\n0.235615\n\n0.15..."
          ],
          [
           "11.187620\n\n1\n\n0.069087\n\n0.235615\n\n0.154374\n\n1.973796\n\n2\n\n0.677945\n\n0.433839\n\n0.652324\n\n1.704344\n\n3\n\n..."
          ],
          [
           "0.154374\n\n1.078728\n\n2\n\n0.677945\n\n0.433839\n\n0.652324\n\n0.374209\n\n3\n\n0.264038\n\n0.808055\n\n0.347197\n\n1.56..."
          ],
          [
           "DataFrame.query() Method¶The DataFrame has another method based on evaluated strings, called the que..."
          ],
          [
           "In [25]:\n\nCmean = df['C'].mean() result1 = df[(df.A < Cmean) & (df.B < Cmean)] result2 = df.query('A..."
          ],
          [
           "In [28]:\n\ndf.values.nbytes\n\nOut[28]:\n\n32000\n\nOn the performance side, eval() can be faster even when..."
          ],
          [
           "Further Resources\n\n< High-Performance Pandas: eval() and query() | Contents | Visualization with Mat..."
          ],
          [
           "Pandas on PyVideo: From PyCon to SciPy to PyData, many conferences have featured tutorials from Pand..."
          ],
          [
           "Visualization with Matplotlib\n\n< Further Resources | Contents | Simple Line Plots >\n\nWe'll now take ..."
          ],
          [
           "In recent years, however, the interface and style of Matplotlib have begun to show their age. Newer ..."
          ],
          [
           "In [1]:\n\nimport matplotlib as mpl\n\nimport matplotlib.pyplot as plt\n\nThe plt interface is what we wil..."
          ],
          [
           "Plotting from a script¶If you are using Matplotlib from within a script, the function plt.show() is ..."
          ],
          [
           "Plotting from an IPython shell¶It can be very convenient to use Matplotlib interactively within an I..."
          ],
          [
           "For this book, we will generally opt for %matplotlib inline:\n\nIn [3]:\n\n%matplotlib inline\n\nAfter run..."
          ],
          [
           "r\n\n--r\n\n--  1 jakevdp  staff    16K Aug 11 10:59 my_figure.png\n\nTo confirm that it contains what we ..."
          ],
          [
           "Note that when saving your figure, it's not necessary to use plt.show() or related commands discusse..."
          ],
          [
           "It is important to note that this interface is stateful: it keeps track of the \"current\" figure and ..."
          ],
          [
           "For more simple plots, the choice of which style to use is largely a matter of preference, but the o..."
          ],
          [
           "2. Introduction to NumPy¶ Understanding Data Types in Python The Basics of NumPy Arrays Computation ..."
          ],
          [
           "Appendix: Figure Code¶\n\nSimple Line Plots | Python Data Science Handbook\n\nPython Data Science Handbo..."
          ],
          [
           "In [2]:\n\nfig = plt.figure()\n\nax = plt.axes()\n\nIn Matplotlib, the figure (an instance of the class pl..."
          ],
          [
           "In [5]:\n\nplt.plot(x, np.sin(x))\n\nplt.plot(x, np.cos(x));\n\nThat's all there is to plotting simple fun..."
          ],
          [
           "In [6]:\n\nplt.plot(x, np.sin(x - 0), color='blue')        # specify color by name plt.plot(x, np.sin(..."
          ],
          [
           "# For short, you can use the following codes: plt.plot(x, x + 4, linestyle='-')  # solid plt.plot(x,..."
          ],
          [
           "Adjusting the Plot: Axes Limits¶Matplotlib does a decent job of choosing default axes limits for you..."
          ],
          [
           "plt.axis([\n\n1, 11,\n\n1.5, 1.5]);\n\nThe plt.axis() method goes even beyond this, allowing you to do thi..."
          ],
          [
           "plt.xlabel(\"x\")\n\nplt.ylabel(\"sin(x)\");\n\nThe position, size, and style of these labels can be adjuste..."
          ],
          [
           "Aside: Matplotlib Gotchas¶While most plt functions translate directly to ax methods (such as plt.plo..."
          ],
          [
           "< Visualization with Matplotlib | Contents | Simple Scatter Plots >\n\nSimple Scatter Plots | Python D..."
          ],
          [
           "In [2]:\n\nx = np.linspace(0, 10, 30) y = np.sin(x)\n\nplt.plot(x, y, 'o', color='black');\n\nThe third ar..."
          ],
          [
           "In [4]:\n\nplt.plot(x, y, '\n\nok');\n\nAdditional keyword arguments to plt.plot specify a wide range of p..."
          ],
          [
           "In [6]:\n\nplt.scatter(x, y, marker='o');\n\nThe primary difference of plt.scatter from plt.plot is that..."
          ],
          [
           "In [8]:\n\nfrom sklearn.datasets import load_iris\n\niris = load_iris()\n\nfeatures = iris.data.T\n\nplt.sca..."
          ],
          [
           "plot Versus scatter: A Note on Efficiency¶Aside from the different features available in plt.plot an..."
          ],
          [
           "Visualizing Errors\n\n< Simple Scatter Plots | Contents | Density and Contour Plots >\n\nFor any scienti..."
          ],
          [
           "whitegrid')\n\nimport numpy as np\n\nIn [2]:\n\nx = np.linspace(0, 10, 50) dy = 0.8 y = np.sin(x) + dy * n..."
          ],
          [
           "Continuous Errors¶In some situations it is desirable to show errorbars on continuous quantities. Tho..."
          ],
          [
           "xfit = np.linspace(0, 10, 1000) yfit, MSE = gp.predict(xfit[:, np.newaxis], eval_MSE=True) dyfit = 2..."
          ],
          [
           "color='gray', alpha=0.2)\n\nplt.xlim(0, 10);\n\nNote what we've done here with the fill_between function..."
          ],
          [
           "Density and Contour Plots\n\n< Visualizing Errors | Contents | Histograms, Binnings, and Density >\n\nSo..."
          ],
          [
           "A contour plot can be created with the plt.contour function. It takes three arguments: a grid of x v..."
          ],
          [
           "In [5]:\n\nplt.contour(X, Y, Z, 20, cmap='RdGy');\n\nHere we chose the RdGy (short for Red-Gray) colorma..."
          ],
          [
           "plt.contourf(X, Y, Z, 20, cmap='RdGy') plt.colorbar();\n\nThe colorbar makes it clear that the black r..."
          ],
          [
           "There are a few potential gotchas with imshow(), however:\n\nplt.imshow() doesn't accept an x and y gr..."
          ],
          [
           "The combination of these three functions—plt.contour, plt.contourf, and plt.imshow—gives nearly limi..."
          ],
          [
           "In [1]:\n\n%matplotlib inline\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('sea..."
          ],
          [
           "plt.hist(x1, *\n\nkwargs)\n\nplt.hist(x2, *\n\nkwargs)\n\nplt.hist(x3, *\n\nkwargs);\n\nIf you would like to sim..."
          ],
          [
           "In [12]:\n\nplt.hist2d(x, y, bins=30, cmap='Blues')\n\ncb = plt.colorbar()\n\ncb.set_label('counts in bin'..."
          ],
          [
           "plt.hexbin has a number of interesting options, including the ability to specify weights for each po..."
          ],
          [
           "# Plot the result as an image plt.imshow(Z.reshape(Xgrid.shape), origin='lower', aspect='auto', exte..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "But there are many ways we might want to customize such a legend. For example, we can specify the lo..."
          ],
          [
           "In [7]:\n\ny = np.sin(x[:, np.newaxis] + np.pi * np.arange(0, 2, 0.5)) lines = plt.plot(x, y)\n\n# lines..."
          ],
          [
           "In [9]:\n\nimport pandas as pd\n\ncities = pd.read_csv('data/california_cities.csv')\n\n# Extract the data..."
          ],
          [
           "plt.title('California Cities: Area and Population');\n\nThe legend will always reference some object t..."
          ],
          [
           "In [10]:\n\nfig, ax = plt.subplots()\n\nlines = [] styles = ['-', '--', '-. ', ':'] x = np.linspace(0, 1..."
          ],
          [
           "< Histograms, Binnings, and Density | Contents | Customizing Colorbars >\n\nCustomizing Colorbars | Py..."
          ],
          [
           "In [2]:\n\n%matplotlib inline\n\nimport numpy as np\n\nAs we have seen several times throughout this secti..."
          ],
          [
           "Choosing the Colormap¶A full treatment of color choice within visualization is beyond the scope of t..."
          ],
          [
           "# convert RGBA to perceived grayscale luminance # cf. http://alienryderflex.com/hsp.html RGB_weight ..."
          ],
          [
           "In [6]:\n\nview_colormap('jet')\n\nNotice the bright stripes in the grayscale image. Even in full color,..."
          ],
          [
           "In [9]:\n\nview_colormap('RdBu')\n\nWe'll see examples of using some of these color maps as we continue...."
          ],
          [
           "plt.imshow(I, cmap='RdBu')\n\nplt.colorbar()\n\nplt.subplot(1, 2, 2)\n\nplt.imshow(I, cmap='RdBu')\n\nplt.co..."
          ],
          [
           "1, 1);\n\nThe discrete version of a colormap can be used just like any other colormap.\n\nExample: Handw..."
          ],
          [
           "Because each digit is defined by the hue of its 64 pixels, we can consider each digit to be a point ..."
          ],
          [
           "The projection also gives us some interesting insights on the relationships within the dataset: for ..."
          ],
          [
           "In [1]:\n\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn\n\nwhite')\n\nimpor..."
          ],
          [
           "In [3]:\n\nfig = plt.figure() ax1 = fig.add_axes([0.1, 0.5, 0.8, 0.4], xticklabels=[], ylim=(-1.2, 1.2..."
          ],
          [
           "In [4]:\n\nfor i in range(1, 7): plt.subplot(2, 3, i) plt.text(0.5, 0.5, str((2, 3, i)), fontsize=18, ..."
          ],
          [
           "plt.subplots: The Whole Grid in One Go¶The approach just described can become quite tedious when cre..."
          ],
          [
           "In [7]:\n\n# axes are in a two-dimensional array, indexed by [row, col] for i in range(2): for j in ra..."
          ],
          [
           "plt.subplot(grid[0, 1:])\n\nplt.subplot(grid[1, :2])\n\nplt.subplot(grid[1, 2]);\n\nThis type of flexible ..."
          ],
          [
           "# scatter points on the main axes main_ax.plot(x, y, 'ok', markersize=3, alpha=0.2)\n\n# histogram on ..."
          ],
          [
           "Text and Annotation\n\n< Multiple Subplots | Contents | Customizing Ticks >\n\nCreating a good visualiza..."
          ],
          [
           "In [2]:\n\nbirths = pd.read_csv('data/births.csv')\n\nquartiles = np.percentile(births['births'], [25, 5..."
          ],
          [
           "In [4]:\n\nfig, ax = plt.subplots(figsize=(12, 4)) births_by_date.plot(ax=ax)\n\n# Add labels to the plo..."
          ],
          [
           "# Label the axes ax.set(title='USA births by day of year (1969-1988)', ylabel='average daily births'..."
          ],
          [
           "Transforms and Text Position¶In the previous example, we have anchored our text annotations to data ..."
          ],
          [
           "ax.axis([0, 10, 0, 10])\n\n# transform=ax.transData is the default, but we'll specify it anyway ax.tex..."
          ],
          [
           "ax.set_ylim(\n\n6, 6)\n\nfig\n\nOut[6]:\n\nThis behavior can be seen more clearly by changing the axes limit..."
          ],
          [
           "ax.annotate('local minimum', xy=(5\n\nnp.pi,\n\n1), xytext=(2,\n\n6),\n\narrowprops=dict(arrowstyle=\"\n\n>\",\n\n..."
          ],
          [
           "7\n\n4', 4250),  xycoords='data',\n\nbbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\"),\n\nxytext=(10,\n\n40..."
          ],
          [
           "31', 4600),  xycoords='data',\n\nxytext=(\n\n80,\n\n40), textcoords='offset points',\n\narrowprops=dict(arro..."
          ],
          [
           "30, 0), textcoords='offset points',\n\nsize=13, ha='right', va=\"center\",\n\nbbox=dict(boxstyle=\"round\", ..."
          ],
          [
           "ax.set_ylim(3600, 5400);\n\nYou'll notice that the specifications of the arrows and text boxes are ver..."
          ],
          [
           "Customizing Ticks\n\n< Text and Annotation | Contents | Customizing Matplotlib: Configurations and Sty..."
          ],
          [
           "plt.style.use('classic')\n\n%matplotlib inline\n\nimport numpy as np\n\nIn [2]:\n\nax = plt.axes(xscale='log..."
          ],
          [
           "<matplotlib.ticker.NullFormatter object at 0x10db9af60>\n\nWe see that both major and minor tick label..."
          ],
          [
           "In [6]:\n\nfig, ax = plt.subplots(5, 5, figsize=(5, 5)) fig.subplots_adjust(hspace=0, wspace=0)\n\n# Get..."
          ],
          [
           "In [7]:\n\nfig, ax = plt.subplots(4, 4, sharex=True, sharey=True)\n\nParticularly for the x ticks, the n..."
          ],
          [
           "In [9]:\n\n# Plot a sine and cosine curve fig, ax = plt.subplots() x = np.linspace(0, 3 * np.pi, 1000)..."
          ],
          [
           "fig\n\nOut[10]:\n\nBut now these tick labels look a little bit silly: we can see that they are multiples..."
          ],
          [
           "fig\n\nOut[11]:\n\nThis is much better! Notice that we've made use of Matplotlib's LaTeX support, specif..."
          ],
          [
           "AutoLocator (Default.) MaxNLocator with simple defaults.\n\nAutoMinorLocator\n\nLocator for minor ticks\n..."
          ],
          [
           "Customizing Matplotlib: Configurations and Stylesheets\n\n< Customizing Ticks | Contents | Three-Dimen..."
          ],
          [
           "# use a gray background ax = plt.axes(axisbg='#E6E6E6') ax.set_axisbelow(True)\n\n# draw solid white g..."
          ],
          [
           "Changing the Defaults: rcParams¶Each time Matplotlib loads, it defines a runtime configuration (rc) ..."
          ],
          [
           "plt.rc('ytick', direction='out', color='gray')\n\nplt.rc('patch', edgecolor='#E6E6E6')\n\nplt.rc('lines'..."
          ],
          [
           "Stylesheets¶The version 1.4 release of Matplotlib in August 2014 added a very convenient style modul..."
          ],
          [
           "Let's create a function that will make two basic types of plot:\n\nIn [9]:\n\ndef hist_and_lines(): np.r..."
          ],
          [
           "with plt.style.context('fivethirtyeight'):\n\nhist_and_lines()\n\nggplot¶The ggplot package in the R lan..."
          ],
          [
           "In [16]:\n\nwith plt.style.context('grayscale'):\n\nhist_and_lines()\n\nSeaborn style¶Matplotlib also has ..."
          ],
          [
           "Dimensional Plotting in Matplotlib\n\n< Customizing Matplotlib: Configurations and Stylesheets | Conte..."
          ],
          [
           "Three-dimensional Points and Lines¶The most basic three-dimensional plot is a line or collection of ..."
          ],
          [
           "Notice that by default, the scatter points have their transparency adjusted to give a sense of depth..."
          ],
          [
           "Sometimes the default viewing angle is not optimal, in which case we can use the view_init method to..."
          ],
          [
           "In [9]:\n\nax = plt.axes(projection='3d') ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='viridis..."
          ],
          [
           "In [11]:\n\ntheta = 2\n\nnp.pi\n\nnp.random.random(1000)\n\nr = 6\n\nnp.random.random(1000)\n\nx = np.ravel(r\n\nn..."
          ],
          [
           "ax.plot_trisurf(x, y, z,\n\ncmap='viridis', edgecolor='none');\n\nThe result is certainly not as clean a..."
          ],
          [
           "Now from this parametrization, we must determine the (x, y, z) positions of the embedded strip. Thin..."
          ],
          [
           "In [17]:\n\n# triangulate in the underlying parametrization from matplotlib.tri import Triangulation t..."
          ],
          [
           "Geographic Data with Basemap\n\n< Three-Dimensional Plotting in Matplotlib | Contents | Visualization ..."
          ],
          [
           "In [2]:\n\nplt.figure(figsize=(8, 8)) m = Basemap(projection='ortho', resolution=None, lat_0=50, lon_0..."
          ],
          [
           "This gives you a brief glimpse into the sort of geographic visualizations that are possible with jus..."
          ],
          [
           "# keys contain the plt.Line2D instances lat_lines = chain(*(tup[1][0] for tup in lats.items())) lon_..."
          ],
          [
           "The additional arguments to Basemap for this view specify the latitude (lat) and longitude (lon) of ..."
          ],
          [
           "The extra arguments to Basemap here refer to the central latitude (lat_0) and longitude (lon_0) for ..."
          ],
          [
           "lat_0=50, lon_0=0)\n\ndraw_map(m);\n\nConic projections¶A Conic projection projects the map onto a singl..."
          ],
          [
           "width=1.6E7, height=1.2E7)\n\ndraw_map(m)\n\nOther projections¶If you're going to do much with map-based..."
          ],
          [
           "Political boundaries\n\ndrawcountries(): Draw country boundaries drawstates(): Draw US state boundarie..."
          ],
          [
           "In [9]:\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 8))\n\nfor i, res in enumerate(['l', 'h']): m = Bas..."
          ],
          [
           "Plotting Data on Maps¶Perhaps the most useful piece of the Basemap toolkit is the ability to over-pl..."
          ],
          [
           "We'll see some examples of a few of these as we continue. For more information on these functions, i..."
          ],
          [
           "# 2. scatter city data, with color reflecting population # and size reflecting area m.scatter(lon, l..."
          ],
          [
           "In [12]:\n\n# !curl\n\nO http://data.giss.nasa.gov/pub/gistemp/gistemp250.nc.gz\n\n# !gunzip gistemp250.nc..."
          ],
          [
           "Finally, we'll use the pcolormesh() method to draw a color mesh of the data. We'll look at North Ame..."
          ],
          [
           "< Three-Dimensional Plotting in Matplotlib | Contents | Visualization with Seaborn >\n\nVisualization ..."
          ],
          [
           "An answer to these problems is Seaborn. Seaborn provides an API on top of Matplotlib that offers san..."
          ],
          [
           "And do a simple plot:\n\nIn [3]:\n\n# Plot the data with Matplotlib defaults plt.plot(x, y) plt.legend('..."
          ],
          [
           "Ah, much better!\n\nExploring Seaborn Plots¶The main idea of Seaborn is that it provides high-level co..."
          ],
          [
           "Histograms and KDE can be combined using distplot:\n\nIn [8]:\n\nsns.distplot(data['x'])\n\nsns.distplot(d..."
          ],
          [
           "sns.jointplot(\"x\", \"y\", data, kind='hex')\n\nPair plots¶When you generalize joint plots to datasets of..."
          ],
          [
           "setosa\n\n4\n\n5.0\n\n3.6\n\n1.4\n\n0.2\n\nsetosa\n\nVisualizing the multidimensional relationships among the samp..."
          ],
          [
           "2\n\n21.01\n\n3.50\n\nMale\n\nNo\n\nSun\n\nDinner\n\n3\n\n3\n\n23.68\n\n3.31\n\nMale\n\nNo\n\nSun\n\nDinner\n\n2\n\n4\n\n24.59\n\n3.61\n\n..."
          ],
          [
           "Joint distributions¶Similar to the pairplot we saw earlier, we can use sns.jointplot to show the joi..."
          ],
          [
           "2.21\n\n56.95\n\n2008\n\n2\n\nRadial Velocity\n\n1\n\n763.000\n\n2.60\n\n19.84\n\n2011\n\n3\n\nRadial Velocity\n\n1\n\n326.030..."
          ],
          [
           "For more information on plotting with Seaborn, see the Seaborn documentation, a tutorial, and the Se..."
          ],
          [
           "M\n\n01:06:49\n\n02:10:42\n\n3\n\n38\n\nM\n\n01:06:16\n\n02:13:45\n\n4\n\n31\n\nM\n\n01:06:32\n\n02:13:59\n\nBy default, Panda..."
          ],
          [
           "33\n\nM\n\n01:05:38\n\n02:08:51\n\n1\n\n32\n\nM\n\n01:06:26\n\n02:09:28\n\n2\n\n31\n\nM\n\n01:06:49\n\n02:10:42\n\n3\n\n38\n\nM\n\n01:..."
          ],
          [
           "split_sec\n\nfinal_sec\n\n0\n\n33\n\nM\n\n01:05:38\n\n02:08:51\n\n3938.0\n\n7731.0\n\n1\n\n32\n\nM\n\n01:06:26\n\n02:09:28\n\n39..."
          ],
          [
           "The dotted line shows where someone's time would lie if they ran the marathon at a perfectly steady ..."
          ],
          [
           "0.026262\n\n2\n\n31\n\nM\n\n01:06:49\n\n02:10:42\n\n4009.0\n\n7842.0\n\n0.022443\n\n3\n\n38\n\nM\n\n01:06:16\n\n02:13:45\n\n3976..."
          ],
          [
           "In [31]:\n\nsum(data.split_frac < 0)\n\nOut[31]:\n\n251\n\nOut of nearly 40,000 participants, there were onl..."
          ],
          [
           "sns.kdeplot(data.split_frac[data.gender=='M'], label='men', shade=True)\n\nsns.kdeplot(data.split_frac..."
          ],
          [
           "age\n\ngender\n\nsplit\n\nfinal\n\nsplit_sec\n\nfinal_sec\n\nsplit_frac\n\nage_dec\n\n0\n\n33\n\nM\n\n01:05:38\n\n02:08:51\n\n..."
          ],
          [
           "8039.0\n\n0.006842\n\n30\n\nIn [36]:\n\nmen = (data.gender == 'M') women = (data.gender == 'W')\n\nwith sns.ax..."
          ],
          [
           "In [37]:\n\ng = sns.lmplot('final_sec', 'split_frac', col='gender', data=data, markers=\". \", scatter_k..."
          ],
          [
           "Further Resources\n\n< Visualization with Seaborn | Contents | Machine Learning >\n\nMatplotlib Resource..."
          ],
          [
           "Bokeh is a JavaScript visualization library with a Python frontend that creates highly interactive v..."
          ],
          [
           "Machine Learning | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAbout\n\nArchive\n\nThis ..."
          ],
          [
           "Machine Learning\n\n< Further Resources | Contents | What Is Machine Learning? >\n\nIn many ways, machin..."
          ],
          [
           "Much of this material is drawn from the Scikit-Learn tutorials and workshops I have given on several..."
          ],
          [
           "2. Introduction to NumPy¶ Understanding Data Types in Python The Basics of NumPy Arrays Computation ..."
          ],
          [
           "Appendix: Figure Code¶\n\nWhat Is Machine Learning? | Python Data Science Handbook\n\nPython Data Scienc..."
          ],
          [
           "What Is Machine Learning?\n\n< Machine Learning | Contents | Introducing Scikit-Learn >\n\nBefore we tak..."
          ],
          [
           "Categories of Machine Learning¶At the most fundamental level, machine learning can be categorized in..."
          ],
          [
           "Classification: Predicting discrete labels¶We will first take a look at a simple classification task..."
          ],
          [
           "figure source in Appendix\n\nNow that this model has been trained, it can be generalized to new, unlab..."
          ],
          [
           "For the training set, these labels might be determined by individual inspection of a small represent..."
          ],
          [
           "figure source in Appendix\n\nNotice that the feature 1-feature 2 plane here is the same as in the two-..."
          ],
          [
           "The distances for a small number of these galaxies might be determined through an independent set of..."
          ],
          [
           "figure source in Appendix\n\nk-means fits a model consisting of k cluster centers; the optimal centers..."
          ],
          [
           "figure source in Appendix\n\nVisually, it is clear that there is some structure in this data: it is dr..."
          ],
          [
           "Summary¶Here we have seen a few simple examples of some of the basic types of machine learning appro..."
          ],
          [
           "Introducing Scikit\n\nLearn\n\n< What Is Machine Learning? | Contents | Hyperparameters and Model Valida..."
          ],
          [
           "In [1]:\n\nimport seaborn as sns\n\niris = sns.load_dataset('iris')\n\niris.head()\n\nOut[1]:\n\nsepal_length\n..."
          ],
          [
           "4\n\n5.0\n\n3.6\n\n1.4\n\n0.2\n\nsetosa\n\nHere each row of the data refers to a single observed flower, and the..."
          ],
          [
           "Target array¶In addition to the feature matrix X, we also generally work with a label or target arra..."
          ],
          [
           "In [3]:\n\nX_iris = iris.drop('species', axis=1)\n\nX_iris.shape\n\nOut[3]:\n\n(150, 4)\n\nIn [4]:\n\ny_iris = i..."
          ],
          [
           "Sensible defaults: When models require user-specified parameters, the library defines an appropriate..."
          ],
          [
           "In [5]:\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\nrng = np.random.RandomState(42)\n\nx = 1..."
          ],
          [
           "Would we like to fit for the offset (i.e., y-intercept)? Would we like the model to be normalized? W..."
          ],
          [
           "3. Arrange data into a features matrix and target vector¶Previously we detailed the Scikit-Learn dat..."
          ],
          [
           "model.coef_\n\nOut[10]:\n\narray([ 1.9776566])\n\nIn [11]:\n\nmodel.intercept_\n\nOut[11]:\n\n0.9033107255311163..."
          ],
          [
           "In [13]:\n\nXfit = xfit[:, np.newaxis]\n\nyfit = model.predict(Xfit)\n\nFinally, let's visualize the resul..."
          ],
          [
           "In [15]:\n\nfrom sklearn.cross_validation import train_test_split Xtrain, Xtest, ytrain, ytest = train..."
          ],
          [
           "With an accuracy topping 97%, we see that even this very naive classification algorithm is effective..."
          ],
          [
           "In [19]:\n\niris['PCA1'] = X_2D[:, 0] iris['PCA2'] = X_2D[:, 1] sns.lmplot(\"PCA1\", \"PCA2\", hue='specie..."
          ],
          [
           "As before, we will add the cluster label to the Iris DataFrame and use Seaborn to plot the results:\n..."
          ],
          [
           "In [22]:\n\nfrom sklearn.datasets import load_digits\n\ndigits = load_digits()\n\ndigits.images.shape\n\nOut..."
          ],
          [
           "In order to work with this data within Scikit-Learn, we need a two-dimensional, [n_samples, n_featur..."
          ],
          [
           "iso = Isomap(n_components=2)\n\niso.fit(digits.data)\n\ndata_projected = iso.transform(digits.data)\n\ndat..."
          ],
          [
           "This plot gives us some good intuition into how well various numbers are separated in the larger 64-..."
          ],
          [
           "In [30]:\n\nfrom sklearn.metrics import accuracy_score\n\naccuracy_score(ytest, y_model)\n\nOut[30]:\n\n0.83..."
          ],
          [
           "In [32]:\n\nfig, axes = plt.subplots(10, 10, figsize=(8, 8), subplot_kw={'xticks':[], 'yticks':[]}, gr..."
          ],
          [
           "Summary¶\n\nIn this section we have covered the essential features of the Scikit-Learn data representa..."
          ],
          [
           "Choose a class of model Choose model hyperparameters Fit the model to the training data Use the mode..."
          ],
          [
           "In [2]:\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nmodel = KNeighborsClassifier(n_neighbor..."
          ],
          [
           "Model validation the right way: Holdout sets¶So what can be done? A better sense of a model's perfor..."
          ],
          [
           "Model validation via cross-validation¶One disadvantage of using a holdout set for model validation i..."
          ],
          [
           "(0.95999999999999996, 0.90666666666666662)\n\nWhat comes out are two accuracy scores, which we could c..."
          ],
          [
           "Repeating the validation across different subsets of the data gives us an even better idea of the pe..."
          ],
          [
           "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  1.,  1.,  1.,  1.,..."
          ],
          [
           "1.,  1.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 1...."
          ],
          [
           "1., 1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  1.,  1.,  1.,  0.,  1...."
          ],
          [
           "1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1..."
          ],
          [
           "1.,  1., 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  1.,  1.,  1.,  1...."
          ],
          [
           "Because we have 150 samples, the leave one out cross-validation yields scores for 150 trials, and th..."
          ],
          [
           "The Bias-variance trade-off¶Fundamentally, the question of \"the best model\" is about finding a sweet..."
          ],
          [
           "figure source in Appendix The score here is the $R^2$ score, or coefficient of determination, which ..."
          ],
          [
           "The means of tuning the model complexity varies from model to model; when we discuss individual mode..."
          ],
          [
           "LinearRegression(*\n\nkwargs))\n\nNow let's create some data to which we will fit our model:\n\nIn [11]:\n\n..."
          ],
          [
           "X_test = np.linspace(\n\n0.1, 1.1, 500)[:, None]\n\nplt.scatter(X.ravel(), y, color='black') axis = plt...."
          ],
          [
           "plt.plot(degree, np.median(train_score, 1), color='blue', label='training score') plt.plot(degree, n..."
          ],
          [
           "Learning Curves¶One important aspect of model complexity is that the optimal model will generally de..."
          ],
          [
           "The solid lines show the new results, while the fainter dashed lines show the results of the previou..."
          ],
          [
           "With these features in mind, we would expect a learning curve to look qualitatively like that shown ..."
          ],
          [
           "ax[i].plot(N, np.mean(train_lc, 1), color='blue', label='training score') ax[i].plot(N, np.mean(val_..."
          ],
          [
           "ax[i].legend(loc='best')\n\nThis is a valuable diagnostic, because it gives us a visual depiction of h..."
          ],
          [
           "Validation in Practice: Grid Search¶The preceding discussion is meant to give you some intuition int..."
          ],
          [
           "In [19]:\n\ngrid.fit(X, y);\n\nNow that this is fit, we can ask for the best parameters as follows:\n\nIn ..."
          ],
          [
           "Summary¶In this section, we have begun to explore the concept of model validation and hyperparameter..."
          ],
          [
           "Feature Engineering\n\n< Hyperparameters and Model Validation | Contents | In Depth: Naive Bayes Class..."
          ],
          [
           "You might be tempted to encode this data with a straightforward numerical mapping:\n\nIn [2]:\n\n{'Queen..."
          ],
          [
           "Notice that the 'neighborhood' column has been expanded into three separate columns, representing th..."
          ],
          [
           "Text Features¶Another common need in feature engineering is to convert text to a set of representati..."
          ],
          [
           "In [8]:\n\nimport pandas as pd\n\npd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n\nOut[8]:\n\ne..."
          ],
          [
           "Out[9]:\n\nevil\n\nhorizon\n\nof\n\nproblem\n\nqueen\n\n0\n\n0.517856\n\n0.000000\n\n0.680919\n\n0.517856\n\n0.000000\n\n1\n\n..."
          ],
          [
           "Derived Features¶Another useful type of feature is one that is mathematically derived from some inpu..."
          ],
          [
           "plt.scatter(x, y)\n\nplt.plot(x, yfit);\n\nIt's clear that we need a more sophisticated model to describ..."
          ],
          [
           "plt.scatter(x, y)\n\nplt.plot(x, yfit);\n\nThis idea of improving a model not by changing the model, but..."
          ],
          [
           "When applying a typical machine learning model to such data, we will need to first replace such miss..."
          ],
          [
           "model = LinearRegression().fit(X2, y)\n\nmodel.predict(X2)\n\nOut[16]:\n\narray([ 13.14869292,  14.3784627..."
          ],
          [
           "1  8\n\n5]\n\n[ 14. 16.\n\n1. 8.\n\n5.]\n\nAll the steps of the model are applied automatically. Notice that f..."
          ],
          [
           "In Depth: Naive Bayes Classification\n\n< Feature Engineering | Contents | In Depth: Linear Regression..."
          ],
          [
           "Bayesian Classification¶Naive Bayes classifiers are built on Bayesian classification methods. These ..."
          ],
          [
           "quantities we can compute more directly: $$ P(L~|~{\\rm features}) = \\frac{P({\\rm features}~|~L)P(L)}..."
          ],
          [
           "= \\frac{P({\\rm features}~|~L_1)}{P({\\rm features}~|~L_2)}\\frac{P(L_1)}{P(L_2)} $$ All we need now is..."
          ],
          [
           "of such a Bayesian classifier. The general version of such a training step is a very difficult task,..."
          ],
          [
           "This is where the \"naive\" in \"naive Bayes\" comes in: if we make very naive assumptions about the gen..."
          ],
          [
           "figure source in Appendix\n\nThe ellipses here represent the Gaussian generative model for each label,..."
          ],
          [
           "Now we can plot this new data to get an idea of where the decision boundary is:\n\nIn [5]:\n\nplt.scatte..."
          ],
          [
           "The columns give the posterior probabilities of the first and second label, respectively. If you are..."
          ],
          [
           "In [7]:\n\nfrom sklearn.datasets import fetch_20newsgroups\n\ndata = fetch_20newsgroups()\n\ndata.target_n..."
          ],
          [
           "In [8]:\n\ncategories = ['talk.religion.misc', 'soc.religion.christian',\n\n'sci.space', 'comp.graphics'..."
          ],
          [
           "In [10]:\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.naive_bayes impo..."
          ],
          [
           "Evidently, even this very simple classifier can successfully separate space talk from computer talk,..."
          ],
          [
           "When to Use Naive Bayes¶Because naive Bayesian classifiers make such stringent assumptions about dat..."
          ],
          [
           "< Feature Engineering | Contents | In Depth: Linear Regression >\n\nIn Depth: Linear Regression | Pyth..."
          ],
          [
           "Simple Linear Regression¶We will start with the most familiar linear regression, a straight-line fit..."
          ],
          [
           "plt.scatter(x, y)\n\nplt.plot(xfit, yfit);\n\nThe slope and intercept of the data are contained in the m..."
          ],
          [
           "In [5]:\n\nrng = np.random.RandomState(1) X = 10 * rng.rand(100, 3) y = 0.5 + np.dot(X, [1.5, -2., 1.]..."
          ],
          [
           "Basis Function Regression¶One trick you can use to adapt linear regression to nonlinear relationship..."
          ],
          [
           "In [6]:\n\nfrom sklearn.preprocessing import PolynomialFeatures x = np.array([2, 3, 4]) poly = Polynom..."
          ],
          [
           "poly_model.fit(x[:, np.newaxis], y)\n\nyfit = poly_model.predict(xfit[:, np.newaxis])\n\nplt.scatter(x, ..."
          ],
          [
           "def __init__(self, N, width_factor=2.0):\n\nself.N = N\n\nself.width_factor = width_factor\n\n@staticmetho..."
          ],
          [
           "plt.plot(xfit, yfit)\n\nplt.xlim(0, 10);\n\nWe put this example here just to make clear that there is no..."
          ],
          [
           "In [11]:\n\ndef basis_plot(model, title=None): fig, ax = plt.subplots(2, sharex=True) model.fit(x[:, n..."
          ],
          [
           "Ridge regression ($L_2$ Regularization)¶Perhaps the most common form of regularization is known as r..."
          ],
          [
           "Lasso regression ($L_1$ regularization)¶Another very common type of regularization is known as lasso..."
          ],
          [
           "Example: Predicting Bicycle Traffic¶\n\nAs an example, let's take a look at whether we can predict the..."
          ],
          [
           "xm6k/rows.csv?accessType=DOWNLOAD\n\nIn [15]:\n\nimport pandas as pd counts = pd.read_csv('FremontBridge..."
          ],
          [
           "Similarly, we might expect riders to behave differently on holidays; let's add an indicator of this ..."
          ],
          [
           "plt.ylim(8, 17)\n\nOut[19]:\n\n(8, 17)\n\nWe can also add the average temperature and total precipitation ..."
          ],
          [
           "In [22]:\n\ndaily.head()\n\nOut[22]:\n\nTotal\n\nMon\n\nTue\n\nWed\n\nThu\n\nFri\n\nSat\n\nSun\n\nholiday\n\ndaylight_hrs\n\nP..."
          ],
          [
           "0.002740\n\n2012\n\n10\n\n05\n\n3148.0\n\n0.0\n\n0.0\n\n0.0\n\n0.0\n\n1.0\n\n0.0\n\n0.0\n\n0.0\n\n11.161038\n\n0.0\n\n15.30\n\n1.0\n\n..."
          ],
          [
           "0.0\n\n15.85\n\n1.0\n\n0.010959\n\nWith this in place, we can choose the columns to use, and fit a linear re..."
          ],
          [
           "In [24]:\n\ndaily[['Total', 'predicted']].plot(alpha=0.5);\n\nIt is evident that we have missed some key..."
          ],
          [
           "In [26]:\n\nfrom sklearn.utils import resample np.random.seed(1) err = np.std([model.fit(*resample(X, ..."
          ],
          [
           "We first see that there is a relatively stable trend in the weekly baseline: there are many more rid..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "# use seaborn plotting defaults import seaborn as sns; sns.set()\n\nMotivating Support Vector Machines..."
          ],
          [
           "In [3]:\n\nxfit = np.linspace(-1, 3.5) plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn') plt.plo..."
          ],
          [
           "In [4]:\n\nxfit = np.linspace(-1, 3.5) plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n\nfor m,..."
          ],
          [
           "In [5]:\n\nfrom sklearn.svm import SVC # \"Support vector classifier\" model = SVC(kernel='linear', C=1E..."
          ],
          [
           "# create grid to evaluate model x = np.linspace(xlim[0], xlim[1], 30) y = np.linspace(ylim[0], ylim[..."
          ],
          [
           "This is the dividing line that maximizes the margin between the two sets of points. Notice that a fe..."
          ],
          [
           "In [9]:\n\ndef plot_svm(N=10, ax=None): X, y = make_blobs(n_samples=200, centers=2, random_state=0, cl..."
          ],
          [
           "If you are running this notebook live, you can use IPython's interactive widgets to view this featur..."
          ],
          [
           "It is clear that no linear discrimination will ever be able to separate this data. But we can draw a..."
          ],
          [
           "180, 180),\n\nX=fixed(X), y=fixed(y));\n\nWe can see that with this additional dimension, the data becom..."
          ],
          [
           "clf = SVC(kernel='rbf', C=1E6)\n\nclf.fit(X, y)\n\nOut[14]:\n\nSVC(C=1000000.0, cache_size=200, class_weig..."
          ],
          [
           "In [16]:\n\nX, y = make_blobs(n_samples=100, centers=2, random_state=0, cluster_std=1.2) plt.scatter(X..."
          ],
          [
           "for axi, C in zip(ax, [10.0, 0.1]): model = SVC(kernel='linear', C=C).fit(X, y) axi.scatter(X[:, 0],..."
          ],
          [
           "print(faces.target_names)\n\nprint(faces.images.shape)\n\n['Ariel Sharon' 'Colin Powell' 'Donald Rumsfel..."
          ],
          [
           "from sklearn.decomposition import RandomizedPCA\n\nfrom sklearn.pipeline import make_pipeline\n\npca = R..."
          ],
          [
           "%time grid.fit(Xtrain, ytrain)\n\nprint(grid.best_params_)\n\nCPU times: user 47.8 s, sys: 4.08 s, total..."
          ],
          [
           "Out of this small sample, our optimal estimator mislabeled only a single face (Bush’s face in the bo..."
          ],
          [
           "We might also display the confusion matrix between these classes:\n\nIn [26]:\n\nfrom sklearn.metrics im..."
          ],
          [
           "Support Vector Machine Summary¶We have seen here a brief intuitive introduction to the principals be..."
          ],
          [
           "< In Depth: Linear Regression | Contents | In-Depth: Decision Trees and Random Forests >\n\nIn-Depth: ..."
          ],
          [
           "In [1]:\n\n%matplotlib inline import numpy as np import matplotlib.pyplot as plt import seaborn as sns..."
          ],
          [
           "In [2]:\n\nfrom sklearn.datasets import make_blobs\n\nX, y = make_blobs(n_samples=300, centers=4, random..."
          ],
          [
           "Let's write a quick utility function to help us visualize the output of the classifier:\n\nIn [4]:\n\nde..."
          ],
          [
           "Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n\n# Create a color plot with the r..."
          ],
          [
           "Notice that as the depth increases, we tend to get very strangely shaped classification regions; for..."
          ],
          [
           "In [7]:\n\n# helpers_05_08 is found in the online appendix import helpers_05_08 helpers_05_08.randomiz..."
          ],
          [
           "bag.fit(X, y)\n\nvisualize_classifier(bag, X, y)\n\nIn this example, we have randomized the data by fitt..."
          ],
          [
           "We see that by averaging over 100 randomly perturbed models, we end up with an overall model that is..."
          ],
          [
           "from sklearn.ensemble import RandomForestRegressor\n\nforest = RandomForestRegressor(200)\n\nforest.fit(..."
          ],
          [
           "dict_keys(['target', 'data', 'target_names', 'DESCR', 'images'])\n\nTo remind us what we're looking at..."
          ],
          [
           "We can take a look at the classification report for this classifier:\n\nIn [15]:\n\nfrom sklearn import ..."
          ],
          [
           "Both training and prediction are very fast, because of the simplicity of the underlying decision tre..."
          ],
          [
           "In Depth: Principal Component Analysis\n\n< In-Depth: Decision Trees and Random Forests | Contents | I..."
          ],
          [
           "In [2]:\n\nrng = np.random.RandomState(1) X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T plt.scatter(..."
          ],
          [
           "[[ 0.94446029  0.32862557]\n\n[ 0.32862557\n\n0.94446029]]\n\nIn [5]:\n\nprint(pca.explained_variance_)\n\n[ 0..."
          ],
          [
           "These vectors represent the principal axes of the data, and the length of the vector is an indicatio..."
          ],
          [
           "In [8]:\n\nX_new = pca.inverse_transform(X_pca) plt.scatter(X[:, 0], X[:, 1], alpha=0.2) plt.scatter(X..."
          ],
          [
           "digits = load_digits()\n\ndigits.data.shape\n\nOut[9]:\n\n(1797, 64)\n\nRecall that the data consists of 8×8..."
          ],
          [
           "plt.ylabel('component 2')\n\nplt.colorbar();\n\nRecall what these components mean: the full data is a 64..."
          ],
          [
           "What do the components mean?¶We can go a bit further here, and begin to ask what the reduced dimensi..."
          ],
          [
           "But the pixel-wise representation is not the only choice of basis. We can also use other basis funct..."
          ],
          [
           "In [12]:\n\npca = PCA().fit(digits.data)\n\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\n\nplt.xlab..."
          ],
          [
           "In [13]:\n\ndef plot_digits(data): fig, axes = plt.subplots(4, 10, figsize=(10, 4), subplot_kw={'xtick..."
          ],
          [
           "In [16]:\n\ncomponents = pca.transform(noisy)\n\nfiltered = pca.inverse_transform(components)\n\nplot_digi..."
          ],
          [
           "Let's take a look at the principal axes that span this dataset. Because this is a large dataset, we ..."
          ],
          [
           "In [19]:\n\nfig, axes = plt.subplots(3, 8, figsize=(9, 4), subplot_kw={'xticks':[], 'yticks':[]}, grid..."
          ],
          [
           "In [21]:\n\n# Compute the components and projected faces pca = RandomizedPCA(150).fit(faces.data) comp..."
          ],
          [
           "ax[1, 0].set_ylabel('150\n\ndim\\nreconstruction');\n\nThe top row here shows the input images, while the..."
          ],
          [
           "Principal Component Analysis Summary¶In this section we have discussed the use of principal componen..."
          ],
          [
           "< In-Depth: Decision Trees and Random Forests | Contents | In-Depth: Manifold Learning >\n\nIn-Depth: ..."
          ],
          [
           "In\n\nDepth: Manifold Learning\n\n< In Depth: Principal Component Analysis | Contents | In Depth: k-Mean..."
          ],
          [
           "Here we will demonstrate a number of manifold methods, going most deeply into a couple techniques: m..."
          ],
          [
           "# Open this PNG and draw random points from it from matplotlib.image import imread data = imread('he..."
          ],
          [
           "Multidimensional Scaling (MDS)¶Looking at data like this, we can see that the particular choice of x..."
          ],
          [
           "In [5]:\n\nfrom sklearn.metrics import pairwise_distances\n\nD = pairwise_distances(X)\n\nD.shape\n\nOut[5]:..."
          ],
          [
           "np.allclose(D, D2)\n\nOut[7]:\n\nTrue\n\nThis distance matrix gives us a representation of our data that i..."
          ],
          [
           "MDS as Manifold Learning¶The usefulness of this becomes more apparent when we consider the fact that..."
          ],
          [
           "We can now ask the MDS estimator to input this three-dimensional data, compute the distance matrix, ..."
          ],
          [
           "0.75\n\nnp.pi\n\nx = np.sin(t)\n\ny = X[:, 1]\n\nz = np.sign(t)\n\n(np.cos(t)\n\n1)\n\nreturn np.vstack((x, y, z))..."
          ],
          [
           "The best two-dimensional linear embeding does not unwrap the S-curve, but instead throws out the ori..."
          ],
          [
           "figure source in Appendix\n\nHere each faint line represents a distance that should be preserved in th..."
          ],
          [
           "fig, ax = plt.subplots() ax.scatter(out[:, 0], out[:, 1], **colorize) ax.set_ylim(0.15, -0.15);\n\nThe..."
          ],
          [
           "In manifold learning, there is no good framework for handling missing data. In contrast, there are s..."
          ],
          [
           "For toy problems such as the S-curve we saw before, locally linear embedding (LLE) and its variants ..."
          ],
          [
           "In [16]:\n\nfrom sklearn.datasets import fetch_lfw_people\n\nfaces = fetch_lfw_people(min_faces_per_pers..."
          ],
          [
           "plt.plot(np.cumsum(model.explained_variance_ratio_))\n\nplt.xlabel('n components')\n\nplt.ylabel('cumula..."
          ],
          [
           "proj = model.fit_transform(data) ax.plot(proj[:, 0], proj[:, 1], '.k')\n\nif images is not None: min_d..."
          ],
          [
           "The result is interesting: the first two Isomap dimensions seem to describe global image features: t..."
          ],
          [
           "In [23]:\n\nfig, ax = plt.subplots(6, 8, subplot_kw=dict(xticks=[], yticks=[])) for i, axi in enumerat..."
          ],
          [
           "The resulting scatter plot shows some of the relationships between the data points, but is a bit cro..."
          ],
          [
           "< In Depth: Principal Component Analysis | Contents | In Depth: k-Means Clustering >\n\nIn Depth: k-Me..."
          ],
          [
           "Introducing k\n\nMeans¶\n\nThe k-means algorithm searches for a pre-determined number of clusters within..."
          ],
          [
           "kmeans = KMeans(n_clusters=4)\n\nkmeans.fit(X)\n\ny_kmeans = kmeans.predict(X)\n\nLet's visualize the resu..."
          ],
          [
           "k\n\nMeans Algorithm: Expectation–Maximization¶\n\nExpectation–maximization (E–M) is a powerful algorith..."
          ],
          [
           "In [5]:\n\nfrom sklearn.metrics import pairwise_distances_argmin\n\ndef find_clusters(X, n_clusters, rse..."
          ],
          [
           "Caveats of expectation–maximization¶There are a few issues to be aware of when using the expectation..."
          ],
          [
           "Whether the result is meaningful is a question that is difficult to answer definitively; one approac..."
          ],
          [
           "This situation is reminiscent of the discussion in In-Depth: Support Vector Machines, where we used ..."
          ],
          [
           "We see that with this kernel transform approach, the kernelized k-means is able to find the more com..."
          ],
          [
           "In [11]:\n\nfrom sklearn.datasets import load_digits\n\ndigits = load_digits()\n\ndigits.data.shape\n\nOut[1..."
          ],
          [
           "We see that even without the labels, KMeans is able to find clusters whose centers are recognizable ..."
          ],
          [
           "In [16]:\n\nfrom sklearn.metrics import confusion_matrix mat = confusion_matrix(digits.target, labels)..."
          ],
          [
           "clusters = kmeans.fit_predict(digits_proj)\n\n# Permute the labels labels = np.zeros_like(clusters) fo..."
          ],
          [
           "The image itself is stored in a three-dimensional array of size (height, width, RGB), containing red..."
          ],
          [
           "fig, ax = plt.subplots(1, 2, figsize=(16, 6)) ax[0].scatter(R, G, color=colors, marker='.') ax[0].se..."
          ],
          [
           "kmeans = MiniBatchKMeans(16)\n\nkmeans.fit(data)\n\nnew_colors = kmeans.cluster_centers_[kmeans.predict(..."
          ],
          [
           "< In-Depth: Manifold Learning | Contents | In Depth: Gaussian Mixture Models >\n\nIn Depth: Gaussian M..."
          ],
          [
           "Motivating GMM: Weaknesses of k-Means¶Let's take a look at some of the weaknesses of k-means and thi..."
          ],
          [
           "From an intuitive standpoint, we might expect that the clustering assignment for some points is more..."
          ],
          [
           "# plot the representation of the KMeans model centers = kmeans.cluster_centers_ radii = [cdist(X[lab..."
          ],
          [
           "plot_kmeans(kmeans, X_stretched)\n\nBy eye, we recognize that these transformed clusters are non-circu..."
          ],
          [
           "In [7]:\n\nfrom sklearn.mixture import GMM gmm = GMM(n_components=4).fit(X) labels = gmm.predict(X) pl..."
          ],
          [
           "In [9]:\n\nsize = 50 * probs.max(1) ** 2  # square emphasizes differences plt.scatter(X[:, 0], X[:, 1]..."
          ],
          [
           "# Convert covariance to principal axes if covariance.shape == (2, 2): U, s, Vt = np.linalg.svd(covar..."
          ],
          [
           "With this in place, we can take a look at what the four-component GMM gives us for our initial data:..."
          ],
          [
           "This makes clear that GMM addresses the two main practical issues with k-means encountered before.\n\n..."
          ],
          [
           "In [13]:\n\nfrom sklearn.datasets import make_moons Xmoon, ymoon = make_moons(200, noise=.05, random_s..."
          ],
          [
           "In [16]:\n\nXnew = gmm16.sample(400, random_state=42)\n\nplt.scatter(Xnew[:, 0], Xnew[:, 1]);\n\nGMM is co..."
          ],
          [
           "plt.plot(n_components, [m.bic(Xmoon) for m in models], label='BIC') plt.plot(n_components, [m.aic(Xm..."
          ],
          [
           "digits = load_digits()\n\ndigits.data.shape\n\nOut[18]:\n\n(1797, 64)\n\nNext let's plot the first 100 of th..."
          ],
          [
           "data.shape\n\nOut[20]:\n\n(1797, 41)\n\nThe result is 41 dimensions, a reduction of nearly 1/3 with almost..."
          ],
          [
           "Finally, we can use the inverse transform of the PCA object to construct the new digits:\n\nIn [24]:\n\n..."
          ],
          [
           "In\n\nDepth: Kernel Density Estimation\n\n< In Depth: Gaussian Mixture Models | Contents | Application: ..."
          ],
          [
           "In [2]:\n\ndef make_data(N, f=0.3, rseed=1):\n\nrand = np.random.RandomState(rseed)\n\nx = rand.randn(N)\n\n..."
          ],
          [
           "Out[4]:\n\n1.0\n\nOne of the issues with using a histogram as a density estimator is that the choice of ..."
          ],
          [
           "On the left, the histogram makes clear that this is a bimodal distribution. On the right, we see a u..."
          ],
          [
           "Out[7]:\n\n(\n\n0.2, 8)\n\nThe problem with our two binnings stems from the fact that the height of the bl..."
          ],
          [
           "plt.axis([\n\n4, 8,\n\n0.2, 8]);\n\nThe result looks a bit messy, but is a much more robust reflection of ..."
          ],
          [
           "plt.axis([\n\n4, 8,\n\n0.2, 5]);\n\nThis smoothed-out plot, with a Gaussian distribution contributed at th..."
          ],
          [
           "Kernel Density Estimation in Practice¶The free parameters of kernel density estimation are the kerne..."
          ],
          [
           "# score_samples returns the log of the probability density logprob = kde.score_samples(x_d[:, None])..."
          ],
          [
           "(\n\n0.02, 0.22)\n\nThe result here is normalized such that the area under the curve is equal to 1.\n\nSel..."
          ],
          [
           "from sklearn.grid_search import GridSearchCV\n\nfrom sklearn.cross_validation import LeaveOneOut\n\nband..."
          ],
          [
           "Example: KDE on a Sphere¶Perhaps the most common use of KDE is in graphically representing distribut..."
          ],
          [
           "In [14]:\n\nfrom mpl_toolkits.basemap import Basemap\n\nfrom sklearn.datasets.species_distributions impo..."
          ],
          [
           "Unfortunately, this doesn't give a very good idea of the density of the species, because points in t..."
          ],
          [
           "for i, axi in enumerate(ax): axi.set_title(species_names[i])\n\n# plot coastlines with basemap m = Bas..."
          ],
          [
           "Compared to the simple scatter plot we initially used, this visualization paints a much clearer pict..."
          ],
          [
           "The algorithm is straightforward and intuitive to understand; the more difficult piece is couching i..."
          ],
          [
           "def predict_proba(self, X): logprobs = np.array([model.score_samples(X) for model in self.models_])...."
          ],
          [
           "Next comes the class initialization method: def __init__(self, bandwidth=1.0, kernel='gaussian'): se..."
          ],
          [
           "Notice that each persistent result of the fit is stored with a trailing underscore (e.g., self.logpr..."
          ],
          [
           "Using our custom estimator¶Let's try this custom estimator on a problem we have seen before: the cla..."
          ],
          [
           "{'bandwidth': 7.0548023107186433}\n\naccuracy = 0.966611018364\n\nWe see that this not-so-naive Bayesian..."
          ],
          [
           "Finally, if you want some practice building your own estimator, you might tackle building a similar ..."
          ],
          [
           "Application: A Face Detection Pipeline\n\n< In-Depth: Kernel Density Estimation | Contents | Further M..."
          ],
          [
           "HOG Features¶The Histogram of Gradients is a straightforward feature extraction procedure that was d..."
          ],
          [
           "ax[1].imshow(hog_vis)\n\nax[1].set_title('visualization of HOG features');\n\nHOG in Action: A Simple Fa..."
          ],
          [
           "positive_patches.shape\n\nOut[3]:\n\n(13233, 62, 47)\n\nThis gives us a sample of 13,000 face images to us..."
          ],
          [
           "In [5]:\n\nfrom sklearn.feature_extraction.image import PatchExtractor\n\ndef extract_patches(img, N, sc..."
          ],
          [
           "Our hope is that these would sufficiently cover the space of \"non-faces\" that our algorithm is likel..."
          ],
          [
           "In [9]:\n\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.cross_validation import cross_val_..."
          ],
          [
           "In [12]:\n\nmodel = grid.best_estimator_\n\nmodel.fit(X_train, y_train)\n\nOut[12]:\n\nLinearSVC(C=4.0, clas..."
          ],
          [
           "Next, let's create a window that iterates over patches of this image, and compute HOG features for e..."
          ],
          [
           "In [16]:\n\nfig, ax = plt.subplots()\n\nax.imshow(test_image, cmap='gray')\n\nax.axis('off')\n\nNi, Nj = pos..."
          ],
          [
           "All of the detected patches overlap and found the face in the image! Not bad for a few lines of Pyth..."
          ],
          [
           "In fact, the sliding_window() utility used here is already built with this in mind. We should combin..."
          ],
          [
           "An intro to these deep neural net methods is conceptually (and computationally!) beyond the scope of..."
          ],
          [
           "Machine Learning in Python¶To learn more about machine learning in Python, I'd suggest some of the f..."
          ],
          [
           "Machine Learning: Taught by Andrew Ng (Coursera), this is a very clearly-taught free online course w..."
          ],
          [
           "Appendix: Figure Code\n\n< Further Machine Learning Resources | Contents |\n\nMany of the figures used t..."
          ],
          [
           "def draw_cube(ax, xy, size, depth=0.4, edges=None, label=None, label_kwargs=None, **kwargs): \"\"\"draw..."
          ],
          [
           "if 9 in edges: ax.plot([x + depth, x + depth + size], [y + depth + size, y + depth + size], **kwargs..."
          ],
          [
           "label_kwargs=dict(color='gray'))\n\ndepth = 0.3\n\n#----------------------------------------------------..."
          ],
          [
           "draw_cube(ax, (12, 10), 1, depth, [1, 2, 3, 4, 5, 6, 9], '5', **solid) draw_cube(ax, (13, 10), 1, de..."
          ],
          [
           "# first block draw_cube(ax, (1, 7.5), 1, depth, [1, 2, 3, 4, 5, 6, 9], '1', **solid) draw_cube(ax, (..."
          ],
          [
           "# second block draw_cube(ax, (6, 7.5), 1, depth, [1, 2, 3, 4, 5, 6, 9], '0', **solid) draw_cube(ax, ..."
          ],
          [
           "# third block draw_cube(ax, (12, 7.5), 1, depth, [1, 2, 3, 4, 5, 6, 9], '1', **solid) draw_cube(ax, ..."
          ],
          [
           "ax.text(5, 7.0, '+', size=12, ha='center', va='center') ax.text(10.5, 7.0, '=', size=12, ha='center'..."
          ],
          [
           "draw_cube(ax, (2, 3), 1, depth, [1, 2, 3, 6, 7, 9, 10, 11], '0', **dotted) draw_cube(ax, (2, 2), 1, ..."
          ],
          [
           "draw_cube(ax, (6, 2), 1, depth, range(2, 13), '0', **dotted) draw_cube(ax, (7, 2), 1, depth, [2, 3, ..."
          ],
          [
           "draw_cube(ax, (12, 2), 1, depth, [2, 3, 4], '1', **solid) draw_cube(ax, (13, 2), 1, depth, [2, 3], '..."
          ],
          [
           "ax.set_ylim(0.5, 12.5)\n\nfig.savefig('figures/02.05\n\nbroadcasting.png')\n\nAggregation and Grouping¶Fig..."
          ],
          [
           "# draw horizontal lines for i in range(nrows + 1): plt.plot([x, x + dx * ncols], 2 * [y + i * dy], *..."
          ],
          [
           "#---------------------------------------------------------\n\n# Draw figure\n\nimport pandas as pd df = ..."
          ],
          [
           "result = df.groupby(df.index).sum()\n\ndraw_dataframe(result, [6, 0.75])\n\nstyle = dict(fontsize=14, ha..."
          ],
          [
           "plt.annotate('', (3.8, 3.8), (3.2, 3.8), arrowprops=arrowprops) plt.annotate('', (3.8, 1.75), (3.2, ..."
          ],
          [
           "split\n\napply\n\ncombine.png')\n\nWhat Is Machine Learning?¶\n\nIn [5]:\n\n# common plot formatting for below..."
          ],
          [
           "# predict the labels\n\ny2 = clf.predict(X2)\n\nClassification Example Figure 1¶\n\nIn [7]:\n\n# plot the da..."
          ],
          [
           "# plot points and model fig, ax = plt.subplots(figsize=(8, 6)) line_style = dict(levels = [-1.0, 0.0..."
          ],
          [
           "ax[1].scatter(X2[:, 0], X2[:, 1], c=y2, **point_style) ax[1].contour(xy1, xy2, Z, **line_style) ax[1..."
          ],
          [
           "# predict the labels\n\ny2 = model.predict(X2)\n\nRegression Example Figure 1¶\n\nIn [11]:\n\n# plot data po..."
          ],
          [
           "# plot points in 3D fig = plt.figure() ax = fig.add_subplot(111, projection='3d') ax.scatter(X[:, 0]..."
          ],
          [
           "# Hide axes (is there a better way?) ax.w_xaxis.line.set_visible(False) ax.w_yaxis.line.set_visible(..."
          ],
          [
           "# compute and plot model color mesh xx, yy = np.meshgrid(np.linspace(-4, 4), np.linspace(-3, 3)) Xfi..."
          ],
          [
           "ax[1].scatter(X2[:, 0], X2[:, 1], c=y2, s=50, cmap='viridis', norm=pts.norm) ax[1].axis([-4, 4, -3, ..."
          ],
          [
           "# format the plot\n\nformat_plot(ax, 'Input Data')\n\nfig.savefig('figures/05.01\n\nclustering\n\n1.png')\n\nC..."
          ],
          [
           "# format the plot\n\nformat_plot(ax, 'Input Data')\n\nfig.savefig('figures/05.01\n\ndimesionality\n\n1.png')..."
          ],
          [
           "Learn¶\n\nFeatures and Labels Grid¶The following is the code generating the diagram showing the featur..."
          ],
          [
           "# Draw labels vector ax.vlines(range(8, 10), ymin=0, ymax=9, lw=1) ax.hlines(range(10), xmin=8, xmax..."
          ],
          [
           "Hyperparameters and Model Validation¶\n\nCross\n\nValidation Figures¶\n\nIn [21]:\n\ndef draw_rects(N, ax, t..."
          ],
          [
           "fig.savefig('figures/05.03\n\n2\n\nfold\n\nCV.png')\n\n5\n\nFold Cross\n\nValidation¶\n\nIn [23]:\n\nfig = plt.figur..."
          ],
          [
           "from sklearn.pipeline import make_pipeline\n\ndef PolynomialRegression(degree=2, *\n\nkwargs):\n\nreturn m..."
          ],
          [
           "ax[1].scatter(X.ravel(), y, s=40) ax[1].plot(xfit.ravel(), model20.predict(xfit), color='gray') ax[1..."
          ],
          [
           "X2, y2 = make_data(10, rseed=42)\n\nax[0].scatter(X.ravel(), y, s=40, c='blue') ax[0].plot(xfit.ravel(..."
          ],
          [
           "ax[1].scatter(X.ravel(), y, s=40, c='blue') ax[1].plot(xfit.ravel(), model20.predict(xfit), color='g..."
          ],
          [
           "bias\n\nvariance\n\n2.png')\n\nValidation Curve¶\n\nIn [28]:\n\nx = np.linspace(0, 1, 1000) y1 = -(x - 0.5) **..."
          ],
          [
           "ax.set_xlim(0, 1)\n\nax.set_ylim(\n\n0.3, 0.5)\n\nax.set_xlabel(r'model complexity $\\longrightarrow$', siz..."
          ],
          [
           "ax.text(0.2, 0.88, \"training score\", rotation=-10, size=16, color='blue') ax.text(0.2, 0.5, \"validat..."
          ],
          [
           "curve.png')\n\nGaussian Naive Bayes¶Gaussian Naive Bayes Example¶Figure Context\n\nIn [30]:\n\nfrom sklear..."
          ],
          [
           "for label, color in enumerate(['red', 'blue']): mask = (y == label) mu, std = X[mask].mean(0), X[mas..."
          ],
          [
           "class GaussianFeatures(BaseEstimator, TransformerMixin): \"\"\"Uniformly-spaced Gaussian Features for 1..."
          ],
          [
           "gauss_model = make_pipeline(GaussianFeatures(10, 1.0),\n\nLinearRegression())\n\ngauss_model.fit(x[:, np..."
          ],
          [
           "fig.savefig('figures/05.06\n\ngaussian\n\nbasis.png')\n\nRandom Forests¶\n\nHelper Code¶The following will c..."
          ],
          [
           "xx, yy = np.meshgrid(np.linspace(\n\nxlim, num=200),\n\nnp.linspace(\n\nylim, num=200))\n\nZ = estimator.pre..."
          ],
          [
           "[xlim[0], tree.threshold[i]], ylim)\n\nplot_boundaries(tree.children_right[i],\n\n[tree.threshold[i], xl..."
          ],
          [
           "def randomized_tree_interactive(X, y):\n\nN = int(0.75\n\nX.shape[0])\n\nxlim = (X[:, 0].min(), X[:, 0].ma..."
          ],
          [
           "def text(ax, x, y, t, size=20, **kwargs): ax.text(x, y, t, ha='center', va='center', size=size, bbox..."
          ],
          [
           "text(ax, 0.66, 0.45, \"yes\", 12, alpha=0.4) text(ax, 0.79, 0.45, \"no\", 12, alpha=0.4)\n\nax.plot([0.3, ..."
          ],
          [
           "decision\n\ntree.png')\n\nDecision Tree Levels¶\n\nIn [34]:\n\nfrom helpers_05_08 import visualize_tree\n\nfro..."
          ],
          [
           "Decision Tree Overfitting¶\n\nIn [35]:\n\nmodel = DecisionTreeClassifier()\n\nfig, ax = plt.subplots(1, 2,..."
          ],
          [
           "In [38]:\n\nrng = np.random.RandomState(1) X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T pca = PCA(n..."
          ],
          [
           "# plot principal components X_pca = pca.transform(X) ax[1].scatter(X_pca[:, 0], X_pca[:, 1], alpha=0..."
          ],
          [
           "components = np.eye(len(coefficients), len(x))\n\nmean = np.zeros_like(x) + mean\n\nfig = plt.figure(fig..."
          ],
          [
           "for i in range(n_components): approx = approx + coefficients[i] * components[i] show(0, i + counter,..."
          ],
          [
           "Xproj = pca.fit_transform(digits.data)\n\nsns.set_style('white')\n\nfig = plot_pca_components(digits.dat..."
          ],
          [
           "# Open this PNG and draw random points from it from matplotlib.image import imread data = imread('he..."
          ],
          [
           "In [44]:\n\nfrom mpl_toolkits.mplot3d.art3d import Line3DCollection\n\nfrom sklearn.neighbors import Nea..."
          ],
          [
           "for axi, title, lines in zip(ax, titles, [lines_MDS, lines_LLE]): axi.scatter3D(XS[:, 0], XS[:, 1], ..."
          ],
          [
           "rng = np.random.RandomState(42) centers = [0, 4] + rng.randn(4, 2)\n\ndef draw_points(ax, c, factor=1)..."
          ],
          [
           "ax.yaxis.set_major_formatter(plt.NullFormatter())\n\nreturn ax\n\nfig = plt.figure(figsize=(15, 4)) gs =..."
          ],
          [
           "draw_points(ax1, y_pred)\n\ndraw_centers(ax1, centers)\n\n# M-step new_centers = np.array([X[y_pred == i..."
          ],
          [
           "fig.savefig('figures/05.11\n\nexpectation\n\nmaximization.png')\n\nInteractive K-Means¶The following scrip..."
          ],
          [
           "def plot_centers(centers): plt.scatter(centers[:, 0], centers[:, 1], marker='o', c=np.arange(centers..."
          ],
          [
           "# plot the data and cluster centers plot_points(X, labels, n_clusters) plot_centers(old_centers)\n\n# ..."
          ],
          [
           "In [47]:\n\nfrom sklearn.mixture import GMM\n\nfrom matplotlib.patches import Ellipse\n\ndef draw_ellipse(..."
          ],
          [
           "for i, cov_type in enumerate(['diag', 'spherical', 'full']): model = GMM(1, covariance_type=cov_type..."
          ],
          [
           "Python Data Science Handbook\n\nAbout\n\nArchive\n\nPython Data Science Handbook\n\nJake VanderPlas\n\nThis we..."
          ],
          [
           "4. Visualization with Matplotlib¶ Simple Line Plots Simple Scatter Plots Visualizing Errors Density ..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt, circle",
         "marker": {
          "color": "#FFA15A",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -2.8285391,
          -2.34034,
          -1.7600737,
          9.799409,
          -1.9578912,
          -1.9594734,
          -2.4356751,
          -2.2404714,
          -2.2204823,
          -2.176203,
          -2.3731992,
          -2.509023,
          -1.7005967,
          -1.5495359,
          -0.43732914,
          -0.38917246,
          -2.6466973,
          -2.3250537,
          -0.67745763,
          -0.44371295,
          -0.670433,
          -0.35896674,
          -0.2801737,
          -0.48529944,
          -0.50055355,
          -2.1393752,
          0.098434165,
          0.0033154443,
          -0.04482453,
          -0.076502495,
          0.101481274,
          -0.07263264,
          0.21647796,
          -0.08531854,
          -3.6583767,
          -0.70616245,
          0.09000756,
          0.016314147,
          0.07414878,
          0.26103455,
          0.0076841232,
          0.07027151,
          -0.7137144,
          -0.19123077,
          0.007767697,
          0.00511484,
          0.005227574,
          0.846946,
          0.7694822,
          0.89058936,
          0.7817294,
          0.8554977,
          0.66796553,
          0.7445461,
          0.31672022,
          -2.7656305,
          -3.5359619,
          -3.7536001,
          -3.8002915,
          -3.621456,
          -3.778726,
          -3.529492,
          -3.520893,
          -3.5994666,
          -3.7119253,
          -3.7139654,
          -2.3209686,
          -1.6383153,
          -2.4824178,
          -3.4773023,
          -2.657543,
          -2.144222,
          -2.5718277,
          -2.317317,
          -3.2844195,
          -3.216757,
          -3.3590045,
          -3.3103025,
          -3.5656624,
          -3.7427065,
          -4.2723565,
          -3.9272296,
          -4.2195654,
          -3.9040432,
          -2.7187464,
          -3.4287236,
          -4.1222053,
          -4.334365,
          -4.43658,
          -4.2563825,
          -4.508393,
          -4.446512,
          -4.5157285,
          -4.5465946,
          -4.367011,
          -4.35015,
          -4.5442023,
          -4.6069427,
          -4.441752,
          -4.3682775,
          -4.6017647,
          -4.272188,
          -3.9825284,
          -5.1646733,
          -5.282578,
          -5.6054873,
          -5.511481,
          -5.8924875,
          -5.5167627,
          -5.662896,
          -5.736589,
          -5.665486,
          -2.0296369,
          -5.6048236,
          -5.424985,
          -5.2041316,
          -4.8581405,
          -4.852481,
          -4.6006727,
          -4.986135,
          -4.912364,
          -4.9219437,
          -4.4861875,
          -9.381635,
          -8.920625,
          -5.2887383,
          -5.006134,
          -4.8983307,
          -5.0380797,
          -5.1728597,
          -4.9208937,
          -5.1011214,
          -5.2878375,
          -5.182767,
          -5.683824,
          -6.72401,
          -10.052089,
          -6.6824336,
          -6.5900774,
          -6.4995623,
          -6.6613784,
          -6.531308,
          -6.644002,
          -6.598999,
          -6.634221,
          -6.6816983,
          -6.9031124,
          -6.633232,
          -6.6796317,
          -6.5864806,
          -4.4521513,
          -4.5240865,
          -4.634356,
          -4.436371,
          -4.483457,
          -4.503023,
          -4.814377,
          -5.0254865,
          -6.7465854,
          -5.576467,
          -5.492009,
          -4.1356716,
          -3.9545176,
          -4.0707026,
          -4.271841,
          -4.3134017,
          -4.2506604,
          -4.119433,
          -3.3520133,
          -3.2662346,
          -3.3239765,
          -3.557538,
          5.5851235,
          -3.8432126,
          -3.262464,
          -3.2158382,
          -2.9828482,
          -2.7706697,
          -2.6637578,
          -2.370052,
          -3.4085374,
          -3.3085303,
          -3.672339,
          -3.7167492,
          -2.713046,
          -2.4885128,
          -2.3306823,
          -3.7875965,
          -6.6293764,
          -6.61664,
          -6.7305765,
          -7.0689173,
          -6.573412,
          -7.5436797,
          -7.125707,
          -7.594417,
          -6.8478584,
          -7.694247,
          -6.687414,
          -6.8511424,
          -7.0721717,
          -7.5980887,
          -6.634183,
          -6.6637,
          -6.57064,
          -6.812221,
          -6.7424836,
          -7.246784,
          -7.4753633,
          -7.2448316,
          -7.7970905,
          -7.5986276,
          -7.1805816,
          -7.703859,
          -7.5942326,
          -7.974748,
          -7.526327,
          -3.5076606,
          -6.8520756,
          -5.734476,
          -8.268746,
          -7.2174497,
          -7.3568964,
          -7.3931293,
          -5.1860127,
          -7.0770903,
          -5.353463,
          -6.0119777,
          -5.8083057,
          -5.986404,
          -5.972027,
          -5.0181923,
          -4.9619675,
          -6.134816,
          -6.0917463,
          -6.071916,
          -6.2081523,
          -6.3120112,
          -6.4695587,
          -6.305546,
          -6.7362432,
          -5.8970904,
          -8.247836,
          -7.763838,
          -7.8883724,
          -7.9278245,
          -8.067421,
          -8.172685,
          -7.9134364,
          -7.774486,
          -7.6716385,
          -7.9305587,
          -7.981327,
          -8.077691,
          -8.0224085,
          -7.862281,
          -7.9533405,
          -7.9874177,
          -7.558785,
          -7.894411,
          -7.2807837,
          -7.6159787,
          -8.135911,
          -7.941787,
          -8.176305,
          -10.067876,
          -9.689781,
          -8.01842,
          -8.9114485,
          -9.199967,
          -9.21177,
          -9.556477,
          -9.505028,
          -9.569825,
          -9.562413,
          -9.546736,
          -9.421037,
          -9.482257,
          -9.3834505,
          -9.567153,
          -9.661236,
          -9.5369835,
          -9.519755,
          -9.574507,
          -10.740825,
          -11.397922,
          -11.145483,
          -11.408893,
          -11.151366,
          -11.303566,
          -11.337428,
          -11.350297,
          -11.307069,
          -11.227841,
          -11.479769,
          -11.31868,
          -11.334479,
          -11.162159,
          -10.877351,
          -10.703853,
          -10.864415,
          -10.20213,
          -10.652688,
          -10.876395,
          -9.183197,
          -9.082855,
          -9.358776,
          -9.1665945,
          -9.223245,
          -9.250975,
          -9.153001,
          -9.068106,
          -8.725421,
          -8.679809,
          -9.030868,
          -8.687996,
          -9.031821,
          -9.128599,
          -9.3141365,
          -9.133201,
          -9.901746,
          -9.712407,
          -9.601708,
          -9.64382,
          -9.508226,
          -9.11533,
          -9.419601,
          -9.805251,
          -9.226991,
          -9.605776,
          -9.591647,
          -9.663788,
          -9.64563,
          -9.610048,
          -9.599701,
          -9.579547,
          -9.6200075,
          -9.621729,
          -9.630072,
          -9.606632,
          -9.829006,
          -9.2256365,
          -8.900714,
          -8.707122,
          -8.916144,
          -8.8453045,
          -8.836547,
          -8.95952,
          -8.814463,
          -9.535622,
          -8.901312,
          -9.068712,
          -11.203335,
          -11.012157,
          -11.110022,
          -11.070148,
          -11.033011,
          -11.052643,
          -11.244045,
          -2.0009584,
          -1.200231,
          -1.5159515,
          -1.0416648,
          -1.2593114,
          -0.9343024,
          -1.4134051,
          -1.554751,
          -1.5620174,
          -1.3733089,
          -1.5224676,
          -1.408857,
          -1.3985764,
          -1.441899,
          -1.4312243,
          -1.3931836,
          -1.748593,
          -1.511118,
          -10.737429,
          -11.797996,
          -11.99383,
          -12.165111,
          -11.96475,
          -11.843879,
          -10.814454,
          -11.966735,
          -11.928887,
          -11.751583,
          -11.946088,
          -12.06944,
          -12.049416,
          -12.042093,
          -12.054041,
          -12.106599,
          -12.035619,
          -10.879219,
          -12.074804,
          -12.003025,
          -10.506505,
          -9.970322,
          -10.5096655,
          -10.602619,
          -9.970019,
          -10.209398,
          -10.896601,
          -10.956582,
          -9.790105,
          -11.459403,
          -11.492784,
          -11.578564,
          -11.660324,
          -11.609691,
          -3.3775415,
          -5.0959926,
          -6.270655,
          -6.562015,
          -6.8154926,
          -6.679537,
          -6.774388,
          -6.9260354,
          -7.21503,
          -7.175493,
          -6.9520473,
          -6.7340713,
          -6.6710224,
          -6.2834587,
          -10.907215,
          -2.7754772,
          -7.81092,
          -8.15007,
          -8.296831,
          -8.831467,
          -8.265006,
          -8.447879,
          -4.447408,
          -8.705761,
          -9.210645,
          -7.8450418,
          -2.357937,
          -7.6986656,
          -8.835117,
          -8.511384,
          -8.091865,
          -7.9947424,
          -9.168668,
          -8.961889,
          -8.604899,
          -8.975122,
          -7.768369,
          -8.125803,
          -7.9970975,
          -6.3755817,
          0.5688776,
          -7.221946,
          -6.3254423,
          -6.356555,
          -6.0399323,
          -6.1402287,
          -6.223986,
          -6.118132,
          -6.0359225,
          -6.1015,
          -6.1317725,
          -6.152091,
          -6.267285,
          -6.5188937,
          -5.81313,
          -6.1019588,
          -6.030977,
          -6.192798,
          -8.340205,
          -8.22023,
          -8.359053,
          -8.499559,
          -8.120699,
          -8.408907,
          -7.0745854,
          -6.4905906,
          -6.2502456,
          -5.8792067,
          -6.1468806,
          -6.289903,
          -6.177386,
          -5.974636,
          -3.8979836,
          -3.876084,
          -9.341038,
          -9.432974,
          -9.462831,
          -9.475799,
          -9.391276,
          -9.562666,
          -6.785538,
          -10.833068,
          -10.938835,
          -10.314329,
          -9.941543,
          -9.354767,
          -9.767843,
          -9.643751,
          -10.218531,
          -3.1246183,
          -2.9624317,
          -9.693553,
          -9.668701,
          -9.462621,
          -9.6029415,
          -9.571788,
          -9.553992,
          -9.42616,
          -9.384723,
          -9.79935,
          -9.315671,
          -9.15176,
          -8.375341,
          -8.7566185,
          -8.149975,
          -8.180077,
          -8.123646,
          -8.201614,
          -8.157769,
          -8.1803,
          -7.6722016,
          -6.0510874,
          -5.9860415,
          -5.9808803,
          -5.8527966,
          -5.5270686,
          -5.7748895,
          -5.9001775,
          -6.2280617,
          -6.8206353,
          -6.926873,
          -6.745749,
          -6.6533303,
          -6.75306,
          -6.815064,
          -6.793391,
          -6.698759,
          -6.7789807,
          -7.103981,
          -6.8851333,
          -7.289865,
          -7.43754,
          -10.180406,
          -6.9758224,
          -7.527223,
          -8.05876,
          -8.434988,
          -7.6939836,
          -7.238274,
          -7.5239215,
          -7.9221463,
          -7.8631372,
          -8.300946,
          -8.836374,
          -8.990503,
          -10.99938,
          -9.787329,
          -10.128898,
          -9.740841,
          -9.735016,
          -9.653185,
          -9.529884,
          -9.839732,
          -9.587758,
          -9.72789,
          -8.398137,
          -7.641188,
          9.994946,
          9.928367,
          9.9883175,
          -2.3443685,
          9.984115,
          8.6882925,
          7.1154423,
          6.1502776,
          6.1273246,
          6.197057,
          -1.5609679,
          6.2858834,
          6.378167,
          -2.233927,
          7.9017015,
          9.798417,
          -8.520016,
          0.83246607,
          0.9896589,
          1.0260513,
          3.5390656,
          3.4676788,
          3.8668501,
          3.4248722,
          3.668686,
          1.503928,
          1.2807946,
          0.9275373,
          0.9394714,
          -1.2605653,
          -3.647752,
          -3.1872075,
          -3.6568294,
          0.111196294,
          0.7437901,
          -0.3615413,
          9.5497265,
          1.4628515,
          1.0917616,
          2.198182,
          2.1880465,
          2.157805,
          2.7496653,
          -4.654122,
          -4.685057,
          -4.6665025,
          -4.6604815,
          -4.690322,
          2.3716803,
          5.2134914,
          4.9061365,
          3.4289615,
          3.3230145,
          3.2064636,
          3.3844676,
          3.3308413,
          4.022267,
          3.6111233,
          0.67104244,
          3.4039125,
          3.0483377,
          2.2100284,
          9.483537,
          6.160424,
          3.4318826,
          3.0422316,
          5.645178,
          4.943893,
          6.3301034,
          3.47323,
          3.4344375,
          8.662555,
          -6.18385,
          3.4281561,
          1.5108336,
          5.632043,
          4.990566,
          4.616749,
          4.820909,
          5.362836,
          4.9798994,
          4.903206,
          1.7298602,
          4.7741547,
          4.9476995,
          5.3005815,
          1.318235,
          5.8698196,
          4.874694,
          9.303198,
          3.4456456,
          3.5055027,
          3.3161552,
          3.5699708,
          3.4086611,
          3.4177494,
          -0.47215194,
          3.40666,
          0.93870676,
          5.1040983,
          5.0922804,
          6.839999,
          -11.616066,
          -11.737302,
          -11.046768,
          -10.570795,
          -9.906867,
          -11.663577,
          -11.827901,
          -9.96462,
          5.7105374,
          8.986014,
          0.8436698,
          0.37456405,
          0.93995714,
          0.783414,
          0.8732476,
          1.4157323,
          0.8489849,
          1.2034829,
          0.2220371,
          0.96839726,
          1.0850601,
          0.86883587,
          0.61781615,
          -0.8043928,
          0.53561294,
          0.954539,
          0.0021713378,
          -0.30349454,
          8.646941,
          9.392472,
          6.6267567,
          1.2142899,
          1.3981817,
          1.2211595,
          1.1101947,
          6.0844955,
          5.4353833,
          5.245605,
          5.4844823,
          -0.18474706,
          0.7436646,
          5.9987755,
          -2.19345,
          -2.1780381,
          -1.4343204,
          -2.0570967,
          -2.0855286,
          -3.5172248,
          -3.8177588,
          -2.0865047,
          -2.1311274,
          -2.20235,
          -2.412783,
          -1.9353958,
          -2.173766,
          -2.1992328,
          -1.6496743,
          -2.2260733,
          -2.0914369,
          -2.0404618,
          -2.5185623,
          -2.2404475,
          -4.4906664,
          -2.5722713,
          -3.0484111,
          -2.8886876,
          -2.4741266,
          -2.5483465,
          -2.4216514,
          -2.3799782,
          -2.5079658,
          -1.994215,
          -2.1703813,
          -2.3593528,
          -2.1218002,
          -2.0466082,
          -1.6533371,
          -2.2762694,
          -1.3040224,
          -3.3662066,
          -1.6451229,
          -1.414134,
          -1.3194177,
          -1.3207023,
          -1.3784422,
          -1.2916778,
          -1.3207431,
          -1.5701439,
          -1.4091312,
          -1.4574305,
          -1.4699914,
          -1.4765017,
          -1.5100046,
          -4.737473,
          -1.2673299,
          -1.4201889,
          -1.6022018,
          -1.3710077,
          -1.3150791,
          -1.3485634,
          -1.368175,
          -1.3037542,
          -1.3486793,
          -1.329834,
          -1.4561609,
          -1.2816695,
          -1.4922271,
          -1.3969204,
          -1.457569,
          -3.3141117,
          -2.2057862,
          -2.6629438,
          -1.31987,
          -5.923124,
          -5.9695063,
          -5.8855214,
          -5.8678026,
          -6.1252875,
          -5.9447145,
          -5.481808,
          -5.8276567,
          -0.110090144,
          0.39708316,
          -6.8148546,
          -7.3767433,
          -6.8693323,
          -7.475139,
          4.7842064,
          0.5663078,
          0.8582437,
          0.7029403,
          1.7290452,
          0.47835338,
          0.6412283,
          -0.19680068,
          -0.989849,
          -1.1065937,
          -0.9054882,
          -1.1079754,
          -1.2918333,
          -1.0970635,
          0.73629194,
          -0.9500462,
          -1.1433179,
          -1.3515137,
          -1.1240985,
          -1.0692025,
          8.17994,
          8.612125,
          7.886107,
          -3.768366,
          -3.8210225,
          -3.4641092,
          -3.791004,
          -3.8283494,
          -3.8190355,
          -3.8613992,
          -3.7986848,
          -3.8068337,
          -3.7937872,
          -3.8280368,
          -3.447185,
          -9.309749,
          -9.388049,
          -9.344158,
          -9.412305,
          -0.45890486,
          0.385001,
          0.5130478,
          0.1489784,
          0.4764367,
          0.05521262,
          -1.6549796,
          -9.653765,
          0.2928012,
          -1.2491537,
          -1.0617031,
          -0.5313696,
          -1.2778499,
          0.48825192,
          0.68010587,
          1.8805572,
          0.9540609,
          0.68903655,
          0.6739199,
          0.6578187,
          0.63119984,
          0.667542,
          0.3145785,
          -0.18513268,
          -0.31276163,
          -0.4474133,
          0.23670249,
          0.81820136,
          0.9976808,
          1.1466264,
          0.9438685,
          -3.0223963,
          0.5643051,
          0.9828393,
          0.24151044,
          -1.3359463,
          -1.286901,
          -1.5644114,
          -1.2456689,
          -1.1496953,
          -4.2505455,
          -1.6897777,
          -1.2783886,
          -2.284162,
          -2.098463,
          -1.5290347,
          -1.2754741,
          -1.2005602,
          -1.2326672,
          -1.1847471,
          -0.8019279,
          -2.7860668,
          -2.349589
         ],
         "xaxis": "x",
         "y": [
          -9.407577,
          -10.795481,
          -9.003908,
          -2.326682,
          -8.826276,
          -8.838286,
          -9.479656,
          -8.97279,
          -8.639133,
          -8.634405,
          -10.607784,
          -9.507455,
          -8.776456,
          -8.663896,
          -8.441342,
          -8.527039,
          -9.584544,
          -10.775959,
          -8.386731,
          -8.083985,
          -7.410874,
          -8.163065,
          -8.111094,
          -7.77882,
          -7.8915505,
          -9.104524,
          -8.500075,
          -8.4338665,
          -8.478961,
          -8.341693,
          -8.473541,
          -8.418707,
          -8.435359,
          -8.369855,
          -7.8240433,
          -8.380406,
          -8.458127,
          -8.436738,
          -8.352855,
          -8.377351,
          -8.415865,
          -8.498911,
          -8.182736,
          -8.605475,
          -8.485406,
          -8.463445,
          -8.457678,
          -8.154817,
          -8.176795,
          -8.20531,
          -8.204717,
          -8.178129,
          -8.239689,
          -8.245319,
          -8.425376,
          -8.37448,
          -7.979539,
          -7.4271245,
          -7.498674,
          -7.938178,
          -7.977697,
          -7.955114,
          -8.057448,
          -8.04135,
          -7.8697877,
          -7.908683,
          -9.308326,
          -8.600447,
          -8.553626,
          -7.7150497,
          -8.068004,
          -8.300669,
          -9.879285,
          -10.602156,
          -6.6542873,
          -6.68202,
          -6.866291,
          -6.6001906,
          -6.524225,
          -6.4250145,
          -5.7019024,
          5.292903,
          5.394734,
          -6.443019,
          -6.883863,
          -6.649238,
          -5.889848,
          -5.6223326,
          -5.2219696,
          -5.456366,
          -5.4902143,
          -5.2631507,
          -5.0243278,
          -5.308723,
          -5.1386924,
          -5.1379275,
          -5.655725,
          -6.0639544,
          -5.3541126,
          -5.187669,
          -7.344406,
          -7.371993,
          -7.2948046,
          -6.9332366,
          -6.75505,
          -6.5590925,
          -6.693464,
          -6.582638,
          -6.610723,
          -6.5970273,
          -6.6303,
          -6.687164,
          5.901748,
          -6.5774965,
          -6.8925705,
          -6.7411437,
          -6.58966,
          -7.4969935,
          -7.405485,
          -7.387591,
          -7.46383,
          -7.390399,
          -7.5346246,
          2.8744278,
          3.6134949,
          -6.689681,
          -6.298024,
          -6.0938315,
          -6.1534963,
          -6.2430787,
          -5.9070983,
          -6.3639936,
          -6.6324906,
          -6.5413637,
          5.5816073,
          -5.9993315,
          3.9298935,
          -6.1800594,
          -6.220305,
          -6.2788754,
          -6.2289877,
          -6.4054017,
          -6.1774,
          -6.242476,
          -6.2054987,
          -6.0661397,
          -5.8391576,
          -6.396065,
          -6.272276,
          -6.2516336,
          -5.3522854,
          -5.4367557,
          -5.547433,
          -5.078603,
          -5.3122616,
          -4.9062543,
          -5.7367196,
          -6.115079,
          4.0093346,
          4.2842226,
          4.036926,
          -5.074164,
          -5.251096,
          -5.2496567,
          -5.0053906,
          -5.0130234,
          -5.0901513,
          -4.8200297,
          5.4144564,
          5.315193,
          5.3733764,
          5.200579,
          4.3988442,
          -7.192925,
          -7.6203527,
          -6.7671885,
          -7.176559,
          -7.19184,
          -6.862882,
          -6.70503,
          -6.605287,
          -6.891404,
          -6.7473655,
          -8.571483,
          -8.440652,
          -7.518291,
          -10.655317,
          -8.919331,
          -10.99446,
          -10.998232,
          -11.201598,
          -11.216276,
          -11.078724,
          -11.15217,
          -11.227513,
          -11.258402,
          -11.066037,
          -11.09228,
          -10.828748,
          -10.494744,
          -10.082391,
          -9.881885,
          -11.082187,
          -11.134659,
          -11.114469,
          -11.014207,
          -10.86477,
          -11.160692,
          -11.253769,
          -11.162091,
          -10.824348,
          -11.074836,
          -11.0825405,
          -11.261253,
          -11.234979,
          -11.174026,
          -11.143017,
          -8.872672,
          -10.43879,
          -6.7706957,
          -10.643582,
          -9.617655,
          -9.246393,
          -8.977731,
          -6.2331314,
          -8.999036,
          -9.049689,
          -9.190521,
          -8.940255,
          -9.07125,
          -8.787933,
          -7.3144183,
          -7.4907527,
          -8.912311,
          -8.908873,
          -9.002703,
          -8.981608,
          -9.024984,
          -8.982099,
          -9.052296,
          -9.172619,
          -9.091849,
          -10.8113575,
          -11.254681,
          -11.225153,
          -11.242764,
          -11.143423,
          -11.017475,
          -11.04668,
          -11.146234,
          -10.780477,
          -11.185198,
          -11.068972,
          -11.261304,
          -11.226221,
          -11.244076,
          -11.132081,
          -11.134041,
          -10.922898,
          -11.187801,
          -10.875314,
          -11.188486,
          -11.160939,
          -11.196669,
          -11.048241,
          2.7788532,
          2.9627197,
          -10.357408,
          -9.923694,
          -9.04028,
          -8.914633,
          -8.98217,
          -9.099913,
          -9.146027,
          -9.12215,
          -9.088626,
          -9.250516,
          -9.1559515,
          -9.267907,
          -9.138814,
          -9.25084,
          -9.146117,
          -9.651427,
          -9.352193,
          -9.563295,
          -9.572781,
          -9.57379,
          -9.592008,
          -9.541898,
          -9.572715,
          -9.568187,
          -9.585769,
          -9.570153,
          -9.575288,
          -9.592348,
          -9.572694,
          -9.568148,
          -9.571451,
          -9.525544,
          -9.509823,
          -9.546593,
          -9.526424,
          -9.550994,
          -9.583631,
          -11.229003,
          -11.132815,
          -10.453901,
          -11.06567,
          -11.040398,
          -11.091281,
          -11.191834,
          -11.102183,
          -11.257385,
          -11.178907,
          -11.1785345,
          3.1567934,
          2.5240707,
          2.1813383,
          2.2750177,
          2.6761935,
          2.0750382,
          1.4550215,
          0.75511247,
          0.82543766,
          1.430902,
          2.12544,
          1.7964824,
          2.656953,
          2.0955539,
          0.7029389,
          0.87965786,
          0.8558242,
          0.7257422,
          0.9657617,
          1.0000327,
          0.6680413,
          0.6388522,
          0.69511944,
          0.7818741,
          0.81912124,
          2.4549856,
          2.3187554,
          2.8102446,
          2.9145484,
          2.9112892,
          2.96835,
          3.0469673,
          2.8719656,
          2.984592,
          1.7096583,
          3.0746298,
          3.0547621,
          4.6651845,
          4.5529137,
          4.7165728,
          4.7052393,
          4.6979527,
          4.6174655,
          4.6728415,
          -7.48888,
          -7.1857786,
          -7.363668,
          -7.1905127,
          -7.2028475,
          -7.3169084,
          -7.3231287,
          -7.4094167,
          -7.228465,
          -7.2078505,
          -6.98265,
          -6.9679756,
          -6.787795,
          -6.9461803,
          -6.9370136,
          -7.0781064,
          -7.269666,
          -7.0371284,
          2.7966123,
          2.080039,
          1.9637911,
          1.9607152,
          1.9634337,
          2.048863,
          2.3545656,
          1.9905227,
          2.017501,
          2.139593,
          1.9844959,
          1.9240283,
          1.9679157,
          1.923936,
          1.9294764,
          1.9570974,
          1.9584631,
          2.5264647,
          1.9798867,
          1.9774605,
          2.7324622,
          4.069551,
          3.8609781,
          3.8839846,
          4.6623206,
          2.8883562,
          3.0598512,
          2.9392538,
          3.2501621,
          3.3394673,
          3.4708755,
          3.4619813,
          3.4382715,
          3.503796,
          -8.496133,
          -7.1341095,
          -6.912138,
          -7.758997,
          -7.831183,
          -7.648928,
          -7.8535395,
          -8.012338,
          -8.481059,
          -8.640238,
          -8.092738,
          -7.626743,
          -7.641156,
          -7.5738535,
          2.3092518,
          -9.246588,
          6.1999907,
          6.332217,
          6.423413,
          6.4595037,
          6.324896,
          6.4408755,
          6.4893293,
          6.569818,
          6.755494,
          6.120477,
          -10.568732,
          5.8672824,
          6.5587053,
          6.721864,
          6.69112,
          6.65499,
          6.536428,
          6.6049075,
          6.324132,
          6.625611,
          5.905239,
          6.478294,
          6.4479575,
          6.0659204,
          3.0113683,
          5.9136205,
          5.1052155,
          4.8201284,
          4.874243,
          4.701255,
          4.9326572,
          5.9142284,
          6.07551,
          6.2300735,
          6.0309386,
          6.1014423,
          5.384527,
          4.636994,
          4.3786373,
          4.54065,
          4.5579734,
          4.5299516,
          6.0261874,
          6.1093717,
          5.754927,
          5.008577,
          5.8274207,
          6.1748977,
          5.590022,
          6.5441785,
          6.3504205,
          6.1731443,
          6.3797035,
          6.269203,
          6.1385527,
          6.3065815,
          7.158393,
          7.0304036,
          6.494046,
          6.5841475,
          6.444295,
          6.65025,
          6.5959625,
          6.4098783,
          4.6782575,
          4.6999087,
          4.8077135,
          4.7770276,
          5.2809987,
          5.989358,
          5.800219,
          6.191676,
          5.1807704,
          8.282732,
          8.494986,
          5.268329,
          5.702117,
          6.317799,
          6.020665,
          6.1116953,
          6.4153547,
          6.440867,
          6.5301847,
          6.136778,
          6.1907105,
          6.0887165,
          6.6794863,
          6.305226,
          6.6501775,
          6.6550126,
          6.615063,
          6.5061493,
          6.6410985,
          6.5845003,
          6.4002,
          6.208421,
          6.108183,
          6.2536087,
          6.0395913,
          5.9777284,
          6.112003,
          6.0084424,
          6.1265607,
          5.559924,
          5.4056635,
          5.4194264,
          5.4274936,
          5.4231005,
          5.37439,
          5.4324765,
          5.4850945,
          5.2503057,
          5.435167,
          5.4218535,
          5.571866,
          5.4354086,
          3.2596366,
          5.5208373,
          5.810615,
          6.4362197,
          5.5286665,
          4.5692325,
          4.297966,
          4.274122,
          4.0192533,
          4.0651684,
          3.5556674,
          3.0280068,
          3.7507193,
          2.4809687,
          3.2387636,
          3.2678533,
          3.0587077,
          3.2717147,
          3.3189564,
          3.445723,
          3.1856353,
          3.2317073,
          3.2307408,
          6.1686773,
          4.277613,
          -1.9403094,
          -2.086201,
          -2.2858822,
          -10.557104,
          -2.0405147,
          -2.0612998,
          -2.1804883,
          -2.0031965,
          -2.1802864,
          -2.2743685,
          6.352853,
          -1.6307586,
          -1.4007652,
          6.800026,
          -2.08606,
          -1.8782394,
          3.7047286,
          3.08904,
          3.217915,
          3.1804464,
          3.746566,
          4.1552052,
          4.1094737,
          3.7026286,
          4.1690807,
          3.9008167,
          3.9596329,
          3.855547,
          3.7758656,
          8.8790865,
          7.151777,
          7.3518033,
          7.312377,
          4.5708003,
          4.3735642,
          5.738236,
          -1.7573928,
          3.7680721,
          4.0418277,
          3.7963905,
          3.9978333,
          3.9784088,
          4.020168,
          1.8330581,
          1.7482976,
          1.7542887,
          1.7331381,
          1.7619717,
          4.035256,
          3.9874096,
          4.207502,
          4.773295,
          4.265878,
          5.2833624,
          5.144329,
          5.1009765,
          4.973937,
          4.8186283,
          6.851073,
          4.9140444,
          5.312929,
          4.9942136,
          -1.6634583,
          -1.612113,
          -0.6803866,
          -0.24101488,
          -1.414002,
          -1.8231848,
          -1.5225585,
          3.1688845,
          4.087666,
          -1.3972294,
          -9.113511,
          3.8521876,
          3.8057575,
          -2.4770358,
          -2.7909315,
          -2.934004,
          -2.8044903,
          -2.5688257,
          -2.9075384,
          -2.800067,
          5.182201,
          -2.977203,
          -3.3548644,
          -2.68218,
          4.3232307,
          -2.3978794,
          -2.8573968,
          -1.4132569,
          4.1876054,
          4.307882,
          4.124998,
          3.8289194,
          3.875686,
          4.1198516,
          7.088851,
          4.1059446,
          6.4633107,
          4.876138,
          4.936712,
          0.21219902,
          3.4437363,
          3.5447836,
          3.5807412,
          3.2300384,
          3.241817,
          3.4191737,
          3.4952204,
          3.9716423,
          0.89657027,
          -1.055613,
          5.5555506,
          5.645033,
          5.764261,
          5.743965,
          6.125999,
          5.4285765,
          5.627129,
          5.581118,
          6.103089,
          5.69127,
          5.6171064,
          5.8989477,
          5.5368066,
          5.1482315,
          5.179167,
          5.2691813,
          4.779905,
          5.0144815,
          -1.1492043,
          -1.2247093,
          3.4868314,
          6.3216233,
          5.6343703,
          6.3960347,
          6.246426,
          3.3832781,
          2.9733956,
          3.0266407,
          2.6689253,
          4.968926,
          4.479343,
          2.9047625,
          7.5174727,
          7.282874,
          7.3905,
          6.932826,
          6.989722,
          7.330239,
          7.1596413,
          6.7332025,
          7.0788016,
          7.37012,
          7.516441,
          7.1395965,
          7.2698555,
          7.328646,
          7.432481,
          6.9315557,
          7.5690517,
          7.9601474,
          6.7520833,
          6.5618105,
          5.797952,
          5.929424,
          5.6828175,
          5.8072877,
          6.2143435,
          6.443658,
          6.3378997,
          6.5009036,
          6.480788,
          7.1276183,
          6.7169294,
          6.5052667,
          7.22532,
          7.3253818,
          7.232087,
          6.7708483,
          6.43953,
          7.313332,
          8.469614,
          9.216424,
          9.208198,
          9.230454,
          9.216669,
          9.229157,
          9.278396,
          9.2156,
          9.369112,
          9.288035,
          9.214578,
          9.200049,
          9.379061,
          6.4056106,
          9.053037,
          9.158756,
          8.103758,
          9.093396,
          9.333641,
          9.203954,
          9.199632,
          8.841984,
          8.686302,
          8.002343,
          8.946179,
          9.25807,
          9.024952,
          8.412179,
          8.923039,
          7.4575653,
          7.9878035,
          8.053405,
          5.3336077,
          4.3796377,
          4.3153105,
          4.321434,
          4.3962865,
          4.4357705,
          4.46185,
          4.407113,
          4.3952584,
          4.423592,
          4.6182466,
          4.522816,
          4.8401947,
          4.8166075,
          4.831156,
          -2.699443,
          4.4302716,
          4.6477904,
          4.5350127,
          4.5432415,
          4.5751686,
          4.4652553,
          4.904655,
          5.097447,
          5.1506863,
          5.0848985,
          5.153304,
          5.304228,
          5.090133,
          4.8788605,
          5.065391,
          5.1561875,
          5.3497143,
          5.1124706,
          5.0802197,
          -2.8670697,
          -2.3130097,
          -2.145538,
          7.0648446,
          9.257774,
          8.727509,
          9.199238,
          9.246818,
          9.229953,
          9.260429,
          9.218914,
          9.201215,
          9.212452,
          9.278144,
          8.76289,
          5.120013,
          4.8426356,
          4.313659,
          3.5811481,
          6.852381,
          5.947078,
          6.4078484,
          6.7732744,
          6.7245955,
          6.5713625,
          7.4656925,
          5.7139325,
          6.7361493,
          8.932674,
          8.462712,
          7.0835423,
          7.2741637,
          7.258759,
          6.7511525,
          6.3486757,
          6.751851,
          7.078397,
          7.0981894,
          7.1283565,
          7.0210238,
          6.955178,
          7.0705113,
          6.9965725,
          7.070946,
          6.9152155,
          6.914152,
          6.5870275,
          6.365972,
          6.4654255,
          6.495302,
          7.87602,
          6.7165847,
          6.504649,
          6.8466787,
          7.422479,
          7.4061217,
          7.6800404,
          7.6620817,
          7.475536,
          6.3232512,
          7.126292,
          8.873501,
          7.922913,
          7.8147993,
          8.516778,
          9.113371,
          8.875425,
          8.707011,
          7.987311,
          7.757045,
          -9.519039,
          -10.706965
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "CHAPTER 1: Introduction to Machine Learning - Python Machine Learning [Book]\n\nSkip to main content\n\n..."
          ],
          [
           "Start your free trial\n\nCHAPTER 1Introduction to Machine Learning\n\nWelcome to Python Machine Learning..."
          ],
          [
           "About O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nCommunity partners\n\nAffi..."
          ],
          [
           "Close\n\nCHAPTER 2: Extending Python Using NumPy - Python Machine Learning [Book]\n\nSkip to main conten..."
          ],
          [
           "Start your free trial\n\nCHAPTER 2Extending Python Using NumPy\n\nWhat Is NumPy? In Python, you usually ..."
          ],
          [
           "Get Python Machine Learning now with the O’Reilly learning platform. O’Reilly members experience boo..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "What Is Pandas? While NumPy arrays are a much‐improved N‐dimensional array object version over Pytho..."
          ],
          [
           "08:00:00,5.0 4,2016-06-02 12:00:00,4.9 5,2016-06-02 18:00:00,5.5 6,2016-06-03 08:00:00,5.6 7,2016-06..."
          ],
          [
           "18,2016-06-07 08:00:00,6.6 19,2016-06-07 12:00:00,4.1 20,2016-06-07 18:00:00,6.9 21,2016-06-08 08:00..."
          ],
          [
           "To be able to deal with data stored as tables, you need a new data type that is more suited to deal ..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nCHAPTER 4Data Visualization Using matplotlib\n\nWhat Is matplotlib? As the adag..."
          ],
          [
           "Plotting Line Charts To see how easy it is to use matplotlib, let's plot ...\n\nGet Python Machine Lea..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nCHAPTER 5Getting Started with Scikit‐learn for Machine Learning\n\nIntroduction..."
          ],
          [
           "Close\n\nCHAPTER 6: Supervised Learning—Linear Regression - Python Machine Learning [Book]\n\nSkip to ma..."
          ],
          [
           "Figure 6.1: Some terminologies for features and label\n\nTIP Features are also sometimes called explan..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nCHAPTER 7Supervised Learning—Classification Using Logistic Regression\n\nWhat I..."
          ],
          [
           "Close\n\nCHAPTER 8: Supervised Learning—Classification Using Support Vector Machines - Python Machine ..."
          ],
          [
           "Figure 8.1: Using SVM to separate two classes of animals\n\nOnce the line is drawn to separate the cla..."
          ],
          [
           "logo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJ..."
          ],
          [
           "Individuals\n\nFeatures\n\nAll features\n\nCourses\n\nCertifications\n\nInteractive learning\n\nLive events\n\nAns..."
          ],
          [
           "Figure 9.1: The classification of a point depends on the majority of its neighbors\n\nTIP KNN is also ..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nCHAPTER 10Unsupervised Learning—Clustering Using K‐Means\n\nWhat Is Unsupervise..."
          ],
          [
           "Close\n\nCHAPTER 11: Using Azure Machine Learning Studio - Python Machine Learning [Book]\n\nSkip to mai..."
          ],
          [
           "Start your free trial\n\nCHAPTER 11Using Azure Machine Learning Studio\n\nWhat Is Microsoft Azure Machin..."
          ],
          [
           "Close\n\nCHAPTER 12: Deploying Machine Learning Models - Python Machine Learning [Book]\n\nSkip to main ..."
          ],
          [
           "Start your free trial\n\nCHAPTER 12Deploying Machine Learning Models\n\nDeploying ML The main goal of ma..."
          ],
          [
           "Start your free trial\n\nAbout O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nC..."
          ],
          [
           "Close\n\nIndex\n\nPython Machine Learning [Book]\n\nSkip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor bus..."
          ],
          [
           "Start your free trial\n\nIndex\n\nA accuracy, computing of, 168–171 algorithms categories of in ML, 5 co..."
          ],
          [
           "B\n\nBagging, 143\n\nbar chart\n\ndefined, 73\n\nplotting of, 73–77\n\nbar() function, 73\n\nbias, 141–144\n\nBool..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\PythonML-Lee.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\PythonML-Lee.txt, circle",
         "marker": {
          "color": "#19d3f3",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\PythonML-Lee.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          10.473553,
          10.5712185,
          14.797825,
          10.678641,
          -3.267096,
          12.333795,
          10.529681,
          -11.086033,
          -10.27904,
          -10.385921,
          -2.1254795,
          10.695083,
          -7.8303733,
          -7.549992,
          10.648281,
          9.928094,
          9.332112,
          8.753515,
          12.827281,
          8.010993,
          8.50164,
          0.8828965,
          14.329192,
          8.055779,
          7.94526,
          12.860418,
          6.751553,
          10.201154,
          9.758173,
          10.341177,
          9.10745,
          14.68863,
          10.643611,
          8.992893,
          9.348503,
          14.35265
         ],
         "xaxis": "x",
         "y": [
          -2.3872817,
          -2.5170004,
          -3.4059691,
          -2.591402,
          -7.099635,
          -3.4628904,
          -2.6685019,
          2.3612132,
          3.0617225,
          2.9501266,
          -6.989784,
          -2.6611602,
          5.1523757,
          6.0442653,
          -2.5342944,
          -2.1352286,
          -1.563864,
          -1.507759,
          -3.7091973,
          -1.175431,
          -1.4032032,
          5.669987,
          -3.4783995,
          -1.7723969,
          -1.4909343,
          -3.811163,
          -1.7664156,
          -2.7680192,
          -2.0531235,
          -2.567645,
          -2.2806258,
          -3.4272301,
          -2.6045356,
          -1.2664535,
          -2.3635967,
          -3.7180476
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Giving Computers the Ability to Learn from Data - Python Machine Learning - Third Edition [Book]\n\nSk..."
          ],
          [
           "Get Python Machine Learning - Third Edition now with the O’Reilly learning platform. O’Reilly member..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n2 Training Simple Machine Learning Algorithms for Classification\n\nIn this cha..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Insights reporting\n\nBlog\n\nContent sponsorship\n\nPython Machine Learning - Third Edition by Sebastian ..."
          ],
          [
           "Submit an RFP\n\nDiversity\n\nO’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\n..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Dealing with missing data\n\nIt is ...\n\nGet Python Machine Learning - Third Edition now with the O’Rei..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n5 Compressing Data via Dimensionality Reduction\n\nIn Chapter 4, Building Good ..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Insights reporting\n\nBlog\n\nContent sponsorship\n\nPython Machine Learning - Third Edition by Sebastian ..."
          ],
          [
           "Affiliate program\n\nSubmit an RFP\n\nDiversity\n\nO’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletter..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Close\n\nApplying Machine Learning to Sentiment Analysis - Python Machine Learning - Third Edition [Bo..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n9 Embedding a Machine Learning Model into a Web Application\n\nIn the previous ..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Insights reporting\n\nBlog\n\nContent sponsorship\n\nPython Machine Learning - Third Edition by Sebastian ..."
          ],
          [
           "O’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nl..."
          ],
          [
           "Sign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividuals\n\nFeatures\n\nAll fea..."
          ],
          [
           "Close\n\nImplementing a Multilayer Artificial Neural Network from Scratch - Python Machine Learning - ..."
          ],
          [
           "Gaining ...\n\nGet Python Machine Learning - Third Edition now with the O’Reilly learning platform. O’..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n13 Parallelizing Neural Network Training with TensorFlow\n\nIn this chapter, we..."
          ],
          [
           "International\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJapan\n\nDownload the O’..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "Close\n\nClassifying Images with Deep Convolutional Neural Networks - Python Machine Learning - Third ..."
          ],
          [
           "Convolution operations in one and two dimensions The building blocks of CNN architectures Implementi..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\n16 Modeling Sequential Data Using Recurrent Neural Networks\n\nIn the previous ..."
          ],
          [
           "International\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJapan\n\nDownload the O’..."
          ],
          [
           "Courses\n\nCertifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nConte..."
          ],
          [
           "Close\n\nReinforcement Learning for Decision Making in Complex Environments - Python Machine Learning ..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\PythonML-RaschkaMirjalili.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\PythonML-RaschkaMirjalili.txt, circle",
         "marker": {
          "color": "#FF6692",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\PythonML-RaschkaMirjalili.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          9.94338,
          11.67421,
          10.737729,
          8.623768,
          14.29369,
          10.081612,
          14.606187,
          9.071321,
          9.987583,
          10.66006,
          7.6111846,
          14.3235035,
          10.087718,
          14.231302,
          9.611316,
          8.004659,
          10.685448,
          8.893799,
          14.326975,
          9.53063,
          14.816351,
          7.827227,
          8.338275,
          13.478516,
          9.436273,
          8.549195,
          14.374115,
          8.934144,
          8.490113,
          8.364491,
          13.649643,
          8.326356,
          14.413354,
          8.475912,
          8.681735,
          8.649383
         ],
         "xaxis": "x",
         "y": [
          -2.2603648,
          -3.1192446,
          -2.6587794,
          -1.6654581,
          -2.6339557,
          -2.6811998,
          -3.353416,
          -2.211518,
          -2.3702266,
          -2.4992945,
          -1.3997111,
          -2.8819804,
          -2.6057441,
          -3.5209498,
          -1.694994,
          -1.7484143,
          -2.7018394,
          -2.1180587,
          -2.768885,
          -2.201929,
          -3.4016542,
          -2.0763664,
          -3.9380958,
          -3.5041375,
          -3.9265187,
          -3.9722035,
          -3.1584814,
          -4.124789,
          -4.0999537,
          -3.9892755,
          -4.5215154,
          -3.9930997,
          -3.209312,
          -3.8701923,
          -2.7520552,
          -2.7557237
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "1. Probably Approximately Correct Software - Thoughtful Machine Learning with Python [Book]\n\nSkip to..."
          ],
          [
           "Start your free trial\n\nChapter 1. Probably Approximately Correct Software If you’ve ever flown on an..."
          ],
          [
           "The year 2014 saw the Heartbleed bug infection, which made many sites using SSL vulnerable. As a res..."
          ],
          [
           "SOLID SOLID is a framework that helps design better object-oriented code. In the same ways that the ..."
          ],
          [
           "Figure 1-1. A multi-tool like this has too many responsibilities\n\nOpen/Closed Principle The OCP, som..."
          ],
          [
           "Dependency Inversion Principle The DIP is a principle that guides us to depend on abstractions, not ..."
          ],
          [
           "Testing or TDD In the early days of aviation, pilots didn’t use checklists to test whether their air..."
          ],
          [
           "This led to the Agile Manifesto as well as the culture of testing and TDD, spearheaded by Kent Beck,..."
          ],
          [
           "Refactoring Refactoring is one of the hardest programming practices to explain to nonprogrammers, wh..."
          ],
          [
           "Technical debt in many cases arises through not writing tests or not following the SOLID principles...."
          ],
          [
           "Refactor your code to avoid a buildup of technical debt\n\nThe real question now is what makes the sof..."
          ],
          [
           "Writing the Right Software with Machine Learning In The Knowledge-Creating Company, Nonaka and Takeu..."
          ],
          [
           "The issue with inductive reasoning, though, is that you can only feed the algorithm data that you kn..."
          ],
          [
           "Hidden feedback loops Having built-in hidden features in model OCP\n\nUndeclared consumers/visibility ..."
          ],
          [
           "SRP In machine learning code, one of the biggest challenges for people to realize is that the code a..."
          ],
          [
           "OCP Recall that the OCP is about opening classes for extension but not modification. One way this ma..."
          ],
          [
           "LSP Not a lot of people talk about the LSP anymore because many programmers are advocating for compo..."
          ],
          [
           "ISP The ISP is the notion that a client-specific interface is better than a general purpose one. In ..."
          ],
          [
           "Many times this just isn’t the case. Take for instance the price of a stock; in the morning it might..."
          ],
          [
           "DIP The Dependency Inversion Principle is about limiting our buildups of data and making code more f..."
          ],
          [
           "Machine Learning Code Is Complex but Not Impossible At times, machine learning code can be difficult..."
          ],
          [
           "TDD: Scientific Method 2.0 Every true scientist is a dreamer and a skeptic. Daring to put a person o..."
          ],
          [
           "The Plan for the Book This book will cover a lot of ground with machine learning, but by the end you..."
          ],
          [
           "Get Thoughtful Machine Learning with Python now with the O’Reilly learning platform. O’Reilly member..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 2. A Quick Introduction to Machine Learning You’ve picked up this boo..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 3. K-Nearest Neighbors Have you ever bought a house before? If you’re..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 4. Naive Bayesian Classification Remember how email was several years..."
          ],
          [
           "Using Bayes’ Theorem to Find Fraudulent Orders Imagine you’re running an online store and lately you..."
          ],
          [
           "Conditional Probabilities Most people understand what we mean by the probability of something happen..."
          ],
          [
           "set(a) | set(b) #=> [1,2,3,4,5] Finally, the probability of A given B looks as follows in Python: a ..."
          ],
          [
           "r\n\nd\n\n)\n\n=\n\nP(Fraud∩Giftcard) P(Giftcard)\n\nNow this works if you know the actual probability of Frau..."
          ],
          [
           "P\n\n(\n\nF\n\nr\n\na\n\nu\n\nd\n\n∣\n\nG\n\ni\n\nf\n\nt\n\nc\n\na\n\nr\n\nd\n\n)\n\n=\n\nP(Giftcard∣Fraud)P(Fraud) P(Giftcard)\n\nRemembe..."
          ],
          [
           ")\n\n=\n\n60%\n\n10% 10%\n\n=\n\n60\n\n%\n\nThe beauty of this is that your work on measuring fraudulent orders is..."
          ],
          [
           "P\n\n(\n\nA\n\n∩\n\nB\n\n)\n\n=\n\nP\n\n(\n\nB\n\n|\n\nA\n\n)\n\nP\n\n(\n\nA\n\n)\n\n. This is assuming these events are not mutually ..."
          ],
          [
           ",\n\nA 2\n\n,\n\n⋯\n\n,\n\nA n\n\n1\n\n)\n\nThis expanded version is useful in trying to solve our problem by feedin..."
          ],
          [
           "s\n\n)\n\n=\n\nP(Giftcard,Promos∣Fraud)P(Fraud) P(Giftcard,Promos)\n\nLet’s ignore the denominator for now, ..."
          ],
          [
           "G\n\n|\n\nF\n\n)\n\nP\n\n(\n\nP\n\n|\n\nF\n\n,\n\nG\n\n)\n\nNow at this point we have a conundrum: how do you measure the pr..."
          ],
          [
           "i\n\nf\n\nt\n\nc\n\na\n\nr\n\nd\n\n∣\n\nF\n\nr\n\na\n\nu\n\nd\n\n)\n\nP\n\n(\n\nP\n\nr\n\no\n\nm\n\no\n\n∣\n\nF\n\nr\n\na\n\nu\n\nd\n\n)\n\nThis would be pr..."
          ],
          [
           "a\n\nu\n\nd\n\n)\n\nP\n\n(\n\nG\n\ni\n\nf\n\nt\n\nc\n\na\n\nr\n\nd\n\n∣\n\nF\n\nr\n\na\n\nu\n\nd\n\n)\n\nP\n\n(\n\nP\n\nr\n\no\n\nm\n\no\n\n∣\n\nF\n\nr\n\na\n\nu\n\nd..."
          ],
          [
           "Multiple promos used\n\n50%\n\n30%\n\nProbability of class\n\n10%\n\n90%\n\nAt this point, you can use this info..."
          ],
          [
           "Pseudocount There is one big challenge with a Naive Bayesian Classifier, and that is the introductio..."
          ],
          [
           "0\n\nPrince\n\n75%\n\n15%\n\nNigeria\n\n85%\n\n10%\n\nNow let’s assume we want to calculate a score for ham or spa..."
          ],
          [
           "What the classes look like interacting with each other\n\nA good data source\n\nA tokenization model\n\nAn..."
          ],
          [
           "EmailObject The EmailObject class has one responsibility, which is to parse an incoming email messag..."
          ],
          [
           "class TestPlaintextEmailObject(unittest.TestCase):\n\nCLRF = \"\\n\\n\"\n\ndef setUp(self): self.plain_file ..."
          ],
          [
           "Any method that is prefixed with test_ will be treated as a test to be run.\n\nsetUp(self) is a specia..."
          ],
          [
           "not isinstance(a,b)\n\nDo note that we will not use all of these methods; they are listed here for fut..."
          ],
          [
           "@staticmethod def _single_body(part): \"\"\" Get text from part. :param part: email.Message :return: st..."
          ],
          [
           "expected = BeautifulSoup(body, 'html.parser').text\n\nactual_body = self.html_email.body()\n\nself.asser..."
          ],
          [
           "if content_type == 'text/html': return BeautifulSoup(body, 'html.parser').text elif content_type == ..."
          ],
          [
           "class TestTokenizer(unittest.TestCase): def setUp(self): self.string = \"this is a test of the emerge..."
          ],
          [
           "return re.findall(\"\\w+\", string.lower())\n\n@staticmethod\n\ndef unique_tokenizer(string):\n\nreturn set(T..."
          ],
          [
           "Storing training data\n\nBuilding a Bayesian classifier\n\nError minimization through cross\n\nvalidation\n..."
          ],
          [
           "def test_multiple_categories(self): categories = self.trainer.categories expected = set([k for k, v ..."
          ],
          [
           "def test_counts_all_at_zero(self): for cat in ['_all', 'spam', 'ham', 'scram']: self.assertEqual(sel..."
          ],
          [
           "B\n\n)\n\n= P(B∣A i )P(A i ) ∑ j P(B∣A j )P(A j )\n\nBut because we’re being naive about this, we’ve disti..."
          ],
          [
           "W n\n\n∣\n\nS\n\np\n\na\n\nm\n\n)\n\nwhich is then divided by some normalizing constant, Z. Our goal now is to bui..."
          ],
          [
           "\"\"\"\n\nCalculates score\n\n:param email: EmailObject\n\n:return: float number\n\n\"\"\"\n\nself.train()\n\ncat_tota..."
          ],
          [
           "def test_adds_up_to_one(self): trainer = self.trainer scores = list(trainer.normalized_score(self.em..."
          ],
          [
           "normalized = {cat: (aggregate / scoresum) \\ for cat, aggregate in score.items()} return normalized\n\n..."
          ],
          [
           "def preference(self): return sorted(self.categories, key=lambda cat: self.total_for(cat)) Now that w..."
          ],
          [
           "def classify(self, email):\n\nscore = self.score(email)\n\nmax_score = 0.0\n\npreference = self.preference..."
          ],
          [
           "Minimizing false positives Up until this point, our goal with making models has been to minimize err..."
          ],
          [
           "from spam_trainer import SpamTrainer\n\nfrom email_object import EmailObject\n\nprint(\"Cross Validation\"..."
          ],
          [
           "with io.open(file, 'rb') as eml_file: emails.append(EmailObject(eml_file, category=label))\n\nprint(\"D..."
          ],
          [
           "validate(trainer, emails) Last, we can analyze the other direction of the cross-validation (i.e., va..."
          ],
          [
           "Email count\n\nWord count\n\nProbability of email\n\nProbability of word\n\nSpam\n\n1,378\n\n231,472\n\n31.8%\n\n36...."
          ],
          [
           "About O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nCommunity partners\n\nAffi..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 5. Decision Trees and Random Forests Every day we make decisions. Eve..."
          ],
          [
           "When ...\n\nGet Thoughtful Machine Learning with Python now with the O’Reilly learning platform. O’Rei..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 6. Hidden Markov Models Intuition informs much of what we do: for exa..."
          ],
          [
           "Figure ...\n\nGet Thoughtful Machine Learning with Python now with the O’Reilly learning platform. O’R..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 7. Support Vector Machines In this chapter, we will set out to solve ..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 8. Neural Networks Humans are amazing pattern matchers. When we come ..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 9. Clustering Up until this point we have been solving problems of fi..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Feature selection\n\nFeature transformation\n\nEnsemble learning\n\nBootstrapping\n\nI’ll outline the benefi..."
          ],
          [
           "Press releases\n\nMedia coverage\n\nCommunity partners\n\nAffiliate program\n\nSubmit an RFP\n\nDiversity\n\nO’R..."
          ],
          [
           "Close\n\n11. Putting It Together: Conclusion - Thoughtful Machine Learning with Python [Book]\n\nSkip to..."
          ],
          [
           "Start your free trial\n\nChapter 11. Putting It Together: Conclusion Well, here we are! The end of the..."
          ],
          [
           "Supervised Supervised learning is the most common machine learning category. This is functional appr..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Blog\n\nContent sponsorship\n\nThoughtful Machine Learning with Python by Matthew Kirk\n\nBuy on Amazon\n\nB..."
          ],
          [
           "aggregation (see bagging)Brown Corpus, Part-of-Speech Tagging with the Brown Corpus-How to Make This..."
          ],
          [
           "International\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJapan\n\nDownload the O’..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\ThoughtfulML-Kirk.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\ThoughtfulML-Kirk.txt, circle",
         "marker": {
          "color": "#B6E880",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\ThoughtfulML-Kirk.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          10.8665695,
          8.3080635,
          8.007924,
          7.856766,
          7.699763,
          7.8133283,
          8.086398,
          7.954926,
          7.9695244,
          7.8827176,
          7.8499928,
          7.6479363,
          7.5203657,
          7.533338,
          7.521399,
          6.9956517,
          7.2027564,
          7.335226,
          6.9849496,
          7.4882245,
          8.090379,
          8.188479,
          8.584558,
          10.774055,
          13.496348,
          8.227068,
          10.747828,
          6.8937187,
          13.316179,
          4.935911,
          3.54377,
          3.4643264,
          3.5668063,
          3.4307513,
          3.5116365,
          3.5808034,
          3.6272004,
          3.5855634,
          3.5094929,
          3.4903734,
          3.9510503,
          3.4367068,
          3.5688415,
          4.807729,
          4.890135,
          5.0266376,
          4.6652355,
          4.4113135,
          0.9413947,
          4.5604973,
          4.558347,
          4.572585,
          4.7292886,
          4.3528314,
          4.9050193,
          4.8412795,
          4.764516,
          4.830593,
          4.2345805,
          4.774307,
          4.688822,
          4.670729,
          4.6082234,
          4.7408266,
          5.126282,
          5.2135735,
          4.903626,
          4.8533683,
          4.949631,
          5.0197387,
          14.975982,
          10.476345,
          8.19746,
          10.701721,
          13.300706,
          5.9092507,
          10.32995,
          13.379466,
          8.417986,
          10.792205,
          8.134263,
          10.937994,
          6.7116356,
          12.92628,
          6.8750215,
          14.849132,
          10.77414,
          7.8322015,
          8.375395,
          13.148938,
          10.552784,
          6.318393,
          14.465791
         ],
         "xaxis": "x",
         "y": [
          -2.6559582,
          0.021307979,
          0.33160502,
          0.44049016,
          0.40343043,
          0.4174848,
          0.5010892,
          0.2397147,
          0.47066858,
          0.41835395,
          0.14775719,
          -2.3886452,
          -0.16712476,
          0.2669855,
          0.22373171,
          0.13836344,
          0.17676386,
          0.11969008,
          0.1137207,
          0.19068627,
          -1.4076176,
          -1.0765516,
          -1.9549263,
          -2.6977897,
          -4.4041514,
          -2.0846925,
          -2.6610515,
          -0.7908447,
          -4.2517138,
          -3.1125474,
          -3.2968874,
          -3.2442386,
          -3.2861302,
          -3.2689924,
          -3.2767851,
          -3.2983847,
          -3.2788703,
          -3.2898324,
          -3.2772458,
          -3.2992067,
          -3.2239506,
          -3.2695813,
          -3.278225,
          -3.13515,
          -3.0608675,
          -4.2132554,
          -4.7534876,
          -4.8663974,
          -7.605729,
          -4.747803,
          -4.709799,
          -4.709787,
          -4.3411546,
          -4.911165,
          -4.373724,
          -4.5044055,
          -4.4489207,
          -4.3519983,
          -3.2202024,
          -4.503027,
          -4.6474175,
          -4.6620836,
          -4.4951653,
          -4.490221,
          -3.9175262,
          -4.3639035,
          -4.472978,
          -4.4836154,
          -4.483931,
          -3.401569,
          -3.4543414,
          -2.3197465,
          3.5399547,
          -2.9412427,
          -4.061575,
          -2.4946446,
          -2.8451269,
          -4.3784184,
          -1.3203768,
          -2.7431827,
          -3.8208244,
          -2.6505136,
          -1.7800136,
          -4.0474935,
          -0.47159663,
          -3.342797,
          -2.6218457,
          -1.9954157,
          -1.9822469,
          -4.052818,
          -2.54866,
          -2.1993647,
          -2.9381857
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "okay hello welcome to uh week 11's lecture uh it's been a little while since we\n\ntalked about some o..."
          ],
          [
           "just as a review here what we've got is uh uh this is our typical\n\nkind of you know well anyway mach..."
          ],
          [
           "just based off the training set we can do that all right we can basically detect our error rate thin..."
          ],
          [
           "just building something in isolation what's it going to look like when it's actually working out the..."
          ],
          [
           "in a classification standpoint all right so we're doing all classification here i'll talk about regr..."
          ],
          [
           "potential threat to a system might be a one right that's a positive outcome that we positively ident..."
          ],
          [
           "okay all right all right so\n\nlet's work through an example we're talking here about intruder fraud d..."
          ],
          [
           "this is data point x right the likelihood\n\nprobability of that particular data point being spam is 5..."
          ],
          [
           "on positive and negative classification i don't think i need to read through all this let's just loo..."
          ],
          [
           "right is that because our threshold is so low right is that we\n\nhave no tolerance for potential frau..."
          ],
          [
           "according to what problem you might have right you might adjust that threshold measure right\n\nmaybe ..."
          ],
          [
           "predict true positives how often are we right okay not that good okay all right so\n\nnot so good here..."
          ],
          [
           "positive and false positive rate and those just become data points on a axis you just graph them\n\non..."
          ],
          [
           "it's much more kind of oriented towards this balance between false positives\n\nand true positives oh ..."
          ],
          [
           "is sensitivity all right we talked about that um okay\n\nuh and this is just one minus specificity all..."
          ],
          [
           "then penalizing you if you're not doing that well so i would i would certainly consider that\n\nespeci..."
          ],
          [
           "of one can be expected you know your case when our model gives us less than a forty percent\n\nprobabi..."
          ],
          [
           "know that's not super useful but it is really good for multi-class models\n\nall right and it and it w..."
          ],
          [
           "amongst all three of these all right so almost perfect agreement right so if we assume here we do a\n..."
          ],
          [
           "basically just the detection rate but in multi-class samples it works really well right so you can s..."
          ],
          [
           "the standard ones that i think a lot of people are familiar with mean squared error right that's jus..."
          ],
          [
           "one does all right is it just normalizes all right that root mean squared error\n\nby dividing it by t..."
          ],
          [
           "that's not quite as bad right so it helps put that into context that's what this does here it's all ..."
          ],
          [
           "all right that is the data grows all right it's not heavily dependent on a large number of covariate..."
          ],
          [
           "is under fit so here we have high bias okay and low variance\n\nso that's what we see down here all ri..."
          ],
          [
           "it right it probably goes out to this second rim all right but it's not that far off\n\nsomething like..."
          ],
          [
           "discussing here all right but it also kind of is an extension all right of that all right so i just\n..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\Week7-lecture.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\Week7-lecture.txt, circle",
         "marker": {
          "color": "#FF97FF",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\Week7-lecture.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          8.589866,
          7.516312,
          7.297101,
          8.023968,
          8.351492,
          8.50316,
          8.324321,
          8.4054575,
          8.450032,
          8.637371,
          8.404679,
          8.469046,
          8.458164,
          8.435552,
          8.471423,
          8.219326,
          8.426529,
          8.271361,
          8.426391,
          8.136818,
          7.842808,
          7.076408,
          6.3309565,
          5.5376425,
          6.5661983,
          7.9011827,
          7.9878855
         ],
         "xaxis": "x",
         "y": [
          -0.3665003,
          3.225103,
          3.052013,
          3.0421677,
          3.2149763,
          3.3066654,
          3.5063672,
          3.2774444,
          3.3333616,
          3.5325465,
          3.1727297,
          3.2849424,
          3.30844,
          3.2656543,
          3.2690654,
          3.3777308,
          3.228685,
          3.2401762,
          3.2891033,
          3.2428586,
          3.6721702,
          3.8166094,
          3.5906649,
          3.9609077,
          3.6473336,
          3.115199,
          0.8757337
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "okay all right so let me pop this up here\n\nbigger i can do that there we go all right so we've been ..."
          ],
          [
           "have a leaf node or terminal node kind of the same thing it has one node coming in one edge and then..."
          ],
          [
           "of classifying setosa right that's remember that's a type of flower\n\nthat we have there does such a ..."
          ],
          [
           "to be able to decide uh how to classify our target variable all right all right so\n\nyou know dependi..."
          ],
          [
           "here you know it might be that you know a certain person you know fifty percent will go on uh on\n\na ..."
          ],
          [
           "example to maybe a perfect classification of whether they will go on to the second date or not right..."
          ],
          [
           "whether someone will go on a second date or not all right okay all right\n\nso decision trees are hier..."
          ],
          [
           "predestined right you could have a couple of variables that are incredibly good at predicting these ..."
          ],
          [
           "individual node those individual internal leaves okay all right\n\nand it will consider every possible..."
          ],
          [
           "related to basically to information gain which is the key component to kind of\n\nunderstand how decis..."
          ],
          [
           "some pretty weighty advantages right it is simple to understand and interpret through data visualiza..."
          ],
          [
           "we'll be using to use uh use these methods in the wrong circumstances all right they do have\n\nlike a..."
          ],
          [
           "this is why you know a single decision tree depending on how good or bad your data is can be very\n\nu..."
          ],
          [
           "but until we get there we have to understand what one tree is doing before we start building forests..."
          ],
          [
           "right so we're thinking about basically this is our equation in\n\npractice here just this portion of ..."
          ],
          [
           "clumsy through that all right the idea here is that information gain is basically going to be right ..."
          ],
          [
           "what we see here is that if the answer is yes all right that two of these uh\n\ntwo of these dots stop..."
          ],
          [
           "we're gonna take the average of these two numbers right so the average of 0.8\n\n0.0 all right and we'..."
          ],
          [
           "right and then we just subtract it from one and so we get 0.54\n\nall right okay so that would basical..."
          ],
          [
           "side of the uh side of the equation okay so let's take a look at another\n\nanother example here all r..."
          ],
          [
           "variable here sunny so that resulted in one yes all right all right\n\nand uh two nodes two nodes all ..."
          ],
          [
           "going to be 0 right okay and then we're going to subtract it by 1. so we're going to get all right 0..."
          ],
          [
           "perfectly terrible example all right so here what we see is we have perfect disagreement okay\n\nregar..."
          ],
          [
           "the same idea about net gain all right so pi in this equation just represents\n\nthe probability that ..."
          ],
          [
           "we see is you know kind of a a genie index here we're subtracting this from one that's\n\nbasically po..."
          ],
          [
           "mean squared error is how it's done if you were doing um if we were doing a continuous\n\nreducing bas..."
          ],
          [
           "kind of a pure split between this is this is pregnant and\n\nthat's the other way around sorry not pre..."
          ],
          [
           "at least you know 10 data points in every node all right so that would avoid kind of\n\nover spitting ..."
          ],
          [
           "are available all right are ones that have not been used uh anywhere higher all right\n\ninside the sp..."
          ],
          [
           "just stop there because uh you know the decision space is pretty low all right\n\nokay so the we talke..."
          ],
          [
           "anyway that's that that's there's let's assume that there's 24 dots here or something like that and ..."
          ],
          [
           "uh we talked about that a little bit we're gonna talk much more about that next week but that's basi..."
          ],
          [
           "visualization and they're intuitive so they can be useful for all those all those types of reasons b..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\Week9-lecture.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\Week9-lecture.txt, circle",
         "marker": {
          "color": "#FECB52",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\Week9-lecture.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          7.7358317,
          7.68802,
          8.0031595,
          8.076731,
          8.372819,
          8.197188,
          7.8396983,
          8.2190075,
          8.048908,
          7.7725863,
          7.278573,
          6.9200587,
          7.155208,
          7.773997,
          8.582617,
          8.483608,
          8.70082,
          8.319828,
          8.619146,
          8.338656,
          8.683946,
          8.608617,
          8.652462,
          8.589261,
          8.445887,
          8.154837,
          7.75057,
          7.4863563,
          8.019798,
          7.168205,
          6.6073866,
          7.393848,
          7.715951
         ],
         "xaxis": "x",
         "y": [
          4.137862,
          4.165685,
          3.9642234,
          3.5529854,
          4.038456,
          3.9907067,
          4.0748887,
          4.193686,
          4.372248,
          4.235395,
          3.9599485,
          3.7768714,
          3.945485,
          4.148575,
          4.679432,
          4.5173993,
          4.5902,
          4.3835692,
          4.7028246,
          4.5631866,
          4.849548,
          4.6687417,
          4.6825967,
          4.744578,
          4.588737,
          4.2963305,
          4.0140963,
          4.0039907,
          4.1507053,
          3.7343056,
          3.3136427,
          4.065073,
          1.8960693
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "What is a decision tree?"
          ]
         ],
         "hovertemplate": "source=User query<br>symbol=star<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "User query, star",
         "marker": {
          "color": "black",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           100
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "diamond"
         },
         "mode": "markers",
         "name": "User query, star",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          7.513973
         ],
         "xaxis": "x",
         "y": [
          4.022849
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 700,
        "legend": {
         "itemsizing": "constant",
         "title": {
          "text": "<b>Chunk source</b>"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "<b>2D Projection of Chunk Embeddings via PaCMAP</b>"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# vistualize pca projection\n",
    "\n",
    "df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"x\": documents_projected[i, 0],\n",
    "            \"y\": documents_projected[i, 1],\n",
    "            \"source\": docs_processed[i].metadata[\"source\"],#[\"source\"],#.split(\"/\")[1],\n",
    "            \"extract\": docs_processed[i].page_content[:100] + \"...\",\n",
    "            \"symbol\": \"circle\",\n",
    "            \"size_col\": 4,\n",
    "        }\n",
    "        for i in range(len(docs_processed))\n",
    "    ]\n",
    "    + [\n",
    "        {\n",
    "            \"x\": documents_projected[-1, 0],\n",
    "            \"y\": documents_projected[-1, 1],\n",
    "            \"source\": \"User query\",\n",
    "            \"extract\": user_query,\n",
    "            \"size_col\": 100,\n",
    "            \"symbol\": \"star\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Visualize the embedding\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"source\",\n",
    "    hover_data=\"extract\",\n",
    "    size=\"size_col\",\n",
    "    symbol=\"symbol\",\n",
    "    color_discrete_map={\"User query\": \"black\"},\n",
    "    width=1000,\n",
    "    height=700,\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(opacity=1, line=dict(width=0, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "fig.update_layout(\n",
    "    legend_title_text=\"<b>Chunk source</b>\",\n",
    "    title=\"<b>2D Projection of Chunk Embeddings via PaCMAP</b>\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
