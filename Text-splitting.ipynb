{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing with chunking/embedding code from https://huggingface.co/learn/cookbook/advanced_rag on PythonDSHandbook.txt, Week7-lecture.txt, Week9-lecture.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "from tqdm.notebook import tqdm #progress bar\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Tuple #type hinting\n",
    "# from datasets import Dataset #to load in premade example datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)  # This will be helpful when visualizing retriever outputs\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter #splitter\n",
    "\n",
    "#langsmith setup\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "#load in Documents\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter #alt import\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# embedding and searching\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "#plotting\n",
    "import pacmap\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKDOWN_SEPARATORS = [\n",
    "    \"\\n#{1,6} \",\n",
    "    \"```\\n\",\n",
    "    \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
    "    \"\\n---+\\n\",\n",
    "    \"\\n___+\\n\",\n",
    "    \"\\n\\n\",\n",
    "    \"\\n\",\n",
    "    \" \",\n",
    "    \"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:25<00:00,  2.56s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33420d02e9954784974547ec0e2b3f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## load in docs (must be in IA-in-HigherEd dir)\n",
    "loader = DirectoryLoader('./RAG-docs/processed/', glob=\"**/*.txt\", show_progress = True) #all .txt files in processed folder\n",
    "docs = loader.load()\n",
    "docs\n",
    "\n",
    "# save as LC docs\n",
    "RAW_KNOWLEDGE_BASE = [\n",
    "    LangchainDocument(page_content=doc.page_content, metadata= doc.metadata) for doc in tqdm(docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wat6sv\\AppData\\Local\\miniconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's maximum sequence length: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384e7a150c56447fbd5ed7280e054903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split (chunk) docs with chunk size = max seq length()\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "seq_len = SentenceTransformer(EMBEDDING_MODEL_NAME).max_seq_length\n",
    "print(f\"Model's maximum sequence length: {seq_len}\")\n",
    "\n",
    "\n",
    "def split_documents(\n",
    "    chunk_size: int,\n",
    "    knowledge_base: List[LangchainDocument],\n",
    "    tokenizer_name: Optional[str] = EMBEDDING_MODEL_NAME,\n",
    ") -> List[LangchainDocument]:\n",
    "    \"\"\"\n",
    "    Split documents into chunks of maximum size `chunk_size` tokens and return a list of documents.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "        AutoTokenizer.from_pretrained(tokenizer_name),\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=int(chunk_size / 10),\n",
    "        add_start_index=True,\n",
    "        strip_whitespace=True,\n",
    "        separators=MARKDOWN_SEPARATORS,\n",
    "    )\n",
    "\n",
    "    docs_processed = []\n",
    "    for doc in knowledge_base:\n",
    "        docs_processed += text_splitter.split_documents([doc])\n",
    "\n",
    "    # Remove duplicates\n",
    "    unique_texts = {}\n",
    "    docs_processed_unique = []\n",
    "    for doc in docs_processed:\n",
    "        if doc.page_content not in unique_texts:\n",
    "            unique_texts[doc.page_content] = True\n",
    "            docs_processed_unique.append(doc)\n",
    "\n",
    "    return docs_processed_unique\n",
    "\n",
    "\n",
    "docs_processed = split_documents(\n",
    "    seq_len,  # We choose a chunk size adapted to our model\n",
    "    RAW_KNOWLEDGE_BASE,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
    ")\n",
    "\n",
    "# Let's visualize the chunk sizes we would have in tokens from a common model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME)\n",
    "lengths = [len(tokenizer.encode(doc.page_content)) for doc in tqdm(docs_processed)]\n",
    "fig = pd.Series(lengths).hist()\n",
    "plt.title(\"Distribution of document lengths in the knowledge base (in count of tokens)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings for docs \n",
    "## Takes a while to run loacally (~6 min w/ PythonDS, Week7, Week9)\n",
    "\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    multi_process=True,\n",
    "    # model_kwargs={\"device\": \"cuda\"}, #using cpu when running locally - change if connecting to GPU for more speed\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
    ")\n",
    "\n",
    "#edit distance strategy for use case\n",
    "KNOWLEDGE_VECTOR_DATABASE = FAISS.from_documents(\n",
    "    docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try chroma for vector storage\n",
    "\n",
    "\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# text_splitter  = RecursiveCharacterTextSplitter(chunk_size=seq_len,chunk_overlap=20)\n",
    "# text_chunks = text_splitter.split_documents(RAW_KNOWLEDGE_BASE)\n",
    "\n",
    "\n",
    "# vectorstore = Chroma.from_documents(documents=text_chunks, \n",
    "#                                     embedding=embedding_model)#,\n",
    "#                                     # persist_directory=\"data/vectorstore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_docs = vectorstore.similarity_search(\"What is a decision tree?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in sim_docs:\n",
    "#     print(doc.metadata['source'], \"\\n\", doc.page_content, \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWLEDGE_VECTOR_DATABASE.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed a user query in the same space\n",
    "user_query = \"What is a decision tree?\"\n",
    "query_vector = embedding_model.embed_query(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pca projection of embeddings for visualization\n",
    "\n",
    "embedding_projector = pacmap.PaCMAP(n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0, random_state=1)\n",
    "\n",
    "embeddings_2d = [\n",
    "    list(KNOWLEDGE_VECTOR_DATABASE.index.reconstruct_n(idx, 1)[0]) for idx in range(len(docs_processed))\n",
    "] + [query_vector]\n",
    "\n",
    "# Fit the data (the index of transformed data corresponds to the index of the original data)\n",
    "documents_projected = embedding_projector.fit_transform(np.array(embeddings_2d), init=\"pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Chapter 1: Introducing Active Machine Learning - Active Machine Learning with Python [Book]\n\nSkip to..."
          ],
          [
           "Get Active Machine Learning with Python now with the O’Reilly learning platform. O’Reilly members ex..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n2 Designing Query Strategy Frameworks Query strategies act as the engine that..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Answers\n\nInsights reporting\n\nBlog\n\nContent sponsorship\n\nActive Machine Learning with Python by Marga..."
          ],
          [
           "Affiliate program\n\nSubmit an RFP\n\nDiversity\n\nO’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletter..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Start your free trial\n\nAbout O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nC..."
          ],
          [
           "Close\n\nChapter 5: Leveraging Active Learning for Big Data - Active Machine Learning with Python [Boo..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n6 Evaluating and Enhancing Efficiency In this chapter, we will explore the im..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Answers\n\nInsights reporting\n\nBlog\n\nContent sponsorship\n\nActive Machine Learning with Python by Marga..."
          ],
          [
           "Submit an RFP\n\nDiversity\n\nO’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\n..."
          ],
          [
           "Sign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividuals\n\nFeatures\n\nAll fea..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\ActiveMLwithPython-Masson-Forsythe.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\ActiveMLwithPython-Masson-Forsythe.txt, circle",
         "marker": {
          "color": "#EF553B",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\ActiveMLwithPython-Masson-Forsythe.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          11.658587,
          12.358637,
          11.559008,
          11.361844,
          16.212793,
          11.371932,
          14.894184,
          11.62587,
          15.317937,
          11.319534,
          11.750568,
          11.502607,
          16.090538,
          11.400341,
          15.338058,
          11.577166
         ],
         "xaxis": "x",
         "y": [
          -1.9808246,
          -3.0407941,
          -2.1608374,
          -1.9259272,
          -5.2263403,
          -1.7162765,
          -4.915801,
          -1.8895842,
          -5.021869,
          -1.9640338,
          -1.9825373,
          -1.9118588,
          -5.20609,
          -1.9425197,
          -5.0223556,
          -1.9600452
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "1. The Machine Learning Landscape - Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFl..."
          ],
          [
           "Start your free trial\n\nChapter 1. The Machine Learning Landscape When most people hear “Machine Lear..."
          ],
          [
           "Then we will look at the workflow of a typical ML project, discuss the main challenges you may face,..."
          ],
          [
           "Your spam filter is a Machine Learning program that, given examples of spam emails (e.g., flagged by..."
          ],
          [
           "You would test your program and repeat steps 1 and 2 until it was good enough to launch.\n\nFigure 1\n\n..."
          ],
          [
           "Figure 1-2. The Machine Learning approach\n\nFigure 1-3. Automatically adapting to change\n\nAnother are..."
          ],
          [
           "Problems for which existing solutions require a lot of fine-tuning or long lists of rules: one Machi..."
          ],
          [
           "Creating a chatbot or a personal assistant\n\nThis involves many NLP components, including natural lan..."
          ],
          [
           "Recommending a product that a client may be interested in, based on past purchases\n\nThis is a recomm..."
          ],
          [
           "These criteria are not exclusive; you can combine them in any way you like. For example, a state-of-..."
          ],
          [
           "Figure 1-5. A labeled training set for spam classification (an example of supervised learning)\n\nA ty..."
          ],
          [
           "k\n\nNearest Neighbors\n\nLinear Regression\n\nLogistic Regression\n\nSupport Vector Machines (SVMs)\n\nDecisi..."
          ],
          [
           "t-Distributed Stochastic Neighbor Embedding (t-SNE)\n\nAssociation rule learning\n\nApriori\n\nEclat\n\nFor ..."
          ],
          [
           "Figure 1-9. Example of a t-SNE visualization highlighting semantic clusters3\n\nA related task is dime..."
          ],
          [
           "Yet another important unsupervised task is anomaly detection—for example, detecting unusual credit c..."
          ],
          [
           "Semisupervised learning Since labeling data is usually time-consuming and costly, you will often hav..."
          ],
          [
           "Reinforcement Learning Reinforcement Learning is a very different beast. The learning system, called..."
          ],
          [
           "Batch and Online Learning Another criterion used to classify Machine Learning systems is whether or ..."
          ],
          [
           "If you have a lot of data and you automate your system to train from scratch every day, it will end ..."
          ],
          [
           "Figure 1-13. In online learning, a model is trained and launched into production, and then it keeps ..."
          ],
          [
           "One important parameter of online learning systems is how fast they should adapt to changing data: t..."
          ],
          [
           "Instance-Based Versus Model-Based Learning One more way to categorize Machine Learning systems is by..."
          ],
          [
           "Figure 1\n\n15. Instance\n\nbased learning\n\nModel-based learning Another way to generalize from a set of..."
          ],
          [
           "Let’s plot the data for these countries (Figure 1-17).\n\nFigure 1-17. Do you see a trend here?\n\nThere..."
          ],
          [
           "Figure 1-18. A few possible linear models\n\nBefore you can use your model, you need to define the par..."
          ],
          [
           "Now the model fits the training data as closely as possible (for a linear model), as you can see in ..."
          ],
          [
           "encoding='latin1', na_values=\"n/a\")\n\n# Prepare the data country_stats = prepare_country_stats(oecd_b..."
          ],
          [
           "# Train the model\n\nmodel.fit(X, y)\n\n# Make a prediction for Cyprus X_new = [[22587]]  # Cyprus's GDP..."
          ],
          [
           "You studied the data.\n\nYou selected a model.\n\nYou trained it on the training data (i.e., the learnin..."
          ],
          [
           "The Unreasonable Effectiveness of Data In a famous paper published in 2001, Microsoft researchers Mi..."
          ],
          [
           "Figure 1-21. A more representative training sample\n\nIf you train a linear model on this data, you ge..."
          ],
          [
           "First, to obtain the addresses to send the polls to, the Literary Digest used telephone directories,..."
          ],
          [
           "If some instances are clearly outliers, it may help to simply discard them or try to fix the errors ..."
          ],
          [
           "Creating new features by gathering new data\n\nNow that we have looked at many examples of bad data, l..."
          ],
          [
           "Figure 1-22. Overfitting the training data\n\nComplex models such as deep neural networks can detect s..."
          ],
          [
           "Gather more training data.\n\nReduce the noise in the training data (e.g., fix data errors and remove ..."
          ],
          [
           "You can see that regularization forced the model to have a smaller slope: this model does not fit th..."
          ],
          [
           "Reduce the constraints on the model (e.g., reduce the regularization hyperparameter).\n\nStepping Back..."
          ],
          [
           "Testing and Validating The only way to know how well a model will generalize to new cases is to actu..."
          ],
          [
           "Hyperparameter Tuning and Model Selection Evaluating a model is simple enough: just use a test set. ..."
          ],
          [
           "More specifically, you train multiple models with various hyperparameters on the reduced training se..."
          ],
          [
           "Data Mismatch In some cases, it’s easy to get a large amount of data for training, but this data pro..."
          ],
          [
           "After the model is trained (on the training set, not on the train-dev set), you can evaluate it on t..."
          ],
          [
           "No Free Lunch Theorem A model is a simplified version of the observations. The simplifications are m..."
          ],
          [
           "What is a labeled training set?\n\nWhat are the two most common supervised tasks?\n\nCan you name four c..."
          ],
          [
           "What can go wrong if you tune hyperparameters using the test set?\n\nSolutions to these exercises are ..."
          ],
          [
           "It’s just boring pandas code that joins the life satisfaction data from the OECD with the GDP per ca..."
          ],
          [
           "Support\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAust..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Fine\n\ntune your model.\n\nPresent your solution.\n\nLaunch, monitor, and maintain your system.\n\nWorking ..."
          ],
          [
           "Start your free trial\n\nAbout O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nC..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 3. Classification In Chapter 1 I mentioned that the most common super..."
          ],
          [
           "A DESCR key describing the dataset\n\nA data key containing an array with one ...\n\nGet Hands-On Machin..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "Start your free trial\n\nChapter 4. Training Models So far we have treated Machine Learning models and..."
          ],
          [
           "Using an iterative optimization approach called Gradient Descent (GD) that gradually tweaks the mode..."
          ],
          [
           "Linear Regression In Chapter 1 we looked at a simple regression model of life satisfaction: life_sat..."
          ],
          [
           "In this equation:\n\nθ is the model’s parameter vector, containing the bias term θ0 and the feature we..."
          ],
          [
           "OK, that’s the Linear Regression model—but how do we train it? Well, recall that training a model me..."
          ],
          [
           "The Normal Equation To find the value of θ that minimizes the cost function, there is a closed-form ..."
          ],
          [
           "Now let’s compute θ^ using the Normal Equation. We will use the inv() function from NumPy’s linear a..."
          ],
          [
           "we used to generate the data is y = 4 + 3x1 + Gaussian noise. Let’s see what the equation found: >>>..."
          ],
          [
           "original function. Now we can make predictions using θ^: >>> X_new = np.array([[0], [2]]) >>> X_new_..."
          ],
          [
           "y, \"b.\") plt.axis([0, 2, 0, 15]) plt.show()..."
          ],
          [
           "Figure 4-2. Linear Regression model predictions..."
          ],
          [
           "Performing Linear Regression using Scikit-Learn is simple:2 >>> from sklearn.linear_model import Lin..."
          ],
          [
           "you could call directly: >>> theta_best_svd, residuals, rank, s = np.linalg.lstsq(X_b, y, rcond=1e-6..."
          ],
          [
           "The pseudoinverse itself is computed using a standard matrix factorization technique called Singular..."
          ],
          [
           "then it replaces all the nonzero values with their inverse, and finally it transposes the resulting ..."
          ],
          [
           "This approach is more efficient than computing the Normal Equation, plus it handles edge cases nicel..."
          ],
          [
           "Also, once you have trained your Linear Regression model (using the Normal Equation or any other alg..."
          ],
          [
           "Figure 4-3. In this depiction of Gradient Descent, the model parameters are initialized randomly and..."
          ],
          [
           "Figure 4\n\n6. Gradient Descent pitfalls\n\nFortunately, the MSE cost function for a Linear Regression m..."
          ],
          [
           "This diagram also illustrates the fact that training a model means searching for a combination of mo..."
          ],
          [
           "θ ⊺\n\nx (i)\n\ny (i)\n\n)\n\nx j (i)\n\nInstead of computing these partial derivatives individually, you can ..."
          ],
          [
           "2 m\n\nX ⊺\n\n(\n\nX\n\nθ\n\ny\n\n)\n\nWarning Notice that this formula involves calculations over the full traini..."
          ],
          [
           "theta = np.random.randn(2,1)  # random initialization\n\nfor iteration in range(n_iterations): gradien..."
          ],
          [
           "Figure 4-8. Gradient Descent with various learning rates\n\nOn the left, the learning rate is too low:..."
          ],
          [
           "Stochastic Gradient Descent The main problem with Batch Gradient Descent is the fact that it uses th..."
          ],
          [
           "Figure 4-9. With Stochastic Gradient Descent, each training step is much faster but also much more s..."
          ],
          [
           "theta = np.random.randn(2,1)  # random initialization\n\nfor epoch in range(n_epochs): for i in range(..."
          ],
          [
           "Figure 4-10. The first 20 steps of Stochastic Gradient Descent\n\nNote that since instances are picked..."
          ],
          [
           "To perform Linear Regression using Stochastic GD with Scikit-Learn, you can use the SGDRegressor cla..."
          ],
          [
           "Mini-batch Gradient Descent The last Gradient Descent algorithm we will look at is called Mini-batch..."
          ],
          [
           "Figure 4-11. Gradient Descent paths in parameter space\n\nLet’s compare the algorithms we’ve discussed..."
          ],
          [
           "SGDRegressor\n\nNote There is almost no difference after training: all these algorithms end up with ve..."
          ],
          [
           "Figure 4-12. Generated nonlinear and noisy dataset\n\nClearly, a straight line will never fit this dat..."
          ],
          [
           "0.56\n\nx 1  2\n\n+\n\n0.93\n\nx 1\n\n+\n\n1.78\n\nwhen in fact the original function was\n\ny\n\n=\n\n0.5\n\nx 1  2\n\n+\n\n1..."
          ],
          [
           "Learning Curves If you perform high-degree Polynomial Regression, you will likely fit the training d..."
          ],
          [
           "Figure 4\n\n14. High\n\ndegree Polynomial Regression\n\nThis high-degree Polynomial Regression model is se..."
          ],
          [
           "def plot_learning_curves(model, X, y): X_train, X_val, y_train, y_val = train_test_split(X, y, test_..."
          ],
          [
           "Figure 4\n\n15. Learning curves\n\nThis model that’s underfitting deserves a bit of explanation. First, ..."
          ],
          [
           "polynomial_regression = Pipeline([\n\n(\"poly_features\", PolynomialFeatures(degree=10, include_bias=Fal..."
          ],
          [
           "Variance\n\nThis part is due to the model’s excessive sensitivity to small variations in the training ..."
          ],
          [
           "Ridge Regression Ridge Regression (also called Tikhonov regularization) is a regularized version of ..."
          ],
          [
           "The hyperparameter α controls how much you want to regularize the model. If α = 0, then Ridge Regres..."
          ],
          [
           "Figure 4-17. A linear model (left) and a polynomial model (right), both with various levels of Ridge..."
          ],
          [
           "θ ^\n\n=\n\n(X ⊺ X+αA)\n\n1\n\nX ⊺\n\ny\n\nHere is how to perform Ridge Regression with Scikit-Learn using a clo..."
          ],
          [
           "Lasso Regression Least Absolute Shrinkage and Selection Operator Regression (usually simply called L..."
          ],
          [
           "Figure 4-18. A linear model (left) and a polynomial model (right), both using various levels of Lass..."
          ],
          [
           "The small white circles show the path that Gradient Descent takes to optimize some model parameters ..."
          ],
          [
           "The Lasso cost function is not differentiable at θi = 0 (for i = 1, 2, ⋯, n), but Gradient Descent s..."
          ],
          [
           "Elastic Net Elastic Net is a middle ground between Ridge Regression and Lasso Regression. The regula..."
          ],
          [
           "Early Stopping A very different way to regularize iterative learning algorithms such as Gradient Des..."
          ],
          [
           "(\"std_scaler\", StandardScaler())\n\n])\n\nX_train_poly_scaled = poly_scaler.fit_transform(X_train)\n\nX_va..."
          ],
          [
           "Logistic Regression As we discussed in Chapter 1, some regression algorithms can be used for classif..."
          ],
          [
           "Equation 4\n\n14. Logistic function\n\nσ\n\n(\n\nt\n\n)\n\n=\n\n1 1+exp(\n\nt)\n\nFigure 4\n\n21. Logistic function\n\nOnc..."
          ],
          [
           "Training and Cost Function Now you know how a Logistic Regression model estimates probabilities and ..."
          ],
          [
           "Logistic Regression cost function (log loss)J(θ)=-1m∑i=1my(i)logp^(i)+(1-y(i))log1-p^(i) The bad new..."
          ],
          [
           "Decision Boundaries Let’s use the iris dataset to illustrate Logistic Regression. This is a famous d..."
          ],
          [
           "log_reg = LogisticRegression() log_reg.fit(X, y) Let’s look at the model’s estimated probabilities f..."
          ],
          [
           "Figure 4-23. Estimated probabilities and decision boundary\n\nThe petal width of Iris virginica flower..."
          ],
          [
           "Note that it is a linear boundary.16 Each parallel line represents the points where the model output..."
          ],
          [
           "(\n\nx\n\n)\n\n=\n\n(θ (k) ) ⊺\n\nx\n\nNote that each class has its own dedicated parameter vector θ(k). All the..."
          ],
          [
           "y ^\n\n=\n\nargmax k\n\nσ\n\ns(x) k\n\n=\n\nargmax k\n\ns k\n\n(\n\nx\n\n)\n\n=\n\nargmax k\n\n(θ (k) ) ⊺\n\nx\n\nThe argmax opera..."
          ],
          [
           "yk(i) is the target probability that the ith instance belongs to class k. In general, it is either e..."
          ],
          [
           "∇ θ (k)\n\nJ\n\n(\n\nΘ\n\n)\n\n=\n\n1 m\n\n∑ i=1 m\n\np ^ k (i)\n\ny k (i)\n\nx (i)\n\nNow you can compute the gradient ve..."
          ],
          [
           "softmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=10) softmax_reg.fit(X, ..."
          ],
          [
           "Exercises\n\nWhich Linear Regression training algorithm can you use if you have a training set with mi..."
          ],
          [
           "Lasso instead of Ridge Regression?\n\nElastic Net instead of Lasso?\n\nSuppose you want to classify pict..."
          ],
          [
           "Implement Batch Gradient Descent with early stopping for Softmax Regression (without using Scikit-Le..."
          ],
          [
           "Stochastic Average GD is a variant of Stochastic GD. For more details, see the presentation “Minimiz..."
          ],
          [
           "O’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nl..."
          ],
          [
           "Close\n\n5. Support Vector Machines - Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFl..."
          ],
          [
           "Linear SVM Classification The fundamental idea behind SVMs is best explained with some pictures. Fig..."
          ],
          [
           "Newsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\n..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Start your free trial\n\nChapter 6. Decision Trees Like SVMs, Decision Trees are versatile Machine Lea..."
          ],
          [
           "Get Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition now with the O’R..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 7. Ensemble Learning and Random Forests Suppose you pose a complex qu..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 8. Dimensionality Reduction Many Machine Learning problems involve th..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 9. Unsupervised Learning Techniques Although most of the applications..."
          ],
          [
           "As a result, the labeled dataset will be quite small, ...\n\nGet Hands-On Machine Learning with Scikit..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nChapter 10. Introduction to Artificial Neural Networks with Keras Birds inspi..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 11. Training Deep Neural Networks In Chapter 10 we introduced artific..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 12. Custom Models and Training with TensorFlow Up until now, we’ve us..."
          ],
          [
           "A Quick Tour of TensorFlow As you know, TensorFlow is a powerful library for numerical ...\n\nGet Hand..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nChapter 13. Loading and Preprocessing Data with TensorFlow So far we have use..."
          ],
          [
           "These need to be encoded, for example using one-hot encoding, bag-of-words encoding, ...\n\nGet Hands-..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nChapter 14. Deep Computer Vision Using Convolutional Neural Networks Although..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 15. Processing Sequences Using RNNs and CNNs The batter hits the ball..."
          ],
          [
           "A (very) limited ...\n\nGet Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Ed..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 16. Natural Language Processing with RNNs and Attention When Alan Tur..."
          ],
          [
           "This will allow us to generate some original text, and in the process we ...\n\nGet Hands-On Machine L..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nChapter 17. Representation Learning and Generative Learning Using Autoencoder..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 18. Reinforcement Learning Reinforcement Learning (RL) is one of the ..."
          ],
          [
           "In this chapter we will first explain what Reinforcement Learning is and what it’s good at, then pre..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nChapter 19. Training and Deploying TensorFlow Models at Scale Once you have a..."
          ],
          [
           "If you use the cloud platform, you will also get many ...\n\nGet Hands-On Machine Learning with Scikit..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nAppendix A. Exercise Solutions Note Solutions to the coding exercises are ava..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nAppendix B. Machine Learning Project Checklist This checklist can guide you t..."
          ],
          [
           "Get the Data Note: automate as much as possible so you can easily get fresh data.\n\nList the data you..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Appendix C. SVM Dual Problem To understand duality, you first need to understand the Lagrange multip..."
          ],
          [
           "2y, subject to an equality constraint: 3x + 2y + 1 = 0. Using the Lagrange multipliers method, we st..."
          ],
          [
           "called a Lagrange multiplier. Joseph-Louis Lagrange showed that if (x^,y^) is a solution to the cons..."
          ],
          [
           "regard to x, y, and α; we can find the points where these derivatives are all equal to zero; and the..."
          ],
          [
           "2\n\nx ^\n\n3\n\nα ^\n\n=\n\n2\n\n2\n\nα ^\n\n=\n\n3\n\nx ^\n\n2\n\nGet Hands-On Machine Learning with Scikit-Learn, Keras, ..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "The derivative of a constant is 0.\n\nThe derivative of λx is λ (where λ is a constant).\n\nThe derivati..."
          ],
          [
           "0\n\n=\n\nx 2\n\n+\n\n1\n\nThis approach can ...\n\nGet Hands-On Machine Learning with Scikit-Learn, Keras, and ..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "Hopfield Networks Hopfield networks were first introduced by W. A. Little in 1974, then popularized ..."
          ],
          [
           "logo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJ..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Strings Tensors can hold byte strings, which is useful in particular for natural language processing..."
          ],
          [
           "The tf.strings package contains several functions to manipulate string tensors, such as length() to ..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "TF Functions and Concrete Functions TF Functions are polymorphic, meaning they support inputs of dif..."
          ],
          [
           "Such a combination of argument types and shapes is called an input signature. If you call the TF Fun..."
          ],
          [
           "But it will generate a new concrete function if you call tf_cube(tf.constant([2.0])) or tf_cube(tf.c..."
          ],
          [
           "method. It can then be called like a regular function, but it will only support one input signature ..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\HandsOnML-Geron.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\HandsOnML-Geron.txt, circle",
         "marker": {
          "color": "#00cc96",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\HandsOnML-Geron.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          11.1121,
          9.056984,
          9.053043,
          6.723909,
          6.4273243,
          7.983095,
          8.046046,
          7.9644523,
          8.15165,
          7.489684,
          7.479878,
          7.1898384,
          7.2321444,
          7.3159566,
          7.297235,
          7.173306,
          8.163525,
          7.453125,
          7.76927,
          7.592284,
          7.6552367,
          7.06895,
          5.466694,
          4.147755,
          3.3908722,
          4.0158916,
          3.0698025,
          4.239644,
          8.56726,
          6.294133,
          5.252246,
          6.444254,
          6.83061,
          6.6904244,
          5.4824457,
          5.0266223,
          4.7411246,
          5.458759,
          5.3796883,
          4.933786,
          5.1562424,
          5.5566154,
          5.276013,
          8.613472,
          8.6145525,
          5.9087186,
          9.72994,
          14.548252,
          10.496693,
          8.177114,
          15.318218,
          11.287066,
          8.984123,
          8.945747,
          13.825403,
          11.241993,
          8.6283455,
          4.5996656,
          3.6340694,
          2.671483,
          3.958999,
          3.1589103,
          3.23903,
          2.7488756,
          2.7801187,
          -6.408199,
          3.3392162,
          2.8997269,
          2.7961962,
          2.4507103,
          2.2798595,
          3.1966715,
          4.0903125,
          4.1095533,
          4.461552,
          4.1162133,
          3.3137853,
          3.668735,
          3.8320975,
          4.2273,
          4.227836,
          4.121886,
          4.0356703,
          4.1188045,
          3.7550783,
          4.0731163,
          4.0699115,
          3.7625692,
          2.7078936,
          2.045706,
          3.3097444,
          3.57317,
          3.1604455,
          3.4375815,
          3.1443808,
          4.7360897,
          4.307877,
          4.540097,
          4.512369,
          3.576387,
          4.6791844,
          4.575981,
          4.617953,
          3.833419,
          4.4868264,
          4.4848175,
          2.2822835,
          1.5168021,
          1.621847,
          2.3271344,
          3.9270177,
          1.7515465,
          1.6361704,
          1.4461584,
          1.5652508,
          1.2933476,
          1.5605508,
          1.5421778,
          0.8487447,
          1.3807602,
          4.344373,
          4.830801,
          3.9040766,
          4.0668116,
          15.01962,
          9.618809,
          1.5971584,
          14.706767,
          11.205128,
          4.48289,
          11.204825,
          13.765723,
          9.990788,
          11.197475,
          7.843543,
          11.152216,
          7.5444264,
          10.869986,
          13.869957,
          10.18875,
          13.773569,
          10.057283,
          13.742213,
          10.010562,
          10.638213,
          13.861198,
          8.5836935,
          7.351921,
          13.870743,
          10.293412,
          10.7578745,
          10.1368685,
          11.1342945,
          13.772393,
          9.891304,
          11.123576,
          13.9144,
          8.784657,
          13.785342,
          9.892555,
          10.478382,
          13.760422,
          8.295709,
          10.916604,
          13.725204,
          7.883571,
          13.758564,
          8.632016,
          10.800312,
          13.735006,
          2.0524924,
          2.9061239,
          3.2790184,
          3.292728,
          10.832748,
          13.822899,
          10.47014,
          3.1123312,
          11.055989,
          13.7640915,
          10.270554,
          9.987878,
          14.896607,
          10.131165,
          -7.686355,
          -7.6049113,
          13.868931,
          10.920229,
          -7.3884597,
          -7.6353827,
          -7.7196517,
          -7.431463,
          13.939821
         ],
         "xaxis": "x",
         "y": [
          0.26156563,
          -0.5272232,
          -0.44872576,
          -1.4851406,
          -1.8452891,
          0.32826698,
          0.11337072,
          0.13015863,
          0.14268154,
          0.03045088,
          -0.48681176,
          -0.038020544,
          0.028139373,
          0.44288942,
          0.3571342,
          -0.19032635,
          0.14199089,
          -0.16522402,
          0.8265092,
          0.5830974,
          0.8073864,
          -0.96641743,
          2.7102358,
          2.8937838,
          3.971566,
          3.0113194,
          3.1179512,
          3.1782897,
          -0.31030136,
          1.969033,
          2.8527894,
          1.6399945,
          1.3178006,
          1.5467659,
          3.2367969,
          3.5531304,
          4.065231,
          3.7257254,
          4.582401,
          4.4730825,
          4.782029,
          4.6405473,
          4.5227575,
          -0.16005257,
          -0.28848064,
          2.1939878,
          -0.99060374,
          -5.007453,
          -0.5118064,
          0.81665504,
          -5.0161443,
          0.20483403,
          -1.7307196,
          -1.4928675,
          -5.4443293,
          0.20811549,
          0.107536845,
          4.0937967,
          4.269645,
          4.437787,
          4.270836,
          4.4149384,
          4.410184,
          4.3506303,
          4.048192,
          4.7807574,
          3.862142,
          3.5254931,
          3.555805,
          3.2719223,
          2.749642,
          3.921641,
          4.276048,
          4.762013,
          4.4302464,
          4.7699804,
          4.529256,
          4.610769,
          4.5413895,
          4.658578,
          4.6637855,
          4.7290154,
          4.755085,
          4.862804,
          4.181491,
          4.7808657,
          4.3555956,
          4.174794,
          4.07347,
          3.2572298,
          4.3318067,
          5.11851,
          4.996015,
          5.261371,
          5.1481323,
          4.309245,
          3.9232187,
          4.0095487,
          4.0031652,
          4.071738,
          4.0313225,
          4.0478945,
          3.9648001,
          4.263646,
          4.0560803,
          4.5911064,
          5.105607,
          4.843917,
          4.816056,
          4.741284,
          4.633978,
          5.01991,
          4.8902836,
          5.1004243,
          5.045631,
          4.8380384,
          5.08885,
          4.771449,
          4.860842,
          5.0821486,
          4.3256497,
          3.918786,
          4.4609895,
          4.74549,
          -4.929089,
          -1.2575917,
          6.08368,
          -4.7444587,
          0.3110941,
          7.2397017,
          -0.091428615,
          -5.414341,
          -0.76062435,
          0.19734742,
          0.8760752,
          0.32461202,
          0.18138556,
          -0.9612114,
          -5.468749,
          0.94628394,
          -5.4560595,
          0.8814467,
          -5.5326734,
          0.7393669,
          0.5503758,
          -5.5182457,
          0.99464536,
          -0.94873637,
          -5.4657288,
          0.8586234,
          0.589099,
          0.96388173,
          -0.5591283,
          -5.451307,
          0.7718918,
          -0.67891484,
          -5.45263,
          0.6589751,
          -5.5318003,
          0.4867642,
          0.10207372,
          -5.5037313,
          0.8606552,
          -0.80590326,
          -5.463414,
          -0.14596504,
          -5.565563,
          -0.15271148,
          -0.86868536,
          -5.489763,
          5.0103893,
          4.3875623,
          4.656183,
          4.613938,
          -0.097023904,
          -5.43953,
          0.5883605,
          4.5540566,
          -0.5187225,
          -5.506118,
          0.9369585,
          0.815991,
          -4.8111835,
          0.87207496,
          -7.1506543,
          -7.044343,
          -5.469733,
          0.39719072,
          -7.1103225,
          -7.258799,
          -7.2170877,
          -7.215913,
          -4.9230366
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "1. Introduction - Introduction to Machine Learning with Python [Book]\n\nSkip to main content\n\nSign In..."
          ],
          [
           "Outside of commercial applications, machine learning has had a tremendous influence on the way data-..."
          ],
          [
           "Designing rules requires a deep understanding of how a decision should be made by a human expert.\n\nO..."
          ],
          [
           "1.1.1 Problems Machine Learning Can Solve\n\nThe most successful kinds of machine learning algorithms ..."
          ],
          [
           "Determining whether a tumor is benign based on a medical image\n\nHere the input is the image, and the..."
          ],
          [
           "An interesting thing to note about these examples is that although the inputs and outputs look fairl..."
          ],
          [
           "Detecting abnormal access patterns to a website\n\nTo identify abuse or bugs, it is often helpful to f..."
          ],
          [
           "Each entity or row here is known as a sample (or data point) in machine learning, while the columns—..."
          ],
          [
           "What is the best way to phrase my question(s) as a machine learning problem?\n\nHave I collected enoug..."
          ],
          [
           "1.2 Why Python?\n\nPython has become the lingua franca for many data science applications. It combines..."
          ],
          [
           "1.3 scikit-learn scikit-learn is an open source project, meaning that it is free to use and distribu..."
          ],
          [
           "Anaconda\n\nA Python distribution made for large-scale data processing, predictive analytics, and scie..."
          ],
          [
           "1.4 Essential Libraries and Tools\n\nUnderstanding what scikit-learn is and how to use it is important..."
          ],
          [
           "1.4.2 NumPy\n\nNumPy is one of the fundamental packages for scientific computing in Python. It contain..."
          ],
          [
           "1.4.3 SciPy\n\nSciPy is a collection of functions for scientific computing in Python. It provides, amo..."
          ],
          [
           "# Create a 2D NumPy array with a diagonal of ones, and zeros everywhere else eye = np.eye(4) print(\"..."
          ],
          [
           "the nonzero entries are stored sparse_matrix = sparse.csr_matrix(eye) print(\"\\nSciPy sparse CSR matr..."
          ],
          [
           "way to create the same sparse matrix as before, using the COO format: In[4]: data = np.ones(4) row_i..."
          ],
          [
           "1.4.4 matplotlib matplotlib is the primary scientific plotting library in Python. It provides functi..."
          ],
          [
           "Figure 1-1. Simple line plot of the sine function using matplotlib\n\n1.4.5 pandas pandas is a Python ..."
          ],
          [
           "data_pandas = pd.DataFrame(data) # IPython.display allows \"pretty printing\" of dataframes # in the J..."
          ],
          [
           "London\n\nLinda\n\n1.4.6 mglearn\n\nThis book comes with accompanying code, which you can find on https://..."
          ],
          [
           "1.5 Python 2 Versus Python 3\n\nThere are two major versions of Python that are widely used at the mom..."
          ],
          [
           "import pandas as pd\n\nprint(\"pandas version:\", pd.__version__)\n\nimport matplotlib\n\nprint(\"matplotlib ..."
          ],
          [
           "import IPython\n\nprint(\"IPython version:\", IPython.__version__)\n\nimport sklearn print(\"scikit-learn v..."
          ],
          [
           "Now that we have everything set up, let’s dive into our first application of machine learning.\n\n1.7 ..."
          ],
          [
           "1.7.1 Meet the Data\n\nThe data we will use for this example is the Iris dataset, a classical dataset ..."
          ],
          [
           "Notes ---- Data Set Characteristics: :Number of Instances: 150 (50 in each of three classes) :Number..."
          ],
          [
           "We see that the array contains measurements for 150 different flowers. Remember that the individual ..."
          ],
          [
           "The target array contains the species of each of the flowers that were measured, also as a NumPy arr..."
          ],
          [
           "1.7.2 Measuring Success: Training and Testing Data\n\nWe want to build a machine learning model from t..."
          ],
          [
           "In scikit-learn, data is usually denoted with a capital X, while labels are denoted by a lowercase y..."
          ],
          [
           "To make sure that we will get the same output if we run the same function several times, we provide ..."
          ],
          [
           "One of the best ways to inspect data is to visualize it. One way to do this is by using a scatter pl..."
          ],
          [
           "The diagonal of this matrix is filled with histograms of each feature: In[23]: # create dataframe fr..."
          ],
          [
           "1.7.4 Building Your First Model: k-Nearest Neighbors\n\nNow we can start building the actual machine l..."
          ],
          [
           "The knn object encapsulates the algorithm that will be used to build the model from the training dat..."
          ],
          [
           "In the remainder of this book, we will not usually show the output of fit because it doesn’t contain..."
          ],
          [
           "1.7.5 Making Predictions\n\nWe can now make predictions using this model on new data for which we migh..."
          ],
          [
           "1.7.6 Evaluating the Model\n\nThis is where the test set that we created earlier comes in. This data w..."
          ],
          [
           "We can also use the score method of the knn object, which will compute the test set accuracy for us:..."
          ],
          [
           "1.8 Summary and Outlook\n\nLet’s summarize what we learned in this chapter. We started with a brief in..."
          ],
          [
           "We chose the k-nearest neighbors classification algorithm, which makes predictions for a new data po..."
          ],
          [
           "knn = KNeighborsClassifier(n_neighbors=1)\n\nknn.fit(X_train, y_train)\n\nprint(\"Test set score: {:.2f}\"..."
          ],
          [
           "Support\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAust..."
          ],
          [
           "For business\n\nFor government\n\nFor higher ed\n\nIndividuals\n\nFeatures\n\nAll features\n\nCourses\n\nCertifica..."
          ],
          [
           "2.1 Classification and Regression\n\nThere are two major types of supervised machine learning problems..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Answers\n\nInsights reporting\n\nBlog\n\nContent sponsorship\n\nIntroduction to Machine Learning with Python..."
          ],
          [
           "3.1 Types of Unsupervised Learning We will look into two kinds of unsupervised learning in this chap..."
          ],
          [
           "Contact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & N..."
          ],
          [
           "For business\n\nFor government\n\nFor higher ed\n\nIndividuals\n\nFeatures\n\nAll features\n\nCourses\n\nCertifica..."
          ],
          [
           "Start your free trial\n\nChapter 4. Representing Data and Engineering Features\n\nSo far, we’ve assumed ..."
          ],
          [
           "The question of how to represent your data best for a particular application is known as feature eng..."
          ],
          [
           "clerical\n\n<=50K\n\n1\n\n50\n\nSelf\n\nemp\n\nnot\n\ninc\n\nBachelors\n\nMale\n\n13\n\nExec\n\nmanagerial\n\n<=50K\n\n2\n\n38\n\nPr..."
          ],
          [
           "emp\n\nnot\n\ninc\n\nHS\n\ngrad\n\nMale\n\n45\n\nExec\n\nmanagerial\n\n>50K\n\n8\n\n31\n\nPrivate\n\nMasters\n\nFemale\n\n50\n\nProf..."
          ],
          [
           "Some\n\ncollege\n\nMale\n\n80\n\nExec\n\nmanagerial\n\n>50K\n\nThe task is phrased as a classification task with t..."
          ],
          [
           "4.1.1 One\n\nHot\n\nEncoding (Dummy Variables)\n\nBy far the most common way to represent categorical vari..."
          ],
          [
           "Self Employed\n\nSelf Employed Incorporated\n\nGovernment Employee\n\n1\n\n0\n\n0\n\n0\n\nPrivate Employee\n\n0\n\n1\n\n..."
          ],
          [
           "There are two ways to convert your data to a one-hot encoding of categorical variables, using either..."
          ],
          [
           "education\n\ngender\n\nhours\n\nper\n\nweek\n\noccupation\n\nincome\n\n0\n\n39\n\nState\n\ngov\n\nBachelors\n\nMale\n\n40\n\nAdm..."
          ],
          [
           "40\n\nProf\n\nspecialty\n\n<=50K\n\nChecking string\n\nencoded categorical data\n\nAfter reading a dataset like ..."
          ],
          [
           "The get_dummies function automatically transforms all columns that have object type (like strings) o..."
          ],
          [
           "Features after get_dummies: ['age', 'hours-per-week', 'workclass_ ? ', 'workclass_ Federal-gov', 'wo..."
          ],
          [
           "workclass_ Federal\n\ngov\n\nworkclass_\n\nLocal\n\ngov\n\n…\n\noccupation_ Tech\n\nsupport\n\noccupation_\n\nTranspor..."
          ],
          [
           "1.0\n\n0.0\n\n4\n\n28\n\n40\n\n0.0\n\n0.0\n\n0.0\n\n…\n\n0.0\n\n0.0\n\n1.0\n\n0.0\n\n5 rows × 46 columns We can now use the va..."
          ],
          [
           "In this case, we extract only the columns containing features—that is, all columns from age to occup..."
          ],
          [
           "In this example, we called get_dummies on a DataFrame containing both the training and the test data..."
          ],
          [
           "4.1.2 Numbers Can Encode Categoricals\n\nIn the example of the adult dataset, the categorical variable..."
          ],
          [
           "The get_dummies function in pandas treats all numbers as continuous and will not create dummy variab..."
          ],
          [
           "Categorical Feature_socks\n\n0\n\n0\n\n0.0\n\n0.0\n\n1.0\n\n1\n\n1\n\n0.0\n\n1.0\n\n0.0\n\n2\n\n2\n\n0.0\n\n0.0\n\n1.0\n\n3\n\n1\n\n1.0\n..."
          ],
          [
           "0.0\n\n0.0\n\n0.0\n\n0.0\n\n1.0\n\n1\n\n0.0\n\n1.0\n\n0.0\n\n0.0\n\n1.0\n\n0.0\n\n2\n\n0.0\n\n0.0\n\n1.0\n\n0.0\n\n0.0\n\n1.0\n\n3\n\n0.0\n\n1..."
          ],
          [
           "4.2 OneHotEncoder and ColumnTransformer: Categorical Variables with scikit-learn As mentioned before..."
          ],
          [
           "# Setting sparse=False means OneHotEncode will return a numpy array, # not a sparse matrix ohe = One..."
          ],
          [
           "transformed. As usual for scikit-learn, the output is not a DataFrame, so there are no column names...."
          ],
          [
           "and 2 of the first original feature (called x0 here), while the last three columns correspond to the..."
          ],
          [
           "This is where the ColumnTransformer class comes in handy: it allows you to apply different transform..."
          ],
          [
           "Out[12]: [cols=\",,,,,,,\",options=\"header\",] |=======================================================..."
          ],
          [
           "|53 |Private |11th |Male |40 |Handlers-cleaners |<=50K |4 |28 |Private |Bachelors |Female |40 |Prof-..."
          ],
          [
           "age and hours-per-week. This is exactly what ColumnTransformer can do for us. Each transformation in..."
          ],
          [
           "Each transformer is applied to the corresponding columns, and the result of the transformations are ..."
          ],
          [
           "ct.fit(X_train) X_train_trans = ct.transform(X_train) print(X_train_trans.shape) Out[14]: (24420, 44..."
          ],
          [
           "4.3 Convenient ColumnTransformer creation with make_columntransformer Creating a ColumnTransformer u..."
          ],
          [
           "4.4 Binning, Discretization, Linear Models, and Trees\n\nThe best way to represent data depends not on..."
          ],
          [
           "plt.plot(line, reg.predict(line), label=\"linear regression\")\n\nplt.plot(X[:, 0], y, 'o', c='k') plt.y..."
          ],
          [
           "We imagine a partition of the input range for the feature (in this case, the numbers from –3 to 3) i..."
          ],
          [
           "of the data (i.e., having smaller bins where there’s more data). Both of these strategies are implem..."
          ],
          [
           "1.155, 1.744,  2.333,  2.921])] Here, the first bin contains all data points with feature values fro..."
          ],
          [
           "per feature. This is why they are a list of length one in this case. Using transform, we can encode ..."
          ],
          [
           "In[21]: X_binned = kb.transform(X) X_binned Out[21]: <120x10 sparse matrix of type '<class 'numpy.fl..."
          ],
          [
           "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0. ], [0., 0., 0., 0., 0., 0., 0., 0., 0., 1. ], [0., 0...."
          ],
          [
           "0., 0., 0., 0., 0. ], [0., 1., 0., 0., 0., 0., 0., 0., 0., 0. ], [1., 0., 0., 0., 0., 0., 0., 0., 0...."
          ],
          [
           "[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]) We can see that the first data point with value -0.753 wa..."
          ],
          [
           "categorical feature which encodes which bin a data point is in. You can forego the one-hot-encoding ..."
          ],
          [
           "= kb.transform(X) Now we build a new linear regression model and a new decision tree model on the on..."
          ],
          [
           "reg = LinearRegression().fit(X_binned, y) plt.plot(line, reg.predict(line_binned), label='linear reg..."
          ],
          [
           "reg = DecisionTreeRegressor(min_samples_split=3).fit(X_binned, y) plt.plot(line, reg.predict(line_bi..."
          ],
          [
           "If there are good reasons to use a linear model for a particular dataset—say, because it is very lar..."
          ],
          [
           "plt.vlines(kb.bin_edges_[0], -3, 3, linewidth=1, alpha=.2) plt.legend(loc=\"best\") plt.ylabel(\"Regres..."
          ],
          [
           "Figure 4-3. Linear regression using binned features and a single global slope\n\nIn this example, the ..."
          ],
          [
           "plt.vlines(kb.bin_edges_[0],\n\n3, 3, linewidth=1, alpha=.2)\n\nplt.plot(X[:, 0], y, 'o', c='k') plt.yla..."
          ],
          [
           "# include polynomials up to x ** 10: # the default \"include_bias=True\" adds a feature that's constan..."
          ],
          [
           "20918.278] [    1.392     1.938     2.697     3.754     5.226     7.274    10.125 14.094    19.618  ..."
          ],
          [
           "line_poly = poly.transform(line) plt.plot(line, reg.predict(line_poly), label='polynomial linear reg..."
          ],
          [
           "Figure 4-6. Comparison of different gamma parameters for an SVM with RBF kernel\n\nUsing a more comple..."
          ],
          [
           "# rescale data scaler = MinMaxScaler() X_train_scaled = scaler.fit_transform(X_train) X_test_scaled ..."
          ],
          [
           "The exact correspondence between input and output features can be found using the get_feature_names ..."
          ],
          [
           "'x0 x5', 'x0 x6', 'x0 x7', 'x0 x8', 'x0 x9', 'x0 x10', 'x0 x11', 'x0 x12', 'x1^2', 'x1 x2', 'x1 x3',..."
          ],
          [
           "x5', 'x2 x6', 'x2 x7', 'x2 x8', 'x2 x9', 'x2 x10', 'x2 x11', 'x2 x12', 'x3^2', 'x3 x4', 'x3 x5', 'x3..."
          ],
          [
           "'x4 x10', 'x4 x11', 'x4 x12', 'x5^2', 'x5 x6', 'x5 x7', 'x5 x8', 'x5 x9', 'x5 x10', 'x5 x11', 'x5 x1..."
          ],
          [
           "'x8^2', 'x8 x9', 'x8 x10', 'x8 x11', 'x8 x12', 'x9^2', 'x9 x10', 'x9 x11', 'x9 x12', 'x10^2', 'x10 x..."
          ],
          [
           "first feature squared (\"x0^2\") and combinations of the first and the other features...."
          ],
          [
           "Let’s compare the performance using Ridge on the data with and without interactions: In[38]: from sk..."
          ],
          [
           "Clearly, the interactions and polynomial features gave us a good boost in performance when using Rid..."
          ],
          [
           "4.6 Univariate Nonlinear Transformations\n\nWe just saw that adding squared or cubed features can help..."
          ],
          [
           "X = rnd.poisson(10 * np.exp(X_org)) y = np.dot(X_org, w) Let’s look at the first 10 entries of the f..."
          ],
          [
           "0]))) Out[41]: Number of feature appearances: [28 38 68 48 61 59 45 56 37 40 35 34 36 26 23 26 27 21..."
          ],
          [
           "2  5  2  1 2  3  3  2  2  3  3  0  1  2  1  0  0  3  1  0  0  0  1  3  0  1  0  2  0 1  1  0  0  0  ..."
          ],
          [
           "2  0  1  1  0  0  0  0  1  1  0  0  0  0  0 0  0  1  0  0  0  0  0  1  1  0  0  1  0  0  0  0  0  0 ..."
          ],
          [
           "0 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1] The value 2 seems to be the most common, with 68 a..."
          ],
          [
           "are appearing twice. We visualize the counts in Figure 4-7: In[42]: bins = np.bincount(X[:, 0]) plt...."
          ],
          [
           "Figure 4-7. Histogram of feature values for X[0]..."
          ],
          [
           "Features X[:, 1] and X[:, 2] have similar properties. This kind of distribution of values (many smal..."
          ],
          [
           "train_test_split(X, y, random_state=0) score = Ridge().fit(X_train, y_train).score(X_test, y_test) p..."
          ],
          [
           "logarithm is not defined at 0), we can’t actually just apply log, but we have to compute log(X + 1):..."
          ],
          [
           "color='gray') plt.ylabel(\"Number of appearances\") plt.xlabel(\"Value\")..."
          ],
          [
           "Figure 4-8. Histogram of feature values for X[0] after logarithmic transformation\n\nBuilding a ridge ..."
          ],
          [
           "4.7 Automatic Feature Selection\n\nWith so many ways to create new features, you might get tempted to ..."
          ],
          [
           "To use univariate feature selection in scikit-learn, you need to choose a test, usually either f_cla..."
          ],
          [
           "X_train, X_test, y_train, y_test = train_test_split( X_w_noise, cancer.target, random_state=0, test_..."
          ],
          [
           "X_train.shape: (284, 80)\n\nX_train_selected.shape: (284, 40)\n\nAs you can see, the number of features ..."
          ],
          [
           "# transform test data\n\nX_test_selected = select.transform(X_test)\n\nlr = LogisticRegression() lr.fit(..."
          ],
          [
           "4.7.2 Model\n\nBased Feature Selection\n\nModel-based feature selection uses a supervised machine learni..."
          ],
          [
           "To use model-based feature selection, we need to use the SelectFromModel transformer: In[50]: from s..."
          ],
          [
           "result to what we got with univariate feature selection, we used the median as a threshold, so that ..."
          ],
          [
           "X_train_l1 = select.transform(X_train) print(\"X_train.shape: {}\".format(X_train.shape)) print(\"X_tra..."
          ],
          [
           "Figure 4-10. Features selected by SelectFromModel using the RandomForestClassifier\n\nThis time, all b..."
          ],
          [
           "4.7.3 Iterative Feature Selection\n\nIn univariate testing we used no model, while in model-based sele..."
          ],
          [
           "Figure 4-11. Features selected by recursive feature elimination with the random forest classifier mo..."
          ],
          [
           "score = LogisticRegression().fit(X_train_rfe, y_train).score(X_test_rfe, y_test) print(\"Test score: ..."
          ],
          [
           "4.8 Utilizing Expert Knowledge\n\nFeature engineering is often an important place to use expert knowle..."
          ],
          [
           "Adding a feature does not force a machine learning algorithm to use it, and even if the holiday info..."
          ],
          [
           "We resample the data into three-hour intervals to obtain the main trends for each day: In[57]: citib..."
          ],
          [
           "Figure 4-12. Number of bike rentals over time for a selected Citi Bike station\n\nLooking at the data,..."
          ],
          [
           "A (surprisingly) common way that dates are stored on computers is using POSIX time, which is the num..."
          ],
          [
           "plt.xticks(range(0, len(X), 8), xticks.strftime(\"%a %m-%d\"), rotation=90, ha=\"left\")\n\nplt.plot(range..."
          ],
          [
           "Figure 4-13. Predictions made by a random forest using only the POSIX time\n\nThe predictions on the t..."
          ],
          [
           "Figure 4-14. Predictions made by a random forest using only the hour of the day\n\nThe R2 is already m..."
          ],
          [
           "Figure 4-16. Predictions made by linear regression using day of week and hour of day as features\n\nLi..."
          ],
          [
           "Using interaction features, we can allow the model to learn one coefficient for each combination of ..."
          ],
          [
           "This transformation finally yields a model that performs similarly well to the random forest. A big ..."
          ],
          [
           "Figure 4-19. Coefficients of the linear regression model using a product of hour and day\n\n4.9 Summar..."
          ],
          [
           "Close\n\n5. Model Evaluation and Improvement - Introduction to Machine Learning with Python [Book]\n\nSk..."
          ],
          [
           "To evaluate our supervised models, so far we have split our dataset into a training set and a test s..."
          ],
          [
           "Close\n\n6. Algorithm Chains and Pipelines - Introduction to Machine Learning with Python [Book]\n\nSkip..."
          ],
          [
           "As an example of the importance of chaining models, we noticed that we can greatly improve the perfo..."
          ],
          [
           "Privacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & T..."
          ],
          [
           "For higher ed\n\nIndividuals\n\nFeatures\n\nAll features\n\nCourses\n\nCertifications\n\nInteractive learning\n\nL..."
          ],
          [
           "Start your free trial\n\nChapter 7. Working with Text Data\n\nIn Chapter 4, we talked about two kinds of..."
          ],
          [
           "Close\n\n8. Wrapping Up - Introduction to Machine Learning with Python [Book]\n\nSkip to main content\n\nS..."
          ],
          [
           "8.1 Approaching a Machine Learning Problem With all the great methods that we introduced in this boo..."
          ],
          [
           "Newsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\n..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\IntroToMLwithPython-MullerGuido.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\IntroToMLwithPython-MullerGuido.txt, circle",
         "marker": {
          "color": "#ab63fa",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\IntroToMLwithPython-MullerGuido.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          10.588784,
          8.892862,
          8.1830435,
          7.892244,
          7.3376327,
          7.3468103,
          7.041915,
          6.812949,
          8.815756,
          -6.383344,
          9.708387,
          -6.5375767,
          9.884409,
          -8.884145,
          2.0596223,
          1.7597715,
          2.1174505,
          2.14621,
          -5.620714,
          -5.446065,
          -8.121766,
          2.0872629,
          -6.9315667,
          -5.3204756,
          0.06414747,
          7.6701765,
          0.01957292,
          -0.058691524,
          -0.37618318,
          -0.16159153,
          0.40168932,
          0.42918387,
          0.49553743,
          -0.07580673,
          0.08366417,
          0.28120512,
          0.74484164,
          2.8458948,
          0.47820714,
          0.32676026,
          0.42665794,
          0.18515769,
          0.97536516,
          0.698166,
          15.208985,
          9.10875,
          9.216538,
          13.442822,
          10.076941,
          7.4884033,
          15.210412,
          11.615782,
          6.6766257,
          3.103813,
          2.1345794,
          2.1293428,
          2.4227085,
          2.2319827,
          2.2473843,
          2.149107,
          2.0823963,
          2.261263,
          2.0807414,
          2.1364915,
          2.1253855,
          2.1518648,
          2.9691584,
          2.0963104,
          2.4286666,
          2.1173954,
          2.0722685,
          -0.99409336,
          2.0425198,
          1.8859943,
          2.1092367,
          1.9423648,
          2.1153352,
          2.1193554,
          2.2835932,
          2.2313316,
          2.3051713,
          2.5182726,
          2.109077,
          2.2235456,
          2.048196,
          1.5664912,
          1.4946476,
          1.5102559,
          1.5686737,
          1.6566901,
          -0.9369437,
          -0.94443184,
          1.6610917,
          1.545204,
          1.7173431,
          1.9815785,
          2.0384307,
          2.23106,
          1.983835,
          1.9369266,
          1.9625429,
          1.8144838,
          1.8742334,
          2.6568794,
          2.535884,
          1.7982562,
          1.2794608,
          -0.8298323,
          -0.779939,
          -0.7926586,
          0.57932156,
          1.5984662,
          3.156141,
          3.2991445,
          2.0684521,
          -1.093442,
          -0.2517855,
          -0.90691525,
          -0.9858469,
          -0.8121287,
          -2.825162,
          0.44307595,
          3.212847,
          2.7114308,
          -2.0652525,
          -5.7227716,
          2.8710535,
          5.5917683,
          3.92197,
          2.7963862,
          3.4579515,
          3.7234583,
          4.211184,
          3.997759,
          3.9035857,
          1.2486753,
          3.8738217,
          4.0631857,
          3.9667215,
          3.950794,
          6.283936,
          5.8104396,
          -6.409661,
          4.622759,
          4.592395,
          4.402406,
          4.4387145,
          4.519743,
          4.6388035,
          4.514653,
          4.266328,
          5.0890245,
          10.320265,
          1.8057845,
          10.8849945,
          1.4405938,
          15.021406,
          11.406216,
          7.354011,
          10.822141,
          9.336909,
          15.248218
         ],
         "xaxis": "x",
         "y": [
          -1.9230508,
          -0.4354201,
          0.47014415,
          -0.39643285,
          0.17775899,
          0.115634106,
          0.12940155,
          -0.13631262,
          -0.38029626,
          -9.167789,
          -1.8518425,
          -9.174131,
          -1.8949438,
          -7.748041,
          2.33268,
          1.982536,
          2.2386692,
          2.1964781,
          5.3840113,
          4.724711,
          -9.037577,
          5.244063,
          -9.228174,
          5.285932,
          4.2720194,
          -0.559527,
          4.3870864,
          4.42115,
          4.330866,
          4.276907,
          4.6634088,
          4.4207425,
          4.3481827,
          4.6279645,
          5.175966,
          4.8017216,
          4.474659,
          4.362474,
          4.624214,
          4.4668856,
          4.7327104,
          4.534775,
          4.8619747,
          4.5595393,
          -4.993634,
          -0.61618423,
          -0.8730261,
          -4.256026,
          -1.0926307,
          -0.037745815,
          -5.0294704,
          -2.171616,
          0.33075115,
          -0.05948753,
          -0.32659367,
          -0.1944572,
          -0.09711648,
          -0.042067286,
          -0.16447659,
          0.052201115,
          -0.26338136,
          -0.15364656,
          0.22488038,
          0.029890563,
          -0.21198408,
          0.15804675,
          2.6362326,
          0.055813573,
          -0.16912274,
          0.105156094,
          0.14271978,
          0.9783666,
          0.39579427,
          1.0550815,
          0.7843434,
          0.69115794,
          0.16433571,
          -0.22275387,
          -0.13328741,
          0.062144537,
          0.90469617,
          1.7068868,
          0.4563176,
          2.4746935,
          2.5072403,
          2.0464911,
          1.9155173,
          1.8062414,
          1.4955369,
          1.7484502,
          1.0250912,
          1.007733,
          1.9275291,
          1.4573253,
          1.5908984,
          2.4441285,
          2.2309034,
          2.3298173,
          2.3865502,
          2.1358225,
          2.254409,
          3.0299332,
          3.1778498,
          3.9595137,
          3.8635259,
          2.808031,
          2.5669372,
          1.1025004,
          1.1721327,
          1.1452465,
          1.9723926,
          2.7448065,
          3.187816,
          3.0404863,
          2.265519,
          3.2198074,
          2.4347262,
          1.0148207,
          1.0081549,
          1.331769,
          3.7440434,
          2.9712787,
          3.2446501,
          3.6653714,
          3.9450052,
          4.803538,
          2.4391239,
          1.588314,
          1.9724816,
          2.6517935,
          2.2183616,
          1.933871,
          2.223157,
          1.848138,
          1.8980839,
          3.4335418,
          1.8848411,
          1.9055706,
          1.8297682,
          1.9126563,
          1.286449,
          1.2475804,
          1.4606209,
          1.2897534,
          1.4606357,
          2.02461,
          1.5564631,
          1.4653467,
          1.3741543,
          1.2833906,
          1.6490862,
          0.84758866,
          -1.8201876,
          4.978008,
          -1.8035719,
          5.0000587,
          -4.9366426,
          -2.061996,
          -0.42810988,
          -2.1070924,
          -0.7032831,
          -5.029333
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "1. Let’s Discuss Learning - Machine Learning with Python for Everyone [Book]\n\nSkip to main content\n\n..."
          ],
          [
           "Get Machine Learning with Python for Everyone now with the O’Reilly learning platform. O’Reilly memb..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n2. Some Technical Background\n\n2.1 About Our Setup We’re about to get down—fun..."
          ],
          [
           "logo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJ..."
          ],
          [
           "Features\n\nAll features\n\nCourses\n\nCertifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsight..."
          ],
          [
           "Close\n\n4. Predicting Numerical Values: Getting Started with Regression - Machine Learning with Pytho..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "5.1 Evaluation and Why Less Is More Lao Tzu: Those that know others are wise. Those that know themse..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Answers\n\nInsights reporting\n\nBlog\n\nContent sponsorship\n\nMachine Learning with Python for Everyone by..."
          ],
          [
           "Close\n\n7. Evaluating Regressors - Machine Learning with Python for Everyone [Book]\n\nSkip to main con..."
          ],
          [
           "diabetes.target,\n\ntest_size=.25,\n\nrandom_state=42)\n\n(diabetes_train_ftrs, diabetes_test_ftrs, diabet..."
          ],
          [
           "International\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJapan\n\nDownload the O’..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "8.1 Revisiting Classification So far, we’ve discussed two classifiers: Naive Bayes (NB) and k-Neares..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "d_tts = skms.train_test_split(diabetes.data,\n\ndiabetes.target,\n\ntest_size=.25,\n\nrandom_state=42)\n\n(d..."
          ],
          [
           "International\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJapan\n\nDownload the O’..."
          ],
          [
           "Courses\n\nCertifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nConte..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "11. Tuning Hyperparameters and Pipelines In [1]: Click here to view code image # setup from mlwpy im..."
          ],
          [
           "Privacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & T..."
          ],
          [
           "For higher ed\n\nIndividuals\n\nFeatures\n\nAll features\n\nCourses\n\nCertifications\n\nInteractive learning\n\nL..."
          ],
          [
           "(iris_train_ftrs, iris_test_ftrs,\n\niris_train_tgt, iris_test_tgt) = tts\n\n12.1 Ensembles Up to this p..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\n13. Models That Engineer Features for Us In [1]: Click here to view code imag..."
          ],
          [
           "Close\n\n14. Feature Engineering for Domains: Domain-Specific Learning - Machine Learning with Python ..."
          ],
          [
           "Issues 1 and 2 are specific to a learning problem you are focused on. We discussed issue 3 in Chapte..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\n15. Connections, Extensions, and Further Directions In [1]: from mlwpy import..."
          ],
          [
           "Privacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & T..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\MLwithPythonforEveryone-Fenner.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\MLwithPythonforEveryone-Fenner.txt, circle",
         "marker": {
          "color": "#FFA15A",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\MLwithPythonforEveryone-Fenner.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          9.488716,
          12.8040695,
          11.502389,
          10.700813,
          15.310359,
          10.342628,
          9.833144,
          11.218479,
          10.231516,
          16.202662,
          10.664029,
          9.933923,
          9.93455,
          15.883472,
          10.5482645,
          9.649499,
          9.951791,
          9.924182,
          15.8007965,
          10.288356,
          11.050801,
          9.769671,
          14.801321,
          10.446735,
          10.506057,
          13.507375,
          10.139004,
          10.403335,
          10.006733,
          13.75869,
          10.936335,
          15.336455
         ],
         "xaxis": "x",
         "y": [
          -0.22532117,
          -3.4105985,
          -1.974965,
          -1.6625556,
          -5.025942,
          -1.3757614,
          -2.6373918,
          -1.9035766,
          -0.79146916,
          -5.222996,
          -1.6103806,
          -2.7828264,
          -2.850555,
          -5.1734643,
          -1.4272217,
          -1.6275805,
          -2.7444303,
          -2.9041193,
          -5.1323714,
          -1.7379544,
          -1.6343881,
          -2.90094,
          -4.889566,
          -2.1507087,
          -1.102099,
          -4.279189,
          -2.4888728,
          -1.747415,
          -0.7183215,
          -4.9168696,
          -1.1943009,
          -5.0514493
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Archives | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAbout\n\nArchive\n\nArchives and ..."
          ],
          [
           "4. Visualization with Matplotlib¶ Simple Line Plots Simple Scatter Plots Visualizing Errors Density ..."
          ],
          [
           "Preface\n\n| Contents | IPython: Beyond Normal Python >\n\nWhat Is Data Science?¶This is a book about do..."
          ],
          [
           "data\n\nscience\n\nvenn\n\ndiagram). Used by permission.)\n\nWhile some of the intersection labels are a bit..."
          ],
          [
           "Who Is This Book For?¶In my teaching both at the University of Washington and at various tech-focuse..."
          ],
          [
           "Why Python?¶Python has emerged over the last couple decades as a first-class tool for scientific com..."
          ],
          [
           "Python 2 vs Python 3¶This book uses the syntax of Python 3, which contains language enhancements tha..."
          ],
          [
           "The PyData world is certainly much larger than these five packages, and is growing every day. With t..."
          ],
          [
           "If you feel your use of code examples falls outside fair use or the per‐ mission given above, feel f..."
          ],
          [
           "Any of the packages included with Anaconda can also be installed manually on top of Miniconda; for t..."
          ],
          [
           "2. Introduction to NumPy¶ Understanding Data Types in Python The Basics of NumPy Arrays Computation ..."
          ],
          [
           "Appendix: Figure Code¶\n\nIPython: Beyond Normal Python | Python Data Science Handbook\n\nPython Data Sc..."
          ],
          [
           "IPython: Beyond Normal Python\n\n< Preface | Contents | Help and Documentation in IPython >\n\nThere are..."
          ],
          [
           "This chapter will start by stepping through some of the IPython features that are useful to the prac..."
          ],
          [
           "Launching the IPython Shell¶This chapter, like most of this book, is not designed to be absorbed pas..."
          ],
          [
           "Launching the Jupyter Notebook¶The Jupyter notebook is a browser-based graphical interface to the IP..."
          ],
          [
           "< Preface | Contents | Help and Documentation in IPython >\n\nPython Data Science Handbook | Python Da..."
          ],
          [
           "4. Visualization with Matplotlib¶ Simple Line Plots Simple Scatter Plots Visualizing Errors Density ..."
          ],
          [
           "Help and Documentation in IPython\n\n< IPython: Beyond Normal Python | Contents | Keyboard Shortcuts i..."
          ],
          [
           "Here we'll discuss IPython's tools to quickly access this information, namely the ? character to exp..."
          ],
          [
           "Return the number of items of a sequence or mapping.\n\nThis notation works for just about anything, i..."
          ],
          [
           "This quick access to documentation via docstrings is one reason you should get in the habit of alway..."
          ],
          [
           "Using ? and/or ? ? gives a powerful and quick interface for finding information about what any Pytho..."
          ],
          [
           "Though Python has no strictly-enforced distinction between public/external attributes and private/in..."
          ],
          [
           "Beyond tab completion: wildcard matching¶Tab completion is useful if you know the first few characte..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "Keyboard Shortcuts in the IPython Shell\n\n< Help and Documentation in IPython | Contents | IPython Ma..."
          ],
          [
           "Navigation shortcuts¶While the use of the left and right arrow keys to move backward and forward in ..."
          ],
          [
           "Ctrl-t Transpose (i.e., switch) previous two characters\n\nCommand History Shortcuts¶Perhaps the most ..."
          ],
          [
           "At any point, you can add more characters to refine the search, or press Ctrl-r again to search furt..."
          ],
          [
           "Ctrl\n\nc\n\nInterrupt current Python command\n\nCtrl\n\nd\n\nExit IPython session\n\nThe Ctrl-c in particular c..."
          ],
          [
           "IPython Magic Commands\n\n< Keyboard Shortcuts in the IPython Shell | Contents | Input and Output Hist..."
          ],
          [
           "The code is formatted as it would appear in the Python interpreter, and if you copy and paste this d..."
          ],
          [
           "These magic commands, like others we'll see, make available functionality that would be difficult or..."
          ],
          [
           "There are several options to fine-tune how your code is run; you can see the documentation in the no..."
          ],
          [
           "Help on Magic Functions: ?, %magic, and %lsmagic¶Like normal Python functions, IPython magic functio..."
          ],
          [
           "Input and Output History\n\n< IPython Magic Commands | Contents | IPython and Shell Commands >\n\nPrevio..."
          ],
          [
           "Out[3]:\n\n0.4161468365471424\n\nWe've imported the built-in math package, then computed the sine and th..."
          ],
          [
           "Note that not all operations have outputs: for example, import statements and print statements don't..."
          ],
          [
           "In [11]: print(___)\n\n0.9092974268256817\n\nIPython stops there: more than three underscores starts to ..."
          ],
          [
           "Related Magic Commands¶For accessing a batch of previous inputs at once, the %history magic command ..."
          ],
          [
           "IPython and Shell Commands\n\n< Input and Output History | Contents | Errors and Debugging >\n\nWhen wor..."
          ],
          [
           "Quick Introduction to the Shell¶A full intro to using the shell/terminal/command-line is well beyond..."
          ],
          [
           "osx:~ $ pwd                            # pwd = print working directory /home/jake                   ..."
          ],
          [
           "Shell Commands in IPython¶Any command that works at the command-line can be used in IPython by prefi..."
          ],
          [
           "Communication in the other direction–passing Python variables into the shell–is possible using the {..."
          ],
          [
           "In fact, by default you can even use this without the % sign: In [15]: cd myproject /home/jake/proje..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "1\n\nreturn func1(a, b)\n\nIn [2]:\n\nfunc2(1)\n\n----------------------------------------------------------..."
          ],
          [
           "ZeroDivisionError: division by zero\n\nCalling func2 results in an error, and reading the printed trac..."
          ],
          [
           "In [5]:\n\n%xmode Verbose\n\nException reporting mode: Verbose\n\nIn [6]:\n\nfunc2(1)\n\n---------------------..."
          ],
          [
           "ZeroDivisionError: division by zero\n\nThis extra information can help narrow-in on why the exception ..."
          ],
          [
           "ipdb> print(a)\n\n1\n\nipdb> print(b)\n\n0\n\nipdb> quit\n\nThe interactive debugger allows much more than thi..."
          ],
          [
           "ipdb> quit\n\nThis allows you to quickly find out not only what caused the error, but what function ca..."
          ],
          [
           "ipdb> print(b)\n\n0\n\nipdb> quit\n\nFinally, if you have a script that you'd like to run from the beginni..."
          ],
          [
           "Profiling and Timing Code | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAbout\n\nArchi..."
          ],
          [
           "%time: Time the execution of a single statement %timeit: Time repeated execution of a single stateme..."
          ],
          [
           "total += i\n\n(\n\n1) *\n\nj\n\n1 loops, best of 3: 407 ms per loop\n\nSometimes repeating an operation is not..."
          ],
          [
           "In [5]:\n\nprint(\"sorting an already sorted list:\") %time L.sort()\n\nsorting an already sorted list: CP..."
          ],
          [
           "Profiling Full Scripts: %prun¶A program is made of many single statements, and sometimes timing thes..."
          ],
          [
           "Ordered by: internal time\n\nncalls  tottime  percall  cumtime  percall filename:lineno(function) 5   ..."
          ],
          [
           "Line-By-Line Profiling with %lprun¶The function-by-function profiling of %prun is useful, but someti..."
          ],
          [
           "Line #      Hits         Time  Per Hit   % Time  Line Contents =====================================..."
          ],
          [
           "In [12]:\n\n%load_ext memory_profiler\n\nThe memory profiler extension contains two useful magic functio..."
          ],
          [
           "In [15]:\n\nfrom mprun_demo import sum_of_lists\n\n%mprun\n\nf sum_of_lists sum_of_lists(1000000)\n\nThe res..."
          ],
          [
           "Filename: ./mprun_demo.py\n\nLine #    Mem usage    Increment   Line Contents ========================..."
          ],
          [
           "More IPython Resources | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAbout\n\nArchive\n..."
          ],
          [
           "Web Resources¶ The IPython website: The IPython website links to documentation, examples, tutorials,..."
          ],
          [
           "Finally, a reminder that you can find help on your own: IPython's ?-based help functionality (discus..."
          ],
          [
           "Introduction to NumPy\n\n< More IPython Resources | Contents | Understanding Data Types in Python >\n\nT..."
          ],
          [
           "NumPy (short for Numerical Python) provides an efficient interface to store and operate on dense dat..."
          ],
          [
           "Throughout this chapter, and indeed the rest of the book, you'll find that this is the way we will i..."
          ],
          [
           "Table of Contents¶Preface¶1. IPython: Beyond Normal Python¶ Help and Documentation in IPython Keyboa..."
          ],
          [
           "5. Machine Learning¶ What Is Machine Learning? Introducing Scikit-Learn Hyperparameters and Model Va..."
          ],
          [
           "Understanding Data Types in Python\n\n< Introduction to NumPy | Contents | The Basics of NumPy Arrays ..."
          ],
          [
           "This sort of flexibility is one piece that makes Python and other dynamically-typed languages conven..."
          ],
          [
           "This means that there is some overhead in storing an integer in Python as compared to an integer in ..."
          ],
          [
           "In [3]:\n\nL2 = [str(c) for c in L] L2\n\nOut[3]:\n\n['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n\nI..."
          ],
          [
           "At the implementation level, the array essentially contains a single pointer to one contiguous block..."
          ],
          [
           "In [7]:\n\nimport numpy as np\n\nCreating Arrays from Python Lists¶First, we can use np.array to create ..."
          ],
          [
           "In [11]:\n\n# nested lists result in multi-dimensional arrays np.array([range(i, i + 3) for i in [2, 4..."
          ],
          [
           "# Create a 3x5 array filled with 3.14 np.full((3, 5), 3.14)\n\nOut[14]:\n\narray([[ 3.14,  3.14,  3.14, ..."
          ],
          [
           "Out[17]:\n\narray([[ 0.99844933,  0.52183819,  0.22421193], [ 0.08007488,  0.45429293,  0.20941444], [..."
          ],
          [
           "In [20]:\n\n# Create a 3x3 identity matrix np.eye(3)\n\nOut[20]:\n\narray([[ 1.,  0.,  0. ], [ 0.,  1.,  0..."
          ],
          [
           "intp Integer used for indexing (same as C ssize_t; normally either int32 or int64)\n\nint8\n\nByte (\n\n12..."
          ],
          [
           "complex64 Complex number, represented by two 32-bit floats\n\ncomplex128 Complex number, represented b..."
          ],
          [
           "Attributes of arrays: Determining the size, shape, memory consumption, and data types of arrays Inde..."
          ],
          [
           "print(\"x3 shape:\", x3.shape)\n\nprint(\"x3 size: \", x3.size)\n\nx3 ndim:  3 x3 shape: (3, 4, 5) x3 size: ..."
          ],
          [
           "In [5]:\n\nx1\n\nOut[5]:\n\narray([5, 0, 3, 3, 7, 9])\n\nIn [6]:\n\nx1[0]\n\nOut[6]:\n\n5\n\nIn [7]:\n\nx1[4]\n\nOut[7]:..."
          ],
          [
           "Out[12]:\n\n1\n\nIn [13]:\n\nx2[2,\n\n1]\n\nOut[13]:\n\n7\n\nValues can also be modified using any of the above in..."
          ],
          [
           "If any of these are unspecified, they default to the values start=0, stop=size of dimension, step=1...."
          ],
          [
           "Out[21]:\n\narray([1, 3, 5, 7, 9])\n\nA potentially confusing case is when the step value is negative. I..."
          ],
          [
           "In [26]:\n\nx2[:3, ::2]  # all rows, every other column\n\nOut[26]:\n\narray([[12,  2],\n\n[ 7,  8],\n\n[ 1,  ..."
          ],
          [
           "print(x2[0])  # equivalent to x2[0, :]\n\n[12  5  2  4]\n\nSubarrays as no-copy views¶One important–and ..."
          ],
          [
           "print(x2)\n\n[[99  5  2  4] [ 7  6  8  8] [ 1  6  7  7]]\n\nThis default behavior is actually quite usef..."
          ],
          [
           "In [38]:\n\ngrid = np.arange(1, 10).reshape((3, 3)) print(grid)\n\n[[1 2 3]\n\n[4 5 6]\n\n[7 8 9]]\n\nNote tha..."
          ],
          [
           "Out[41]:\n\narray([[1],\n\n[2],\n\n[3]])\n\nIn [42]:\n\n# column vector via newaxis x[:, np.newaxis]\n\nOut[42]:..."
          ],
          [
           "You can also concatenate more than two arrays at once:\n\nIn [44]:\n\nz = [99, 99, 99] print(np.concaten..."
          ],
          [
           "In [48]:\n\nx = np.array([1, 2, 3]) grid = np.array([[9, 8, 7], [6, 5, 4]])\n\n# vertically stack the ar..."
          ],
          [
           "[1 2 3] [99 99] [3 2 1]\n\nNotice that N split-points, leads to N + 1 subarrays. The related functions..."
          ],
          [
           "Computation on NumPy Arrays: Universal Functions | Python Data Science Handbook\n\nPython Data Science..."
          ],
          [
           "The Slowness of Loops¶Python's default implementation (known as CPython) does some operations very s..."
          ],
          [
           "values = np.random.randint(1, 10, size=5) compute_reciprocals(values)\n\nOut[1]:\n\narray([ 0.16666667, ..."
          ],
          [
           "Introducing UFuncs¶For many types of operations, NumPy provides a convenient interface into just thi..."
          ],
          [
           "Out[5]:\n\narray([ 0.        ,  0.5       ,  0.66666667,  0.75      ,  0.8       ])\n\nAnd ufunc operati..."
          ],
          [
           "In [7]:\n\nx = np.arange(4) print(\"x     =\", x) print(\"x + 5 =\", x + 5) print(\"x - 5 =\", x - 5) print(..."
          ],
          [
           "(0.5\n\nx + 1)\n\n** 2\n\nOut[9]:\n\narray([\n\n1.  ,\n\n2.25,\n\n4.  ,\n\n6.25])\n\nEach of these arithmetic operatio..."
          ],
          [
           "np.power\n\nExponentiation (e.g., 2 *\n\n3 = 8)\n\n% np.mod Modulus/remainder (e.g., 9 % 4 = 1)\n\nAdditiona..."
          ],
          [
           "x = np.array([3 - 4j, 4 - 3j, 2 + 0j, 0 + 1j]) np.abs(x)\n\nOut[14]:\n\narray([ 5.,  5.,  2.,  1.])\n\nTri..."
          ],
          [
           "The values are computed to within machine precision, which is why values that should be zero do not ..."
          ],
          [
           "x     = [1, 2, 3] e^x   = [  2.71828183   7.3890561   20.08553692] 2^x   = [ 2. 4. 8.] 3^x   = [ 3  ..."
          ],
          [
           "There are also some specialized versions that are useful for maintaining precision with very small i..."
          ],
          [
           "In [21]:\n\nfrom scipy import special\n\nIn [22]:\n\n# Gamma functions (generalized factorials) and relate..."
          ],
          [
           "erf(x)  = [ 0. 0.32862676  0.67780119  0.84270079] erfc(x) = [ 1. 0.67137324  0.32219881  0.15729921..."
          ],
          [
           "This can even be used with array views. For example, we can write the results of a computation to ev..."
          ],
          [
           "15\n\nSimilarly, calling reduce on the multiply ufunc results in the product of all array elements:\n\nI..."
          ],
          [
           "x = np.arange(1, 6)\n\nnp.multiply.outer(x, x)\n\nOut[30]:\n\narray([[ 1,  2,  3,  4,  5], [ 2,  4,  6,  8..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "The syntax is quite similar to that of NumPy's sum function, and the result is the same in the simpl..."
          ],
          [
           "NumPy's corresponding functions have similar syntax, and again operate much more quickly:\n\nIn [6]:\n\n..."
          ],
          [
           "In [9]:\n\nM = np.random.random((3, 4))\n\nprint(M)\n\n[[ 0.8967576   0.03783739  0.75952519  0.06682827] ..."
          ],
          [
           "In [12]:\n\nM.max(axis=1)\n\nOut[12]:\n\narray([ 0.8967576 ,  0.99196818,  0.6687194 ])\n\nThe way the axis ..."
          ],
          [
           "Compute mean of elements\n\nnp.std\n\nnp.nanstd\n\nCompute standard deviation\n\nnp.var\n\nnp.nanvar\n\nCompute ..."
          ],
          [
           "order,name,height(cm)\n\n1,George Washington,189\n\n2,John Adams,170\n\n3,Thomas Jefferson,189\n\nWe'll use ..."
          ],
          [
           "In [16]:\n\nprint(\"25th percentile:   \", np.percentile(heights, 25)) print(\"Median:            \", np.m..."
          ],
          [
           "Computation on Arrays: Broadcasting | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAb..."
          ],
          [
           "Out[2]:\n\narray([5, 6, 7])\n\nBroadcasting allows these types of binary operations to be performed on a..."
          ],
          [
           "Here the one-dimensional array a is stretched, or broadcast across the second dimension in order to ..."
          ],
          [
           "Rules of Broadcasting¶Broadcasting in NumPy follows a strict set of rules to determine the interacti..."
          ],
          [
           "M.shape\n\n> (2, 3)\n\na.shape\n\n> (2, 3)\n\nThe shapes match, and we see that the final shape will be (2, ..."
          ],
          [
           "In [11]:\n\na + b\n\nOut[11]:\n\narray([[0, 1, 2],\n\n[1, 2, 3],\n\n[2, 3, 4]])\n\nBroadcasting example 3¶Now le..."
          ],
          [
           "In [13]:\n\nM + a\n\n--------------------------------------------------------------------------- ValueEr..."
          ],
          [
           "M + a[:, np.newaxis]\n\nOut[15]:\n\narray([[ 1.,  1. ],\n\n[ 2.,  2. ],\n\n[ 3.,  3.]])\n\nAlso note that whil..."
          ],
          [
           "Centering an array¶\n\nIn the previous section, we saw that ufuncs allow a NumPy user to remove the ne..."
          ],
          [
           "17,\n\n7.77156117e\n\n17,\n\n1.66533454e\n\n17])\n\nTo within machine precision, the mean is now zero.\n\nPlotti..."
          ],
          [
           "The result is a compelling visualization of the two-dimensional function.\n\n< Aggregations: Min, Max,..."
          ],
          [
           "In [1]:\n\nimport numpy as np\n\nimport pandas as pd\n\n# use pandas to extract rainfall inches as a NumPy..."
          ],
          [
           "Digging into the data¶One approach to this would be to answer these questions by hand: loop through ..."
          ],
          [
           "Out[5]:\n\narray([ True,  True, False, False, False], dtype=bool)\n\nIn [6]:\n\nx > 3  # greater than\n\nOut..."
          ],
          [
           "(2\n\nx) == (x *\n\n2)\n\nOut[11]:\n\narray([False,  True, False, False, False], dtype=bool)\n\nAs in the case..."
          ],
          [
           "[2, 4, 7, 6]])\n\nIn [13]:\n\nx < 6\n\nOut[13]:\n\narray([[ True,  True,  True,  True], [False, False,  True..."
          ],
          [
           "In [16]:\n\nnp.sum(x < 6)\n\nOut[16]:\n\n8\n\nThe benefit of sum() is that like with other NumPy aggregation..."
          ],
          [
           "Out[21]:\n\nFalse\n\nnp.all and np.any can be used along particular axes as well. For example:\n\nIn [22]:..."
          ],
          [
           "In [23]:\n\nnp.sum((inches > 0.5) & (inches < 1))\n\nOut[23]:\n\n29\n\nSo we see that there are 29 days with..."
          ],
          [
           "In [25]:\n\nprint(\"Number days without rain:      \", np.sum(inches == 0)) print(\"Number days with rain..."
          ],
          [
           "Now to select these values from the array, we can simply index on this Boolean array; this is known ..."
          ],
          [
           "Median precip on rainy days in 2014 (inches):    0.194881889764 Median precip on summer days in 2014..."
          ],
          [
           "False\n\nIn [32]:\n\nbool(42 or 0)\n\nOut[32]:\n\nTrue\n\nWhen you use & and | on integers, the expression ope..."
          ],
          [
           "Out[37]:\n\narray([ True,  True,  True, False,  True,  True], dtype=bool)\n\nUsing or on these arrays wi..."
          ],
          [
           "Trying to evaluate the truth or falsehood of the entire array will give the same ValueError we saw p..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "[51 92 14 71 60 20 82 86 74 74]\n\nSuppose we want to access three different elements. We could do it ..."
          ],
          [
           "array([[ 0,  1,  2,  3], [ 4,  5,  6,  7], [ 8,  9, 10, 11]])\n\nLike with standard indexing, the firs..."
          ],
          [
           "Out[8]:\n\narray([[0, 0, 0],\n\n[2, 1, 3],\n\n[4, 2, 6]])\n\nIt is always important to remember with fancy i..."
          ],
          [
           "Out[12]:\n\narray([[ 0,  2],\n\n[ 4,  6],\n\n[ 8, 10]])\n\nAll of these indexing options combined lead to a ..."
          ],
          [
           "In [15]:\n\nindices = np.random.choice(X.shape[0], 20, replace=False) indices\n\nOut[15]:\n\narray([93, 45..."
          ],
          [
           "In [18]:\n\nx = np.arange(10) i = np.array([2, 1, 8, 4]) x[i] = 99 print(x)\n\n[ 0 99 99  3 99  5  6  7 ..."
          ],
          [
           "array([ 6.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.])\n\nYou might expect that x[3] would contain ..."
          ],
          [
           "Example: Binning Data¶You can use these ideas to efficiently bin data to create a histogram by hand...."
          ],
          [
           "This function will create a nearly identical plot to the one seen here. To compute the binning, matp..."
          ],
          [
           "print(\"Custom routine:\") %timeit np.add.at(counts, np.searchsorted(bins, x), 1)\n\nNumPy routine: 10 l..."
          ],
          [
           "Sorting Arrays\n\n< Fancy Indexing | Contents | Structured Data: NumPy's Structured Arrays >\n\nUp to th..."
          ],
          [
           "Out[2]:\n\narray([1, 2, 3, 4, 5])\n\nAs any first-year computer science major will tell you, the selecti..."
          ],
          [
           "Out[4]:\n\narray([1, 2, 3, 4, 5])\n\nThis silly sorting method relies on pure chance: it repeatedly appl..."
          ],
          [
           "Out[5]:\n\narray([1, 2, 3, 4, 5])\n\nIf you prefer to sort the array in-place, you can instead use the s..."
          ],
          [
           "rand = np.random.RandomState(42) X = rand.randint(0, 10, (4, 6)) print(X)\n\n[[6 3 7 4 6 9] [2 6 7 4 3..."
          ],
          [
           "Keep in mind that this treats each row or column as an independent array, and any relationships betw..."
          ],
          [
           "The result is an array where the first two slots in each row contain the smallest values from that r..."
          ],
          [
           "In [16]:\n\ndist_sq = np.sum((X[:, np.newaxis, :] - X[np.newaxis, :, :]) ** 2, axis=-1)\n\nThis operatio..."
          ],
          [
           "In [20]:\n\ndist_sq.diagonal()\n\nOut[20]:\n\narray([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n\nI..."
          ],
          [
           "Notice that the first column gives the numbers 0 through 9 in order: this is due to the fact that ea..."
          ],
          [
           "Each point in the plot has lines drawn to its two nearest neighbors. At first glance, it might seem ..."
          ],
          [
           "Aside: Big-O Notation¶Big-O notation is a means of describing how the number of operations required ..."
          ],
          [
           "When trying to analyze billions or trillions of samples, the difference between $\\mathcal{O}[N]$ and..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "But this is a bit clumsy. There's nothing here that tells us that the three arrays are related; it w..."
          ],
          [
           "In [5]:\n\ndata['name'] = name\n\ndata['age'] = age\n\ndata['weight'] = weight\n\nprint(data)\n\n[('Alice', 25..."
          ],
          [
           "# Get names where age is under 30 data[data['age'] < 30]['name']\n\nOut[9]:\n\narray(['Alice', 'Doug'],\n..."
          ],
          [
           "In [11]:\n\nnp.dtype({'names':('name', 'age', 'weight'),\n\n'formats':((np.str_, 10), int, np.float32)})..."
          ],
          [
           "The shortened string format codes may seem confusing, but they are built on simple principles. The f..."
          ],
          [
           "'V'\n\nRaw data (void)\n\nnp.dtype('V') == np.void\n\nMore Advanced Compound Types¶It is possible to defin..."
          ],
          [
           "RecordArrays: Structured Arrays with a Twist¶NumPy also provides the np.recarray class, which is alm..."
          ],
          [
           "Whether the more convenient notation is worth the additional overhead will depend on your own applic..."
          ],
          [
           "Data Manipulation with Pandas\n\n< Structured Data: NumPy's Structured Arrays | Contents | Introducing..."
          ],
          [
           "In this chapter, we will focus on the mechanics of using Series, DataFrame, and related structures e..."
          ],
          [
           "And to display Pandas's built-in documentation, you can use this: In [4]: pd?\n\nMore detailed documen..."
          ],
          [
           "3. Data Manipulation with Pandas¶ Introducing Pandas Objects Data Indexing and Selection Operating o..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "Out[2]:\n\n0    0.25 1    0.50 2    0.75 3    1.00 dtype: float64\n\nAs we see in the output, the Series..."
          ],
          [
           "Series as generalized NumPy array¶\n\nFrom what we've seen so far, it may look like the Series object ..."
          ],
          [
           "2    0.25 5    0.50 3    0.75 7    1.00 dtype: float64\n\nIn [10]:\n\ndata[5]\n\nOut[10]:\n\n0.5\n\nSeries as ..."
          ],
          [
           "In [12]:\n\npopulation['California']\n\nOut[12]:\n\n38332521\n\nUnlike a dictionary, though, the Series also..."
          ],
          [
           "data can be a dictionary, in which index defaults to the sorted dictionary keys:\n\nIn [16]:\n\npd.Serie..."
          ],
          [
           "DataFrame as a generalized NumPy array¶If a Series is an analog of a one-dimensional array with flex..."
          ],
          [
           "423967\n\n38332521\n\nFlorida\n\n170312\n\n19552860\n\nIllinois\n\n149995\n\n12882135\n\nNew York\n\n141297\n\n19651127\n..."
          ],
          [
           "In [22]:\n\nstates['area']\n\nOut[22]:\n\nCalifornia    423967 Florida       170312 Illinois      149995 N..."
          ],
          [
           "From a list of dicts¶Any list of dictionaries can be made into a DataFrame. We'll use a simple list ..."
          ],
          [
           "'area': area})\n\nOut[26]:\n\narea\n\npopulation\n\nCalifornia\n\n423967\n\n38332521\n\nFlorida\n\n170312\n\n19552860\n..."
          ],
          [
           "In [28]:\n\nA = np.zeros(3, dtype=[('A', 'i8'), ('B', 'f8')]) A\n\nOut[28]:\n\narray([(0, 0.0), (0, 0.0), ..."
          ],
          [
           "ind = pd.Index([2, 3, 5, 7, 11]) ind\n\nOut[30]:\n\nInt64Index([2, 3, 5, 7, 11], dtype='int64')\n\nIndex a..."
          ],
          [
           "In [34]:\n\nind[1] = 0\n\n--------------------------------------------------------------------------- Ty..."
          ],
          [
           "In [35]:\n\nindA = pd.Index([1, 3, 5, 7, 9]) indB = pd.Index([2, 3, 5, 7, 11])\n\nIn [36]:\n\nindA & indB ..."
          ],
          [
           "Data Indexing and Selection\n\n< Introducing Pandas Objects | Contents | Operating on Data in Pandas >..."
          ],
          [
           "Series as dictionary¶Like a dictionary, the Series object provides a mapping from a collection of ke..."
          ],
          [
           "Series objects can even be modified with a dictionary-like syntax. Just as you can extend a dictiona..."
          ],
          [
           "# masking data[(data > 0.3) & (data < 0.8)]\n\nOut[9]:\n\nb    0.50 c    0.75 dtype: float64\n\nIn [10]:\n\n..."
          ],
          [
           "# explicit index when indexing data[1]\n\nOut[12]:\n\n'a'\n\nIn [13]:\n\n# implicit index when slicing data[..."
          ],
          [
           "data.iloc[1:3]\n\nOut[17]:\n\n3    b 5    c dtype: object\n\nA third indexing attribute, ix, is a hybrid o..."
          ],
          [
           "In [18]:\n\narea = pd.Series({'California': 423967, 'Texas': 695662, 'New York': 141297, 'Florida': 17..."
          ],
          [
           "Equivalently, we can use attribute-style access with column names that are strings:\n\nIn [20]:\n\ndata...."
          ],
          [
           "data['density'] = data['pop'] / data['area'] data\n\nOut[23]:\n\narea\n\npop\n\ndensity\n\nCalifornia\n\n423967\n..."
          ],
          [
           "In [24]:\n\ndata.values\n\nOut[24]:\n\narray([[  4.23967000e+05,   3.83325210e+07,   9.04139261e+01], [  1..."
          ],
          [
           "6.956620e+05\n\npop\n\n3.833252e+07\n\n1.955286e+07\n\n1.288214e+07\n\n1.965113e+07\n\n2.644819e+07\n\ndensity\n\n9...."
          ],
          [
           "California    423967 Florida       170312 Illinois      149995 New York      141297 Texas         69..."
          ],
          [
           "Illinois\n\n149995\n\n12882135\n\nThe ix indexer allows a hybrid of these two approaches:\n\nIn [30]:\n\ndata...."
          ],
          [
           "In [32]:\n\ndata.iloc[0, 2] = 90\n\ndata\n\nOut[32]:\n\narea\n\npop\n\ndensity\n\nCalifornia\n\n423967\n\n38332521\n\n90..."
          ],
          [
           "density\n\nFlorida\n\n170312\n\n19552860\n\n114.806121\n\nIllinois\n\n149995\n\n12882135\n\n85.883763\n\nSuch slices c..."
          ],
          [
           "< Introducing Pandas Objects | Contents | Operating on Data in Pandas >\n\nOperating on Data in Pandas..."
          ],
          [
           "Ufuncs: Index Preservation¶Because Pandas is designed to work with NumPy, any NumPy ufunc will work ..."
          ],
          [
           "In [4]:\n\nnp.exp(ser)\n\nOut[4]:\n\n0     403.428793 1      20.085537 2    1096.633158 3      54.598150 d..."
          ],
          [
           "Index alignment in Series¶As an example, suppose we are combining two different data sources, and fi..."
          ],
          [
           "In [9]:\n\nA = pd.Series([2, 4, 6], index=[0, 1, 2]) B = pd.Series([1, 3, 5], index=[1, 2, 3]) A + B\n\n..."
          ],
          [
           "0\n\n1\n\n11\n\n1\n\n5\n\n1\n\nIn [12]:\n\nB = pd.DataFrame(rng.randint(0, 10, (3, 3)), columns=list('BAC')) B\n\nOu..."
          ],
          [
           "In [14]:\n\nfill = A.stack().mean()\n\nA.add(B, fill_value=fill)\n\nOut[14]:\n\nA\n\nB\n\nC\n\n0\n\n1.0\n\n15.0\n\n13.5\n..."
          ],
          [
           "In [15]:\n\nA = rng.randint(10, size=(3, 4)) A\n\nOut[15]:\n\narray([[3, 8, 2, 4],\n\n[2, 6, 4, 8],\n\n[6, 1, ..."
          ],
          [
           "2\n\n2\n\n4\n\n2\n\n3\n\n7\n\n1\n\n4\n\nIf you would instead like to operate column-wise, you can use the object met..."
          ],
          [
           "T\n\n0\n\n0.0\n\nNaN\n\n0.0\n\nNaN\n\n1\n\n1.0\n\nNaN\n\n2.0\n\nNaN\n\n2\n\n3.0\n\nNaN\n\n1.0\n\nNaN\n\nThis preservation and alignm..."
          ],
          [
           "Handling Missing Data\n\n< Operating on Data in Pandas | Contents | Hierarchical Indexing >\n\nThe diffe..."
          ],
          [
           "Trade-Offs in Missing Data Conventions¶There are a number of schemes that have been developed to ind..."
          ],
          [
           "Missing Data in Pandas¶The way in which Pandas handles missing values is constrained by its reliance..."
          ],
          [
           "None: Pythonic missing data¶The first sentinel value used by Pandas is None, a Python singleton obje..."
          ],
          [
           "dtype = int 100 loops, best of 3: 3.06 ms per loop\n\nThe use of Python objects in an array also means..."
          ],
          [
           "TypeError: unsupported operand type(s) for +: 'int' and 'NoneType'\n\nThis reflects the fact that addi..."
          ],
          [
           "In [8]:\n\nvals2.sum(), vals2.min(), vals2.max()\n\nOut[8]:\n\n(nan, nan, nan)\n\nNumPy does provide some sp..."
          ],
          [
           "x = pd.Series(range(2), dtype=int)\n\nx\n\nOut[11]:\n\n0    0 1    1 dtype: int64\n\nIn [12]:\n\nx[0] = None\n\n..."
          ],
          [
           "Cast to object\n\nNone or np.nan\n\nKeep in mind that in Pandas, string data is always stored with an ob..."
          ],
          [
           "data[data.notnull()]\n\nOut[15]:\n\n0        1 2    hello dtype: object\n\nThe isnull() and notnull() meth..."
          ],
          [
           "3.0\n\n5\n\n2\n\nNaN\n\n4.0\n\n6\n\nWe cannot drop single values from a DataFrame; we can only drop full rows or..."
          ],
          [
           "In [20]:\n\ndf[3] = np.nan\n\ndf\n\nOut[20]:\n\n0\n\n1\n\n2\n\n3\n\n0\n\n1.0\n\nNaN\n\n2\n\nNaN\n\n1\n\n2.0\n\n3.0\n\n5\n\nNaN\n\n2\n\nNaN..."
          ],
          [
           "2\n\n3\n\n1\n\n2.0\n\n3.0\n\n5\n\nNaN\n\nHere the first and last row have been dropped, because they contain only ..."
          ],
          [
           "In [25]:\n\n# forward\n\nfill\n\ndata.fillna(method='ffill')\n\nOut[25]:\n\na    1.0 b    1.0 c    2.0 d    2...."
          ],
          [
           "Out[28]:\n\n0\n\n1\n\n2\n\n3\n\n0\n\n1.0\n\n1.0\n\n2.0\n\n2.0\n\n1\n\n2.0\n\n3.0\n\n5.0\n\n5.0\n\n2\n\nNaN\n\n4.0\n\n6.0\n\n6.0\n\nNotice th..."
          ],
          [
           "Hierarchical Indexing\n\n< Handling Missing Data | Contents | Combining Datasets: Concat and Append >\n..."
          ],
          [
           "In [2]:\n\nindex = [('California', 2000), ('California', 2010), ('New York', 2000), ('New York', 2010)..."
          ],
          [
           "pop[[i for i in pop.index if i[1] == 2010]]\n\nOut[4]:\n\n(California, 2010)    37253956 (New York, 2010..."
          ],
          [
           "In [6]:\n\npop = pop.reindex(index)\n\npop\n\nOut[6]:\n\nCalifornia  2000    33871648 2010    37253956 New Y..."
          ],
          [
           "In [8]:\n\npop_df = pop.unstack()\n\npop_df\n\nOut[8]:\n\n2000\n\n2010\n\nCalifornia\n\n33871648\n\n37253956\n\nNew Yo..."
          ],
          [
           "In [10]:\n\npop_df = pd.DataFrame({'total': pop,\n\n'under18': [9267089, 9284094,\n\n4687374, 4318033,\n\n59..."
          ],
          [
           "Out[11]:\n\n2000\n\n2010\n\nCalifornia\n\n0.273594\n\n0.249211\n\nNew York\n\n0.247010\n\n0.222831\n\nTexas\n\n0.283251\n..."
          ],
          [
           "0.610054\n\n2\n\n0.171495\n\n0.886688\n\nThe work of creating the MultiIndex is done in the background. Simi..."
          ],
          [
           "Out[14]:\n\nMultiIndex(levels=[['a', 'b'], [1, 2]], labels=[[0, 0, 1, 1], [0, 1, 0, 1]])\n\nYou can cons..."
          ],
          [
           "In [17]:\n\npd.MultiIndex(levels=[['a', 'b'], [1, 2]], labels=[[0, 0, 1, 1], [0, 1, 0, 1]])\n\nOut[17]:\n..."
          ],
          [
           "With more involved datasets, this can be a useful way to keep track of the meaning of various index ..."
          ],
          [
           "visit\n\n2013\n\n1\n\n31.0\n\n38.7\n\n32.0\n\n36.7\n\n35.0\n\n37.2\n\n2\n\n44.0\n\n37.7\n\n50.0\n\n35.0\n\n29.0\n\n36.7\n\n2014\n\n1\n\n..."
          ],
          [
           "2013\n\n1\n\n32.0\n\n36.7\n\n2\n\n50.0\n\n35.0\n\n2014\n\n1\n\n39.0\n\n37.8\n\n2\n\n48.0\n\n37.3\n\nFor complicated records cont..."
          ],
          [
           "In [23]:\n\npop['California']\n\nOut[23]:\n\nyear 2000    33871648 2010    37253956 dtype: int64\n\nPartial ..."
          ],
          [
           "In [27]:\n\npop[['California', 'Texas']]\n\nOut[27]:\n\nstate       year California  2000    33871648 2010..."
          ],
          [
           "2\n\n47.0\n\n37.8\n\n48.0\n\n37.3\n\n51.0\n\n36.5\n\nRemember that columns are primary in a DataFrame, and the syn..."
          ],
          [
           "In [31]:\n\nhealth_data.loc[:, ('Bob', 'HR')]\n\nOut[31]:\n\nyear  visit 2013  1        31.0 2        44.0..."
          ],
          [
           "Bob\n\nGuido\n\nSue\n\ntype\n\nHR\n\nHR\n\nHR\n\nyear\n\nvisit\n\n2013\n\n1\n\n31.0\n\n32.0\n\n35.0\n\n2014\n\n1\n\n30.0\n\n39.0\n\n61.0..."
          ],
          [
           "In [34]:\n\nindex = pd.MultiIndex.from_product([['a', 'c', 'b'], [1, 2]]) data = pd.Series(np.random.r..."
          ],
          [
           "In [36]:\n\ndata = data.sort_index()\n\ndata\n\nOut[36]:\n\nchar  int a     1      0.003001 2      0.164974 ..."
          ],
          [
           "pop.unstack(level=1)\n\nOut[39]:\n\nyear\n\n2000\n\n2010\n\nstate\n\nCalifornia\n\n33871648\n\n37253956\n\nNew York\n\n1..."
          ],
          [
           "year\n\npopulation\n\n0\n\nCalifornia\n\n2000\n\n33871648\n\n1\n\nCalifornia\n\n2010\n\n37253956\n\n2\n\nNew York\n\n2000\n\n1..."
          ],
          [
           "19378102\n\nTexas\n\n2000\n\n20851820\n\n2010\n\n25145561\n\nIn practice, I find this type of reindexing to be o..."
          ],
          [
           "2014\n\n1\n\n30.0\n\n37.4\n\n39.0\n\n37.8\n\n61.0\n\n36.9\n\n2\n\n47.0\n\n37.8\n\n48.0\n\n37.3\n\n51.0\n\n36.5\n\nPerhaps we'd lik..."
          ],
          [
           "By further making use of the axis keyword, we can take the mean among levels on the columns as well:..."
          ],
          [
           "Aside: Panel Data¶Pandas has a few other fundamental data structures that we have not yet discussed,..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "For convenience, we'll define this function which creates a DataFrame of a particular form that will..."
          ],
          [
           "def _repr_html_(self):\n\nreturn '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n\nfor a in se..."
          ],
          [
           "In [5]:\n\nx = [[1, 2],\n\n[3, 4]]\n\nnp.concatenate([x, x], axis=1)\n\nOut[5]:\n\narray([[1, 2, 1, 2],\n\n[3, 4..."
          ],
          [
           "Out[6]:\n\n1    A 2    B 3    C 4    D 5    E 6    F dtype: object\n\nIt also works to concatenate highe..."
          ],
          [
           "B2\n\n3\n\nA3\n\nB3\n\n4\n\nA4\n\nB4\n\nBy default, the concatenation takes place row-wise within the DataFrame (i..."
          ],
          [
           "0\n\nA0\n\nB0\n\nC0\n\nD0\n\n1\n\nA1\n\nB1\n\nC1\n\nD1\n\nWe could have equivalently specified axis=1; here we've used t..."
          ],
          [
           "A0\n\nB0\n\n1\n\nA1\n\nB1\n\n0\n\nA2\n\nB2\n\n1\n\nA3\n\nB3\n\nNotice the repeated indices in the result. While this is va..."
          ],
          [
           "Out[11]:\n\nx\n\nA\n\nB\n\n0\n\nA0\n\nB0\n\n1\n\nA1\n\nB1\n\ny\n\nA\n\nB\n\n0\n\nA2\n\nB2\n\n1\n\nA3\n\nB3\n\npd.concat([x, y], ignore_ind..."
          ],
          [
           "y\n\nA\n\nB\n\n0\n\nA2\n\nB2\n\n1\n\nA3\n\nB3\n\npd.concat([x, y], keys=['x', 'y'])\n\nA\n\nB\n\nx\n\n0\n\nA0\n\nB0\n\n1\n\nA1\n\nB1\n\ny\n..."
          ],
          [
           "Out[13]:\n\ndf5\n\nA\n\nB\n\nC\n\n1\n\nA1\n\nB1\n\nC1\n\n2\n\nA2\n\nB2\n\nC2\n\ndf6\n\nB\n\nC\n\nD\n\n3\n\nB3\n\nC3\n\nD3\n\n4\n\nB4\n\nC4\n\nD4\n\npd..."
          ],
          [
           "In [14]:\n\ndisplay('df5', 'df6',\n\n\"pd.concat([df5, df6], join='inner')\")\n\nOut[14]:\n\ndf5\n\nA\n\nB\n\nC\n\n1\n\n..."
          ],
          [
           "In [15]:\n\ndisplay('df5', 'df6',\n\n\"pd.concat([df5, df6], join_axes=[df5.columns])\")\n\nOut[15]:\n\ndf5\n\nA..."
          ],
          [
           "The append() method¶Because direct array concatenation is so common, Series and DataFrame objects ha..."
          ],
          [
           "B2\n\n3\n\nA3\n\nB3\n\n4\n\nA4\n\nB4\n\nKeep in mind that unlike the append() and extend() methods of Python lists..."
          ],
          [
           "Combining Datasets: Merge and Join\n\n< Combining Datasets: Concat and Append | Contents | Aggregation..."
          ],
          [
           "Relational Algebra¶The behavior implemented in pd.merge() is a subset of what is known as relational..."
          ],
          [
           "In [2]:\n\ndf1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'], 'group': ['Accounting', 'En..."
          ],
          [
           "df3\n\nOut[3]:\n\nemployee\n\ngroup\n\nhire_date\n\n0\n\nBob\n\nAccounting\n\n2008\n\n1\n\nJake\n\nEngineering\n\n2012\n\n2\n\nL..."
          ],
          [
           "In [4]:\n\ndf4 = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'], 'supervisor': ['Carly', '..."
          ],
          [
           "2012\n\nGuido\n\n2\n\nLisa\n\nEngineering\n\n2004\n\nGuido\n\n3\n\nSue\n\nHR\n\n2014\n\nSteve\n\nThe resulting DataFrame has..."
          ],
          [
           "employee\n\ngroup\n\n0\n\nBob\n\nAccounting\n\n1\n\nJake\n\nEngineering\n\n2\n\nLisa\n\nEngineering\n\n3\n\nSue\n\nHR\n\ndf5\n\ngr..."
          ],
          [
           "Sue\n\nHR\n\nspreadsheets\n\n7\n\nSue\n\nHR\n\norganization\n\nThese three types of joins can be used with other P..."
          ],
          [
           "Engineering\n\n3\n\nSue\n\nHR\n\ndf2\n\nemployee\n\nhire_date\n\n0\n\nLisa\n\n2004\n\n1\n\nBob\n\n2008\n\n2\n\nJake\n\n2012\n\n3\n\nSu..."
          ],
          [
           "In [7]:\n\ndf3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'], 'salary': [70000, 80000, 120000..."
          ],
          [
           "70000\n\n1\n\nJake\n\nEngineering\n\nJake\n\n80000\n\n2\n\nLisa\n\nEngineering\n\nLisa\n\n120000\n\n3\n\nSue\n\nHR\n\nSue\n\n90000..."
          ],
          [
           "df2a = df2.set_index('employee')\n\ndisplay('df1a', 'df2a')\n\nOut[9]:\n\ndf1a\n\ngroup\n\nemployee\n\nBob\n\nAcco..."
          ],
          [
           "employee\n\nLisa\n\n2004\n\nBob\n\n2008\n\nJake\n\n2012\n\nSue\n\n2014\n\npd.merge(df1a, df2a, left_index=True, right_..."
          ],
          [
           "2014\n\ndf1a.join(df2a)\n\ngroup\n\nhire_date\n\nemployee\n\nBob\n\nAccounting\n\n2008\n\nJake\n\nEngineering\n\n2012\n\nL..."
          ],
          [
           "group\n\nname\n\nsalary\n\n0\n\nAccounting\n\nBob\n\n70000\n\n1\n\nEngineering\n\nJake\n\n80000\n\n2\n\nEngineering\n\nLisa\n\n1..."
          ],
          [
           "Out[13]:\n\ndf6\n\nname\n\nfood\n\n0\n\nPeter\n\nfish\n\n1\n\nPaul\n\nbeans\n\n2\n\nMary\n\nbread\n\ndf7\n\nname\n\ndrink\n\n0\n\nMary..."
          ],
          [
           "In [15]:\n\ndisplay('df6', 'df7', \"pd.merge(df6, df7, how='outer')\")\n\nOut[15]:\n\ndf6\n\nname\n\nfood\n\n0\n\nPe..."
          ],
          [
           "Out[16]:\n\ndf6\n\nname\n\nfood\n\n0\n\nPeter\n\nfish\n\n1\n\nPaul\n\nbeans\n\n2\n\nMary\n\nbread\n\ndf7\n\nname\n\ndrink\n\n0\n\nMary..."
          ],
          [
           "Finally, you may end up in a case where your two input DataFrames have conflicting column names. Con..."
          ],
          [
           "name\n\nrank_x\n\nrank_y\n\n0\n\nBob\n\n1\n\n3\n\n1\n\nJake\n\n2\n\n1\n\n2\n\nLisa\n\n3\n\n4\n\n3\n\nSue\n\n4\n\n2\n\nBecause the output w..."
          ],
          [
           "Jake\n\n1\n\n2\n\nLisa\n\n4\n\n3\n\nSue\n\n2\n\npd.merge(df8, df9, on=\"name\", suffixes=[\"_L\", \"_R\"])\n\nname\n\nrank_L\n\n..."
          ],
          [
           "In [19]:\n\n# Following are shell commands to download the data # !curl -O https://raw.githubuserconte..."
          ],
          [
           "under18\n\n2012\n\n1117489.0\n\n1\n\nAL\n\ntotal\n\n2012\n\n4817528.0\n\n2\n\nAL\n\nunder18\n\n2010\n\n1130966.0\n\n3\n\nAL\n\ntot..."
          ],
          [
           "Arizona\n\nAZ\n\n3\n\nArkansas\n\nAR\n\n4\n\nCalifornia\n\nCA\n\nGiven this information, say we want to compute a re..."
          ],
          [
           "2\n\nAL\n\nunder18\n\n2010\n\n1130966.0\n\nAlabama\n\n3\n\nAL\n\ntotal\n\n2010\n\n4785570.0\n\nAlabama\n\n4\n\nAL\n\nunder18\n\n20..."
          ],
          [
           "PR\n\ntotal\n\n1991\n\nNaN\n\nNaN\n\n2451\n\nPR\n\nunder18\n\n1991\n\nNaN\n\nNaN\n\n2452\n\nPR\n\ntotal\n\n1993\n\nNaN\n\nNaN\n\nIt ap..."
          ],
          [
           "Out[25]:\n\nstate/region    False ages            False year            False population       True st..."
          ],
          [
           "4\n\nAL\n\nunder18\n\n2011\n\n1125763.0\n\nAlabama\n\n52423.0\n\nAgain, let's check for nulls to see if there were..."
          ],
          [
           "ages\n\nyear\n\npopulation\n\nstate\n\narea (sq. mi)\n\n0\n\nAL\n\nunder18\n\n2012\n\n1117489.0\n\nAlabama\n\n52423.0\n\n1\n\n..."
          ],
          [
           "data2010 = final.query(\"year == 2010 & ages == 'total'\") data2010.head()\n\nOut[30]:\n\nstate/region\n\nag..."
          ],
          [
           "In [31]:\n\ndata2010.set_index('state', inplace=True) density = data2010['population'] / data2010['are..."
          ],
          [
           "We see that the least dense state, by far, is Alaska, averaging slightly over one resident per squar..."
          ],
          [
           "In [1]:\n\nimport numpy as np\n\nimport pandas as pd\n\nclass display(object): \"\"\"Display HTML representat..."
          ],
          [
           "planets.shape\n\nOut[2]:\n\n(1035, 6)\n\nIn [3]:\n\nplanets.head()\n\nOut[3]:\n\nmethod\n\nnumber\n\norbital_period\n..."
          ],
          [
           "2009\n\nThis has some details on the 1,000+ extrasolar planets discovered up to 2014.\n\nSimple Aggregat..."
          ],
          [
           "df\n\nOut[7]:\n\nA\n\nB\n\n0\n\n0.155995\n\n0.020584\n\n1\n\n0.058084\n\n0.969910\n\n2\n\n0.866176\n\n0.832443\n\n3\n\n0.601115\n..."
          ],
          [
           "In [10]:\n\nplanets.dropna().describe()\n\nOut[10]:\n\nnumber\n\norbital_period\n\nmass\n\ndistance\n\nyear\n\ncount..."
          ],
          [
           "39.940000\n\n2009.000000\n\n75%\n\n2.00000\n\n999.600000\n\n2.867500\n\n59.332500\n\n2011.000000\n\nmax\n\n6.00000\n\n17..."
          ],
          [
           "Product of all items\n\nsum()\n\nSum of all items\n\nThese are all methods of DataFrame and Series objects..."
          ],
          [
           "While this could certainly be done manually using some combination of the masking, aggregation, and ..."
          ],
          [
           "The most basic split-apply-combine operation can be computed with the groupby() method of DataFrames..."
          ],
          [
           "The GroupBy object¶The GroupBy object is a very flexible abstraction. In many ways, you can simply t..."
          ],
          [
           "planets.groupby('method')['orbital_period'].median()\n\nOut[16]:\n\nmethod Astrometry                   ..."
          ],
          [
           "This can be useful for doing certain things manually, though it is often much faster to use the buil..."
          ],
          [
           "2009.131579\n\n2.781901\n\n2004.0\n\n2008.00\n\n2009.0\n\n2011.00\n\n2013.0\n\nMicrolensing\n\n23.0\n\n2009.782609\n\n2...."
          ],
          [
           "4.249052\n\n1989.0\n\n2005.00\n\n2009.0\n\n2011.00\n\n2014.0\n\nTransit\n\n397.0\n\n2011.236776\n\n2.077867\n\n2002.0\n\n2..."
          ],
          [
           "Aggregate, filter, transform, apply¶The preceding discussion focused on aggregation for the combine ..."
          ],
          [
           "4\n\nB\n\n4\n\n7\n\n5\n\nC\n\n5\n\n9\n\nAggregation¶We're now familiar with GroupBy aggregations with sum(), median(..."
          ],
          [
           "In [21]:\n\ndf.groupby('key').aggregate({'data1': 'min',\n\n'data2': 'max'})\n\nOut[21]:\n\ndata1\n\ndata2\n\nke..."
          ],
          [
           "3\n\nA\n\n3\n\n3\n\n4\n\nB\n\n4\n\n7\n\n5\n\nC\n\n5\n\n9\n\ndf.groupby('key').std()\n\ndata1\n\ndata2\n\nkey\n\nA\n\n2.12132\n\n1.414214..."
          ],
          [
           "Transformation¶While aggregation must return a reduced version of the data, transformation can retur..."
          ],
          [
           "In [24]:\n\ndef norm_by_data2(x): # x is a DataFrame of group values x['data1'] /= x['data2'].sum() re..."
          ],
          [
           "3\n\n3\n\nA\n\n0.375000\n\n3\n\n4\n\nB\n\n0.571429\n\n7\n\n5\n\nC\n\n0.416667\n\n9\n\napply() within a GroupBy is quite flexib..."
          ],
          [
           "2\n\nC\n\n2\n\n3\n\n3\n\nA\n\n3\n\n3\n\n4\n\nB\n\n4\n\n7\n\n5\n\nC\n\n5\n\n9\n\ndf.groupby(L).sum()\n\ndata1\n\ndata2\n\n0\n\n7\n\n17\n\n1\n\n4\n\n3..."
          ],
          [
           "4\n\nB\n\n4\n\n7\n\n5\n\nC\n\n5\n\n9\n\ndf.groupby(df['key']).sum()\n\ndata1\n\ndata2\n\nkey\n\nA\n\n3\n\n8\n\nB\n\n5\n\n7\n\nC\n\n7\n\n12\n\n..."
          ],
          [
           "5\n\n9\n\ndf2.groupby(mapping).sum()\n\ndata1\n\ndata2\n\nconsonant\n\n12\n\n19\n\nvowel\n\n3\n\n8\n\nAny Python function¶..."
          ],
          [
           "6.0\n\nA list of valid keys¶Further, any of the preceding key choices can be combined to group on a mu..."
          ],
          [
           "2.0\n\nEclipse Timing Variations\n\n0.0\n\n0.0\n\n5.0\n\n10.0\n\nImaging\n\n0.0\n\n0.0\n\n29.0\n\n21.0\n\nMicrolensing\n\n0...."
          ],
          [
           "Transit Timing Variations\n\n0.0\n\n0.0\n\n0.0\n\n9.0\n\nThis shows the power of combining many of the operati..."
          ],
          [
           "Pivot Tables\n\n< Aggregation and Grouping | Contents | Vectorized String Operations >\n\nWe have seen h..."
          ],
          [
           "embarked\n\nclass\n\nwho\n\nadult_male\n\ndeck\n\nembark_town\n\nalive\n\nalone\n\n0\n\n0\n\n3\n\nmale\n\n22.0\n\n1\n\n0\n\n7.2500..."
          ],
          [
           "S\n\nFirst\n\nwoman\n\nFalse\n\nC\n\nSouthampton\n\nyes\n\nFalse\n\n4\n\n0\n\n3\n\nmale\n\n35.0\n\n0\n\n0\n\n8.0500\n\nS\n\nThird\n\nman..."
          ],
          [
           "survived\n\nsex\n\nfemale\n\n0.742038\n\nmale\n\n0.188908\n\nThis immediately gives us some insight: overall, th..."
          ],
          [
           "male\n\n0.368852\n\n0.157407\n\n0.135447\n\nThis gives us a better idea of how both gender and class affecte..."
          ],
          [
           "Multi-level pivot tables¶Just as in the GroupBy, the grouping in pivot tables can be specified with ..."
          ],
          [
           "In [7]:\n\nfare = pd.qcut(titanic['fare'], 2) titanic.pivot_table('survived', ['sex', age], [fare, 'cl..."
          ],
          [
           "0.098039\n\n0.125000\n\n0.391304\n\n0.030303\n\n0.192308\n\nThe result is a four-dimensional aggregation with ..."
          ],
          [
           "In [8]:\n\ntitanic.pivot_table(index='sex', columns='class',\n\naggfunc={'survived':sum, 'fare':'mean'})..."
          ],
          [
           "Third\n\nAll\n\nsex\n\nfemale\n\n0.968085\n\n0.921053\n\n0.500000\n\n0.742038\n\nmale\n\n0.368852\n\n0.157407\n\n0.135447\n..."
          ],
          [
           "In [11]:\n\nbirths = pd.read_csv('data/births.csv')\n\nTaking a look at the data, we see that it's relat..."
          ],
          [
           "births.pivot_table('births', index='decade', columns='gender', aggfunc='sum')\n\nOut[13]:\n\ngender\n\nF\n\n..."
          ],
          [
           "Further data exploration¶Though this doesn't necessarily relate to the pivot table, there are a few ..."
          ],
          [
           "births = births.query('(births > @mu - 5 * @sig) & (births < @mu + 5 * @sig)')\n\nNext we set the day ..."
          ],
          [
           "In [19]:\n\nimport matplotlib.pyplot as plt\n\nimport matplotlib as mpl\n\nbirths.pivot_table('births', in..."
          ],
          [
           "In [21]:\n\nbirths_by_date.index = [pd.datetime(2012, month, day) for (month, day) in births_by_date.i..."
          ],
          [
           "In particular, the striking feature of this graph is the dip in birthrate on US holidays (e.g., Inde..."
          ],
          [
           "Vectorized String Operations\n\n< Pivot Tables | Contents | Working with Time Series >\n\nOne strength o..."
          ],
          [
           "Out[2]:\n\n['Peter', 'Paul', 'Mary', 'Guido']\n\nThis is perhaps sufficient to work with some data, but ..."
          ],
          [
           "AttributeError: 'NoneType' object has no attribute 'capitalize'\n\nPandas includes features to address..."
          ],
          [
           "Methods similar to Python string methods¶Nearly all Python's built-in string methods are mirrored by..."
          ],
          [
           "In [7]:\n\nmonte.str.lower()\n\nOut[7]:\n\n0    graham chapman 1       john cleese 2     terry gilliam 3  ..."
          ],
          [
           "Method\n\nDescription\n\nmatch() Call re.match() on each element, returning a boolean.\n\nextract() Call r..."
          ],
          [
           "monte.str.findall(r'^[^AEIOU].\n\n[^aeiou]$')\n\nOut[12]:\n\n0    [Graham Chapman] 1                  [] 2..."
          ],
          [
           "join() Join strings in each element of the Series with passed separator\n\nget_dummies() extract dummy..."
          ],
          [
           "1)\n\nOut[14]:\n\n0    Chapman 1     Cleese 2    Gilliam 3       Idle 4      Jones 5      Palin dtype: o..."
          ],
          [
           "4\n\nB|C\n\nTerry Jones\n\n5\n\nB|C|D\n\nMichael Palin\n\nThe get_dummies() routine lets you quickly split-out t..."
          ],
          [
           "Example: Recipe Database¶These vectorized string operations become most useful in the process of cle..."
          ],
          [
           "except ValueError as e:\n\nprint(\"ValueError:\", e)\n\nValueError: Trailing data\n\nOops! We get a ValueErr..."
          ],
          [
           "In [21]:\n\nrecipes.shape\n\nOut[21]:\n\n(173278, 17)\n\nWe see there are nearly 200,000 recipes, and 17 col..."
          ],
          [
           "In [23]:\n\nrecipes.ingredients.str.len().describe()\n\nOut[23]:\n\ncount    173278.000000 mean        244..."
          ],
          [
           "Out[26]:\n\n10526\n\nWe could even look to see whether any recipes misspell the ingredient as \"cinamon\":..."
          ],
          [
           "We can then build a Boolean DataFrame consisting of True and False values, indicating whether this i..."
          ],
          [
           "False\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\n4\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n..."
          ],
          [
           "In [31]:\n\nrecipes.name[selection.index]\n\nOut[31]:\n\n2069      All cremat with a Little Gem, dandelion..."
          ],
          [
           "< Pivot Tables | Contents | Working with Time Series >\n\nWorking with Time Series | Python Data Scien..."
          ],
          [
           "In this section, we will introduce how to work with each of these types of date/time data in Pandas...."
          ],
          [
           "Or, using the dateutil module, you can parse dates from a variety of string formats:\n\nIn [2]:\n\nfrom ..."
          ],
          [
           "Typed arrays of times: NumPy's datetime64¶The weaknesses of Python's datetime format inspired the Nu..."
          ],
          [
           "07\n\n11',\n\n'2015\n\n07\n\n12', '2015\n\n07\n\n13', '2015\n\n07\n\n14', '2015\n\n07\n\n15'], dtype='datetime64[D]')\n\nB..."
          ],
          [
           "07\n\n04')\n\nHere is a minute\n\nbased datetime:\n\nIn [7]:\n\nnp.datetime64('2015\n\n07\n\n04 12:00')\n\nOut[7]:\n\n..."
          ],
          [
           "[9.2e18 BC, 9.2e18 AD]\n\nM\n\nMonth\n\n± 7.6e17 years\n\n[7.6e17 BC, 7.6e17 AD]\n\nW\n\nWeek\n\n± 1.7e17 years\n\n[..."
          ],
          [
           "fs Femtosecond ± 2.6 hours [ 1969 AD, 1970 AD]\n\nas Attosecond ± 9.2 seconds [ 1969 AD, 1970 AD]\n\nFor..."
          ],
          [
           "Timestamp('2015\n\n07\n\n04 00:00:00')\n\nIn [10]:\n\ndate.strftime('%A')\n\nOut[10]:\n\n'Saturday'\n\nAdditionall..."
          ],
          [
           "In the next section, we will take a closer look at manipulating time series data with the tools prov..."
          ],
          [
           "In [14]:\n\ndata['2015']\n\nOut[14]:\n\n2015-07-04    2 2015-08-04    3 dtype: int64\n\nLater, we will see a..."
          ],
          [
           "In [15]:\n\ndates = pd.to_datetime([datetime(2015, 7, 3), '4th of July, 2015', '2015-Jul-6', '07-07-20..."
          ],
          [
           "'2015\n\n07\n\n08'],\n\ndtype='int64', freq='D')\n\nA TimedeltaIndex is created, for example, when a date is..."
          ],
          [
           "Out[18]:\n\nDatetimeIndex(['2015\n\n07\n\n03', '2015\n\n07\n\n04', '2015\n\n07\n\n05', '2015\n\n07\n\n06',\n\n'2015\n\n07\n..."
          ],
          [
           "08', '2015\n\n07\n\n09', '2015\n\n07\n\n10'],\n\ndtype='datetime64[ns]', freq='D')\n\nThe spacing can be modifie..."
          ],
          [
           "03 07:00:00'],\n\ndtype='datetime64[ns]', freq='H')\n\nTo create regular sequences of Period or Timedelt..."
          ],
          [
           "pd.timedelta_range(0, periods=10, freq='H')\n\nOut[22]:\n\nTimedeltaIndex(['00:00:00', '01:00:00', '02:0..."
          ],
          [
           "A\n\nYear end\n\nBA\n\nBusiness year end\n\nH\n\nHours\n\nBH\n\nBusiness hours\n\nT\n\nMinutes\n\nS\n\nSeconds\n\nL\n\nMillise..."
          ],
          [
           "W\n\nSUN, W\n\nMON, W\n\nTUE, W\n\nWED, etc.\n\nOn top of this, codes can be combined with numbers to specify ..."
          ],
          [
           "Out[24]:\n\nDatetimeIndex(['2015\n\n07\n\n01', '2015\n\n07\n\n02', '2015\n\n07\n\n03', '2015\n\n07\n\n06',\n\n'2015\n\n07\n..."
          ],
          [
           "In [25]:\n\nfrom pandas_datareader import data\n\ngoog = data.DataReader('GOOG', start='2004', end='2016..."
          ],
          [
           "For simplicity, we'll use just the closing price:\n\nIn [26]:\n\ngoog = goog['Close']\n\nWe can visualize ..."
          ],
          [
           "');\n\nplt.legend(['input', 'resample', 'asfreq'],\n\nloc='upper left');\n\nNotice the difference: at each..."
          ],
          [
           "o')\n\nax[1].legend([\"back\n\nfill\", \"forward\n\nfill\"]);\n\nThe top panel is the default: non-business days..."
          ],
          [
           "11\n\n05')\n\noffset = pd.Timedelta(900, 'D')\n\nax[0].legend(['input'], loc=2)\n\nax[0].get_xticklabels()[2..."
          ],
          [
           "In [32]:\n\nROI = 100\n\n(goog.tshift(\n\n365) / goog\n\n1)\n\nROI.plot()\n\nplt.ylabel('% Return on Investment'..."
          ],
          [
           "', '-\n\n', ':'])\n\nax.lines[0].set_alpha(0.3)\n\nAs with group-by operations, the aggregate() and apply(..."
          ],
          [
           "In [34]:\n\n# !curl\n\no FremontBridge.csv https://data.seattle.gov/api/views/65db\n\nxm6k/rows.csv?access..."
          ],
          [
           "2012\n\n10\n\n03 04:00:00\n\n6.0\n\n1.0\n\nFor convenience, we'll further process this dataset by shortening t..."
          ],
          [
           "50%\n\n33.000000\n\n28.000000\n\n65.000000\n\n75%\n\n79.000000\n\n67.000000\n\n151.000000\n\nmax\n\n825.000000\n\n717.00..."
          ],
          [
           "', '\n\n'])\n\nplt.ylabel('Weekly bicycle count');\n\nThis shows us some interesting seasonal trends: as y..."
          ],
          [
           "', '\n\n']);\n\nDigging into the data¶While these smoothed data views are useful to get an idea of the g..."
          ],
          [
           "In [44]:\n\nby_weekday = data.groupby(data.index.dayofweek).mean() by_weekday.index = ['Mon', 'Tues', ..."
          ],
          [
           "Now we'll use some of the Matplotlib tools described in Multiple Subplots to plot two panels side by..."
          ],
          [
           "Python Data Science Handbook\n\nAbout\n\nArchive\n\nThis is an excerpt from the Python Data Science Handbo..."
          ],
          [
           "In [1]:\n\nimport numpy as np\n\nrng = np.random.RandomState(42)\n\nx = rng.rand(1000000)\n\ny = rng.rand(10..."
          ],
          [
           "tmp1 = (x > 0.5) tmp2 = (y < 0.5) mask = tmp1 & tmp2\n\nIn other words, every intermediate step is exp..."
          ],
          [
           "In [6]:\n\nimport pandas as pd nrows, ncols = 100000, 100 rng = np.random.RandomState(42) df1, df2, df..."
          ],
          [
           "Out[9]:\n\nTrue\n\nOperations supported by pd.eval()¶As of Pandas v0.16, pd.eval() supports a wide range..."
          ],
          [
           "Out[12]:\n\nTrue\n\nBitwise operators¶pd.eval() supports the & and | bitwise operators:\n\nIn [13]:\n\nresul..."
          ],
          [
           "Out[15]:\n\nTrue\n\nOther operations¶Other operations such as function calls, conditional statements, lo..."
          ],
          [
           "0.808055\n\n0.347197\n\n4\n\n0.589161\n\n0.252418\n\n0.557789\n\nUsing pd.eval() as above, we can compute expres..."
          ],
          [
           "In [19]:\n\ndf.head()\n\nOut[19]:\n\nA\n\nB\n\nC\n\n0\n\n0.375506\n\n0.406939\n\n0.069938\n\n1\n\n0.069087\n\n0.235615\n\n0.15..."
          ],
          [
           "11.187620\n\n1\n\n0.069087\n\n0.235615\n\n0.154374\n\n1.973796\n\n2\n\n0.677945\n\n0.433839\n\n0.652324\n\n1.704344\n\n3\n\n..."
          ],
          [
           "0.154374\n\n1.078728\n\n2\n\n0.677945\n\n0.433839\n\n0.652324\n\n0.374209\n\n3\n\n0.264038\n\n0.808055\n\n0.347197\n\n1.56..."
          ],
          [
           "DataFrame.query() Method¶The DataFrame has another method based on evaluated strings, called the que..."
          ],
          [
           "In [25]:\n\nCmean = df['C'].mean() result1 = df[(df.A < Cmean) & (df.B < Cmean)] result2 = df.query('A..."
          ],
          [
           "In [28]:\n\ndf.values.nbytes\n\nOut[28]:\n\n32000\n\nOn the performance side, eval() can be faster even when..."
          ],
          [
           "Further Resources\n\n< High-Performance Pandas: eval() and query() | Contents | Visualization with Mat..."
          ],
          [
           "Pandas on PyVideo: From PyCon to SciPy to PyData, many conferences have featured tutorials from Pand..."
          ],
          [
           "Visualization with Matplotlib\n\n< Further Resources | Contents | Simple Line Plots >\n\nWe'll now take ..."
          ],
          [
           "In recent years, however, the interface and style of Matplotlib have begun to show their age. Newer ..."
          ],
          [
           "In [1]:\n\nimport matplotlib as mpl\n\nimport matplotlib.pyplot as plt\n\nThe plt interface is what we wil..."
          ],
          [
           "Plotting from a script¶If you are using Matplotlib from within a script, the function plt.show() is ..."
          ],
          [
           "Plotting from an IPython shell¶It can be very convenient to use Matplotlib interactively within an I..."
          ],
          [
           "For this book, we will generally opt for %matplotlib inline:\n\nIn [3]:\n\n%matplotlib inline\n\nAfter run..."
          ],
          [
           "r\n\n--r\n\n--  1 jakevdp  staff    16K Aug 11 10:59 my_figure.png\n\nTo confirm that it contains what we ..."
          ],
          [
           "Note that when saving your figure, it's not necessary to use plt.show() or related commands discusse..."
          ],
          [
           "It is important to note that this interface is stateful: it keeps track of the \"current\" figure and ..."
          ],
          [
           "For more simple plots, the choice of which style to use is largely a matter of preference, but the o..."
          ],
          [
           "2. Introduction to NumPy¶ Understanding Data Types in Python The Basics of NumPy Arrays Computation ..."
          ],
          [
           "Appendix: Figure Code¶\n\nSimple Line Plots | Python Data Science Handbook\n\nPython Data Science Handbo..."
          ],
          [
           "In [2]:\n\nfig = plt.figure()\n\nax = plt.axes()\n\nIn Matplotlib, the figure (an instance of the class pl..."
          ],
          [
           "In [5]:\n\nplt.plot(x, np.sin(x))\n\nplt.plot(x, np.cos(x));\n\nThat's all there is to plotting simple fun..."
          ],
          [
           "In [6]:\n\nplt.plot(x, np.sin(x - 0), color='blue')        # specify color by name plt.plot(x, np.sin(..."
          ],
          [
           "# For short, you can use the following codes: plt.plot(x, x + 4, linestyle='-')  # solid plt.plot(x,..."
          ],
          [
           "Adjusting the Plot: Axes Limits¶Matplotlib does a decent job of choosing default axes limits for you..."
          ],
          [
           "plt.axis([\n\n1, 11,\n\n1.5, 1.5]);\n\nThe plt.axis() method goes even beyond this, allowing you to do thi..."
          ],
          [
           "plt.xlabel(\"x\")\n\nplt.ylabel(\"sin(x)\");\n\nThe position, size, and style of these labels can be adjuste..."
          ],
          [
           "Aside: Matplotlib Gotchas¶While most plt functions translate directly to ax methods (such as plt.plo..."
          ],
          [
           "< Visualization with Matplotlib | Contents | Simple Scatter Plots >\n\nSimple Scatter Plots | Python D..."
          ],
          [
           "In [2]:\n\nx = np.linspace(0, 10, 30) y = np.sin(x)\n\nplt.plot(x, y, 'o', color='black');\n\nThe third ar..."
          ],
          [
           "In [4]:\n\nplt.plot(x, y, '\n\nok');\n\nAdditional keyword arguments to plt.plot specify a wide range of p..."
          ],
          [
           "In [6]:\n\nplt.scatter(x, y, marker='o');\n\nThe primary difference of plt.scatter from plt.plot is that..."
          ],
          [
           "In [8]:\n\nfrom sklearn.datasets import load_iris\n\niris = load_iris()\n\nfeatures = iris.data.T\n\nplt.sca..."
          ],
          [
           "plot Versus scatter: A Note on Efficiency¶Aside from the different features available in plt.plot an..."
          ],
          [
           "Visualizing Errors\n\n< Simple Scatter Plots | Contents | Density and Contour Plots >\n\nFor any scienti..."
          ],
          [
           "whitegrid')\n\nimport numpy as np\n\nIn [2]:\n\nx = np.linspace(0, 10, 50) dy = 0.8 y = np.sin(x) + dy * n..."
          ],
          [
           "Continuous Errors¶In some situations it is desirable to show errorbars on continuous quantities. Tho..."
          ],
          [
           "xfit = np.linspace(0, 10, 1000) yfit, MSE = gp.predict(xfit[:, np.newaxis], eval_MSE=True) dyfit = 2..."
          ],
          [
           "color='gray', alpha=0.2)\n\nplt.xlim(0, 10);\n\nNote what we've done here with the fill_between function..."
          ],
          [
           "Density and Contour Plots\n\n< Visualizing Errors | Contents | Histograms, Binnings, and Density >\n\nSo..."
          ],
          [
           "A contour plot can be created with the plt.contour function. It takes three arguments: a grid of x v..."
          ],
          [
           "In [5]:\n\nplt.contour(X, Y, Z, 20, cmap='RdGy');\n\nHere we chose the RdGy (short for Red-Gray) colorma..."
          ],
          [
           "plt.contourf(X, Y, Z, 20, cmap='RdGy') plt.colorbar();\n\nThe colorbar makes it clear that the black r..."
          ],
          [
           "There are a few potential gotchas with imshow(), however:\n\nplt.imshow() doesn't accept an x and y gr..."
          ],
          [
           "The combination of these three functions—plt.contour, plt.contourf, and plt.imshow—gives nearly limi..."
          ],
          [
           "In [1]:\n\n%matplotlib inline\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('sea..."
          ],
          [
           "plt.hist(x1, *\n\nkwargs)\n\nplt.hist(x2, *\n\nkwargs)\n\nplt.hist(x3, *\n\nkwargs);\n\nIf you would like to sim..."
          ],
          [
           "In [12]:\n\nplt.hist2d(x, y, bins=30, cmap='Blues')\n\ncb = plt.colorbar()\n\ncb.set_label('counts in bin'..."
          ],
          [
           "plt.hexbin has a number of interesting options, including the ability to specify weights for each po..."
          ],
          [
           "# Plot the result as an image plt.imshow(Z.reshape(Xgrid.shape), origin='lower', aspect='auto', exte..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "But there are many ways we might want to customize such a legend. For example, we can specify the lo..."
          ],
          [
           "In [7]:\n\ny = np.sin(x[:, np.newaxis] + np.pi * np.arange(0, 2, 0.5)) lines = plt.plot(x, y)\n\n# lines..."
          ],
          [
           "In [9]:\n\nimport pandas as pd\n\ncities = pd.read_csv('data/california_cities.csv')\n\n# Extract the data..."
          ],
          [
           "plt.title('California Cities: Area and Population');\n\nThe legend will always reference some object t..."
          ],
          [
           "In [10]:\n\nfig, ax = plt.subplots()\n\nlines = [] styles = ['-', '--', '-. ', ':'] x = np.linspace(0, 1..."
          ],
          [
           "< Histograms, Binnings, and Density | Contents | Customizing Colorbars >\n\nCustomizing Colorbars | Py..."
          ],
          [
           "In [2]:\n\n%matplotlib inline\n\nimport numpy as np\n\nAs we have seen several times throughout this secti..."
          ],
          [
           "Choosing the Colormap¶A full treatment of color choice within visualization is beyond the scope of t..."
          ],
          [
           "# convert RGBA to perceived grayscale luminance # cf. http://alienryderflex.com/hsp.html RGB_weight ..."
          ],
          [
           "In [6]:\n\nview_colormap('jet')\n\nNotice the bright stripes in the grayscale image. Even in full color,..."
          ],
          [
           "In [9]:\n\nview_colormap('RdBu')\n\nWe'll see examples of using some of these color maps as we continue...."
          ],
          [
           "plt.imshow(I, cmap='RdBu')\n\nplt.colorbar()\n\nplt.subplot(1, 2, 2)\n\nplt.imshow(I, cmap='RdBu')\n\nplt.co..."
          ],
          [
           "1, 1);\n\nThe discrete version of a colormap can be used just like any other colormap.\n\nExample: Handw..."
          ],
          [
           "Because each digit is defined by the hue of its 64 pixels, we can consider each digit to be a point ..."
          ],
          [
           "The projection also gives us some interesting insights on the relationships within the dataset: for ..."
          ],
          [
           "In [1]:\n\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn\n\nwhite')\n\nimpor..."
          ],
          [
           "In [3]:\n\nfig = plt.figure() ax1 = fig.add_axes([0.1, 0.5, 0.8, 0.4], xticklabels=[], ylim=(-1.2, 1.2..."
          ],
          [
           "In [4]:\n\nfor i in range(1, 7): plt.subplot(2, 3, i) plt.text(0.5, 0.5, str((2, 3, i)), fontsize=18, ..."
          ],
          [
           "plt.subplots: The Whole Grid in One Go¶The approach just described can become quite tedious when cre..."
          ],
          [
           "In [7]:\n\n# axes are in a two-dimensional array, indexed by [row, col] for i in range(2): for j in ra..."
          ],
          [
           "plt.subplot(grid[0, 1:])\n\nplt.subplot(grid[1, :2])\n\nplt.subplot(grid[1, 2]);\n\nThis type of flexible ..."
          ],
          [
           "# scatter points on the main axes main_ax.plot(x, y, 'ok', markersize=3, alpha=0.2)\n\n# histogram on ..."
          ],
          [
           "Text and Annotation\n\n< Multiple Subplots | Contents | Customizing Ticks >\n\nCreating a good visualiza..."
          ],
          [
           "In [2]:\n\nbirths = pd.read_csv('data/births.csv')\n\nquartiles = np.percentile(births['births'], [25, 5..."
          ],
          [
           "In [4]:\n\nfig, ax = plt.subplots(figsize=(12, 4)) births_by_date.plot(ax=ax)\n\n# Add labels to the plo..."
          ],
          [
           "# Label the axes ax.set(title='USA births by day of year (1969-1988)', ylabel='average daily births'..."
          ],
          [
           "Transforms and Text Position¶In the previous example, we have anchored our text annotations to data ..."
          ],
          [
           "ax.axis([0, 10, 0, 10])\n\n# transform=ax.transData is the default, but we'll specify it anyway ax.tex..."
          ],
          [
           "ax.set_ylim(\n\n6, 6)\n\nfig\n\nOut[6]:\n\nThis behavior can be seen more clearly by changing the axes limit..."
          ],
          [
           "ax.annotate('local minimum', xy=(5\n\nnp.pi,\n\n1), xytext=(2,\n\n6),\n\narrowprops=dict(arrowstyle=\"\n\n>\",\n\n..."
          ],
          [
           "7\n\n4', 4250),  xycoords='data',\n\nbbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\"),\n\nxytext=(10,\n\n40..."
          ],
          [
           "31', 4600),  xycoords='data',\n\nxytext=(\n\n80,\n\n40), textcoords='offset points',\n\narrowprops=dict(arro..."
          ],
          [
           "30, 0), textcoords='offset points',\n\nsize=13, ha='right', va=\"center\",\n\nbbox=dict(boxstyle=\"round\", ..."
          ],
          [
           "ax.set_ylim(3600, 5400);\n\nYou'll notice that the specifications of the arrows and text boxes are ver..."
          ],
          [
           "Customizing Ticks\n\n< Text and Annotation | Contents | Customizing Matplotlib: Configurations and Sty..."
          ],
          [
           "plt.style.use('classic')\n\n%matplotlib inline\n\nimport numpy as np\n\nIn [2]:\n\nax = plt.axes(xscale='log..."
          ],
          [
           "<matplotlib.ticker.NullFormatter object at 0x10db9af60>\n\nWe see that both major and minor tick label..."
          ],
          [
           "In [6]:\n\nfig, ax = plt.subplots(5, 5, figsize=(5, 5)) fig.subplots_adjust(hspace=0, wspace=0)\n\n# Get..."
          ],
          [
           "In [7]:\n\nfig, ax = plt.subplots(4, 4, sharex=True, sharey=True)\n\nParticularly for the x ticks, the n..."
          ],
          [
           "In [9]:\n\n# Plot a sine and cosine curve fig, ax = plt.subplots() x = np.linspace(0, 3 * np.pi, 1000)..."
          ],
          [
           "fig\n\nOut[10]:\n\nBut now these tick labels look a little bit silly: we can see that they are multiples..."
          ],
          [
           "fig\n\nOut[11]:\n\nThis is much better! Notice that we've made use of Matplotlib's LaTeX support, specif..."
          ],
          [
           "AutoLocator (Default.) MaxNLocator with simple defaults.\n\nAutoMinorLocator\n\nLocator for minor ticks\n..."
          ],
          [
           "Customizing Matplotlib: Configurations and Stylesheets\n\n< Customizing Ticks | Contents | Three-Dimen..."
          ],
          [
           "# use a gray background ax = plt.axes(axisbg='#E6E6E6') ax.set_axisbelow(True)\n\n# draw solid white g..."
          ],
          [
           "Changing the Defaults: rcParams¶Each time Matplotlib loads, it defines a runtime configuration (rc) ..."
          ],
          [
           "plt.rc('ytick', direction='out', color='gray')\n\nplt.rc('patch', edgecolor='#E6E6E6')\n\nplt.rc('lines'..."
          ],
          [
           "Stylesheets¶The version 1.4 release of Matplotlib in August 2014 added a very convenient style modul..."
          ],
          [
           "Let's create a function that will make two basic types of plot:\n\nIn [9]:\n\ndef hist_and_lines(): np.r..."
          ],
          [
           "with plt.style.context('fivethirtyeight'):\n\nhist_and_lines()\n\nggplot¶The ggplot package in the R lan..."
          ],
          [
           "In [16]:\n\nwith plt.style.context('grayscale'):\n\nhist_and_lines()\n\nSeaborn style¶Matplotlib also has ..."
          ],
          [
           "Dimensional Plotting in Matplotlib\n\n< Customizing Matplotlib: Configurations and Stylesheets | Conte..."
          ],
          [
           "Three-dimensional Points and Lines¶The most basic three-dimensional plot is a line or collection of ..."
          ],
          [
           "Notice that by default, the scatter points have their transparency adjusted to give a sense of depth..."
          ],
          [
           "Sometimes the default viewing angle is not optimal, in which case we can use the view_init method to..."
          ],
          [
           "In [9]:\n\nax = plt.axes(projection='3d') ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='viridis..."
          ],
          [
           "In [11]:\n\ntheta = 2\n\nnp.pi\n\nnp.random.random(1000)\n\nr = 6\n\nnp.random.random(1000)\n\nx = np.ravel(r\n\nn..."
          ],
          [
           "ax.plot_trisurf(x, y, z,\n\ncmap='viridis', edgecolor='none');\n\nThe result is certainly not as clean a..."
          ],
          [
           "Now from this parametrization, we must determine the (x, y, z) positions of the embedded strip. Thin..."
          ],
          [
           "In [17]:\n\n# triangulate in the underlying parametrization from matplotlib.tri import Triangulation t..."
          ],
          [
           "Geographic Data with Basemap\n\n< Three-Dimensional Plotting in Matplotlib | Contents | Visualization ..."
          ],
          [
           "In [2]:\n\nplt.figure(figsize=(8, 8)) m = Basemap(projection='ortho', resolution=None, lat_0=50, lon_0..."
          ],
          [
           "This gives you a brief glimpse into the sort of geographic visualizations that are possible with jus..."
          ],
          [
           "# keys contain the plt.Line2D instances lat_lines = chain(*(tup[1][0] for tup in lats.items())) lon_..."
          ],
          [
           "The additional arguments to Basemap for this view specify the latitude (lat) and longitude (lon) of ..."
          ],
          [
           "The extra arguments to Basemap here refer to the central latitude (lat_0) and longitude (lon_0) for ..."
          ],
          [
           "lat_0=50, lon_0=0)\n\ndraw_map(m);\n\nConic projections¶A Conic projection projects the map onto a singl..."
          ],
          [
           "width=1.6E7, height=1.2E7)\n\ndraw_map(m)\n\nOther projections¶If you're going to do much with map-based..."
          ],
          [
           "Political boundaries\n\ndrawcountries(): Draw country boundaries drawstates(): Draw US state boundarie..."
          ],
          [
           "In [9]:\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 8))\n\nfor i, res in enumerate(['l', 'h']): m = Bas..."
          ],
          [
           "Plotting Data on Maps¶Perhaps the most useful piece of the Basemap toolkit is the ability to over-pl..."
          ],
          [
           "We'll see some examples of a few of these as we continue. For more information on these functions, i..."
          ],
          [
           "# 2. scatter city data, with color reflecting population # and size reflecting area m.scatter(lon, l..."
          ],
          [
           "In [12]:\n\n# !curl\n\nO http://data.giss.nasa.gov/pub/gistemp/gistemp250.nc.gz\n\n# !gunzip gistemp250.nc..."
          ],
          [
           "Finally, we'll use the pcolormesh() method to draw a color mesh of the data. We'll look at North Ame..."
          ],
          [
           "< Three-Dimensional Plotting in Matplotlib | Contents | Visualization with Seaborn >\n\nVisualization ..."
          ],
          [
           "An answer to these problems is Seaborn. Seaborn provides an API on top of Matplotlib that offers san..."
          ],
          [
           "And do a simple plot:\n\nIn [3]:\n\n# Plot the data with Matplotlib defaults plt.plot(x, y) plt.legend('..."
          ],
          [
           "Ah, much better!\n\nExploring Seaborn Plots¶The main idea of Seaborn is that it provides high-level co..."
          ],
          [
           "Histograms and KDE can be combined using distplot:\n\nIn [8]:\n\nsns.distplot(data['x'])\n\nsns.distplot(d..."
          ],
          [
           "sns.jointplot(\"x\", \"y\", data, kind='hex')\n\nPair plots¶When you generalize joint plots to datasets of..."
          ],
          [
           "setosa\n\n4\n\n5.0\n\n3.6\n\n1.4\n\n0.2\n\nsetosa\n\nVisualizing the multidimensional relationships among the samp..."
          ],
          [
           "2\n\n21.01\n\n3.50\n\nMale\n\nNo\n\nSun\n\nDinner\n\n3\n\n3\n\n23.68\n\n3.31\n\nMale\n\nNo\n\nSun\n\nDinner\n\n2\n\n4\n\n24.59\n\n3.61\n\n..."
          ],
          [
           "Joint distributions¶Similar to the pairplot we saw earlier, we can use sns.jointplot to show the joi..."
          ],
          [
           "2.21\n\n56.95\n\n2008\n\n2\n\nRadial Velocity\n\n1\n\n763.000\n\n2.60\n\n19.84\n\n2011\n\n3\n\nRadial Velocity\n\n1\n\n326.030..."
          ],
          [
           "For more information on plotting with Seaborn, see the Seaborn documentation, a tutorial, and the Se..."
          ],
          [
           "M\n\n01:06:49\n\n02:10:42\n\n3\n\n38\n\nM\n\n01:06:16\n\n02:13:45\n\n4\n\n31\n\nM\n\n01:06:32\n\n02:13:59\n\nBy default, Panda..."
          ],
          [
           "33\n\nM\n\n01:05:38\n\n02:08:51\n\n1\n\n32\n\nM\n\n01:06:26\n\n02:09:28\n\n2\n\n31\n\nM\n\n01:06:49\n\n02:10:42\n\n3\n\n38\n\nM\n\n01:..."
          ],
          [
           "split_sec\n\nfinal_sec\n\n0\n\n33\n\nM\n\n01:05:38\n\n02:08:51\n\n3938.0\n\n7731.0\n\n1\n\n32\n\nM\n\n01:06:26\n\n02:09:28\n\n39..."
          ],
          [
           "The dotted line shows where someone's time would lie if they ran the marathon at a perfectly steady ..."
          ],
          [
           "0.026262\n\n2\n\n31\n\nM\n\n01:06:49\n\n02:10:42\n\n4009.0\n\n7842.0\n\n0.022443\n\n3\n\n38\n\nM\n\n01:06:16\n\n02:13:45\n\n3976..."
          ],
          [
           "In [31]:\n\nsum(data.split_frac < 0)\n\nOut[31]:\n\n251\n\nOut of nearly 40,000 participants, there were onl..."
          ],
          [
           "sns.kdeplot(data.split_frac[data.gender=='M'], label='men', shade=True)\n\nsns.kdeplot(data.split_frac..."
          ],
          [
           "age\n\ngender\n\nsplit\n\nfinal\n\nsplit_sec\n\nfinal_sec\n\nsplit_frac\n\nage_dec\n\n0\n\n33\n\nM\n\n01:05:38\n\n02:08:51\n\n..."
          ],
          [
           "8039.0\n\n0.006842\n\n30\n\nIn [36]:\n\nmen = (data.gender == 'M') women = (data.gender == 'W')\n\nwith sns.ax..."
          ],
          [
           "In [37]:\n\ng = sns.lmplot('final_sec', 'split_frac', col='gender', data=data, markers=\". \", scatter_k..."
          ],
          [
           "Further Resources\n\n< Visualization with Seaborn | Contents | Machine Learning >\n\nMatplotlib Resource..."
          ],
          [
           "Bokeh is a JavaScript visualization library with a Python frontend that creates highly interactive v..."
          ],
          [
           "Machine Learning | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAbout\n\nArchive\n\nThis ..."
          ],
          [
           "Machine Learning\n\n< Further Resources | Contents | What Is Machine Learning? >\n\nIn many ways, machin..."
          ],
          [
           "Much of this material is drawn from the Scikit-Learn tutorials and workshops I have given on several..."
          ],
          [
           "2. Introduction to NumPy¶ Understanding Data Types in Python The Basics of NumPy Arrays Computation ..."
          ],
          [
           "Appendix: Figure Code¶\n\nWhat Is Machine Learning? | Python Data Science Handbook\n\nPython Data Scienc..."
          ],
          [
           "What Is Machine Learning?\n\n< Machine Learning | Contents | Introducing Scikit-Learn >\n\nBefore we tak..."
          ],
          [
           "Categories of Machine Learning¶At the most fundamental level, machine learning can be categorized in..."
          ],
          [
           "Classification: Predicting discrete labels¶We will first take a look at a simple classification task..."
          ],
          [
           "figure source in Appendix\n\nNow that this model has been trained, it can be generalized to new, unlab..."
          ],
          [
           "For the training set, these labels might be determined by individual inspection of a small represent..."
          ],
          [
           "figure source in Appendix\n\nNotice that the feature 1-feature 2 plane here is the same as in the two-..."
          ],
          [
           "The distances for a small number of these galaxies might be determined through an independent set of..."
          ],
          [
           "figure source in Appendix\n\nk-means fits a model consisting of k cluster centers; the optimal centers..."
          ],
          [
           "figure source in Appendix\n\nVisually, it is clear that there is some structure in this data: it is dr..."
          ],
          [
           "Summary¶Here we have seen a few simple examples of some of the basic types of machine learning appro..."
          ],
          [
           "Introducing Scikit\n\nLearn\n\n< What Is Machine Learning? | Contents | Hyperparameters and Model Valida..."
          ],
          [
           "In [1]:\n\nimport seaborn as sns\n\niris = sns.load_dataset('iris')\n\niris.head()\n\nOut[1]:\n\nsepal_length\n..."
          ],
          [
           "4\n\n5.0\n\n3.6\n\n1.4\n\n0.2\n\nsetosa\n\nHere each row of the data refers to a single observed flower, and the..."
          ],
          [
           "Target array¶In addition to the feature matrix X, we also generally work with a label or target arra..."
          ],
          [
           "In [3]:\n\nX_iris = iris.drop('species', axis=1)\n\nX_iris.shape\n\nOut[3]:\n\n(150, 4)\n\nIn [4]:\n\ny_iris = i..."
          ],
          [
           "Sensible defaults: When models require user-specified parameters, the library defines an appropriate..."
          ],
          [
           "In [5]:\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\nrng = np.random.RandomState(42)\n\nx = 1..."
          ],
          [
           "Would we like to fit for the offset (i.e., y-intercept)? Would we like the model to be normalized? W..."
          ],
          [
           "3. Arrange data into a features matrix and target vector¶Previously we detailed the Scikit-Learn dat..."
          ],
          [
           "model.coef_\n\nOut[10]:\n\narray([ 1.9776566])\n\nIn [11]:\n\nmodel.intercept_\n\nOut[11]:\n\n0.9033107255311163..."
          ],
          [
           "In [13]:\n\nXfit = xfit[:, np.newaxis]\n\nyfit = model.predict(Xfit)\n\nFinally, let's visualize the resul..."
          ],
          [
           "In [15]:\n\nfrom sklearn.cross_validation import train_test_split Xtrain, Xtest, ytrain, ytest = train..."
          ],
          [
           "With an accuracy topping 97%, we see that even this very naive classification algorithm is effective..."
          ],
          [
           "In [19]:\n\niris['PCA1'] = X_2D[:, 0] iris['PCA2'] = X_2D[:, 1] sns.lmplot(\"PCA1\", \"PCA2\", hue='specie..."
          ],
          [
           "As before, we will add the cluster label to the Iris DataFrame and use Seaborn to plot the results:\n..."
          ],
          [
           "In [22]:\n\nfrom sklearn.datasets import load_digits\n\ndigits = load_digits()\n\ndigits.images.shape\n\nOut..."
          ],
          [
           "In order to work with this data within Scikit-Learn, we need a two-dimensional, [n_samples, n_featur..."
          ],
          [
           "iso = Isomap(n_components=2)\n\niso.fit(digits.data)\n\ndata_projected = iso.transform(digits.data)\n\ndat..."
          ],
          [
           "This plot gives us some good intuition into how well various numbers are separated in the larger 64-..."
          ],
          [
           "In [30]:\n\nfrom sklearn.metrics import accuracy_score\n\naccuracy_score(ytest, y_model)\n\nOut[30]:\n\n0.83..."
          ],
          [
           "In [32]:\n\nfig, axes = plt.subplots(10, 10, figsize=(8, 8), subplot_kw={'xticks':[], 'yticks':[]}, gr..."
          ],
          [
           "Summary¶\n\nIn this section we have covered the essential features of the Scikit-Learn data representa..."
          ],
          [
           "Choose a class of model Choose model hyperparameters Fit the model to the training data Use the mode..."
          ],
          [
           "In [2]:\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nmodel = KNeighborsClassifier(n_neighbor..."
          ],
          [
           "Model validation the right way: Holdout sets¶So what can be done? A better sense of a model's perfor..."
          ],
          [
           "Model validation via cross-validation¶One disadvantage of using a holdout set for model validation i..."
          ],
          [
           "(0.95999999999999996, 0.90666666666666662)\n\nWhat comes out are two accuracy scores, which we could c..."
          ],
          [
           "Repeating the validation across different subsets of the data gives us an even better idea of the pe..."
          ],
          [
           "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  1.,  1.,  1.,  1.,..."
          ],
          [
           "1.,  1.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 1...."
          ],
          [
           "1., 1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  1.,  1.,  1.,  0.,  1...."
          ],
          [
           "1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1..."
          ],
          [
           "1.,  1., 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  1.,  1.,  1.,  1...."
          ],
          [
           "Because we have 150 samples, the leave one out cross-validation yields scores for 150 trials, and th..."
          ],
          [
           "The Bias-variance trade-off¶Fundamentally, the question of \"the best model\" is about finding a sweet..."
          ],
          [
           "figure source in Appendix The score here is the $R^2$ score, or coefficient of determination, which ..."
          ],
          [
           "The means of tuning the model complexity varies from model to model; when we discuss individual mode..."
          ],
          [
           "LinearRegression(*\n\nkwargs))\n\nNow let's create some data to which we will fit our model:\n\nIn [11]:\n\n..."
          ],
          [
           "X_test = np.linspace(\n\n0.1, 1.1, 500)[:, None]\n\nplt.scatter(X.ravel(), y, color='black') axis = plt...."
          ],
          [
           "plt.plot(degree, np.median(train_score, 1), color='blue', label='training score') plt.plot(degree, n..."
          ],
          [
           "Learning Curves¶One important aspect of model complexity is that the optimal model will generally de..."
          ],
          [
           "The solid lines show the new results, while the fainter dashed lines show the results of the previou..."
          ],
          [
           "With these features in mind, we would expect a learning curve to look qualitatively like that shown ..."
          ],
          [
           "ax[i].plot(N, np.mean(train_lc, 1), color='blue', label='training score') ax[i].plot(N, np.mean(val_..."
          ],
          [
           "ax[i].legend(loc='best')\n\nThis is a valuable diagnostic, because it gives us a visual depiction of h..."
          ],
          [
           "Validation in Practice: Grid Search¶The preceding discussion is meant to give you some intuition int..."
          ],
          [
           "In [19]:\n\ngrid.fit(X, y);\n\nNow that this is fit, we can ask for the best parameters as follows:\n\nIn ..."
          ],
          [
           "Summary¶In this section, we have begun to explore the concept of model validation and hyperparameter..."
          ],
          [
           "Feature Engineering\n\n< Hyperparameters and Model Validation | Contents | In Depth: Naive Bayes Class..."
          ],
          [
           "You might be tempted to encode this data with a straightforward numerical mapping:\n\nIn [2]:\n\n{'Queen..."
          ],
          [
           "Notice that the 'neighborhood' column has been expanded into three separate columns, representing th..."
          ],
          [
           "Text Features¶Another common need in feature engineering is to convert text to a set of representati..."
          ],
          [
           "In [8]:\n\nimport pandas as pd\n\npd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n\nOut[8]:\n\ne..."
          ],
          [
           "Out[9]:\n\nevil\n\nhorizon\n\nof\n\nproblem\n\nqueen\n\n0\n\n0.517856\n\n0.000000\n\n0.680919\n\n0.517856\n\n0.000000\n\n1\n\n..."
          ],
          [
           "Derived Features¶Another useful type of feature is one that is mathematically derived from some inpu..."
          ],
          [
           "plt.scatter(x, y)\n\nplt.plot(x, yfit);\n\nIt's clear that we need a more sophisticated model to describ..."
          ],
          [
           "plt.scatter(x, y)\n\nplt.plot(x, yfit);\n\nThis idea of improving a model not by changing the model, but..."
          ],
          [
           "When applying a typical machine learning model to such data, we will need to first replace such miss..."
          ],
          [
           "model = LinearRegression().fit(X2, y)\n\nmodel.predict(X2)\n\nOut[16]:\n\narray([ 13.14869292,  14.3784627..."
          ],
          [
           "1  8\n\n5]\n\n[ 14. 16.\n\n1. 8.\n\n5.]\n\nAll the steps of the model are applied automatically. Notice that f..."
          ],
          [
           "In Depth: Naive Bayes Classification\n\n< Feature Engineering | Contents | In Depth: Linear Regression..."
          ],
          [
           "Bayesian Classification¶Naive Bayes classifiers are built on Bayesian classification methods. These ..."
          ],
          [
           "quantities we can compute more directly: $$ P(L~|~{\\rm features}) = \\frac{P({\\rm features}~|~L)P(L)}..."
          ],
          [
           "= \\frac{P({\\rm features}~|~L_1)}{P({\\rm features}~|~L_2)}\\frac{P(L_1)}{P(L_2)} $$ All we need now is..."
          ],
          [
           "of such a Bayesian classifier. The general version of such a training step is a very difficult task,..."
          ],
          [
           "This is where the \"naive\" in \"naive Bayes\" comes in: if we make very naive assumptions about the gen..."
          ],
          [
           "figure source in Appendix\n\nThe ellipses here represent the Gaussian generative model for each label,..."
          ],
          [
           "Now we can plot this new data to get an idea of where the decision boundary is:\n\nIn [5]:\n\nplt.scatte..."
          ],
          [
           "The columns give the posterior probabilities of the first and second label, respectively. If you are..."
          ],
          [
           "In [7]:\n\nfrom sklearn.datasets import fetch_20newsgroups\n\ndata = fetch_20newsgroups()\n\ndata.target_n..."
          ],
          [
           "In [8]:\n\ncategories = ['talk.religion.misc', 'soc.religion.christian',\n\n'sci.space', 'comp.graphics'..."
          ],
          [
           "In [10]:\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.naive_bayes impo..."
          ],
          [
           "Evidently, even this very simple classifier can successfully separate space talk from computer talk,..."
          ],
          [
           "When to Use Naive Bayes¶Because naive Bayesian classifiers make such stringent assumptions about dat..."
          ],
          [
           "< Feature Engineering | Contents | In Depth: Linear Regression >\n\nIn Depth: Linear Regression | Pyth..."
          ],
          [
           "Simple Linear Regression¶We will start with the most familiar linear regression, a straight-line fit..."
          ],
          [
           "plt.scatter(x, y)\n\nplt.plot(xfit, yfit);\n\nThe slope and intercept of the data are contained in the m..."
          ],
          [
           "In [5]:\n\nrng = np.random.RandomState(1) X = 10 * rng.rand(100, 3) y = 0.5 + np.dot(X, [1.5, -2., 1.]..."
          ],
          [
           "Basis Function Regression¶One trick you can use to adapt linear regression to nonlinear relationship..."
          ],
          [
           "In [6]:\n\nfrom sklearn.preprocessing import PolynomialFeatures x = np.array([2, 3, 4]) poly = Polynom..."
          ],
          [
           "poly_model.fit(x[:, np.newaxis], y)\n\nyfit = poly_model.predict(xfit[:, np.newaxis])\n\nplt.scatter(x, ..."
          ],
          [
           "def __init__(self, N, width_factor=2.0):\n\nself.N = N\n\nself.width_factor = width_factor\n\n@staticmetho..."
          ],
          [
           "plt.plot(xfit, yfit)\n\nplt.xlim(0, 10);\n\nWe put this example here just to make clear that there is no..."
          ],
          [
           "In [11]:\n\ndef basis_plot(model, title=None): fig, ax = plt.subplots(2, sharex=True) model.fit(x[:, n..."
          ],
          [
           "Ridge regression ($L_2$ Regularization)¶Perhaps the most common form of regularization is known as r..."
          ],
          [
           "Lasso regression ($L_1$ regularization)¶Another very common type of regularization is known as lasso..."
          ],
          [
           "Example: Predicting Bicycle Traffic¶\n\nAs an example, let's take a look at whether we can predict the..."
          ],
          [
           "xm6k/rows.csv?accessType=DOWNLOAD\n\nIn [15]:\n\nimport pandas as pd counts = pd.read_csv('FremontBridge..."
          ],
          [
           "Similarly, we might expect riders to behave differently on holidays; let's add an indicator of this ..."
          ],
          [
           "plt.ylim(8, 17)\n\nOut[19]:\n\n(8, 17)\n\nWe can also add the average temperature and total precipitation ..."
          ],
          [
           "In [22]:\n\ndaily.head()\n\nOut[22]:\n\nTotal\n\nMon\n\nTue\n\nWed\n\nThu\n\nFri\n\nSat\n\nSun\n\nholiday\n\ndaylight_hrs\n\nP..."
          ],
          [
           "0.002740\n\n2012\n\n10\n\n05\n\n3148.0\n\n0.0\n\n0.0\n\n0.0\n\n0.0\n\n1.0\n\n0.0\n\n0.0\n\n0.0\n\n11.161038\n\n0.0\n\n15.30\n\n1.0\n\n..."
          ],
          [
           "0.0\n\n15.85\n\n1.0\n\n0.010959\n\nWith this in place, we can choose the columns to use, and fit a linear re..."
          ],
          [
           "In [24]:\n\ndaily[['Total', 'predicted']].plot(alpha=0.5);\n\nIt is evident that we have missed some key..."
          ],
          [
           "In [26]:\n\nfrom sklearn.utils import resample np.random.seed(1) err = np.std([model.fit(*resample(X, ..."
          ],
          [
           "We first see that there is a relatively stable trend in the weekly baseline: there are many more rid..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "# use seaborn plotting defaults import seaborn as sns; sns.set()\n\nMotivating Support Vector Machines..."
          ],
          [
           "In [3]:\n\nxfit = np.linspace(-1, 3.5) plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn') plt.plo..."
          ],
          [
           "In [4]:\n\nxfit = np.linspace(-1, 3.5) plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n\nfor m,..."
          ],
          [
           "In [5]:\n\nfrom sklearn.svm import SVC # \"Support vector classifier\" model = SVC(kernel='linear', C=1E..."
          ],
          [
           "# create grid to evaluate model x = np.linspace(xlim[0], xlim[1], 30) y = np.linspace(ylim[0], ylim[..."
          ],
          [
           "This is the dividing line that maximizes the margin between the two sets of points. Notice that a fe..."
          ],
          [
           "In [9]:\n\ndef plot_svm(N=10, ax=None): X, y = make_blobs(n_samples=200, centers=2, random_state=0, cl..."
          ],
          [
           "If you are running this notebook live, you can use IPython's interactive widgets to view this featur..."
          ],
          [
           "It is clear that no linear discrimination will ever be able to separate this data. But we can draw a..."
          ],
          [
           "180, 180),\n\nX=fixed(X), y=fixed(y));\n\nWe can see that with this additional dimension, the data becom..."
          ],
          [
           "clf = SVC(kernel='rbf', C=1E6)\n\nclf.fit(X, y)\n\nOut[14]:\n\nSVC(C=1000000.0, cache_size=200, class_weig..."
          ],
          [
           "In [16]:\n\nX, y = make_blobs(n_samples=100, centers=2, random_state=0, cluster_std=1.2) plt.scatter(X..."
          ],
          [
           "for axi, C in zip(ax, [10.0, 0.1]): model = SVC(kernel='linear', C=C).fit(X, y) axi.scatter(X[:, 0],..."
          ],
          [
           "print(faces.target_names)\n\nprint(faces.images.shape)\n\n['Ariel Sharon' 'Colin Powell' 'Donald Rumsfel..."
          ],
          [
           "from sklearn.decomposition import RandomizedPCA\n\nfrom sklearn.pipeline import make_pipeline\n\npca = R..."
          ],
          [
           "%time grid.fit(Xtrain, ytrain)\n\nprint(grid.best_params_)\n\nCPU times: user 47.8 s, sys: 4.08 s, total..."
          ],
          [
           "Out of this small sample, our optimal estimator mislabeled only a single face (Bush’s face in the bo..."
          ],
          [
           "We might also display the confusion matrix between these classes:\n\nIn [26]:\n\nfrom sklearn.metrics im..."
          ],
          [
           "Support Vector Machine Summary¶We have seen here a brief intuitive introduction to the principals be..."
          ],
          [
           "< In Depth: Linear Regression | Contents | In-Depth: Decision Trees and Random Forests >\n\nIn-Depth: ..."
          ],
          [
           "In [1]:\n\n%matplotlib inline import numpy as np import matplotlib.pyplot as plt import seaborn as sns..."
          ],
          [
           "In [2]:\n\nfrom sklearn.datasets import make_blobs\n\nX, y = make_blobs(n_samples=300, centers=4, random..."
          ],
          [
           "Let's write a quick utility function to help us visualize the output of the classifier:\n\nIn [4]:\n\nde..."
          ],
          [
           "Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n\n# Create a color plot with the r..."
          ],
          [
           "Notice that as the depth increases, we tend to get very strangely shaped classification regions; for..."
          ],
          [
           "In [7]:\n\n# helpers_05_08 is found in the online appendix import helpers_05_08 helpers_05_08.randomiz..."
          ],
          [
           "bag.fit(X, y)\n\nvisualize_classifier(bag, X, y)\n\nIn this example, we have randomized the data by fitt..."
          ],
          [
           "We see that by averaging over 100 randomly perturbed models, we end up with an overall model that is..."
          ],
          [
           "from sklearn.ensemble import RandomForestRegressor\n\nforest = RandomForestRegressor(200)\n\nforest.fit(..."
          ],
          [
           "dict_keys(['target', 'data', 'target_names', 'DESCR', 'images'])\n\nTo remind us what we're looking at..."
          ],
          [
           "We can take a look at the classification report for this classifier:\n\nIn [15]:\n\nfrom sklearn import ..."
          ],
          [
           "Both training and prediction are very fast, because of the simplicity of the underlying decision tre..."
          ],
          [
           "In Depth: Principal Component Analysis\n\n< In-Depth: Decision Trees and Random Forests | Contents | I..."
          ],
          [
           "In [2]:\n\nrng = np.random.RandomState(1) X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T plt.scatter(..."
          ],
          [
           "[[ 0.94446029  0.32862557]\n\n[ 0.32862557\n\n0.94446029]]\n\nIn [5]:\n\nprint(pca.explained_variance_)\n\n[ 0..."
          ],
          [
           "These vectors represent the principal axes of the data, and the length of the vector is an indicatio..."
          ],
          [
           "In [8]:\n\nX_new = pca.inverse_transform(X_pca) plt.scatter(X[:, 0], X[:, 1], alpha=0.2) plt.scatter(X..."
          ],
          [
           "digits = load_digits()\n\ndigits.data.shape\n\nOut[9]:\n\n(1797, 64)\n\nRecall that the data consists of 8×8..."
          ],
          [
           "plt.ylabel('component 2')\n\nplt.colorbar();\n\nRecall what these components mean: the full data is a 64..."
          ],
          [
           "What do the components mean?¶We can go a bit further here, and begin to ask what the reduced dimensi..."
          ],
          [
           "But the pixel-wise representation is not the only choice of basis. We can also use other basis funct..."
          ],
          [
           "In [12]:\n\npca = PCA().fit(digits.data)\n\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\n\nplt.xlab..."
          ],
          [
           "In [13]:\n\ndef plot_digits(data): fig, axes = plt.subplots(4, 10, figsize=(10, 4), subplot_kw={'xtick..."
          ],
          [
           "In [16]:\n\ncomponents = pca.transform(noisy)\n\nfiltered = pca.inverse_transform(components)\n\nplot_digi..."
          ],
          [
           "Let's take a look at the principal axes that span this dataset. Because this is a large dataset, we ..."
          ],
          [
           "In [19]:\n\nfig, axes = plt.subplots(3, 8, figsize=(9, 4), subplot_kw={'xticks':[], 'yticks':[]}, grid..."
          ],
          [
           "In [21]:\n\n# Compute the components and projected faces pca = RandomizedPCA(150).fit(faces.data) comp..."
          ],
          [
           "ax[1, 0].set_ylabel('150\n\ndim\\nreconstruction');\n\nThe top row here shows the input images, while the..."
          ],
          [
           "Principal Component Analysis Summary¶In this section we have discussed the use of principal componen..."
          ],
          [
           "< In-Depth: Decision Trees and Random Forests | Contents | In-Depth: Manifold Learning >\n\nIn-Depth: ..."
          ],
          [
           "In\n\nDepth: Manifold Learning\n\n< In Depth: Principal Component Analysis | Contents | In Depth: k-Mean..."
          ],
          [
           "Here we will demonstrate a number of manifold methods, going most deeply into a couple techniques: m..."
          ],
          [
           "# Open this PNG and draw random points from it from matplotlib.image import imread data = imread('he..."
          ],
          [
           "Multidimensional Scaling (MDS)¶Looking at data like this, we can see that the particular choice of x..."
          ],
          [
           "In [5]:\n\nfrom sklearn.metrics import pairwise_distances\n\nD = pairwise_distances(X)\n\nD.shape\n\nOut[5]:..."
          ],
          [
           "np.allclose(D, D2)\n\nOut[7]:\n\nTrue\n\nThis distance matrix gives us a representation of our data that i..."
          ],
          [
           "MDS as Manifold Learning¶The usefulness of this becomes more apparent when we consider the fact that..."
          ],
          [
           "We can now ask the MDS estimator to input this three-dimensional data, compute the distance matrix, ..."
          ],
          [
           "0.75\n\nnp.pi\n\nx = np.sin(t)\n\ny = X[:, 1]\n\nz = np.sign(t)\n\n(np.cos(t)\n\n1)\n\nreturn np.vstack((x, y, z))..."
          ],
          [
           "The best two-dimensional linear embeding does not unwrap the S-curve, but instead throws out the ori..."
          ],
          [
           "figure source in Appendix\n\nHere each faint line represents a distance that should be preserved in th..."
          ],
          [
           "fig, ax = plt.subplots() ax.scatter(out[:, 0], out[:, 1], **colorize) ax.set_ylim(0.15, -0.15);\n\nThe..."
          ],
          [
           "In manifold learning, there is no good framework for handling missing data. In contrast, there are s..."
          ],
          [
           "For toy problems such as the S-curve we saw before, locally linear embedding (LLE) and its variants ..."
          ],
          [
           "In [16]:\n\nfrom sklearn.datasets import fetch_lfw_people\n\nfaces = fetch_lfw_people(min_faces_per_pers..."
          ],
          [
           "plt.plot(np.cumsum(model.explained_variance_ratio_))\n\nplt.xlabel('n components')\n\nplt.ylabel('cumula..."
          ],
          [
           "proj = model.fit_transform(data) ax.plot(proj[:, 0], proj[:, 1], '.k')\n\nif images is not None: min_d..."
          ],
          [
           "The result is interesting: the first two Isomap dimensions seem to describe global image features: t..."
          ],
          [
           "In [23]:\n\nfig, ax = plt.subplots(6, 8, subplot_kw=dict(xticks=[], yticks=[])) for i, axi in enumerat..."
          ],
          [
           "The resulting scatter plot shows some of the relationships between the data points, but is a bit cro..."
          ],
          [
           "< In Depth: Principal Component Analysis | Contents | In Depth: k-Means Clustering >\n\nIn Depth: k-Me..."
          ],
          [
           "Introducing k\n\nMeans¶\n\nThe k-means algorithm searches for a pre-determined number of clusters within..."
          ],
          [
           "kmeans = KMeans(n_clusters=4)\n\nkmeans.fit(X)\n\ny_kmeans = kmeans.predict(X)\n\nLet's visualize the resu..."
          ],
          [
           "k\n\nMeans Algorithm: Expectation–Maximization¶\n\nExpectation–maximization (E–M) is a powerful algorith..."
          ],
          [
           "In [5]:\n\nfrom sklearn.metrics import pairwise_distances_argmin\n\ndef find_clusters(X, n_clusters, rse..."
          ],
          [
           "Caveats of expectation–maximization¶There are a few issues to be aware of when using the expectation..."
          ],
          [
           "Whether the result is meaningful is a question that is difficult to answer definitively; one approac..."
          ],
          [
           "This situation is reminiscent of the discussion in In-Depth: Support Vector Machines, where we used ..."
          ],
          [
           "We see that with this kernel transform approach, the kernelized k-means is able to find the more com..."
          ],
          [
           "In [11]:\n\nfrom sklearn.datasets import load_digits\n\ndigits = load_digits()\n\ndigits.data.shape\n\nOut[1..."
          ],
          [
           "We see that even without the labels, KMeans is able to find clusters whose centers are recognizable ..."
          ],
          [
           "In [16]:\n\nfrom sklearn.metrics import confusion_matrix mat = confusion_matrix(digits.target, labels)..."
          ],
          [
           "clusters = kmeans.fit_predict(digits_proj)\n\n# Permute the labels labels = np.zeros_like(clusters) fo..."
          ],
          [
           "The image itself is stored in a three-dimensional array of size (height, width, RGB), containing red..."
          ],
          [
           "fig, ax = plt.subplots(1, 2, figsize=(16, 6)) ax[0].scatter(R, G, color=colors, marker='.') ax[0].se..."
          ],
          [
           "kmeans = MiniBatchKMeans(16)\n\nkmeans.fit(data)\n\nnew_colors = kmeans.cluster_centers_[kmeans.predict(..."
          ],
          [
           "< In-Depth: Manifold Learning | Contents | In Depth: Gaussian Mixture Models >\n\nIn Depth: Gaussian M..."
          ],
          [
           "Motivating GMM: Weaknesses of k-Means¶Let's take a look at some of the weaknesses of k-means and thi..."
          ],
          [
           "From an intuitive standpoint, we might expect that the clustering assignment for some points is more..."
          ],
          [
           "# plot the representation of the KMeans model centers = kmeans.cluster_centers_ radii = [cdist(X[lab..."
          ],
          [
           "plot_kmeans(kmeans, X_stretched)\n\nBy eye, we recognize that these transformed clusters are non-circu..."
          ],
          [
           "In [7]:\n\nfrom sklearn.mixture import GMM gmm = GMM(n_components=4).fit(X) labels = gmm.predict(X) pl..."
          ],
          [
           "In [9]:\n\nsize = 50 * probs.max(1) ** 2  # square emphasizes differences plt.scatter(X[:, 0], X[:, 1]..."
          ],
          [
           "# Convert covariance to principal axes if covariance.shape == (2, 2): U, s, Vt = np.linalg.svd(covar..."
          ],
          [
           "With this in place, we can take a look at what the four-component GMM gives us for our initial data:..."
          ],
          [
           "This makes clear that GMM addresses the two main practical issues with k-means encountered before.\n\n..."
          ],
          [
           "In [13]:\n\nfrom sklearn.datasets import make_moons Xmoon, ymoon = make_moons(200, noise=.05, random_s..."
          ],
          [
           "In [16]:\n\nXnew = gmm16.sample(400, random_state=42)\n\nplt.scatter(Xnew[:, 0], Xnew[:, 1]);\n\nGMM is co..."
          ],
          [
           "plt.plot(n_components, [m.bic(Xmoon) for m in models], label='BIC') plt.plot(n_components, [m.aic(Xm..."
          ],
          [
           "digits = load_digits()\n\ndigits.data.shape\n\nOut[18]:\n\n(1797, 64)\n\nNext let's plot the first 100 of th..."
          ],
          [
           "data.shape\n\nOut[20]:\n\n(1797, 41)\n\nThe result is 41 dimensions, a reduction of nearly 1/3 with almost..."
          ],
          [
           "Finally, we can use the inverse transform of the PCA object to construct the new digits:\n\nIn [24]:\n\n..."
          ],
          [
           "In\n\nDepth: Kernel Density Estimation\n\n< In Depth: Gaussian Mixture Models | Contents | Application: ..."
          ],
          [
           "In [2]:\n\ndef make_data(N, f=0.3, rseed=1):\n\nrand = np.random.RandomState(rseed)\n\nx = rand.randn(N)\n\n..."
          ],
          [
           "Out[4]:\n\n1.0\n\nOne of the issues with using a histogram as a density estimator is that the choice of ..."
          ],
          [
           "On the left, the histogram makes clear that this is a bimodal distribution. On the right, we see a u..."
          ],
          [
           "Out[7]:\n\n(\n\n0.2, 8)\n\nThe problem with our two binnings stems from the fact that the height of the bl..."
          ],
          [
           "plt.axis([\n\n4, 8,\n\n0.2, 8]);\n\nThe result looks a bit messy, but is a much more robust reflection of ..."
          ],
          [
           "plt.axis([\n\n4, 8,\n\n0.2, 5]);\n\nThis smoothed-out plot, with a Gaussian distribution contributed at th..."
          ],
          [
           "Kernel Density Estimation in Practice¶The free parameters of kernel density estimation are the kerne..."
          ],
          [
           "# score_samples returns the log of the probability density logprob = kde.score_samples(x_d[:, None])..."
          ],
          [
           "(\n\n0.02, 0.22)\n\nThe result here is normalized such that the area under the curve is equal to 1.\n\nSel..."
          ],
          [
           "from sklearn.grid_search import GridSearchCV\n\nfrom sklearn.cross_validation import LeaveOneOut\n\nband..."
          ],
          [
           "Example: KDE on a Sphere¶Perhaps the most common use of KDE is in graphically representing distribut..."
          ],
          [
           "In [14]:\n\nfrom mpl_toolkits.basemap import Basemap\n\nfrom sklearn.datasets.species_distributions impo..."
          ],
          [
           "Unfortunately, this doesn't give a very good idea of the density of the species, because points in t..."
          ],
          [
           "for i, axi in enumerate(ax): axi.set_title(species_names[i])\n\n# plot coastlines with basemap m = Bas..."
          ],
          [
           "Compared to the simple scatter plot we initially used, this visualization paints a much clearer pict..."
          ],
          [
           "The algorithm is straightforward and intuitive to understand; the more difficult piece is couching i..."
          ],
          [
           "def predict_proba(self, X): logprobs = np.array([model.score_samples(X) for model in self.models_])...."
          ],
          [
           "Next comes the class initialization method: def __init__(self, bandwidth=1.0, kernel='gaussian'): se..."
          ],
          [
           "Notice that each persistent result of the fit is stored with a trailing underscore (e.g., self.logpr..."
          ],
          [
           "Using our custom estimator¶Let's try this custom estimator on a problem we have seen before: the cla..."
          ],
          [
           "{'bandwidth': 7.0548023107186433}\n\naccuracy = 0.966611018364\n\nWe see that this not-so-naive Bayesian..."
          ],
          [
           "Finally, if you want some practice building your own estimator, you might tackle building a similar ..."
          ],
          [
           "Application: A Face Detection Pipeline\n\n< In-Depth: Kernel Density Estimation | Contents | Further M..."
          ],
          [
           "HOG Features¶The Histogram of Gradients is a straightforward feature extraction procedure that was d..."
          ],
          [
           "ax[1].imshow(hog_vis)\n\nax[1].set_title('visualization of HOG features');\n\nHOG in Action: A Simple Fa..."
          ],
          [
           "positive_patches.shape\n\nOut[3]:\n\n(13233, 62, 47)\n\nThis gives us a sample of 13,000 face images to us..."
          ],
          [
           "In [5]:\n\nfrom sklearn.feature_extraction.image import PatchExtractor\n\ndef extract_patches(img, N, sc..."
          ],
          [
           "Our hope is that these would sufficiently cover the space of \"non-faces\" that our algorithm is likel..."
          ],
          [
           "In [9]:\n\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.cross_validation import cross_val_..."
          ],
          [
           "In [12]:\n\nmodel = grid.best_estimator_\n\nmodel.fit(X_train, y_train)\n\nOut[12]:\n\nLinearSVC(C=4.0, clas..."
          ],
          [
           "Next, let's create a window that iterates over patches of this image, and compute HOG features for e..."
          ],
          [
           "In [16]:\n\nfig, ax = plt.subplots()\n\nax.imshow(test_image, cmap='gray')\n\nax.axis('off')\n\nNi, Nj = pos..."
          ],
          [
           "All of the detected patches overlap and found the face in the image! Not bad for a few lines of Pyth..."
          ],
          [
           "In fact, the sliding_window() utility used here is already built with this in mind. We should combin..."
          ],
          [
           "An intro to these deep neural net methods is conceptually (and computationally!) beyond the scope of..."
          ],
          [
           "Machine Learning in Python¶To learn more about machine learning in Python, I'd suggest some of the f..."
          ],
          [
           "Machine Learning: Taught by Andrew Ng (Coursera), this is a very clearly-taught free online course w..."
          ],
          [
           "Appendix: Figure Code\n\n< Further Machine Learning Resources | Contents |\n\nMany of the figures used t..."
          ],
          [
           "def draw_cube(ax, xy, size, depth=0.4, edges=None, label=None, label_kwargs=None, **kwargs): \"\"\"draw..."
          ],
          [
           "if 9 in edges: ax.plot([x + depth, x + depth + size], [y + depth + size, y + depth + size], **kwargs..."
          ],
          [
           "label_kwargs=dict(color='gray'))\n\ndepth = 0.3\n\n#----------------------------------------------------..."
          ],
          [
           "draw_cube(ax, (12, 10), 1, depth, [1, 2, 3, 4, 5, 6, 9], '5', **solid) draw_cube(ax, (13, 10), 1, de..."
          ],
          [
           "# first block draw_cube(ax, (1, 7.5), 1, depth, [1, 2, 3, 4, 5, 6, 9], '1', **solid) draw_cube(ax, (..."
          ],
          [
           "# second block draw_cube(ax, (6, 7.5), 1, depth, [1, 2, 3, 4, 5, 6, 9], '0', **solid) draw_cube(ax, ..."
          ],
          [
           "# third block draw_cube(ax, (12, 7.5), 1, depth, [1, 2, 3, 4, 5, 6, 9], '1', **solid) draw_cube(ax, ..."
          ],
          [
           "ax.text(5, 7.0, '+', size=12, ha='center', va='center') ax.text(10.5, 7.0, '=', size=12, ha='center'..."
          ],
          [
           "draw_cube(ax, (2, 3), 1, depth, [1, 2, 3, 6, 7, 9, 10, 11], '0', **dotted) draw_cube(ax, (2, 2), 1, ..."
          ],
          [
           "draw_cube(ax, (6, 2), 1, depth, range(2, 13), '0', **dotted) draw_cube(ax, (7, 2), 1, depth, [2, 3, ..."
          ],
          [
           "draw_cube(ax, (12, 2), 1, depth, [2, 3, 4], '1', **solid) draw_cube(ax, (13, 2), 1, depth, [2, 3], '..."
          ],
          [
           "ax.set_ylim(0.5, 12.5)\n\nfig.savefig('figures/02.05\n\nbroadcasting.png')\n\nAggregation and Grouping¶Fig..."
          ],
          [
           "# draw horizontal lines for i in range(nrows + 1): plt.plot([x, x + dx * ncols], 2 * [y + i * dy], *..."
          ],
          [
           "#---------------------------------------------------------\n\n# Draw figure\n\nimport pandas as pd df = ..."
          ],
          [
           "result = df.groupby(df.index).sum()\n\ndraw_dataframe(result, [6, 0.75])\n\nstyle = dict(fontsize=14, ha..."
          ],
          [
           "plt.annotate('', (3.8, 3.8), (3.2, 3.8), arrowprops=arrowprops) plt.annotate('', (3.8, 1.75), (3.2, ..."
          ],
          [
           "split\n\napply\n\ncombine.png')\n\nWhat Is Machine Learning?¶\n\nIn [5]:\n\n# common plot formatting for below..."
          ],
          [
           "# predict the labels\n\ny2 = clf.predict(X2)\n\nClassification Example Figure 1¶\n\nIn [7]:\n\n# plot the da..."
          ],
          [
           "# plot points and model fig, ax = plt.subplots(figsize=(8, 6)) line_style = dict(levels = [-1.0, 0.0..."
          ],
          [
           "ax[1].scatter(X2[:, 0], X2[:, 1], c=y2, **point_style) ax[1].contour(xy1, xy2, Z, **line_style) ax[1..."
          ],
          [
           "# predict the labels\n\ny2 = model.predict(X2)\n\nRegression Example Figure 1¶\n\nIn [11]:\n\n# plot data po..."
          ],
          [
           "# plot points in 3D fig = plt.figure() ax = fig.add_subplot(111, projection='3d') ax.scatter(X[:, 0]..."
          ],
          [
           "# Hide axes (is there a better way?) ax.w_xaxis.line.set_visible(False) ax.w_yaxis.line.set_visible(..."
          ],
          [
           "# compute and plot model color mesh xx, yy = np.meshgrid(np.linspace(-4, 4), np.linspace(-3, 3)) Xfi..."
          ],
          [
           "ax[1].scatter(X2[:, 0], X2[:, 1], c=y2, s=50, cmap='viridis', norm=pts.norm) ax[1].axis([-4, 4, -3, ..."
          ],
          [
           "# format the plot\n\nformat_plot(ax, 'Input Data')\n\nfig.savefig('figures/05.01\n\nclustering\n\n1.png')\n\nC..."
          ],
          [
           "# format the plot\n\nformat_plot(ax, 'Input Data')\n\nfig.savefig('figures/05.01\n\ndimesionality\n\n1.png')..."
          ],
          [
           "Learn¶\n\nFeatures and Labels Grid¶The following is the code generating the diagram showing the featur..."
          ],
          [
           "# Draw labels vector ax.vlines(range(8, 10), ymin=0, ymax=9, lw=1) ax.hlines(range(10), xmin=8, xmax..."
          ],
          [
           "Hyperparameters and Model Validation¶\n\nCross\n\nValidation Figures¶\n\nIn [21]:\n\ndef draw_rects(N, ax, t..."
          ],
          [
           "fig.savefig('figures/05.03\n\n2\n\nfold\n\nCV.png')\n\n5\n\nFold Cross\n\nValidation¶\n\nIn [23]:\n\nfig = plt.figur..."
          ],
          [
           "from sklearn.pipeline import make_pipeline\n\ndef PolynomialRegression(degree=2, *\n\nkwargs):\n\nreturn m..."
          ],
          [
           "ax[1].scatter(X.ravel(), y, s=40) ax[1].plot(xfit.ravel(), model20.predict(xfit), color='gray') ax[1..."
          ],
          [
           "X2, y2 = make_data(10, rseed=42)\n\nax[0].scatter(X.ravel(), y, s=40, c='blue') ax[0].plot(xfit.ravel(..."
          ],
          [
           "ax[1].scatter(X.ravel(), y, s=40, c='blue') ax[1].plot(xfit.ravel(), model20.predict(xfit), color='g..."
          ],
          [
           "bias\n\nvariance\n\n2.png')\n\nValidation Curve¶\n\nIn [28]:\n\nx = np.linspace(0, 1, 1000) y1 = -(x - 0.5) **..."
          ],
          [
           "ax.set_xlim(0, 1)\n\nax.set_ylim(\n\n0.3, 0.5)\n\nax.set_xlabel(r'model complexity $\\longrightarrow$', siz..."
          ],
          [
           "ax.text(0.2, 0.88, \"training score\", rotation=-10, size=16, color='blue') ax.text(0.2, 0.5, \"validat..."
          ],
          [
           "curve.png')\n\nGaussian Naive Bayes¶Gaussian Naive Bayes Example¶Figure Context\n\nIn [30]:\n\nfrom sklear..."
          ],
          [
           "for label, color in enumerate(['red', 'blue']): mask = (y == label) mu, std = X[mask].mean(0), X[mas..."
          ],
          [
           "class GaussianFeatures(BaseEstimator, TransformerMixin): \"\"\"Uniformly-spaced Gaussian Features for 1..."
          ],
          [
           "gauss_model = make_pipeline(GaussianFeatures(10, 1.0),\n\nLinearRegression())\n\ngauss_model.fit(x[:, np..."
          ],
          [
           "fig.savefig('figures/05.06\n\ngaussian\n\nbasis.png')\n\nRandom Forests¶\n\nHelper Code¶The following will c..."
          ],
          [
           "xx, yy = np.meshgrid(np.linspace(\n\nxlim, num=200),\n\nnp.linspace(\n\nylim, num=200))\n\nZ = estimator.pre..."
          ],
          [
           "[xlim[0], tree.threshold[i]], ylim)\n\nplot_boundaries(tree.children_right[i],\n\n[tree.threshold[i], xl..."
          ],
          [
           "def randomized_tree_interactive(X, y):\n\nN = int(0.75\n\nX.shape[0])\n\nxlim = (X[:, 0].min(), X[:, 0].ma..."
          ],
          [
           "def text(ax, x, y, t, size=20, **kwargs): ax.text(x, y, t, ha='center', va='center', size=size, bbox..."
          ],
          [
           "text(ax, 0.66, 0.45, \"yes\", 12, alpha=0.4) text(ax, 0.79, 0.45, \"no\", 12, alpha=0.4)\n\nax.plot([0.3, ..."
          ],
          [
           "decision\n\ntree.png')\n\nDecision Tree Levels¶\n\nIn [34]:\n\nfrom helpers_05_08 import visualize_tree\n\nfro..."
          ],
          [
           "Decision Tree Overfitting¶\n\nIn [35]:\n\nmodel = DecisionTreeClassifier()\n\nfig, ax = plt.subplots(1, 2,..."
          ],
          [
           "In [38]:\n\nrng = np.random.RandomState(1) X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T pca = PCA(n..."
          ],
          [
           "# plot principal components X_pca = pca.transform(X) ax[1].scatter(X_pca[:, 0], X_pca[:, 1], alpha=0..."
          ],
          [
           "components = np.eye(len(coefficients), len(x))\n\nmean = np.zeros_like(x) + mean\n\nfig = plt.figure(fig..."
          ],
          [
           "for i in range(n_components): approx = approx + coefficients[i] * components[i] show(0, i + counter,..."
          ],
          [
           "Xproj = pca.fit_transform(digits.data)\n\nsns.set_style('white')\n\nfig = plot_pca_components(digits.dat..."
          ],
          [
           "# Open this PNG and draw random points from it from matplotlib.image import imread data = imread('he..."
          ],
          [
           "In [44]:\n\nfrom mpl_toolkits.mplot3d.art3d import Line3DCollection\n\nfrom sklearn.neighbors import Nea..."
          ],
          [
           "for axi, title, lines in zip(ax, titles, [lines_MDS, lines_LLE]): axi.scatter3D(XS[:, 0], XS[:, 1], ..."
          ],
          [
           "rng = np.random.RandomState(42) centers = [0, 4] + rng.randn(4, 2)\n\ndef draw_points(ax, c, factor=1)..."
          ],
          [
           "ax.yaxis.set_major_formatter(plt.NullFormatter())\n\nreturn ax\n\nfig = plt.figure(figsize=(15, 4)) gs =..."
          ],
          [
           "draw_points(ax1, y_pred)\n\ndraw_centers(ax1, centers)\n\n# M-step new_centers = np.array([X[y_pred == i..."
          ],
          [
           "fig.savefig('figures/05.11\n\nexpectation\n\nmaximization.png')\n\nInteractive K-Means¶The following scrip..."
          ],
          [
           "def plot_centers(centers): plt.scatter(centers[:, 0], centers[:, 1], marker='o', c=np.arange(centers..."
          ],
          [
           "# plot the data and cluster centers plot_points(X, labels, n_clusters) plot_centers(old_centers)\n\n# ..."
          ],
          [
           "In [47]:\n\nfrom sklearn.mixture import GMM\n\nfrom matplotlib.patches import Ellipse\n\ndef draw_ellipse(..."
          ],
          [
           "for i, cov_type in enumerate(['diag', 'spherical', 'full']): model = GMM(1, covariance_type=cov_type..."
          ],
          [
           "Python Data Science Handbook\n\nAbout\n\nArchive\n\nPython Data Science Handbook\n\nJake VanderPlas\n\nThis we..."
          ],
          [
           "4. Visualization with Matplotlib¶ Simple Line Plots Simple Scatter Plots Visualizing Errors Density ..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt, circle",
         "marker": {
          "color": "#19d3f3",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -6.9132786,
          -5.7636037,
          -6.3577933,
          6.89349,
          -6.365144,
          -6.387299,
          -6.5501966,
          -6.4593906,
          -6.6481633,
          -6.745427,
          -5.905982,
          -6.69997,
          -6.210032,
          -6.235475,
          -5.608527,
          -5.2934647,
          -6.802971,
          -5.7849193,
          -5.849443,
          -5.9919276,
          -6.563166,
          -5.9445057,
          -6.0212336,
          -6.626959,
          -6.1317635,
          -6.50597,
          -5.3120713,
          -5.205235,
          -5.380774,
          -5.477149,
          -5.195611,
          -5.4732547,
          -5.1787505,
          -5.438554,
          -10.677519,
          -5.830518,
          -5.195373,
          -5.246702,
          -5.4177995,
          -5.2463927,
          -5.315319,
          -5.2345934,
          -5.47862,
          -5.0755315,
          -5.2729464,
          -5.1641593,
          -5.240443,
          -5.205336,
          -4.9264364,
          -4.928647,
          -4.8758616,
          -5.020091,
          -5.0152626,
          -4.994541,
          -5.0935245,
          -10.315998,
          -10.663837,
          -10.659678,
          -10.586184,
          -10.713532,
          -10.8024,
          -10.707301,
          -10.701115,
          -10.777082,
          -10.832243,
          -10.693693,
          -6.6782837,
          -6.1972775,
          -7.6681905,
          -8.727284,
          -6.9156213,
          -6.9942775,
          -6.315251,
          -5.8195124,
          -8.773438,
          -8.73189,
          -8.94843,
          -8.595991,
          -9.025469,
          -9.626382,
          -10.270364,
          -10.934507,
          -11.783916,
          -8.984163,
          -8.712331,
          -9.115144,
          -9.89996,
          -9.742066,
          -10.080194,
          -10.055773,
          -10.258062,
          -10.09257,
          -10.101745,
          -10.220205,
          -10.057475,
          -10.109273,
          -10.443036,
          -10.314999,
          -10.3243265,
          -10.118325,
          -11.021598,
          -10.708868,
          -10.5002575,
          -11.318698,
          -11.415833,
          -11.813113,
          -11.475004,
          -11.84149,
          -11.53979,
          -11.459198,
          -11.614238,
          -11.553734,
          2.5631793,
          -11.553184,
          -11.318331,
          -11.503213,
          -11.206016,
          -11.539545,
          -11.13886,
          -11.424775,
          -11.899904,
          -11.469788,
          -11.53227,
          -6.249455,
          -6.2094545,
          -11.331823,
          -11.015802,
          -10.934065,
          -11.095257,
          -11.080911,
          -10.969019,
          -11.4108925,
          -11.365569,
          -11.102135,
          -3.8292303,
          -13.000442,
          -6.3702893,
          -13.002506,
          -13.00358,
          -12.814715,
          -13.0653925,
          -13.03806,
          -13.08623,
          -12.888471,
          -13.034573,
          -12.839127,
          -13.019112,
          -12.982356,
          -12.952264,
          -12.948264,
          -10.367313,
          -10.151487,
          -10.462881,
          -10.303961,
          -10.272664,
          -10.438221,
          -10.532276,
          -11.08059,
          -11.191898,
          -3.393992,
          -10.388523,
          -10.132209,
          -10.306537,
          -10.185101,
          -10.23738,
          -10.37128,
          -10.1251545,
          -9.839082,
          -9.581895,
          -9.882844,
          -10.004315,
          -9.88074,
          -9.675728,
          -9.582848,
          -8.651665,
          -8.744415,
          -8.442415,
          -8.473544,
          -8.376098,
          -8.264761,
          -8.612937,
          -8.797628,
          -9.23412,
          -8.798861,
          -7.4504113,
          -7.8464446,
          -5.888574,
          -8.769141,
          -9.617036,
          -9.579689,
          -9.687403,
          -9.606601,
          -9.573551,
          -9.769728,
          -9.61155,
          -9.627117,
          -9.877214,
          -9.750573,
          -9.665544,
          -9.741468,
          -9.847294,
          -10.485807,
          -9.418003,
          -9.601818,
          -9.554804,
          -9.590412,
          -9.6109495,
          -9.577562,
          -9.684518,
          -9.724917,
          -10.052537,
          -9.201327,
          -9.608814,
          -9.492579,
          -9.499774,
          -9.771563,
          -9.468697,
          -8.044667,
          -9.881299,
          -11.491731,
          -10.365842,
          -11.033927,
          -11.340981,
          -11.299276,
          -10.659441,
          -11.255407,
          -9.606656,
          -10.0284815,
          -10.19925,
          -10.286445,
          -10.408986,
          -11.393907,
          -11.433287,
          -10.550327,
          -10.513257,
          -10.417299,
          -10.567664,
          -10.727047,
          -10.834477,
          -10.704265,
          -10.918089,
          -10.029108,
          -9.785304,
          -9.40267,
          -9.380476,
          -9.417933,
          -9.48276,
          -9.768097,
          -9.480141,
          -9.435065,
          -9.683637,
          -9.427319,
          -9.489072,
          -9.303821,
          -9.416284,
          -9.1954975,
          -9.425758,
          -9.363777,
          -8.63088,
          -9.37865,
          -9.299637,
          -9.281491,
          -9.478548,
          -9.386797,
          -9.532462,
          -6.7201095,
          -6.4339795,
          -10.061049,
          -11.339107,
          -11.79033,
          -11.909643,
          -11.99796,
          -12.092303,
          -12.082064,
          -11.903485,
          -11.974096,
          -11.901928,
          -12.063873,
          -11.965605,
          -12.066217,
          -12.160052,
          -12.03957,
          -11.560646,
          -11.924719,
          -12.351941,
          -12.857966,
          -12.63333,
          -12.842871,
          -12.710186,
          -12.899579,
          -12.794042,
          -12.84232,
          -12.80797,
          -12.729235,
          -12.868082,
          -12.78845,
          -12.864373,
          -12.668331,
          -12.488013,
          -12.42809,
          -12.490646,
          -12.166962,
          -12.4816265,
          -12.284027,
          -10.273326,
          -10.314625,
          -10.94159,
          -10.414128,
          -10.539947,
          -10.319329,
          -10.200647,
          -10.294073,
          -10.220462,
          -10.195168,
          -10.382203,
          -6.6836185,
          -7.055797,
          -7.2421126,
          -7.3017173,
          -7.010284,
          -7.563028,
          -8.160028,
          -8.47063,
          -8.502371,
          -7.8883963,
          -7.212932,
          -7.4572945,
          -7.0062995,
          -7.2451577,
          -8.559046,
          -8.407499,
          -8.412238,
          -8.548107,
          -8.364375,
          -8.335264,
          -8.467314,
          -8.608348,
          -8.508062,
          -8.573748,
          -8.358703,
          -7.18777,
          -7.2277336,
          -6.2716475,
          -5.9665112,
          -6.0449862,
          -6.058387,
          -5.98392,
          -6.1307435,
          -6.020927,
          -7.99487,
          -6.017914,
          -6.03455,
          -7.8485937,
          -7.613381,
          -7.715413,
          -7.715279,
          -7.6839824,
          -7.755708,
          -7.6919093,
          -8.01098,
          -7.4345145,
          -7.540641,
          -7.100531,
          -7.2376986,
          -7.2387695,
          -7.3914557,
          -7.443179,
          -7.5675187,
          -7.5691314,
          -7.7034397,
          -7.7996917,
          -7.683068,
          -7.549564,
          -7.6279635,
          -7.7073417,
          -7.829534,
          -7.7513757,
          -6.7916217,
          -7.3119755,
          -7.337043,
          -7.390664,
          -7.3261323,
          -7.260696,
          -7.2059817,
          -7.3363976,
          -7.350896,
          -7.2559114,
          -7.3868923,
          -7.382521,
          -7.363714,
          -7.355858,
          -7.3686013,
          -7.3536,
          -7.3359795,
          -6.79755,
          -7.348981,
          -7.3688793,
          -7.1062837,
          -6.3681316,
          -6.709199,
          -6.837997,
          -6.740856,
          -6.997839,
          -6.734888,
          -6.751541,
          -6.3763914,
          -6.384391,
          -6.331795,
          -6.4637065,
          -6.3915644,
          -6.433208,
          -8.188451,
          -11.400272,
          -12.060675,
          -11.738866,
          -11.893107,
          -11.838557,
          -11.741948,
          -11.807732,
          -11.540049,
          -11.581906,
          -11.796097,
          -11.9312105,
          -11.882054,
          -11.501805,
          -7.7008505,
          -7.0828376,
          -5.3892546,
          -5.9423275,
          -6.0696526,
          -6.156545,
          -5.912645,
          -5.8073826,
          -3.4591455,
          -6.3355594,
          -6.925441,
          -5.3564878,
          -5.8914533,
          -5.0469003,
          -6.52202,
          -6.4737144,
          -6.2377625,
          -6.2350864,
          -6.854715,
          -6.678511,
          -6.4088283,
          -6.707344,
          -5.1365814,
          -6.4447794,
          -6.10815,
          -4.2585797,
          -1.5137084,
          -4.607669,
          -4.0766425,
          -3.9568098,
          -3.7437274,
          -3.6682117,
          -3.5601654,
          -4.275308,
          -4.215385,
          -4.2499013,
          -4.144281,
          -4.218973,
          -4.131842,
          -4.1826468,
          -3.3961082,
          -3.6745508,
          -3.1513314,
          -3.2617435,
          -5.9431853,
          -6.2361608,
          -6.0238576,
          -6.007197,
          -5.8646955,
          -6.21874,
          -4.671276,
          -4.829858,
          -4.1774325,
          -3.5946584,
          -4.1884294,
          -4.126795,
          -4.060357,
          -3.9117348,
          -2.108586,
          -2.2194006,
          -7.0387316,
          -7.205405,
          -7.2710094,
          -7.286787,
          -7.276152,
          -7.073473,
          -4.26289,
          -7.5334196,
          -7.5565987,
          -7.2851224,
          -6.9463286,
          -6.5848017,
          -6.9235883,
          -7.007107,
          -7.114165,
          -6.754792,
          -3.0315742,
          -6.949868,
          -6.8393197,
          -7.0144315,
          -7.073302,
          -7.057384,
          -7.362287,
          -7.1412745,
          -7.0043287,
          -7.1195297,
          -6.876744,
          -6.3058486,
          -6.484147,
          -6.454696,
          -6.4713464,
          -6.37866,
          -6.3250895,
          -6.399576,
          -6.4154973,
          -6.3591466,
          -5.2762127,
          -4.3029547,
          -4.3096313,
          -4.4461417,
          -4.2109375,
          -3.9682379,
          -4.189512,
          -4.2416954,
          -4.5116377,
          -5.0121527,
          -4.9753337,
          -4.98387,
          -4.8252473,
          -4.839356,
          -4.982501,
          -4.9360304,
          -4.8499775,
          -4.935854,
          -4.893881,
          -4.9707623,
          -5.066474,
          -5.032271,
          -6.3869805,
          -4.5753293,
          -5.130582,
          -6.1318665,
          -6.2021503,
          -5.069458,
          -4.5076714,
          -4.8030815,
          -5.2069983,
          -5.3717713,
          -5.959122,
          -6.6484494,
          -5.890319,
          -6.7175927,
          -5.8380547,
          -6.0380526,
          -5.5483055,
          -5.6402025,
          -5.7071323,
          -5.7659354,
          -5.8033276,
          -5.6070704,
          -5.796729,
          -5.6776514,
          -5.1512237,
          10.658001,
          10.574458,
          10.189764,
          -5.8153996,
          10.510179,
          9.375963,
          7.975954,
          7.388947,
          7.1805778,
          7.1661463,
          1.0843375,
          7.203639,
          -0.71266985,
          0.55950254,
          8.535013,
          9.814784,
          -5.766895,
          -0.14261456,
          -0.038141213,
          0.12286085,
          3.1137793,
          2.956821,
          3.459975,
          2.9052916,
          2.964565,
          0.8066469,
          0.5480942,
          0.07902046,
          0.03283509,
          -0.93169826,
          -1.5060717,
          -1.3112001,
          -1.7471229,
          -0.37429214,
          0.111757345,
          0.063546404,
          9.53122,
          0.6770189,
          0.40543833,
          1.9678236,
          2.329138,
          2.0606823,
          2.7278779,
          -0.9376068,
          -0.9388092,
          -0.93026835,
          -0.93119586,
          -0.98545444,
          2.5514019,
          4.8551025,
          4.5285974,
          3.638741,
          2.489469,
          3.2068646,
          3.230526,
          3.3567524,
          3.728047,
          3.1041937,
          1.4246737,
          3.3520532,
          3.0322704,
          1.7006238,
          9.375233,
          7.50752,
          2.0689845,
          2.014587,
          7.1894317,
          -7.420111,
          7.780765,
          2.6268394,
          2.479085,
          9.488205,
          -10.407851,
          2.4829302,
          8.662624,
          7.928196,
          7.226158,
          7.07918,
          7.0487666,
          7.2354903,
          7.3630023,
          7.0299234,
          1.4056239,
          7.1867,
          5.6550083,
          6.693657,
          0.7241864,
          6.98414,
          7.275434,
          9.747211,
          2.6067042,
          2.7840142,
          2.5601137,
          2.3991323,
          2.11384,
          2.2751615,
          0.33855352,
          2.2472765,
          1.6029272,
          4.5604043,
          4.6890364,
          5.559826,
          -6.4158964,
          -6.4186172,
          -6.433362,
          -6.458275,
          -6.367396,
          -6.2278633,
          -6.305546,
          3.3503277,
          4.848785,
          9.766863,
          1.3467605,
          0.67191017,
          1.3868424,
          1.3475616,
          1.3188889,
          1.6167096,
          1.331145,
          1.5498382,
          0.95181155,
          1.5013404,
          1.2907385,
          1.4271967,
          1.0378448,
          -0.21833548,
          0.52215636,
          1.0981048,
          0.050407026,
          0.014160111,
          9.3937645,
          9.797759,
          4.9100885,
          3.82992,
          1.4263111,
          3.2443378,
          4.1058497,
          4.580924,
          3.950288,
          4.427121,
          4.184823,
          -0.33681434,
          0.2260367,
          4.289856,
          0.07441788,
          0.38243213,
          0.3756432,
          0.4150019,
          0.3145668,
          -1.6678462,
          -1.9118899,
          0.43310452,
          0.39651582,
          0.18935658,
          -0.3934073,
          0.26869002,
          0.22449395,
          0.24587496,
          0.059650235,
          0.5226548,
          0.13035242,
          -0.13282217,
          0.25944367,
          0.5721961,
          -3.1762955,
          0.77545834,
          0.4459943,
          0.7329173,
          0.6422662,
          0.67598456,
          0.64141876,
          0.7332788,
          0.6059329,
          0.3590143,
          0.5037316,
          0.61125714,
          0.46345136,
          0.16504979,
          -0.29473746,
          0.49852622,
          0.1719056,
          -1.4656937,
          -0.50096905,
          -1.3537494,
          -1.6021638,
          -1.5578759,
          -1.5245122,
          -1.6350709,
          -1.6563687,
          -1.2663908,
          -1.6409547,
          -1.6399372,
          -1.6967795,
          -1.5063745,
          -1.5055883,
          -3.1868422,
          -1.5413065,
          -1.5249159,
          -0.47153395,
          -1.607424,
          -1.6419802,
          -1.5884795,
          -1.5905181,
          -1.5372298,
          -1.4020553,
          -0.8942249,
          -1.6099174,
          -1.6847379,
          -1.4943994,
          -1.2264702,
          -1.5120554,
          -1.6173085,
          -1.1657487,
          -1.4326797,
          -1.8239049,
          -3.2682621,
          -3.3607218,
          -3.2308784,
          -3.3750675,
          -3.3869655,
          -2.9590623,
          -2.3507774,
          -2.6586783,
          -1.4770683,
          -0.7239822,
          -3.7761443,
          -4.816885,
          -4.2988787,
          -4.922643,
          7.076133,
          -0.19222584,
          0.28962323,
          -0.00972145,
          0.92833227,
          -0.0778216,
          -0.092308775,
          -0.8176289,
          -0.56539315,
          -0.8089918,
          -0.4871162,
          -0.6624272,
          -0.5444772,
          -0.62625325,
          0.48360497,
          -0.48443073,
          -0.7534183,
          -0.7059302,
          -0.5820371,
          -0.6549705,
          9.272635,
          8.988332,
          8.757058,
          -2.5274892,
          -3.7662315,
          -3.4343605,
          -3.8028681,
          -3.7978776,
          -3.8691258,
          -3.8388863,
          -3.8071308,
          -3.834161,
          -3.7858114,
          -3.8899345,
          -3.4588494,
          -6.391144,
          -6.43189,
          -6.6537905,
          -6.943536,
          0.8896173,
          0.84288967,
          1.0719829,
          0.51297474,
          0.8747726,
          0.51257116,
          -0.28023556,
          0.21128738,
          0.6821927,
          -1.3894897,
          -0.69707894,
          0.2182469,
          -0.15869614,
          1.2471445,
          1.264855,
          2.2899847,
          1.7812076,
          1.160785,
          1.4305944,
          1.4228568,
          1.541873,
          1.3910999,
          1.3730748,
          0.38275096,
          0.4852613,
          0.7971724,
          0.9050757,
          3.0515015,
          2.8115103,
          3.163853,
          3.1292853,
          -3.1801422,
          2.7159936,
          3.263497,
          2.2666843,
          0.14785498,
          0.1251148,
          -0.37840244,
          0.15772125,
          0.25450316,
          -3.0641725,
          -0.379318,
          -1.3134224,
          -1.4871062,
          -1.0822134,
          -1.1992182,
          -1.470694,
          -1.3865752,
          -1.1690887,
          -0.844409,
          -0.17867376,
          -6.922985,
          -5.71651
         ],
         "xaxis": "x",
         "y": [
          -9.608463,
          -10.74167,
          -9.130352,
          2.3064013,
          -9.128456,
          -9.217553,
          -9.666733,
          -9.304401,
          -9.143915,
          -9.166809,
          -10.644005,
          -9.479386,
          -8.974278,
          -8.798658,
          -7.721664,
          -7.6461625,
          -9.830161,
          -10.795077,
          -7.9020543,
          -7.609098,
          -7.5519166,
          -7.586846,
          -7.5898857,
          -7.670351,
          -7.7063603,
          -9.297882,
          -7.452461,
          -7.392982,
          -7.4162183,
          -7.4061913,
          -7.3621106,
          -7.4891953,
          -7.3656206,
          -7.4573097,
          -5.509446,
          -7.515013,
          -7.3914437,
          -7.350184,
          -7.489292,
          -7.4371243,
          -7.382914,
          -7.4279375,
          -7.5193205,
          -7.3793178,
          -7.50037,
          -7.414735,
          -7.4325857,
          -7.0017376,
          -6.813376,
          -6.876215,
          -6.850388,
          -6.9430547,
          -7.0315366,
          -6.939572,
          -7.213141,
          -5.6047444,
          -5.348163,
          -5.574529,
          -5.6643662,
          -5.342197,
          -5.2148433,
          -5.345816,
          -5.2739563,
          -5.337671,
          -5.3146653,
          -5.275261,
          -9.3371315,
          -8.735542,
          -8.04324,
          -8.364583,
          -8.929468,
          -8.744524,
          -10.230689,
          -10.683698,
          -7.69669,
          -7.3084507,
          -7.3250823,
          -7.5841475,
          -7.533632,
          -7.497275,
          -7.2672124,
          -6.7570276,
          -6.5655675,
          -7.600945,
          -7.261655,
          -7.6645503,
          -7.5733314,
          -7.768549,
          -7.6634603,
          -7.4470572,
          -7.6309743,
          -7.5935407,
          -7.5204353,
          -7.4641433,
          -7.5235157,
          -7.305848,
          -7.397477,
          -7.575253,
          -7.2303343,
          -7.1590037,
          -7.034004,
          -6.221447,
          -6.413742,
          -6.493544,
          -6.606579,
          -6.633757,
          -6.597056,
          -6.4988937,
          -6.175215,
          -6.347101,
          -6.3639946,
          -6.363088,
          4.498102,
          -6.327294,
          -6.6484985,
          -6.752282,
          -7.0277543,
          -6.818131,
          -6.6537642,
          -7.1456127,
          -6.9151196,
          -6.932327,
          -6.8290906,
          1.7992399,
          2.927682,
          -7.013192,
          -7.0901217,
          -7.1578245,
          -7.1290283,
          -7.219568,
          -7.337152,
          -7.0289383,
          -6.9047933,
          -6.8865123,
          6.231094,
          -6.95913,
          2.4402952,
          -6.9350324,
          -6.8066263,
          -6.7732167,
          -6.8065434,
          -6.826325,
          -6.855175,
          -7.01586,
          -6.918887,
          -6.940492,
          -6.8638678,
          -6.7707386,
          -6.8343773,
          -6.8097935,
          -7.520818,
          -7.780623,
          -7.5689955,
          -7.4741173,
          -7.4717374,
          -7.3035097,
          -7.5338473,
          -7.196493,
          -6.649881,
          4.3644547,
          -6.277374,
          -6.950156,
          -6.542824,
          -6.5429754,
          -6.8308344,
          -6.757409,
          -6.881371,
          -6.4303737,
          -6.1036644,
          -6.0532813,
          -6.516698,
          -6.169505,
          -6.314563,
          -6.9059625,
          -8.7357435,
          -8.157784,
          -8.759148,
          -8.717509,
          -8.334394,
          -7.677152,
          -7.527641,
          -8.11765,
          -7.722975,
          -9.61544,
          -9.32059,
          -9.102419,
          -10.659246,
          -10.079383,
          -10.772967,
          -10.677195,
          -11.176414,
          -11.600365,
          -10.907137,
          -11.617628,
          -11.40936,
          -11.705905,
          -10.919167,
          -11.5799055,
          -10.500051,
          -9.774229,
          -10.606752,
          -10.515239,
          -10.711464,
          -10.952066,
          -10.899745,
          -10.658873,
          -10.551031,
          -11.704503,
          -11.696699,
          -11.259165,
          -11.681742,
          -10.870847,
          -10.949702,
          -11.757295,
          -11.546167,
          -11.916555,
          -11.19625,
          -9.5137,
          -10.361463,
          -6.4986043,
          -11.869435,
          -10.30449,
          -10.268296,
          -9.705377,
          -8.221026,
          -9.96153,
          -9.982226,
          -10.083468,
          -9.741208,
          -9.911001,
          -9.572835,
          -6.9961934,
          -7.2731924,
          -9.789112,
          -9.801919,
          -9.842334,
          -9.874361,
          -9.903637,
          -9.932831,
          -9.936162,
          -10.031692,
          -10.068648,
          -11.970503,
          -11.889375,
          -12.080131,
          -12.064817,
          -12.050488,
          -12.280354,
          -11.832605,
          -11.959766,
          -11.57174,
          -12.023691,
          -11.779476,
          -11.573519,
          -11.830443,
          -11.764006,
          -11.98451,
          -11.634463,
          -9.991112,
          -11.680978,
          -10.8620205,
          -11.2002125,
          -12.192089,
          -12.157125,
          -11.849785,
          1.8044467,
          1.6169065,
          -11.583992,
          -12.159255,
          -12.166084,
          -12.08269,
          -12.271331,
          -12.391047,
          -12.3329525,
          -12.085056,
          -12.338654,
          -12.276977,
          -12.355853,
          -11.998185,
          -12.352063,
          -12.495425,
          -12.351004,
          -12.50214,
          -12.4163,
          -12.922025,
          -13.294223,
          -13.135345,
          -13.289542,
          -13.210346,
          -13.31744,
          -13.254526,
          -13.307751,
          -13.226609,
          -13.200049,
          -13.280582,
          -13.227156,
          -13.285307,
          -13.167381,
          -12.981861,
          -12.887028,
          -12.957782,
          -12.773389,
          -12.941237,
          -12.9068,
          -12.860823,
          -12.891101,
          -12.648405,
          -12.846837,
          -12.853007,
          -12.774729,
          -12.724276,
          -12.823787,
          -12.705106,
          -12.534606,
          -12.74288,
          2.6612616,
          2.5422862,
          2.3549123,
          2.0089843,
          2.4570796,
          1.8634531,
          1.8146483,
          1.8369783,
          1.8168238,
          2.017343,
          2.5354605,
          2.2720656,
          1.9196597,
          2.3331234,
          1.8358306,
          1.8526595,
          1.8981616,
          1.9153099,
          1.9098475,
          2.0883722,
          1.9156619,
          1.8749582,
          1.8602549,
          1.8676143,
          1.9054993,
          2.0798202,
          2.381181,
          1.6630142,
          1.6951836,
          1.7697873,
          1.7741222,
          1.8502295,
          1.691407,
          1.8230515,
          1.9392416,
          1.7566229,
          1.7771373,
          3.5470595,
          3.401912,
          3.505017,
          3.4154952,
          3.2452443,
          3.4330945,
          3.232037,
          -9.072673,
          -8.197178,
          -8.42879,
          -7.895111,
          -8.115528,
          -8.215904,
          -8.399815,
          -8.494134,
          -8.517173,
          -8.512918,
          -8.391313,
          -8.586696,
          -8.480032,
          -8.387087,
          -8.478437,
          -8.512113,
          -8.563744,
          -8.606123,
          1.2747078,
          -0.4216184,
          -0.46017006,
          -0.71193254,
          -0.48033658,
          -0.30963525,
          0.9617496,
          -0.45224234,
          -0.5205555,
          -0.44117612,
          -0.61058486,
          -0.58198315,
          -0.54188883,
          -0.5292156,
          -0.57379854,
          -0.49456856,
          -0.4338973,
          1.1342902,
          -0.49438688,
          -0.6072233,
          1.9879103,
          2.623646,
          2.3755612,
          2.4040794,
          3.345013,
          1.9721527,
          1.2149329,
          1.1133711,
          1.9640648,
          1.3548212,
          1.2491895,
          1.1792858,
          1.2279465,
          1.2129916,
          -9.275415,
          -6.891065,
          -8.182369,
          -8.768604,
          -8.823673,
          -8.869169,
          -9.043173,
          -9.121074,
          -9.648361,
          -9.502077,
          -9.130733,
          -8.856721,
          -8.704714,
          -8.672399,
          -9.3443365,
          -9.604506,
          5.5415106,
          5.494681,
          5.6119547,
          5.4500265,
          5.508548,
          5.614739,
          7.1603036,
          5.6721764,
          5.5645313,
          5.3914638,
          -10.60631,
          5.436892,
          5.7024393,
          5.8551917,
          5.830608,
          5.8980656,
          5.589498,
          5.824914,
          5.544251,
          5.66965,
          5.393973,
          5.78658,
          5.8963513,
          6.2974405,
          4.6570764,
          5.822625,
          5.238378,
          5.065107,
          5.039669,
          4.982107,
          5.0583615,
          6.0370326,
          6.382829,
          6.2882867,
          6.3383317,
          6.46954,
          5.1729207,
          4.407565,
          4.317573,
          4.3476853,
          4.4026403,
          4.5270023,
          5.2945185,
          5.2684803,
          5.5082197,
          4.893825,
          5.458185,
          5.3607316,
          4.976678,
          6.067567,
          6.304006,
          6.607079,
          6.4229436,
          6.3255754,
          6.2953916,
          6.4722705,
          7.430674,
          7.280698,
          5.454992,
          5.4234824,
          5.30938,
          5.4152894,
          5.3882475,
          5.398359,
          4.3891573,
          3.7383604,
          3.6071095,
          3.6894362,
          4.3178205,
          5.353644,
          5.059885,
          5.272787,
          4.305969,
          4.189453,
          8.903473,
          4.142427,
          4.9487925,
          5.179572,
          4.9426866,
          5.178403,
          5.456754,
          5.397172,
          5.4707294,
          5.095922,
          5.2751384,
          5.23467,
          5.612763,
          5.2820272,
          5.693885,
          5.6908474,
          5.7685437,
          5.597234,
          5.795723,
          5.619602,
          6.44698,
          6.5619893,
          6.447252,
          6.5253553,
          6.606792,
          6.601618,
          6.6557326,
          6.975093,
          6.637013,
          6.9987965,
          7.334497,
          7.308411,
          7.327882,
          7.4309506,
          7.389409,
          7.4776673,
          7.4339013,
          7.4226723,
          6.923803,
          7.246202,
          6.374894,
          5.4687524,
          1.5491321,
          6.116709,
          5.6354933,
          5.5783205,
          4.905842,
          4.341779,
          4.083632,
          3.9059162,
          3.8303652,
          3.5625682,
          3.2924018,
          2.7759953,
          2.8186533,
          0.83400327,
          2.0450218,
          2.0043006,
          2.1384661,
          1.9977548,
          2.102886,
          2.1710072,
          1.8546206,
          2.103472,
          2.119065,
          5.2876306,
          5.051556,
          -2.1325839,
          -1.977898,
          -1.8812312,
          -10.719803,
          -1.9688547,
          -0.7944612,
          -0.03429233,
          -1.0886204,
          -0.81450254,
          -0.8851516,
          8.604626,
          -0.59272826,
          10.058762,
          9.625669,
          -0.453717,
          -2.1294327,
          2.8800154,
          4.1094174,
          4.3864236,
          4.3059673,
          3.2130435,
          3.6595592,
          3.8290124,
          3.3788881,
          3.8492455,
          4.9575233,
          5.1293726,
          5.489998,
          5.2077427,
          7.02482,
          7.6525574,
          7.7613125,
          7.636822,
          6.438939,
          5.6651,
          7.214644,
          -2.1672544,
          4.9711223,
          5.387564,
          4.986885,
          5.08968,
          4.9474416,
          5.117088,
          1.048772,
          1.0068159,
          0.98922974,
          0.9719217,
          0.9501817,
          4.912273,
          4.448457,
          4.789778,
          5.1879606,
          4.2155356,
          5.542554,
          5.3827877,
          5.4340315,
          5.0855985,
          5.222957,
          7.5317636,
          5.2418404,
          5.7760696,
          5.6780305,
          -2.2159278,
          -0.59908235,
          0.12458382,
          0.5290284,
          -0.122532785,
          -8.38736,
          0.6364439,
          2.8867571,
          3.95651,
          -2.3370042,
          -10.107202,
          3.158172,
          -2.073643,
          -2.1341562,
          -2.3951387,
          -2.9319022,
          -2.6699102,
          -2.1531417,
          -2.5482624,
          -2.5774117,
          5.635492,
          -2.6216197,
          -1.8726017,
          -1.4130375,
          5.3141675,
          -1.2441078,
          -2.308263,
          -2.5701644,
          4.0648074,
          4.0679297,
          4.2721725,
          3.4406857,
          3.44266,
          3.75703,
          7.132684,
          3.7713473,
          6.2830014,
          3.9147768,
          3.9760537,
          2.2773695,
          1.2005185,
          1.1560202,
          1.5803931,
          1.6411918,
          1.8106277,
          1.1306522,
          1.1773254,
          2.9083252,
          1.3234823,
          -1.3504238,
          6.5625176,
          6.7969437,
          6.252356,
          6.066003,
          7.0740294,
          5.7941685,
          6.225228,
          5.723763,
          6.868163,
          6.3284774,
          6.047281,
          6.394536,
          6.1613507,
          6.5730677,
          6.12874,
          6.103497,
          6.1790795,
          6.3325257,
          -1.3816161,
          -0.86001456,
          6.900202,
          7.323504,
          6.0872364,
          7.515673,
          7.2774205,
          6.902311,
          6.5670366,
          4.260223,
          6.2639093,
          6.9568496,
          5.902349,
          6.5563745,
          10.22399,
          9.539026,
          8.902179,
          9.536584,
          9.612292,
          7.8383284,
          7.2852063,
          9.536273,
          9.533194,
          9.395732,
          8.768233,
          9.3927965,
          9.408178,
          9.21411,
          8.747442,
          9.232457,
          9.967697,
          10.298192,
          9.908525,
          9.712199,
          6.38364,
          9.295663,
          9.474245,
          9.616475,
          9.773316,
          9.905543,
          9.734358,
          10.080803,
          9.901353,
          9.239817,
          9.848813,
          9.892687,
          9.399354,
          8.924475,
          8.232173,
          9.315312,
          7.621535,
          7.561626,
          10.213543,
          9.962957,
          9.655746,
          9.893433,
          9.563481,
          9.710157,
          9.589445,
          9.71297,
          9.553782,
          9.041418,
          9.239596,
          8.56215,
          9.510273,
          6.876852,
          9.469334,
          9.488891,
          10.269498,
          9.591174,
          9.6421585,
          9.532783,
          9.599446,
          9.50459,
          9.411329,
          8.676076,
          9.578554,
          9.465807,
          9.252808,
          9.15112,
          9.263828,
          7.962832,
          9.121424,
          8.2865505,
          4.9477744,
          4.2295275,
          4.2480245,
          4.1208487,
          4.2967997,
          4.3566046,
          4.621135,
          4.597213,
          4.47316,
          4.7533207,
          4.867965,
          4.7022443,
          5.432397,
          4.992455,
          5.0213046,
          -2.5958714,
          4.9224,
          4.9584107,
          4.796932,
          4.6873703,
          5.4005823,
          5.465146,
          5.4722605,
          6.3490067,
          6.5485983,
          6.48522,
          6.659829,
          7.12175,
          6.641393,
          5.6926684,
          6.475934,
          6.741211,
          7.3129683,
          6.688788,
          6.49395,
          0.3016367,
          -0.7794175,
          0.16650364,
          7.4920583,
          9.795568,
          9.326847,
          9.844451,
          9.8532095,
          9.939871,
          9.852241,
          9.861248,
          9.84042,
          9.85152,
          9.866467,
          9.539418,
          4.471228,
          3.977055,
          3.336218,
          2.9647598,
          7.3789215,
          6.721514,
          7.367004,
          7.7119117,
          7.460164,
          7.645381,
          8.342213,
          7.869756,
          7.5353947,
          9.495374,
          8.783447,
          7.9173703,
          7.6623745,
          7.474057,
          7.2172313,
          6.4003706,
          6.9253592,
          7.534298,
          7.5186296,
          7.4119496,
          7.524416,
          7.4994555,
          7.5504093,
          7.3222804,
          7.4412265,
          6.7597923,
          7.4019604,
          7.6807194,
          7.61241,
          7.6598544,
          7.6149597,
          8.253049,
          7.7004027,
          7.6356287,
          7.861505,
          8.485284,
          8.485677,
          8.349664,
          8.694184,
          8.519309,
          7.0214963,
          8.530231,
          9.2879,
          8.435019,
          8.140203,
          8.967879,
          9.694328,
          9.316523,
          9.115579,
          8.415315,
          8.252354,
          -9.61713,
          -10.850541
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "CHAPTER 1: Introduction to Machine Learning - Python Machine Learning [Book]\n\nSkip to main content\n\n..."
          ],
          [
           "Start your free trial\n\nCHAPTER 1Introduction to Machine Learning\n\nWelcome to Python Machine Learning..."
          ],
          [
           "About O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nCommunity partners\n\nAffi..."
          ],
          [
           "Close\n\nCHAPTER 2: Extending Python Using NumPy - Python Machine Learning [Book]\n\nSkip to main conten..."
          ],
          [
           "Start your free trial\n\nCHAPTER 2Extending Python Using NumPy\n\nWhat Is NumPy? In Python, you usually ..."
          ],
          [
           "Get Python Machine Learning now with the O’Reilly learning platform. O’Reilly members experience boo..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "What Is Pandas? While NumPy arrays are a much‐improved N‐dimensional array object version over Pytho..."
          ],
          [
           "08:00:00,5.0 4,2016-06-02 12:00:00,4.9 5,2016-06-02 18:00:00,5.5 6,2016-06-03 08:00:00,5.6 7,2016-06..."
          ],
          [
           "18,2016-06-07 08:00:00,6.6 19,2016-06-07 12:00:00,4.1 20,2016-06-07 18:00:00,6.9 21,2016-06-08 08:00..."
          ],
          [
           "To be able to deal with data stored as tables, you need a new data type that is more suited to deal ..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nCHAPTER 4Data Visualization Using matplotlib\n\nWhat Is matplotlib? As the adag..."
          ],
          [
           "Plotting Line Charts To see how easy it is to use matplotlib, let's plot ...\n\nGet Python Machine Lea..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nCHAPTER 5Getting Started with Scikit‐learn for Machine Learning\n\nIntroduction..."
          ],
          [
           "Close\n\nCHAPTER 6: Supervised Learning—Linear Regression - Python Machine Learning [Book]\n\nSkip to ma..."
          ],
          [
           "Figure 6.1: Some terminologies for features and label\n\nTIP Features are also sometimes called explan..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nCHAPTER 7Supervised Learning—Classification Using Logistic Regression\n\nWhat I..."
          ],
          [
           "Close\n\nCHAPTER 8: Supervised Learning—Classification Using Support Vector Machines - Python Machine ..."
          ],
          [
           "Figure 8.1: Using SVM to separate two classes of animals\n\nOnce the line is drawn to separate the cla..."
          ],
          [
           "logo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJ..."
          ],
          [
           "Individuals\n\nFeatures\n\nAll features\n\nCourses\n\nCertifications\n\nInteractive learning\n\nLive events\n\nAns..."
          ],
          [
           "Figure 9.1: The classification of a point depends on the majority of its neighbors\n\nTIP KNN is also ..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nCHAPTER 10Unsupervised Learning—Clustering Using K‐Means\n\nWhat Is Unsupervise..."
          ],
          [
           "Close\n\nCHAPTER 11: Using Azure Machine Learning Studio - Python Machine Learning [Book]\n\nSkip to mai..."
          ],
          [
           "Start your free trial\n\nCHAPTER 11Using Azure Machine Learning Studio\n\nWhat Is Microsoft Azure Machin..."
          ],
          [
           "Close\n\nCHAPTER 12: Deploying Machine Learning Models - Python Machine Learning [Book]\n\nSkip to main ..."
          ],
          [
           "Start your free trial\n\nCHAPTER 12Deploying Machine Learning Models\n\nDeploying ML The main goal of ma..."
          ],
          [
           "Start your free trial\n\nAbout O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nC..."
          ],
          [
           "Close\n\nIndex\n\nPython Machine Learning [Book]\n\nSkip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor bus..."
          ],
          [
           "Start your free trial\n\nIndex\n\nA accuracy, computing of, 168–171 algorithms categories of in ML, 5 co..."
          ],
          [
           "B\n\nBagging, 143\n\nbar chart\n\ndefined, 73\n\nplotting of, 73–77\n\nbar() function, 73\n\nbias, 141–144\n\nBool..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\PythonML-Lee.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\PythonML-Lee.txt, circle",
         "marker": {
          "color": "#FF6692",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\PythonML-Lee.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          11.042307,
          11.084293,
          15.34581,
          11.101027,
          -8.703045,
          13.163875,
          11.071404,
          -8.290428,
          -6.28224,
          -6.4353275,
          -8.027753,
          11.426557,
          -5.2775965,
          -5.079949,
          11.179154,
          10.192046,
          9.656241,
          9.474143,
          13.748593,
          9.23288,
          9.595056,
          1.4472327,
          15.24187,
          8.763134,
          8.703958,
          13.571616,
          7.4057856,
          10.999852,
          10.649747,
          11.194625,
          9.587242,
          15.389534,
          11.3843355,
          10.027464,
          10.24109,
          15.182332
         ],
         "xaxis": "x",
         "y": [
          -2.1168535,
          -2.308144,
          -4.990232,
          -2.171983,
          -7.5867786,
          -3.753616,
          -2.2492678,
          -9.304207,
          1.6123046,
          1.5499972,
          -8.874649,
          -2.0775328,
          4.6208177,
          5.196831,
          -2.0241656,
          -2.1867032,
          -2.000885,
          -1.2680154,
          -4.2355742,
          -1.6659175,
          -1.056373,
          6.2796426,
          -5.0082593,
          -1.4165502,
          -1.58722,
          -4.207172,
          -0.16135043,
          -1.1299844,
          -0.8913166,
          -2.001922,
          -0.6110338,
          -5.0268846,
          -2.145341,
          -1.2043554,
          -1.4381139,
          -4.984288
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Giving Computers the Ability to Learn from Data - Python Machine Learning - Third Edition [Book]\n\nSk..."
          ],
          [
           "Get Python Machine Learning - Third Edition now with the O’Reilly learning platform. O’Reilly member..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n2 Training Simple Machine Learning Algorithms for Classification\n\nIn this cha..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Insights reporting\n\nBlog\n\nContent sponsorship\n\nPython Machine Learning - Third Edition by Sebastian ..."
          ],
          [
           "Submit an RFP\n\nDiversity\n\nO’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\n..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Dealing with missing data\n\nIt is ...\n\nGet Python Machine Learning - Third Edition now with the O’Rei..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n5 Compressing Data via Dimensionality Reduction\n\nIn Chapter 4, Building Good ..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Insights reporting\n\nBlog\n\nContent sponsorship\n\nPython Machine Learning - Third Edition by Sebastian ..."
          ],
          [
           "Affiliate program\n\nSubmit an RFP\n\nDiversity\n\nO’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletter..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Close\n\nApplying Machine Learning to Sentiment Analysis - Python Machine Learning - Third Edition [Bo..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n9 Embedding a Machine Learning Model into a Web Application\n\nIn the previous ..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Insights reporting\n\nBlog\n\nContent sponsorship\n\nPython Machine Learning - Third Edition by Sebastian ..."
          ],
          [
           "O’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nl..."
          ],
          [
           "Sign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividuals\n\nFeatures\n\nAll fea..."
          ],
          [
           "Close\n\nImplementing a Multilayer Artificial Neural Network from Scratch - Python Machine Learning - ..."
          ],
          [
           "Gaining ...\n\nGet Python Machine Learning - Third Edition now with the O’Reilly learning platform. O’..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n13 Parallelizing Neural Network Training with TensorFlow\n\nIn this chapter, we..."
          ],
          [
           "International\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJapan\n\nDownload the O’..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "Close\n\nClassifying Images with Deep Convolutional Neural Networks - Python Machine Learning - Third ..."
          ],
          [
           "Convolution operations in one and two dimensions The building blocks of CNN architectures Implementi..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\n16 Modeling Sequential Data Using Recurrent Neural Networks\n\nIn the previous ..."
          ],
          [
           "International\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJapan\n\nDownload the O’..."
          ],
          [
           "Courses\n\nCertifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nConte..."
          ],
          [
           "Close\n\nReinforcement Learning for Decision Making in Complex Environments - Python Machine Learning ..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\PythonML-RaschkaMirjalili.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\PythonML-RaschkaMirjalili.txt, circle",
         "marker": {
          "color": "#B6E880",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\PythonML-RaschkaMirjalili.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          10.641094,
          12.359755,
          11.478707,
          10.04037,
          16.391401,
          10.873656,
          15.409728,
          9.50543,
          9.926056,
          11.368837,
          8.639608,
          16.253916,
          11.034092,
          15.041237,
          10.4742985,
          8.60954,
          11.59677,
          9.404807,
          16.217205,
          10.436261,
          15.30283,
          7.940157,
          10.307632,
          14.146423,
          10.961072,
          10.512399,
          15.652388,
          10.622222,
          10.411816,
          10.396581,
          13.730239,
          10.065801,
          15.568088,
          10.197053,
          9.477616,
          10.656935
         ],
         "xaxis": "x",
         "y": [
          -1.8476341,
          -2.9524548,
          -2.0822332,
          -1.1157987,
          -5.279587,
          -1.6545695,
          -5.0244617,
          -1.4857168,
          -2.3619967,
          -2.053632,
          -1.0068574,
          -5.2150664,
          -1.65965,
          -4.9027805,
          -1.3986356,
          -1.314397,
          -2.1795244,
          -1.2264912,
          -5.241324,
          -1.3866501,
          -5.0119276,
          -0.48492777,
          0.8221361,
          -4.450933,
          0.3161892,
          0.64460313,
          -5.097173,
          0.19113587,
          0.5997266,
          0.801309,
          -5.0862994,
          1.0735946,
          -5.092954,
          0.766816,
          -0.66303086,
          -0.75391
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "1. Probably Approximately Correct Software - Thoughtful Machine Learning with Python [Book]\n\nSkip to..."
          ],
          [
           "Start your free trial\n\nChapter 1. Probably Approximately Correct Software If you’ve ever flown on an..."
          ],
          [
           "The year 2014 saw the Heartbleed bug infection, which made many sites using SSL vulnerable. As a res..."
          ],
          [
           "SOLID SOLID is a framework that helps design better object-oriented code. In the same ways that the ..."
          ],
          [
           "Figure 1-1. A multi-tool like this has too many responsibilities\n\nOpen/Closed Principle The OCP, som..."
          ],
          [
           "Dependency Inversion Principle The DIP is a principle that guides us to depend on abstractions, not ..."
          ],
          [
           "Testing or TDD In the early days of aviation, pilots didn’t use checklists to test whether their air..."
          ],
          [
           "This led to the Agile Manifesto as well as the culture of testing and TDD, spearheaded by Kent Beck,..."
          ],
          [
           "Refactoring Refactoring is one of the hardest programming practices to explain to nonprogrammers, wh..."
          ],
          [
           "Technical debt in many cases arises through not writing tests or not following the SOLID principles...."
          ],
          [
           "Refactor your code to avoid a buildup of technical debt\n\nThe real question now is what makes the sof..."
          ],
          [
           "Writing the Right Software with Machine Learning In The Knowledge-Creating Company, Nonaka and Takeu..."
          ],
          [
           "The issue with inductive reasoning, though, is that you can only feed the algorithm data that you kn..."
          ],
          [
           "Hidden feedback loops Having built-in hidden features in model OCP\n\nUndeclared consumers/visibility ..."
          ],
          [
           "SRP In machine learning code, one of the biggest challenges for people to realize is that the code a..."
          ],
          [
           "OCP Recall that the OCP is about opening classes for extension but not modification. One way this ma..."
          ],
          [
           "LSP Not a lot of people talk about the LSP anymore because many programmers are advocating for compo..."
          ],
          [
           "ISP The ISP is the notion that a client-specific interface is better than a general purpose one. In ..."
          ],
          [
           "Many times this just isn’t the case. Take for instance the price of a stock; in the morning it might..."
          ],
          [
           "DIP The Dependency Inversion Principle is about limiting our buildups of data and making code more f..."
          ],
          [
           "Machine Learning Code Is Complex but Not Impossible At times, machine learning code can be difficult..."
          ],
          [
           "TDD: Scientific Method 2.0 Every true scientist is a dreamer and a skeptic. Daring to put a person o..."
          ],
          [
           "The Plan for the Book This book will cover a lot of ground with machine learning, but by the end you..."
          ],
          [
           "Get Thoughtful Machine Learning with Python now with the O’Reilly learning platform. O’Reilly member..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 2. A Quick Introduction to Machine Learning You’ve picked up this boo..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 3. K-Nearest Neighbors Have you ever bought a house before? If you’re..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 4. Naive Bayesian Classification Remember how email was several years..."
          ],
          [
           "Using Bayes’ Theorem to Find Fraudulent Orders Imagine you’re running an online store and lately you..."
          ],
          [
           "Conditional Probabilities Most people understand what we mean by the probability of something happen..."
          ],
          [
           "set(a) | set(b) #=> [1,2,3,4,5] Finally, the probability of A given B looks as follows in Python: a ..."
          ],
          [
           "r\n\nd\n\n)\n\n=\n\nP(Fraud∩Giftcard) P(Giftcard)\n\nNow this works if you know the actual probability of Frau..."
          ],
          [
           "P\n\n(\n\nF\n\nr\n\na\n\nu\n\nd\n\n∣\n\nG\n\ni\n\nf\n\nt\n\nc\n\na\n\nr\n\nd\n\n)\n\n=\n\nP(Giftcard∣Fraud)P(Fraud) P(Giftcard)\n\nRemembe..."
          ],
          [
           ")\n\n=\n\n60%\n\n10% 10%\n\n=\n\n60\n\n%\n\nThe beauty of this is that your work on measuring fraudulent orders is..."
          ],
          [
           "P\n\n(\n\nA\n\n∩\n\nB\n\n)\n\n=\n\nP\n\n(\n\nB\n\n|\n\nA\n\n)\n\nP\n\n(\n\nA\n\n)\n\n. This is assuming these events are not mutually ..."
          ],
          [
           ",\n\nA 2\n\n,\n\n⋯\n\n,\n\nA n\n\n1\n\n)\n\nThis expanded version is useful in trying to solve our problem by feedin..."
          ],
          [
           "s\n\n)\n\n=\n\nP(Giftcard,Promos∣Fraud)P(Fraud) P(Giftcard,Promos)\n\nLet’s ignore the denominator for now, ..."
          ],
          [
           "G\n\n|\n\nF\n\n)\n\nP\n\n(\n\nP\n\n|\n\nF\n\n,\n\nG\n\n)\n\nNow at this point we have a conundrum: how do you measure the pr..."
          ],
          [
           "i\n\nf\n\nt\n\nc\n\na\n\nr\n\nd\n\n∣\n\nF\n\nr\n\na\n\nu\n\nd\n\n)\n\nP\n\n(\n\nP\n\nr\n\no\n\nm\n\no\n\n∣\n\nF\n\nr\n\na\n\nu\n\nd\n\n)\n\nThis would be pr..."
          ],
          [
           "a\n\nu\n\nd\n\n)\n\nP\n\n(\n\nG\n\ni\n\nf\n\nt\n\nc\n\na\n\nr\n\nd\n\n∣\n\nF\n\nr\n\na\n\nu\n\nd\n\n)\n\nP\n\n(\n\nP\n\nr\n\no\n\nm\n\no\n\n∣\n\nF\n\nr\n\na\n\nu\n\nd..."
          ],
          [
           "Multiple promos used\n\n50%\n\n30%\n\nProbability of class\n\n10%\n\n90%\n\nAt this point, you can use this info..."
          ],
          [
           "Pseudocount There is one big challenge with a Naive Bayesian Classifier, and that is the introductio..."
          ],
          [
           "0\n\nPrince\n\n75%\n\n15%\n\nNigeria\n\n85%\n\n10%\n\nNow let’s assume we want to calculate a score for ham or spa..."
          ],
          [
           "What the classes look like interacting with each other\n\nA good data source\n\nA tokenization model\n\nAn..."
          ],
          [
           "EmailObject The EmailObject class has one responsibility, which is to parse an incoming email messag..."
          ],
          [
           "class TestPlaintextEmailObject(unittest.TestCase):\n\nCLRF = \"\\n\\n\"\n\ndef setUp(self): self.plain_file ..."
          ],
          [
           "Any method that is prefixed with test_ will be treated as a test to be run.\n\nsetUp(self) is a specia..."
          ],
          [
           "not isinstance(a,b)\n\nDo note that we will not use all of these methods; they are listed here for fut..."
          ],
          [
           "@staticmethod def _single_body(part): \"\"\" Get text from part. :param part: email.Message :return: st..."
          ],
          [
           "expected = BeautifulSoup(body, 'html.parser').text\n\nactual_body = self.html_email.body()\n\nself.asser..."
          ],
          [
           "if content_type == 'text/html': return BeautifulSoup(body, 'html.parser').text elif content_type == ..."
          ],
          [
           "class TestTokenizer(unittest.TestCase): def setUp(self): self.string = \"this is a test of the emerge..."
          ],
          [
           "return re.findall(\"\\w+\", string.lower())\n\n@staticmethod\n\ndef unique_tokenizer(string):\n\nreturn set(T..."
          ],
          [
           "Storing training data\n\nBuilding a Bayesian classifier\n\nError minimization through cross\n\nvalidation\n..."
          ],
          [
           "def test_multiple_categories(self): categories = self.trainer.categories expected = set([k for k, v ..."
          ],
          [
           "def test_counts_all_at_zero(self): for cat in ['_all', 'spam', 'ham', 'scram']: self.assertEqual(sel..."
          ],
          [
           "B\n\n)\n\n= P(B∣A i )P(A i ) ∑ j P(B∣A j )P(A j )\n\nBut because we’re being naive about this, we’ve disti..."
          ],
          [
           "W n\n\n∣\n\nS\n\np\n\na\n\nm\n\n)\n\nwhich is then divided by some normalizing constant, Z. Our goal now is to bui..."
          ],
          [
           "\"\"\"\n\nCalculates score\n\n:param email: EmailObject\n\n:return: float number\n\n\"\"\"\n\nself.train()\n\ncat_tota..."
          ],
          [
           "def test_adds_up_to_one(self): trainer = self.trainer scores = list(trainer.normalized_score(self.em..."
          ],
          [
           "normalized = {cat: (aggregate / scoresum) \\ for cat, aggregate in score.items()} return normalized\n\n..."
          ],
          [
           "def preference(self): return sorted(self.categories, key=lambda cat: self.total_for(cat)) Now that w..."
          ],
          [
           "def classify(self, email):\n\nscore = self.score(email)\n\nmax_score = 0.0\n\npreference = self.preference..."
          ],
          [
           "Minimizing false positives Up until this point, our goal with making models has been to minimize err..."
          ],
          [
           "from spam_trainer import SpamTrainer\n\nfrom email_object import EmailObject\n\nprint(\"Cross Validation\"..."
          ],
          [
           "with io.open(file, 'rb') as eml_file: emails.append(EmailObject(eml_file, category=label))\n\nprint(\"D..."
          ],
          [
           "validate(trainer, emails) Last, we can analyze the other direction of the cross-validation (i.e., va..."
          ],
          [
           "Email count\n\nWord count\n\nProbability of email\n\nProbability of word\n\nSpam\n\n1,378\n\n231,472\n\n31.8%\n\n36...."
          ],
          [
           "About O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nCommunity partners\n\nAffi..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 5. Decision Trees and Random Forests Every day we make decisions. Eve..."
          ],
          [
           "When ...\n\nGet Thoughtful Machine Learning with Python now with the O’Reilly learning platform. O’Rei..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 6. Hidden Markov Models Intuition informs much of what we do: for exa..."
          ],
          [
           "Figure ...\n\nGet Thoughtful Machine Learning with Python now with the O’Reilly learning platform. O’R..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 7. Support Vector Machines In this chapter, we will set out to solve ..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 8. Neural Networks Humans are amazing pattern matchers. When we come ..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 9. Clustering Up until this point we have been solving problems of fi..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Feature selection\n\nFeature transformation\n\nEnsemble learning\n\nBootstrapping\n\nI’ll outline the benefi..."
          ],
          [
           "Press releases\n\nMedia coverage\n\nCommunity partners\n\nAffiliate program\n\nSubmit an RFP\n\nDiversity\n\nO’R..."
          ],
          [
           "Close\n\n11. Putting It Together: Conclusion - Thoughtful Machine Learning with Python [Book]\n\nSkip to..."
          ],
          [
           "Start your free trial\n\nChapter 11. Putting It Together: Conclusion Well, here we are! The end of the..."
          ],
          [
           "Supervised Supervised learning is the most common machine learning category. This is functional appr..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Blog\n\nContent sponsorship\n\nThoughtful Machine Learning with Python by Matthew Kirk\n\nBuy on Amazon\n\nB..."
          ],
          [
           "aggregation (see bagging)Brown Corpus, Part-of-Speech Tagging with the Brown Corpus-How to Make This..."
          ],
          [
           "International\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJapan\n\nDownload the O’..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\ThoughtfulML-Kirk.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\ThoughtfulML-Kirk.txt, circle",
         "marker": {
          "color": "#FF97FF",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\ThoughtfulML-Kirk.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          11.768685,
          7.1633506,
          7.2184224,
          7.137927,
          7.0341334,
          7.092851,
          7.1807947,
          7.212527,
          7.173083,
          7.2031045,
          7.1541877,
          8.657515,
          7.3176475,
          7.001468,
          7.059241,
          6.9765635,
          6.967291,
          7.0631166,
          7.029304,
          7.0917454,
          8.767964,
          9.220668,
          9.420246,
          11.529154,
          13.710714,
          9.116324,
          11.715285,
          7.933664,
          13.624929,
          7.325373,
          6.729821,
          6.7582626,
          6.76208,
          6.7338405,
          6.721091,
          6.738707,
          6.770562,
          6.780125,
          6.738136,
          6.7268825,
          6.8999176,
          6.731537,
          6.722632,
          6.93156,
          6.7640467,
          6.166384,
          5.4994173,
          5.560373,
          -5.5312123,
          5.8091955,
          5.8644843,
          5.594022,
          6.0388284,
          5.655679,
          5.9645963,
          5.5032372,
          5.35067,
          5.701755,
          6.8266683,
          5.3164554,
          5.303895,
          5.3566127,
          5.469312,
          5.525619,
          5.949924,
          5.819331,
          5.6348877,
          5.618791,
          5.5437417,
          6.867331,
          15.32639,
          11.579477,
          6.7070713,
          11.490545,
          13.622031,
          7.179996,
          11.1375675,
          13.713178,
          9.309055,
          11.707567,
          10.23067,
          11.645511,
          7.4186883,
          13.299151,
          6.8835316,
          15.327702,
          11.506164,
          8.812619,
          9.088148,
          13.703956,
          11.174196,
          7.130418,
          15.786063
         ],
         "xaxis": "x",
         "y": [
          -1.9724574,
          2.4308498,
          2.413012,
          2.3446143,
          2.3817446,
          2.3831584,
          2.716716,
          2.3940296,
          2.5044491,
          2.4718204,
          2.2252574,
          -0.0022973123,
          1.7862072,
          2.2416935,
          2.0352304,
          1.9103502,
          2.0472736,
          2.1157255,
          1.6485741,
          2.0815744,
          -0.16603945,
          -0.25238773,
          -0.69219947,
          -2.2217152,
          -4.7861795,
          -0.40418956,
          -1.9793001,
          -1.442006,
          -4.7317348,
          -2.2408128,
          -4.3486285,
          -4.3506107,
          -4.317376,
          -4.3511505,
          -4.4063077,
          -4.234885,
          -4.236371,
          -4.229993,
          -4.319819,
          -4.360812,
          -3.400708,
          -4.3637943,
          -4.317001,
          -2.2947814,
          -2.195217,
          -2.1830342,
          -2.530837,
          -2.5480077,
          -7.1071897,
          -2.5316243,
          -2.5285633,
          -2.4954314,
          -2.3842945,
          -2.6328902,
          -2.4967573,
          -2.435814,
          -2.434402,
          -2.458176,
          -3.340715,
          -2.5141208,
          -2.5426984,
          -2.469682,
          -2.4260933,
          -2.4177065,
          -2.140757,
          -2.3157165,
          -2.4531388,
          -2.4113405,
          -2.332039,
          -2.1277976,
          -5.024036,
          -1.8274095,
          6.749007,
          -1.771404,
          -4.822393,
          -0.9976436,
          -1.3717066,
          -4.850007,
          -1.2128502,
          -1.8922131,
          0.81025755,
          -1.89741,
          -0.058470838,
          -4.2176228,
          1.425298,
          -5.0244317,
          -1.707565,
          -0.35883182,
          -0.888535,
          -4.5248775,
          -2.0276349,
          -0.8542226,
          -5.1480756
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "okay hello welcome to uh week 11's lecture uh it's been a little while since we\n\ntalked about some o..."
          ],
          [
           "just as a review here what we've got is uh uh this is our typical\n\nkind of you know well anyway mach..."
          ],
          [
           "just based off the training set we can do that all right we can basically detect our error rate thin..."
          ],
          [
           "just building something in isolation what's it going to look like when it's actually working out the..."
          ],
          [
           "in a classification standpoint all right so we're doing all classification here i'll talk about regr..."
          ],
          [
           "potential threat to a system might be a one right that's a positive outcome that we positively ident..."
          ],
          [
           "okay all right all right so\n\nlet's work through an example we're talking here about intruder fraud d..."
          ],
          [
           "this is data point x right the likelihood\n\nprobability of that particular data point being spam is 5..."
          ],
          [
           "on positive and negative classification i don't think i need to read through all this let's just loo..."
          ],
          [
           "right is that because our threshold is so low right is that we\n\nhave no tolerance for potential frau..."
          ],
          [
           "according to what problem you might have right you might adjust that threshold measure right\n\nmaybe ..."
          ],
          [
           "predict true positives how often are we right okay not that good okay all right so\n\nnot so good here..."
          ],
          [
           "positive and false positive rate and those just become data points on a axis you just graph them\n\non..."
          ],
          [
           "it's much more kind of oriented towards this balance between false positives\n\nand true positives oh ..."
          ],
          [
           "is sensitivity all right we talked about that um okay\n\nuh and this is just one minus specificity all..."
          ],
          [
           "then penalizing you if you're not doing that well so i would i would certainly consider that\n\nespeci..."
          ],
          [
           "of one can be expected you know your case when our model gives us less than a forty percent\n\nprobabi..."
          ],
          [
           "know that's not super useful but it is really good for multi-class models\n\nall right and it and it w..."
          ],
          [
           "amongst all three of these all right so almost perfect agreement right so if we assume here we do a\n..."
          ],
          [
           "basically just the detection rate but in multi-class samples it works really well right so you can s..."
          ],
          [
           "the standard ones that i think a lot of people are familiar with mean squared error right that's jus..."
          ],
          [
           "one does all right is it just normalizes all right that root mean squared error\n\nby dividing it by t..."
          ],
          [
           "that's not quite as bad right so it helps put that into context that's what this does here it's all ..."
          ],
          [
           "all right that is the data grows all right it's not heavily dependent on a large number of covariate..."
          ],
          [
           "is under fit so here we have high bias okay and low variance\n\nso that's what we see down here all ri..."
          ],
          [
           "it right it probably goes out to this second rim all right but it's not that far off\n\nsomething like..."
          ],
          [
           "discussing here all right but it also kind of is an extension all right of that all right so i just\n..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\Week7-lecture.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\Week7-lecture.txt, circle",
         "marker": {
          "color": "#FECB52",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\Week7-lecture.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          10.166277,
          6.6173744,
          6.682682,
          7.2747865,
          7.757846,
          7.8410425,
          7.63057,
          7.8384547,
          7.814367,
          7.6952863,
          7.674007,
          7.78166,
          7.758721,
          7.768629,
          7.851988,
          7.527283,
          7.721959,
          7.3743105,
          7.6838436,
          7.4158344,
          6.9084024,
          6.594483,
          5.58754,
          4.9507575,
          5.5031247,
          7.0880284,
          6.9717007
         ],
         "xaxis": "x",
         "y": [
          -0.44562447,
          5.441568,
          5.2350035,
          5.8066154,
          5.7009826,
          5.7179666,
          5.8240776,
          5.7102103,
          5.795211,
          5.9685383,
          5.720611,
          5.7373013,
          5.7393827,
          5.7620206,
          5.7596755,
          5.636076,
          5.8372297,
          6.09577,
          5.983443,
          5.8179913,
          6.463605,
          6.1235704,
          4.5067797,
          3.9261694,
          4.7316184,
          5.378583,
          3.3690948
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "okay all right so let me pop this up here\n\nbigger i can do that there we go all right so we've been ..."
          ],
          [
           "have a leaf node or terminal node kind of the same thing it has one node coming in one edge and then..."
          ],
          [
           "of classifying setosa right that's remember that's a type of flower\n\nthat we have there does such a ..."
          ],
          [
           "to be able to decide uh how to classify our target variable all right all right so\n\nyou know dependi..."
          ],
          [
           "here you know it might be that you know a certain person you know fifty percent will go on uh on\n\na ..."
          ],
          [
           "example to maybe a perfect classification of whether they will go on to the second date or not right..."
          ],
          [
           "whether someone will go on a second date or not all right okay all right\n\nso decision trees are hier..."
          ],
          [
           "predestined right you could have a couple of variables that are incredibly good at predicting these ..."
          ],
          [
           "individual node those individual internal leaves okay all right\n\nand it will consider every possible..."
          ],
          [
           "related to basically to information gain which is the key component to kind of\n\nunderstand how decis..."
          ],
          [
           "some pretty weighty advantages right it is simple to understand and interpret through data visualiza..."
          ],
          [
           "we'll be using to use uh use these methods in the wrong circumstances all right they do have\n\nlike a..."
          ],
          [
           "this is why you know a single decision tree depending on how good or bad your data is can be very\n\nu..."
          ],
          [
           "but until we get there we have to understand what one tree is doing before we start building forests..."
          ],
          [
           "right so we're thinking about basically this is our equation in\n\npractice here just this portion of ..."
          ],
          [
           "clumsy through that all right the idea here is that information gain is basically going to be right ..."
          ],
          [
           "what we see here is that if the answer is yes all right that two of these uh\n\ntwo of these dots stop..."
          ],
          [
           "we're gonna take the average of these two numbers right so the average of 0.8\n\n0.0 all right and we'..."
          ],
          [
           "right and then we just subtract it from one and so we get 0.54\n\nall right okay so that would basical..."
          ],
          [
           "side of the uh side of the equation okay so let's take a look at another\n\nanother example here all r..."
          ],
          [
           "variable here sunny so that resulted in one yes all right all right\n\nand uh two nodes two nodes all ..."
          ],
          [
           "going to be 0 right okay and then we're going to subtract it by 1. so we're going to get all right 0..."
          ],
          [
           "perfectly terrible example all right so here what we see is we have perfect disagreement okay\n\nregar..."
          ],
          [
           "the same idea about net gain all right so pi in this equation just represents\n\nthe probability that ..."
          ],
          [
           "we see is you know kind of a a genie index here we're subtracting this from one that's\n\nbasically po..."
          ],
          [
           "mean squared error is how it's done if you were doing um if we were doing a continuous\n\nreducing bas..."
          ],
          [
           "kind of a pure split between this is this is pregnant and\n\nthat's the other way around sorry not pre..."
          ],
          [
           "at least you know 10 data points in every node all right so that would avoid kind of\n\nover spitting ..."
          ],
          [
           "are available all right are ones that have not been used uh anywhere higher all right\n\ninside the sp..."
          ],
          [
           "just stop there because uh you know the decision space is pretty low all right\n\nokay so the we talke..."
          ],
          [
           "anyway that's that that's there's let's assume that there's 24 dots here or something like that and ..."
          ],
          [
           "uh we talked about that a little bit we're gonna talk much more about that next week but that's basi..."
          ],
          [
           "visualization and they're intuitive so they can be useful for all those all those types of reasons b..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\Week9-lecture.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\Week9-lecture.txt, circle",
         "marker": {
          "color": "#636efa",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\Week9-lecture.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          5.943055,
          6.224592,
          6.4876575,
          6.6287704,
          6.775573,
          6.688517,
          6.281117,
          6.4722223,
          6.268499,
          5.966231,
          5.9438934,
          5.817843,
          5.7656655,
          6.0586643,
          7.086982,
          7.060508,
          7.1455307,
          6.946397,
          7.073907,
          6.6761823,
          7.1066794,
          7.164381,
          7.238767,
          7.0979915,
          7.012338,
          6.672426,
          6.225997,
          6.1071286,
          6.510598,
          6.134666,
          5.9276705,
          5.9015126,
          6.726051
         ],
         "xaxis": "x",
         "y": [
          6.906154,
          6.676898,
          6.737655,
          6.5272555,
          6.8932,
          6.8784504,
          6.8852434,
          6.9451985,
          6.921834,
          6.89224,
          6.816133,
          5.9275765,
          6.814287,
          6.903271,
          7.0871444,
          7.071271,
          6.9943337,
          7.103215,
          7.1349196,
          7.1234493,
          7.1482854,
          7.038342,
          6.998463,
          7.100186,
          7.1163263,
          6.895249,
          6.6621013,
          6.4534984,
          6.8513155,
          5.9974256,
          4.9033623,
          6.7024126,
          3.650007
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "What is a decision tree?"
          ]
         ],
         "hovertemplate": "source=User query<br>symbol=star<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "User query, star",
         "marker": {
          "color": "black",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           100
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "diamond"
         },
         "mode": "markers",
         "name": "User query, star",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          5.894196
         ],
         "xaxis": "x",
         "y": [
          6.925725
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 700,
        "legend": {
         "itemsizing": "constant",
         "title": {
          "text": "<b>Chunk source</b>"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "<b>2D Projection of Chunk Embeddings via PaCMAP</b>"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# vistualize pca projection\n",
    "\n",
    "df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"x\": documents_projected[i, 0],\n",
    "            \"y\": documents_projected[i, 1],\n",
    "            \"source\": docs_processed[i].metadata[\"source\"],#[\"source\"],#.split(\"/\")[1],\n",
    "            \"extract\": docs_processed[i].page_content[:100] + \"...\",\n",
    "            \"symbol\": \"circle\",\n",
    "            \"size_col\": 4,\n",
    "        }\n",
    "        for i in range(len(docs_processed))\n",
    "    ]\n",
    "    + [\n",
    "        {\n",
    "            \"x\": documents_projected[-1, 0],\n",
    "            \"y\": documents_projected[-1, 1],\n",
    "            \"source\": \"User query\",\n",
    "            \"extract\": user_query,\n",
    "            \"size_col\": 100,\n",
    "            \"symbol\": \"star\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Visualize the embedding\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"source\",\n",
    "    hover_data=\"extract\",\n",
    "    size=\"size_col\",\n",
    "    symbol=\"symbol\",\n",
    "    color_discrete_map={\"User query\": \"black\"},\n",
    "    width=1000,\n",
    "    height=700,\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(opacity=1, line=dict(width=0, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "fig.update_layout(\n",
    "    legend_title_text=\"<b>Chunk source</b>\",\n",
    "    title=\"<b>2D Projection of Chunk Embeddings via PaCMAP</b>\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
