{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "from tqdm.notebook import tqdm #progress bar\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Tuple #type hinting\n",
    "# from datasets import Dataset #to load in premade example datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)  # This will be helpful when visualizing retriever outputs\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter #splitter\n",
    "\n",
    "#langsmith setup\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "#load in Documents\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter #alt import\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# embedding and searching\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "#plotting\n",
    "import pacmap\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "#for langsmith tracing\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commands to run in shell to set up environment variables (gitbash works best)\n",
    "\n",
    "# export LANGCHAIN_TRACING_V2=true\n",
    "# export LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "# export LANGCHAIN_API_KEY= ***replace with apikey***\n",
    "# LANGCHAIN_API_KEY = os.getenv('LANGCHAIN_API_KEY') # to get api key from .env file\n",
    "# LANGCHAIN_API_KEY\n",
    "# export LANGCHAIN_PROJECT=\"IA-Higher-Ed\"\n",
    "\n",
    "# export OPENAI_API_KEY= ***replace with apikey***\n",
    "# OPENAI_API_KEY = os.getenv('OPEN_AI_KEY') # to get api key from .env file\n",
    "# OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from langsmith import traceable\n",
    "\n",
    "# Auto-trace LLM calls in-context\n",
    "client = wrap_openai(openai.Client(api_key=os.getenv(\"OPEN_AI_KEY\")))\n",
    "\n",
    "@traceable # Auto-trace this function\n",
    "def pipeline(user_input: str):\n",
    "    result = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": user_input}],\n",
    "        model=\"gpt-3.5-turbo\"\n",
    "    )\n",
    "    return result.choices[0].message.content\n",
    "\n",
    "pipeline(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wat6sv\\AppData\\Local\\miniconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning:\n",
      "\n",
      "`resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    multi_process=True,\n",
    "    # model_kwargs={\"device\": \"cuda\"}, #using cpu when running locally - change if connecting to GPU for more speed\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
    ")\n",
    "\n",
    "db = FAISS.load_local(\"faiss_index\", embeddings=embedding_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed a user query in the same space\n",
    "user_query = \"How do I use pandas?\"\n",
    "query_vector = embedding_model.embed_query(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wat6sv\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pacmap\\pacmap.py:822: UserWarning:\n",
      "\n",
      "Warning: random state is set to 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create pca projection of embeddings for visualization\n",
    "\n",
    "embedding_projector = pacmap.PaCMAP(n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0, random_state=1)\n",
    "\n",
    "embeddings_2d = [\n",
    "    list(db.index.reconstruct_n(idx, 1)[0]) for idx in range(db.index.ntotal)\n",
    "] + [query_vector]\n",
    "\n",
    "# Fit the data (the index of transformed data corresponds to the index of the original data)\n",
    "documents_projected = embedding_projector.fit_transform(np.array(embeddings_2d), init=\"pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Chapter 1: Introducing Active Machine Learning - Active Machine Learning with Python [Book]\n\nSkip to..."
          ],
          [
           "Get Active Machine Learning with Python now with the O’Reilly learning platform. O’Reilly members ex..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n2 Designing Query Strategy Frameworks Query strategies act as the engine that..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Answers\n\nInsights reporting\n\nBlog\n\nContent sponsorship\n\nActive Machine Learning with Python by Marga..."
          ],
          [
           "Affiliate program\n\nSubmit an RFP\n\nDiversity\n\nO’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletter..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Start your free trial\n\nAbout O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nC..."
          ],
          [
           "Close\n\nChapter 5: Leveraging Active Learning for Big Data - Active Machine Learning with Python [Boo..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n6 Evaluating and Enhancing Efficiency In this chapter, we will explore the im..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Answers\n\nInsights reporting\n\nBlog\n\nContent sponsorship\n\nActive Machine Learning with Python by Marga..."
          ],
          [
           "Submit an RFP\n\nDiversity\n\nO’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\n..."
          ],
          [
           "Sign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividuals\n\nFeatures\n\nAll fea..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\ActiveMLwithPython-Masson-Forsythe.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\ActiveMLwithPython-Masson-Forsythe.txt, circle",
         "marker": {
          "color": "#EF553B",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\ActiveMLwithPython-Masson-Forsythe.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          10.976603,
          11.605432,
          10.838165,
          10.640253,
          15.477656,
          10.733465,
          14.139782,
          10.976263,
          14.5805025,
          10.736508,
          10.993582,
          10.820453,
          15.353717,
          10.725722,
          14.60446,
          10.897164
         ],
         "xaxis": "x",
         "y": [
          -1.5890224,
          -2.8305285,
          -1.8028445,
          -1.4933574,
          -4.9574676,
          -1.3531333,
          -4.6672263,
          -1.4703276,
          -4.77334,
          -1.5471423,
          -1.6348835,
          -1.5378293,
          -4.940065,
          -1.6039099,
          -4.7762275,
          -1.576185
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "1. The Machine Learning Landscape - Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFl..."
          ],
          [
           "Start your free trial\n\nChapter 1. The Machine Learning Landscape When most people hear “Machine Lear..."
          ],
          [
           "Then we will look at the workflow of a typical ML project, discuss the main challenges you may face,..."
          ],
          [
           "Your spam filter is a Machine Learning program that, given examples of spam emails (e.g., flagged by..."
          ],
          [
           "You would test your program and repeat steps 1 and 2 until it was good enough to launch.\n\nFigure 1\n\n..."
          ],
          [
           "Figure 1-2. The Machine Learning approach\n\nFigure 1-3. Automatically adapting to change\n\nAnother are..."
          ],
          [
           "Problems for which existing solutions require a lot of fine-tuning or long lists of rules: one Machi..."
          ],
          [
           "Creating a chatbot or a personal assistant\n\nThis involves many NLP components, including natural lan..."
          ],
          [
           "Recommending a product that a client may be interested in, based on past purchases\n\nThis is a recomm..."
          ],
          [
           "These criteria are not exclusive; you can combine them in any way you like. For example, a state-of-..."
          ],
          [
           "Figure 1-5. A labeled training set for spam classification (an example of supervised learning)\n\nA ty..."
          ],
          [
           "k\n\nNearest Neighbors\n\nLinear Regression\n\nLogistic Regression\n\nSupport Vector Machines (SVMs)\n\nDecisi..."
          ],
          [
           "t-Distributed Stochastic Neighbor Embedding (t-SNE)\n\nAssociation rule learning\n\nApriori\n\nEclat\n\nFor ..."
          ],
          [
           "Figure 1-9. Example of a t-SNE visualization highlighting semantic clusters3\n\nA related task is dime..."
          ],
          [
           "Yet another important unsupervised task is anomaly detection—for example, detecting unusual credit c..."
          ],
          [
           "Semisupervised learning Since labeling data is usually time-consuming and costly, you will often hav..."
          ],
          [
           "Reinforcement Learning Reinforcement Learning is a very different beast. The learning system, called..."
          ],
          [
           "Batch and Online Learning Another criterion used to classify Machine Learning systems is whether or ..."
          ],
          [
           "If you have a lot of data and you automate your system to train from scratch every day, it will end ..."
          ],
          [
           "Figure 1-13. In online learning, a model is trained and launched into production, and then it keeps ..."
          ],
          [
           "One important parameter of online learning systems is how fast they should adapt to changing data: t..."
          ],
          [
           "Instance-Based Versus Model-Based Learning One more way to categorize Machine Learning systems is by..."
          ],
          [
           "Figure 1\n\n15. Instance\n\nbased learning\n\nModel-based learning Another way to generalize from a set of..."
          ],
          [
           "Let’s plot the data for these countries (Figure 1-17).\n\nFigure 1-17. Do you see a trend here?\n\nThere..."
          ],
          [
           "Figure 1-18. A few possible linear models\n\nBefore you can use your model, you need to define the par..."
          ],
          [
           "Now the model fits the training data as closely as possible (for a linear model), as you can see in ..."
          ],
          [
           "encoding='latin1', na_values=\"n/a\")\n\n# Prepare the data country_stats = prepare_country_stats(oecd_b..."
          ],
          [
           "# Train the model\n\nmodel.fit(X, y)\n\n# Make a prediction for Cyprus X_new = [[22587]]  # Cyprus's GDP..."
          ],
          [
           "You studied the data.\n\nYou selected a model.\n\nYou trained it on the training data (i.e., the learnin..."
          ],
          [
           "The Unreasonable Effectiveness of Data In a famous paper published in 2001, Microsoft researchers Mi..."
          ],
          [
           "Figure 1-21. A more representative training sample\n\nIf you train a linear model on this data, you ge..."
          ],
          [
           "First, to obtain the addresses to send the polls to, the Literary Digest used telephone directories,..."
          ],
          [
           "If some instances are clearly outliers, it may help to simply discard them or try to fix the errors ..."
          ],
          [
           "Creating new features by gathering new data\n\nNow that we have looked at many examples of bad data, l..."
          ],
          [
           "Figure 1-22. Overfitting the training data\n\nComplex models such as deep neural networks can detect s..."
          ],
          [
           "Gather more training data.\n\nReduce the noise in the training data (e.g., fix data errors and remove ..."
          ],
          [
           "You can see that regularization forced the model to have a smaller slope: this model does not fit th..."
          ],
          [
           "Reduce the constraints on the model (e.g., reduce the regularization hyperparameter).\n\nStepping Back..."
          ],
          [
           "Testing and Validating The only way to know how well a model will generalize to new cases is to actu..."
          ],
          [
           "Hyperparameter Tuning and Model Selection Evaluating a model is simple enough: just use a test set. ..."
          ],
          [
           "More specifically, you train multiple models with various hyperparameters on the reduced training se..."
          ],
          [
           "Data Mismatch In some cases, it’s easy to get a large amount of data for training, but this data pro..."
          ],
          [
           "After the model is trained (on the training set, not on the train-dev set), you can evaluate it on t..."
          ],
          [
           "No Free Lunch Theorem A model is a simplified version of the observations. The simplifications are m..."
          ],
          [
           "What is a labeled training set?\n\nWhat are the two most common supervised tasks?\n\nCan you name four c..."
          ],
          [
           "What can go wrong if you tune hyperparameters using the test set?\n\nSolutions to these exercises are ..."
          ],
          [
           "It’s just boring pandas code that joins the life satisfaction data from the OECD with the GDP per ca..."
          ],
          [
           "Support\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAust..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Fine\n\ntune your model.\n\nPresent your solution.\n\nLaunch, monitor, and maintain your system.\n\nWorking ..."
          ],
          [
           "Start your free trial\n\nAbout O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nC..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 3. Classification In Chapter 1 I mentioned that the most common super..."
          ],
          [
           "A DESCR key describing the dataset\n\nA data key containing an array with one ...\n\nGet Hands-On Machin..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "Start your free trial\n\nChapter 4. Training Models So far we have treated Machine Learning models and..."
          ],
          [
           "Using an iterative optimization approach called Gradient Descent (GD) that gradually tweaks the mode..."
          ],
          [
           "Linear Regression In Chapter 1 we looked at a simple regression model of life satisfaction: life_sat..."
          ],
          [
           "In this equation:\n\nθ is the model’s parameter vector, containing the bias term θ0 and the feature we..."
          ],
          [
           "OK, that’s the Linear Regression model—but how do we train it? Well, recall that training a model me..."
          ],
          [
           "The Normal Equation To find the value of θ that minimizes the cost function, there is a closed-form ..."
          ],
          [
           "Now let’s compute θ^ using the Normal Equation. We will use the inv() function from NumPy’s linear a..."
          ],
          [
           "we used to generate the data is y = 4 + 3x1 + Gaussian noise. Let’s see what the equation found: >>>..."
          ],
          [
           "original function. Now we can make predictions using θ^: >>> X_new = np.array([[0], [2]]) >>> X_new_..."
          ],
          [
           "y, \"b.\") plt.axis([0, 2, 0, 15]) plt.show()..."
          ],
          [
           "Figure 4-2. Linear Regression model predictions..."
          ],
          [
           "Performing Linear Regression using Scikit-Learn is simple:2 >>> from sklearn.linear_model import Lin..."
          ],
          [
           "you could call directly: >>> theta_best_svd, residuals, rank, s = np.linalg.lstsq(X_b, y, rcond=1e-6..."
          ],
          [
           "The pseudoinverse itself is computed using a standard matrix factorization technique called Singular..."
          ],
          [
           "then it replaces all the nonzero values with their inverse, and finally it transposes the resulting ..."
          ],
          [
           "This approach is more efficient than computing the Normal Equation, plus it handles edge cases nicel..."
          ],
          [
           "Also, once you have trained your Linear Regression model (using the Normal Equation or any other alg..."
          ],
          [
           "Figure 4-3. In this depiction of Gradient Descent, the model parameters are initialized randomly and..."
          ],
          [
           "Figure 4\n\n6. Gradient Descent pitfalls\n\nFortunately, the MSE cost function for a Linear Regression m..."
          ],
          [
           "This diagram also illustrates the fact that training a model means searching for a combination of mo..."
          ],
          [
           "θ ⊺\n\nx (i)\n\ny (i)\n\n)\n\nx j (i)\n\nInstead of computing these partial derivatives individually, you can ..."
          ],
          [
           "2 m\n\nX ⊺\n\n(\n\nX\n\nθ\n\ny\n\n)\n\nWarning Notice that this formula involves calculations over the full traini..."
          ],
          [
           "theta = np.random.randn(2,1)  # random initialization\n\nfor iteration in range(n_iterations): gradien..."
          ],
          [
           "Figure 4-8. Gradient Descent with various learning rates\n\nOn the left, the learning rate is too low:..."
          ],
          [
           "Stochastic Gradient Descent The main problem with Batch Gradient Descent is the fact that it uses th..."
          ],
          [
           "Figure 4-9. With Stochastic Gradient Descent, each training step is much faster but also much more s..."
          ],
          [
           "theta = np.random.randn(2,1)  # random initialization\n\nfor epoch in range(n_epochs): for i in range(..."
          ],
          [
           "Figure 4-10. The first 20 steps of Stochastic Gradient Descent\n\nNote that since instances are picked..."
          ],
          [
           "To perform Linear Regression using Stochastic GD with Scikit-Learn, you can use the SGDRegressor cla..."
          ],
          [
           "Mini-batch Gradient Descent The last Gradient Descent algorithm we will look at is called Mini-batch..."
          ],
          [
           "Figure 4-11. Gradient Descent paths in parameter space\n\nLet’s compare the algorithms we’ve discussed..."
          ],
          [
           "SGDRegressor\n\nNote There is almost no difference after training: all these algorithms end up with ve..."
          ],
          [
           "Figure 4-12. Generated nonlinear and noisy dataset\n\nClearly, a straight line will never fit this dat..."
          ],
          [
           "0.56\n\nx 1  2\n\n+\n\n0.93\n\nx 1\n\n+\n\n1.78\n\nwhen in fact the original function was\n\ny\n\n=\n\n0.5\n\nx 1  2\n\n+\n\n1..."
          ],
          [
           "Learning Curves If you perform high-degree Polynomial Regression, you will likely fit the training d..."
          ],
          [
           "Figure 4\n\n14. High\n\ndegree Polynomial Regression\n\nThis high-degree Polynomial Regression model is se..."
          ],
          [
           "def plot_learning_curves(model, X, y): X_train, X_val, y_train, y_val = train_test_split(X, y, test_..."
          ],
          [
           "Figure 4\n\n15. Learning curves\n\nThis model that’s underfitting deserves a bit of explanation. First, ..."
          ],
          [
           "polynomial_regression = Pipeline([\n\n(\"poly_features\", PolynomialFeatures(degree=10, include_bias=Fal..."
          ],
          [
           "Variance\n\nThis part is due to the model’s excessive sensitivity to small variations in the training ..."
          ],
          [
           "Ridge Regression Ridge Regression (also called Tikhonov regularization) is a regularized version of ..."
          ],
          [
           "The hyperparameter α controls how much you want to regularize the model. If α = 0, then Ridge Regres..."
          ],
          [
           "Figure 4-17. A linear model (left) and a polynomial model (right), both with various levels of Ridge..."
          ],
          [
           "θ ^\n\n=\n\n(X ⊺ X+αA)\n\n1\n\nX ⊺\n\ny\n\nHere is how to perform Ridge Regression with Scikit-Learn using a clo..."
          ],
          [
           "Lasso Regression Least Absolute Shrinkage and Selection Operator Regression (usually simply called L..."
          ],
          [
           "Figure 4-18. A linear model (left) and a polynomial model (right), both using various levels of Lass..."
          ],
          [
           "The small white circles show the path that Gradient Descent takes to optimize some model parameters ..."
          ],
          [
           "The Lasso cost function is not differentiable at θi = 0 (for i = 1, 2, ⋯, n), but Gradient Descent s..."
          ],
          [
           "Elastic Net Elastic Net is a middle ground between Ridge Regression and Lasso Regression. The regula..."
          ],
          [
           "Early Stopping A very different way to regularize iterative learning algorithms such as Gradient Des..."
          ],
          [
           "(\"std_scaler\", StandardScaler())\n\n])\n\nX_train_poly_scaled = poly_scaler.fit_transform(X_train)\n\nX_va..."
          ],
          [
           "Logistic Regression As we discussed in Chapter 1, some regression algorithms can be used for classif..."
          ],
          [
           "Equation 4\n\n14. Logistic function\n\nσ\n\n(\n\nt\n\n)\n\n=\n\n1 1+exp(\n\nt)\n\nFigure 4\n\n21. Logistic function\n\nOnc..."
          ],
          [
           "Training and Cost Function Now you know how a Logistic Regression model estimates probabilities and ..."
          ],
          [
           "Logistic Regression cost function (log loss)J(θ)=-1m∑i=1my(i)logp^(i)+(1-y(i))log1-p^(i) The bad new..."
          ],
          [
           "Decision Boundaries Let’s use the iris dataset to illustrate Logistic Regression. This is a famous d..."
          ],
          [
           "log_reg = LogisticRegression() log_reg.fit(X, y) Let’s look at the model’s estimated probabilities f..."
          ],
          [
           "Figure 4-23. Estimated probabilities and decision boundary\n\nThe petal width of Iris virginica flower..."
          ],
          [
           "Note that it is a linear boundary.16 Each parallel line represents the points where the model output..."
          ],
          [
           "(\n\nx\n\n)\n\n=\n\n(θ (k) ) ⊺\n\nx\n\nNote that each class has its own dedicated parameter vector θ(k). All the..."
          ],
          [
           "y ^\n\n=\n\nargmax k\n\nσ\n\ns(x) k\n\n=\n\nargmax k\n\ns k\n\n(\n\nx\n\n)\n\n=\n\nargmax k\n\n(θ (k) ) ⊺\n\nx\n\nThe argmax opera..."
          ],
          [
           "yk(i) is the target probability that the ith instance belongs to class k. In general, it is either e..."
          ],
          [
           "∇ θ (k)\n\nJ\n\n(\n\nΘ\n\n)\n\n=\n\n1 m\n\n∑ i=1 m\n\np ^ k (i)\n\ny k (i)\n\nx (i)\n\nNow you can compute the gradient ve..."
          ],
          [
           "softmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=10) softmax_reg.fit(X, ..."
          ],
          [
           "Exercises\n\nWhich Linear Regression training algorithm can you use if you have a training set with mi..."
          ],
          [
           "Lasso instead of Ridge Regression?\n\nElastic Net instead of Lasso?\n\nSuppose you want to classify pict..."
          ],
          [
           "Implement Batch Gradient Descent with early stopping for Softmax Regression (without using Scikit-Le..."
          ],
          [
           "Stochastic Average GD is a variant of Stochastic GD. For more details, see the presentation “Minimiz..."
          ],
          [
           "O’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nl..."
          ],
          [
           "Close\n\n5. Support Vector Machines - Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFl..."
          ],
          [
           "Linear SVM Classification The fundamental idea behind SVMs is best explained with some pictures. Fig..."
          ],
          [
           "Newsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\n..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Start your free trial\n\nChapter 6. Decision Trees Like SVMs, Decision Trees are versatile Machine Lea..."
          ],
          [
           "Get Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition now with the O’R..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 7. Ensemble Learning and Random Forests Suppose you pose a complex qu..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 8. Dimensionality Reduction Many Machine Learning problems involve th..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 9. Unsupervised Learning Techniques Although most of the applications..."
          ],
          [
           "As a result, the labeled dataset will be quite small, ...\n\nGet Hands-On Machine Learning with Scikit..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nChapter 10. Introduction to Artificial Neural Networks with Keras Birds inspi..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 11. Training Deep Neural Networks In Chapter 10 we introduced artific..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 12. Custom Models and Training with TensorFlow Up until now, we’ve us..."
          ],
          [
           "A Quick Tour of TensorFlow As you know, TensorFlow is a powerful library for numerical ...\n\nGet Hand..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nChapter 13. Loading and Preprocessing Data with TensorFlow So far we have use..."
          ],
          [
           "These need to be encoded, for example using one-hot encoding, bag-of-words encoding, ...\n\nGet Hands-..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nChapter 14. Deep Computer Vision Using Convolutional Neural Networks Although..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 15. Processing Sequences Using RNNs and CNNs The batter hits the ball..."
          ],
          [
           "A (very) limited ...\n\nGet Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Ed..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 16. Natural Language Processing with RNNs and Attention When Alan Tur..."
          ],
          [
           "This will allow us to generate some original text, and in the process we ...\n\nGet Hands-On Machine L..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nChapter 17. Representation Learning and Generative Learning Using Autoencoder..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 18. Reinforcement Learning Reinforcement Learning (RL) is one of the ..."
          ],
          [
           "In this chapter we will first explain what Reinforcement Learning is and what it’s good at, then pre..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nChapter 19. Training and Deploying TensorFlow Models at Scale Once you have a..."
          ],
          [
           "If you use the cloud platform, you will also get many ...\n\nGet Hands-On Machine Learning with Scikit..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nAppendix A. Exercise Solutions Note Solutions to the coding exercises are ava..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nAppendix B. Machine Learning Project Checklist This checklist can guide you t..."
          ],
          [
           "Get the Data Note: automate as much as possible so you can easily get fresh data.\n\nList the data you..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Appendix C. SVM Dual Problem To understand duality, you first need to understand the Lagrange multip..."
          ],
          [
           "2y, subject to an equality constraint: 3x + 2y + 1 = 0. Using the Lagrange multipliers method, we st..."
          ],
          [
           "called a Lagrange multiplier. Joseph-Louis Lagrange showed that if (x^,y^) is a solution to the cons..."
          ],
          [
           "regard to x, y, and α; we can find the points where these derivatives are all equal to zero; and the..."
          ],
          [
           "2\n\nx ^\n\n3\n\nα ^\n\n=\n\n2\n\n2\n\nα ^\n\n=\n\n3\n\nx ^\n\n2\n\nGet Hands-On Machine Learning with Scikit-Learn, Keras, ..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "The derivative of a constant is 0.\n\nThe derivative of λx is λ (where λ is a constant).\n\nThe derivati..."
          ],
          [
           "0\n\n=\n\nx 2\n\n+\n\n1\n\nThis approach can ...\n\nGet Hands-On Machine Learning with Scikit-Learn, Keras, and ..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "Hopfield Networks Hopfield networks were first introduced by W. A. Little in 1974, then popularized ..."
          ],
          [
           "logo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJ..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Strings Tensors can hold byte strings, which is useful in particular for natural language processing..."
          ],
          [
           "The tf.strings package contains several functions to manipulate string tensors, such as length() to ..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "TF Functions and Concrete Functions TF Functions are polymorphic, meaning they support inputs of dif..."
          ],
          [
           "Such a combination of argument types and shapes is called an input signature. If you call the TF Fun..."
          ],
          [
           "But it will generate a new concrete function if you call tf_cube(tf.constant([2.0])) or tf_cube(tf.c..."
          ],
          [
           "method. It can then be called like a regular function, but it will only support one input signature ..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\HandsOnML-Geron.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\HandsOnML-Geron.txt, circle",
         "marker": {
          "color": "#00cc96",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\HandsOnML-Geron.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          10.659753,
          8.442203,
          8.473508,
          5.890921,
          5.6179266,
          7.65473,
          7.6331153,
          7.6562743,
          7.7750497,
          7.0297995,
          6.9035845,
          6.8855133,
          6.7576647,
          6.93391,
          6.8641534,
          6.6769395,
          7.787769,
          6.9322815,
          7.3644094,
          7.1330924,
          7.0699754,
          6.367723,
          5.6341133,
          3.732976,
          3.6746564,
          3.666504,
          2.2902613,
          3.6651058,
          7.9841747,
          5.9568343,
          4.9333572,
          5.9699197,
          6.3627687,
          6.2788224,
          5.2342057,
          4.607421,
          4.1641917,
          5.251712,
          4.962042,
          4.562778,
          4.68091,
          5.366308,
          4.934702,
          8.023441,
          8.068948,
          5.3178687,
          8.981534,
          13.80311,
          9.978067,
          6.8392496,
          14.575842,
          10.822139,
          8.03618,
          8.474332,
          13.160406,
          10.789345,
          7.99794,
          4.413638,
          4.0133796,
          3.438887,
          4.129818,
          3.500307,
          3.5314775,
          2.836828,
          3.2375286,
          -7.3460646,
          3.5955307,
          2.6496825,
          3.3503413,
          3.009636,
          3.248218,
          3.4650545,
          4.172674,
          4.4242015,
          4.4924607,
          4.395686,
          3.719362,
          4.0596995,
          4.1052446,
          4.4408836,
          4.451382,
          4.4077516,
          4.355392,
          4.3753004,
          3.9257276,
          4.3820257,
          4.194492,
          3.064658,
          1.6894389,
          0.62021035,
          2.2770758,
          2.5365553,
          1.7659212,
          2.3966932,
          2.03736,
          4.1450453,
          3.942714,
          4.121345,
          4.070801,
          3.6364775,
          4.2290807,
          4.16055,
          4.258761,
          3.8458269,
          4.1206,
          4.664611,
          -1.2984746,
          2.8609045,
          3.000082,
          3.489827,
          4.2947993,
          1.889696,
          1.9686279,
          2.4218917,
          2.436127,
          2.794086,
          2.7596345,
          2.9569244,
          2.6173873,
          2.457137,
          4.343877,
          4.7245936,
          4.1714754,
          4.4220676,
          14.2666855,
          8.785281,
          0.88008535,
          13.927927,
          10.761225,
          -0.34142613,
          10.715636,
          13.079111,
          9.535637,
          10.745926,
          7.5659337,
          10.721082,
          7.1826243,
          10.358932,
          13.209101,
          9.815403,
          13.084257,
          9.649503,
          13.057188,
          9.566857,
          10.203988,
          13.19505,
          8.348749,
          6.8297496,
          13.20678,
          9.892929,
          10.353158,
          9.7637205,
          10.629581,
          13.081331,
          9.489519,
          10.601379,
          13.244061,
          8.32187,
          13.104891,
          9.442801,
          9.958538,
          13.087492,
          7.768506,
          10.221085,
          13.034169,
          7.4848127,
          13.073387,
          8.078829,
          10.299587,
          13.120448,
          2.0645056,
          3.299995,
          3.484728,
          3.5649958,
          9.768217,
          13.157321,
          9.937347,
          3.2689483,
          10.521256,
          13.091709,
          9.903119,
          9.572715,
          14.135143,
          9.777292,
          -4.948591,
          -4.885079,
          13.203613,
          10.494974,
          -4.7308517,
          -5.0342603,
          -5.032405,
          -4.7436924,
          13.204542
         ],
         "xaxis": "x",
         "y": [
          0.53022826,
          -0.1314597,
          -0.12828071,
          -0.3480555,
          -0.63773793,
          0.7800975,
          0.651202,
          0.61160606,
          0.65703964,
          0.75508076,
          0.29519826,
          0.5281471,
          0.7137632,
          0.90166456,
          1.0023084,
          0.5335602,
          0.71920484,
          0.63581663,
          1.51011,
          1.3482319,
          1.5447979,
          -0.016530003,
          2.4468493,
          3.1522448,
          4.6469274,
          3.454385,
          3.3244805,
          3.3258157,
          0.12261604,
          2.2057598,
          2.9254062,
          2.0810187,
          1.7992997,
          2.039891,
          2.9972832,
          3.510694,
          4.224336,
          3.543314,
          3.5247612,
          3.7850168,
          3.713715,
          3.8088217,
          3.4967885,
          0.2996351,
          0.15267459,
          2.2681274,
          -0.7684575,
          -4.75702,
          -0.21047142,
          1.8358783,
          -4.766232,
          0.435867,
          -1.570274,
          -0.996456,
          -5.221159,
          0.45224273,
          0.540333,
          4.682657,
          4.8849096,
          4.668986,
          5.1761737,
          5.4021564,
          5.609784,
          4.880167,
          5.092874,
          3.127005,
          4.447775,
          4.0337496,
          5.537795,
          5.777498,
          5.8949995,
          5.7491994,
          5.310538,
          5.8134537,
          5.381556,
          5.810916,
          5.673748,
          5.6880736,
          5.7822113,
          5.801184,
          5.773454,
          5.8465767,
          5.8816395,
          5.922603,
          5.415937,
          5.835943,
          5.4925146,
          4.8950124,
          4.2144113,
          3.3835306,
          4.3430996,
          4.674174,
          4.65375,
          4.7034373,
          4.6678367,
          4.221362,
          4.6148906,
          4.8755665,
          4.9111886,
          5.1222177,
          4.878926,
          4.8529162,
          4.9631195,
          5.4487014,
          4.9489565,
          5.1118875,
          4.129863,
          3.5271893,
          3.6973708,
          4.483227,
          5.697031,
          3.3752372,
          3.4962144,
          3.4884763,
          3.6179929,
          3.512327,
          4.031084,
          3.8709748,
          2.90591,
          3.6329422,
          5.1653204,
          4.681605,
          5.2110724,
          5.759583,
          -4.681773,
          -0.9818345,
          4.8651605,
          -4.5304418,
          0.523379,
          3.6162124,
          0.16880171,
          -5.165529,
          -0.42179704,
          0.43561533,
          1.4360595,
          0.5598176,
          0.7201159,
          -0.5539802,
          -5.247098,
          1.3029054,
          -5.2077227,
          1.2283595,
          -5.2817516,
          1.1037016,
          0.85481304,
          -5.28955,
          1.562087,
          -0.39960092,
          -5.2436996,
          1.191533,
          0.8852805,
          1.3345491,
          -0.27442208,
          -5.2012467,
          1.1382357,
          -0.3839921,
          -5.225994,
          1.1916426,
          -5.2856445,
          0.9020271,
          0.6373138,
          -5.278038,
          1.5373805,
          -0.49256805,
          -5.2153196,
          0.4333143,
          -5.3145137,
          0.24374081,
          -0.60933846,
          -5.2945185,
          5.258138,
          5.7005105,
          5.5957317,
          5.60453,
          0.11583174,
          -5.21629,
          0.9034734,
          5.244275,
          -0.27285013,
          -5.2774425,
          1.2792376,
          1.1757153,
          -4.557203,
          1.2496172,
          -7.002246,
          -6.991856,
          -5.2454324,
          0.67437065,
          -6.8778687,
          -6.874168,
          -6.690291,
          -6.91271,
          -4.6452327
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "1. Introduction - Introduction to Machine Learning with Python [Book]\n\nSkip to main content\n\nSign In..."
          ],
          [
           "Outside of commercial applications, machine learning has had a tremendous influence on the way data-..."
          ],
          [
           "Designing rules requires a deep understanding of how a decision should be made by a human expert.\n\nO..."
          ],
          [
           "1.1.1 Problems Machine Learning Can Solve\n\nThe most successful kinds of machine learning algorithms ..."
          ],
          [
           "Determining whether a tumor is benign based on a medical image\n\nHere the input is the image, and the..."
          ],
          [
           "An interesting thing to note about these examples is that although the inputs and outputs look fairl..."
          ],
          [
           "Detecting abnormal access patterns to a website\n\nTo identify abuse or bugs, it is often helpful to f..."
          ],
          [
           "Each entity or row here is known as a sample (or data point) in machine learning, while the columns—..."
          ],
          [
           "What is the best way to phrase my question(s) as a machine learning problem?\n\nHave I collected enoug..."
          ],
          [
           "1.2 Why Python?\n\nPython has become the lingua franca for many data science applications. It combines..."
          ],
          [
           "1.3 scikit-learn scikit-learn is an open source project, meaning that it is free to use and distribu..."
          ],
          [
           "Anaconda\n\nA Python distribution made for large-scale data processing, predictive analytics, and scie..."
          ],
          [
           "1.4 Essential Libraries and Tools\n\nUnderstanding what scikit-learn is and how to use it is important..."
          ],
          [
           "1.4.2 NumPy\n\nNumPy is one of the fundamental packages for scientific computing in Python. It contain..."
          ],
          [
           "1.4.3 SciPy\n\nSciPy is a collection of functions for scientific computing in Python. It provides, amo..."
          ],
          [
           "# Create a 2D NumPy array with a diagonal of ones, and zeros everywhere else eye = np.eye(4) print(\"..."
          ],
          [
           "the nonzero entries are stored sparse_matrix = sparse.csr_matrix(eye) print(\"\\nSciPy sparse CSR matr..."
          ],
          [
           "way to create the same sparse matrix as before, using the COO format: In[4]: data = np.ones(4) row_i..."
          ],
          [
           "1.4.4 matplotlib matplotlib is the primary scientific plotting library in Python. It provides functi..."
          ],
          [
           "Figure 1-1. Simple line plot of the sine function using matplotlib\n\n1.4.5 pandas pandas is a Python ..."
          ],
          [
           "data_pandas = pd.DataFrame(data) # IPython.display allows \"pretty printing\" of dataframes # in the J..."
          ],
          [
           "London\n\nLinda\n\n1.4.6 mglearn\n\nThis book comes with accompanying code, which you can find on https://..."
          ],
          [
           "1.5 Python 2 Versus Python 3\n\nThere are two major versions of Python that are widely used at the mom..."
          ],
          [
           "import pandas as pd\n\nprint(\"pandas version:\", pd.__version__)\n\nimport matplotlib\n\nprint(\"matplotlib ..."
          ],
          [
           "import IPython\n\nprint(\"IPython version:\", IPython.__version__)\n\nimport sklearn print(\"scikit-learn v..."
          ],
          [
           "Now that we have everything set up, let’s dive into our first application of machine learning.\n\n1.7 ..."
          ],
          [
           "1.7.1 Meet the Data\n\nThe data we will use for this example is the Iris dataset, a classical dataset ..."
          ],
          [
           "Notes ---- Data Set Characteristics: :Number of Instances: 150 (50 in each of three classes) :Number..."
          ],
          [
           "We see that the array contains measurements for 150 different flowers. Remember that the individual ..."
          ],
          [
           "The target array contains the species of each of the flowers that were measured, also as a NumPy arr..."
          ],
          [
           "1.7.2 Measuring Success: Training and Testing Data\n\nWe want to build a machine learning model from t..."
          ],
          [
           "In scikit-learn, data is usually denoted with a capital X, while labels are denoted by a lowercase y..."
          ],
          [
           "To make sure that we will get the same output if we run the same function several times, we provide ..."
          ],
          [
           "One of the best ways to inspect data is to visualize it. One way to do this is by using a scatter pl..."
          ],
          [
           "The diagonal of this matrix is filled with histograms of each feature: In[23]: # create dataframe fr..."
          ],
          [
           "1.7.4 Building Your First Model: k-Nearest Neighbors\n\nNow we can start building the actual machine l..."
          ],
          [
           "The knn object encapsulates the algorithm that will be used to build the model from the training dat..."
          ],
          [
           "In the remainder of this book, we will not usually show the output of fit because it doesn’t contain..."
          ],
          [
           "1.7.5 Making Predictions\n\nWe can now make predictions using this model on new data for which we migh..."
          ],
          [
           "1.7.6 Evaluating the Model\n\nThis is where the test set that we created earlier comes in. This data w..."
          ],
          [
           "We can also use the score method of the knn object, which will compute the test set accuracy for us:..."
          ],
          [
           "1.8 Summary and Outlook\n\nLet’s summarize what we learned in this chapter. We started with a brief in..."
          ],
          [
           "We chose the k-nearest neighbors classification algorithm, which makes predictions for a new data po..."
          ],
          [
           "knn = KNeighborsClassifier(n_neighbors=1)\n\nknn.fit(X_train, y_train)\n\nprint(\"Test set score: {:.2f}\"..."
          ],
          [
           "Support\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAust..."
          ],
          [
           "For business\n\nFor government\n\nFor higher ed\n\nIndividuals\n\nFeatures\n\nAll features\n\nCourses\n\nCertifica..."
          ],
          [
           "2.1 Classification and Regression\n\nThere are two major types of supervised machine learning problems..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Answers\n\nInsights reporting\n\nBlog\n\nContent sponsorship\n\nIntroduction to Machine Learning with Python..."
          ],
          [
           "3.1 Types of Unsupervised Learning We will look into two kinds of unsupervised learning in this chap..."
          ],
          [
           "Contact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & N..."
          ],
          [
           "For business\n\nFor government\n\nFor higher ed\n\nIndividuals\n\nFeatures\n\nAll features\n\nCourses\n\nCertifica..."
          ],
          [
           "Start your free trial\n\nChapter 4. Representing Data and Engineering Features\n\nSo far, we’ve assumed ..."
          ],
          [
           "The question of how to represent your data best for a particular application is known as feature eng..."
          ],
          [
           "clerical\n\n<=50K\n\n1\n\n50\n\nSelf\n\nemp\n\nnot\n\ninc\n\nBachelors\n\nMale\n\n13\n\nExec\n\nmanagerial\n\n<=50K\n\n2\n\n38\n\nPr..."
          ],
          [
           "emp\n\nnot\n\ninc\n\nHS\n\ngrad\n\nMale\n\n45\n\nExec\n\nmanagerial\n\n>50K\n\n8\n\n31\n\nPrivate\n\nMasters\n\nFemale\n\n50\n\nProf..."
          ],
          [
           "Some\n\ncollege\n\nMale\n\n80\n\nExec\n\nmanagerial\n\n>50K\n\nThe task is phrased as a classification task with t..."
          ],
          [
           "4.1.1 One\n\nHot\n\nEncoding (Dummy Variables)\n\nBy far the most common way to represent categorical vari..."
          ],
          [
           "Self Employed\n\nSelf Employed Incorporated\n\nGovernment Employee\n\n1\n\n0\n\n0\n\n0\n\nPrivate Employee\n\n0\n\n1\n\n..."
          ],
          [
           "There are two ways to convert your data to a one-hot encoding of categorical variables, using either..."
          ],
          [
           "education\n\ngender\n\nhours\n\nper\n\nweek\n\noccupation\n\nincome\n\n0\n\n39\n\nState\n\ngov\n\nBachelors\n\nMale\n\n40\n\nAdm..."
          ],
          [
           "40\n\nProf\n\nspecialty\n\n<=50K\n\nChecking string\n\nencoded categorical data\n\nAfter reading a dataset like ..."
          ],
          [
           "The get_dummies function automatically transforms all columns that have object type (like strings) o..."
          ],
          [
           "Features after get_dummies: ['age', 'hours-per-week', 'workclass_ ? ', 'workclass_ Federal-gov', 'wo..."
          ],
          [
           "workclass_ Federal\n\ngov\n\nworkclass_\n\nLocal\n\ngov\n\n…\n\noccupation_ Tech\n\nsupport\n\noccupation_\n\nTranspor..."
          ],
          [
           "1.0\n\n0.0\n\n4\n\n28\n\n40\n\n0.0\n\n0.0\n\n0.0\n\n…\n\n0.0\n\n0.0\n\n1.0\n\n0.0\n\n5 rows × 46 columns We can now use the va..."
          ],
          [
           "In this case, we extract only the columns containing features—that is, all columns from age to occup..."
          ],
          [
           "In this example, we called get_dummies on a DataFrame containing both the training and the test data..."
          ],
          [
           "4.1.2 Numbers Can Encode Categoricals\n\nIn the example of the adult dataset, the categorical variable..."
          ],
          [
           "The get_dummies function in pandas treats all numbers as continuous and will not create dummy variab..."
          ],
          [
           "Categorical Feature_socks\n\n0\n\n0\n\n0.0\n\n0.0\n\n1.0\n\n1\n\n1\n\n0.0\n\n1.0\n\n0.0\n\n2\n\n2\n\n0.0\n\n0.0\n\n1.0\n\n3\n\n1\n\n1.0\n..."
          ],
          [
           "0.0\n\n0.0\n\n0.0\n\n0.0\n\n1.0\n\n1\n\n0.0\n\n1.0\n\n0.0\n\n0.0\n\n1.0\n\n0.0\n\n2\n\n0.0\n\n0.0\n\n1.0\n\n0.0\n\n0.0\n\n1.0\n\n3\n\n0.0\n\n1..."
          ],
          [
           "4.2 OneHotEncoder and ColumnTransformer: Categorical Variables with scikit-learn As mentioned before..."
          ],
          [
           "# Setting sparse=False means OneHotEncode will return a numpy array, # not a sparse matrix ohe = One..."
          ],
          [
           "transformed. As usual for scikit-learn, the output is not a DataFrame, so there are no column names...."
          ],
          [
           "and 2 of the first original feature (called x0 here), while the last three columns correspond to the..."
          ],
          [
           "This is where the ColumnTransformer class comes in handy: it allows you to apply different transform..."
          ],
          [
           "Out[12]: [cols=\",,,,,,,\",options=\"header\",] |=======================================================..."
          ],
          [
           "|53 |Private |11th |Male |40 |Handlers-cleaners |<=50K |4 |28 |Private |Bachelors |Female |40 |Prof-..."
          ],
          [
           "age and hours-per-week. This is exactly what ColumnTransformer can do for us. Each transformation in..."
          ],
          [
           "Each transformer is applied to the corresponding columns, and the result of the transformations are ..."
          ],
          [
           "ct.fit(X_train) X_train_trans = ct.transform(X_train) print(X_train_trans.shape) Out[14]: (24420, 44..."
          ],
          [
           "4.3 Convenient ColumnTransformer creation with make_columntransformer Creating a ColumnTransformer u..."
          ],
          [
           "4.4 Binning, Discretization, Linear Models, and Trees\n\nThe best way to represent data depends not on..."
          ],
          [
           "plt.plot(line, reg.predict(line), label=\"linear regression\")\n\nplt.plot(X[:, 0], y, 'o', c='k') plt.y..."
          ],
          [
           "We imagine a partition of the input range for the feature (in this case, the numbers from –3 to 3) i..."
          ],
          [
           "of the data (i.e., having smaller bins where there’s more data). Both of these strategies are implem..."
          ],
          [
           "1.155, 1.744,  2.333,  2.921])] Here, the first bin contains all data points with feature values fro..."
          ],
          [
           "per feature. This is why they are a list of length one in this case. Using transform, we can encode ..."
          ],
          [
           "In[21]: X_binned = kb.transform(X) X_binned Out[21]: <120x10 sparse matrix of type '<class 'numpy.fl..."
          ],
          [
           "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0. ], [0., 0., 0., 0., 0., 0., 0., 0., 0., 1. ], [0., 0...."
          ],
          [
           "0., 0., 0., 0., 0. ], [0., 1., 0., 0., 0., 0., 0., 0., 0., 0. ], [1., 0., 0., 0., 0., 0., 0., 0., 0...."
          ],
          [
           "[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]) We can see that the first data point with value -0.753 wa..."
          ],
          [
           "categorical feature which encodes which bin a data point is in. You can forego the one-hot-encoding ..."
          ],
          [
           "= kb.transform(X) Now we build a new linear regression model and a new decision tree model on the on..."
          ],
          [
           "reg = LinearRegression().fit(X_binned, y) plt.plot(line, reg.predict(line_binned), label='linear reg..."
          ],
          [
           "reg = DecisionTreeRegressor(min_samples_split=3).fit(X_binned, y) plt.plot(line, reg.predict(line_bi..."
          ],
          [
           "If there are good reasons to use a linear model for a particular dataset—say, because it is very lar..."
          ],
          [
           "plt.vlines(kb.bin_edges_[0], -3, 3, linewidth=1, alpha=.2) plt.legend(loc=\"best\") plt.ylabel(\"Regres..."
          ],
          [
           "Figure 4-3. Linear regression using binned features and a single global slope\n\nIn this example, the ..."
          ],
          [
           "plt.vlines(kb.bin_edges_[0],\n\n3, 3, linewidth=1, alpha=.2)\n\nplt.plot(X[:, 0], y, 'o', c='k') plt.yla..."
          ],
          [
           "# include polynomials up to x ** 10: # the default \"include_bias=True\" adds a feature that's constan..."
          ],
          [
           "20918.278] [    1.392     1.938     2.697     3.754     5.226     7.274    10.125 14.094    19.618  ..."
          ],
          [
           "line_poly = poly.transform(line) plt.plot(line, reg.predict(line_poly), label='polynomial linear reg..."
          ],
          [
           "Figure 4-6. Comparison of different gamma parameters for an SVM with RBF kernel\n\nUsing a more comple..."
          ],
          [
           "# rescale data scaler = MinMaxScaler() X_train_scaled = scaler.fit_transform(X_train) X_test_scaled ..."
          ],
          [
           "The exact correspondence between input and output features can be found using the get_feature_names ..."
          ],
          [
           "'x0 x5', 'x0 x6', 'x0 x7', 'x0 x8', 'x0 x9', 'x0 x10', 'x0 x11', 'x0 x12', 'x1^2', 'x1 x2', 'x1 x3',..."
          ],
          [
           "x5', 'x2 x6', 'x2 x7', 'x2 x8', 'x2 x9', 'x2 x10', 'x2 x11', 'x2 x12', 'x3^2', 'x3 x4', 'x3 x5', 'x3..."
          ],
          [
           "'x4 x10', 'x4 x11', 'x4 x12', 'x5^2', 'x5 x6', 'x5 x7', 'x5 x8', 'x5 x9', 'x5 x10', 'x5 x11', 'x5 x1..."
          ],
          [
           "'x8^2', 'x8 x9', 'x8 x10', 'x8 x11', 'x8 x12', 'x9^2', 'x9 x10', 'x9 x11', 'x9 x12', 'x10^2', 'x10 x..."
          ],
          [
           "first feature squared (\"x0^2\") and combinations of the first and the other features...."
          ],
          [
           "Let’s compare the performance using Ridge on the data with and without interactions: In[38]: from sk..."
          ],
          [
           "Clearly, the interactions and polynomial features gave us a good boost in performance when using Rid..."
          ],
          [
           "4.6 Univariate Nonlinear Transformations\n\nWe just saw that adding squared or cubed features can help..."
          ],
          [
           "X = rnd.poisson(10 * np.exp(X_org)) y = np.dot(X_org, w) Let’s look at the first 10 entries of the f..."
          ],
          [
           "0]))) Out[41]: Number of feature appearances: [28 38 68 48 61 59 45 56 37 40 35 34 36 26 23 26 27 21..."
          ],
          [
           "2  5  2  1 2  3  3  2  2  3  3  0  1  2  1  0  0  3  1  0  0  0  1  3  0  1  0  2  0 1  1  0  0  0  ..."
          ],
          [
           "2  0  1  1  0  0  0  0  1  1  0  0  0  0  0 0  0  1  0  0  0  0  0  1  1  0  0  1  0  0  0  0  0  0 ..."
          ],
          [
           "0 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1] The value 2 seems to be the most common, with 68 a..."
          ],
          [
           "are appearing twice. We visualize the counts in Figure 4-7: In[42]: bins = np.bincount(X[:, 0]) plt...."
          ],
          [
           "Figure 4-7. Histogram of feature values for X[0]..."
          ],
          [
           "Features X[:, 1] and X[:, 2] have similar properties. This kind of distribution of values (many smal..."
          ],
          [
           "train_test_split(X, y, random_state=0) score = Ridge().fit(X_train, y_train).score(X_test, y_test) p..."
          ],
          [
           "logarithm is not defined at 0), we can’t actually just apply log, but we have to compute log(X + 1):..."
          ],
          [
           "color='gray') plt.ylabel(\"Number of appearances\") plt.xlabel(\"Value\")..."
          ],
          [
           "Figure 4-8. Histogram of feature values for X[0] after logarithmic transformation\n\nBuilding a ridge ..."
          ],
          [
           "4.7 Automatic Feature Selection\n\nWith so many ways to create new features, you might get tempted to ..."
          ],
          [
           "To use univariate feature selection in scikit-learn, you need to choose a test, usually either f_cla..."
          ],
          [
           "X_train, X_test, y_train, y_test = train_test_split( X_w_noise, cancer.target, random_state=0, test_..."
          ],
          [
           "X_train.shape: (284, 80)\n\nX_train_selected.shape: (284, 40)\n\nAs you can see, the number of features ..."
          ],
          [
           "# transform test data\n\nX_test_selected = select.transform(X_test)\n\nlr = LogisticRegression() lr.fit(..."
          ],
          [
           "4.7.2 Model\n\nBased Feature Selection\n\nModel-based feature selection uses a supervised machine learni..."
          ],
          [
           "To use model-based feature selection, we need to use the SelectFromModel transformer: In[50]: from s..."
          ],
          [
           "result to what we got with univariate feature selection, we used the median as a threshold, so that ..."
          ],
          [
           "X_train_l1 = select.transform(X_train) print(\"X_train.shape: {}\".format(X_train.shape)) print(\"X_tra..."
          ],
          [
           "Figure 4-10. Features selected by SelectFromModel using the RandomForestClassifier\n\nThis time, all b..."
          ],
          [
           "4.7.3 Iterative Feature Selection\n\nIn univariate testing we used no model, while in model-based sele..."
          ],
          [
           "Figure 4-11. Features selected by recursive feature elimination with the random forest classifier mo..."
          ],
          [
           "score = LogisticRegression().fit(X_train_rfe, y_train).score(X_test_rfe, y_test) print(\"Test score: ..."
          ],
          [
           "4.8 Utilizing Expert Knowledge\n\nFeature engineering is often an important place to use expert knowle..."
          ],
          [
           "Adding a feature does not force a machine learning algorithm to use it, and even if the holiday info..."
          ],
          [
           "We resample the data into three-hour intervals to obtain the main trends for each day: In[57]: citib..."
          ],
          [
           "Figure 4-12. Number of bike rentals over time for a selected Citi Bike station\n\nLooking at the data,..."
          ],
          [
           "A (surprisingly) common way that dates are stored on computers is using POSIX time, which is the num..."
          ],
          [
           "plt.xticks(range(0, len(X), 8), xticks.strftime(\"%a %m-%d\"), rotation=90, ha=\"left\")\n\nplt.plot(range..."
          ],
          [
           "Figure 4-13. Predictions made by a random forest using only the POSIX time\n\nThe predictions on the t..."
          ],
          [
           "Figure 4-14. Predictions made by a random forest using only the hour of the day\n\nThe R2 is already m..."
          ],
          [
           "Figure 4-16. Predictions made by linear regression using day of week and hour of day as features\n\nLi..."
          ],
          [
           "Using interaction features, we can allow the model to learn one coefficient for each combination of ..."
          ],
          [
           "This transformation finally yields a model that performs similarly well to the random forest. A big ..."
          ],
          [
           "Figure 4-19. Coefficients of the linear regression model using a product of hour and day\n\n4.9 Summar..."
          ],
          [
           "Close\n\n5. Model Evaluation and Improvement - Introduction to Machine Learning with Python [Book]\n\nSk..."
          ],
          [
           "To evaluate our supervised models, so far we have split our dataset into a training set and a test s..."
          ],
          [
           "Close\n\n6. Algorithm Chains and Pipelines - Introduction to Machine Learning with Python [Book]\n\nSkip..."
          ],
          [
           "As an example of the importance of chaining models, we noticed that we can greatly improve the perfo..."
          ],
          [
           "Privacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & T..."
          ],
          [
           "For higher ed\n\nIndividuals\n\nFeatures\n\nAll features\n\nCourses\n\nCertifications\n\nInteractive learning\n\nL..."
          ],
          [
           "Start your free trial\n\nChapter 7. Working with Text Data\n\nIn Chapter 4, we talked about two kinds of..."
          ],
          [
           "Close\n\n8. Wrapping Up - Introduction to Machine Learning with Python [Book]\n\nSkip to main content\n\nS..."
          ],
          [
           "8.1 Approaching a Machine Learning Problem With all the great methods that we introduced in this boo..."
          ],
          [
           "Newsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\n..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\IntroToMLwithPython-MullerGuido.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\IntroToMLwithPython-MullerGuido.txt, circle",
         "marker": {
          "color": "#ab63fa",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\IntroToMLwithPython-MullerGuido.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          9.6520605,
          8.351944,
          7.7925406,
          7.347803,
          6.8525696,
          6.960624,
          6.6444187,
          6.566756,
          8.243695,
          -4.121603,
          8.72169,
          -4.2048497,
          8.829069,
          -5.9871564,
          -5.548674,
          -5.9188495,
          -5.6221185,
          -5.9554143,
          -6.6251597,
          -6.201136,
          -6.1397367,
          -1.6158386,
          -4.5536036,
          -6.3290954,
          3.04465,
          5.910677,
          2.8012629,
          2.7581599,
          2.673938,
          2.8383126,
          3.0920367,
          2.79473,
          2.8444176,
          2.7488456,
          2.6746967,
          2.7961752,
          2.3499608,
          3.2378283,
          2.9075832,
          3.0819175,
          3.0140007,
          3.090483,
          3.185631,
          2.9970648,
          14.459482,
          8.473795,
          8.584394,
          12.669311,
          9.306349,
          7.1043763,
          14.462658,
          10.717501,
          6.6392727,
          -3.0010157,
          -3.8588347,
          -3.862709,
          -3.2101276,
          -2.9605155,
          -3.2922668,
          -3.1780324,
          -3.7065578,
          -3.5586083,
          -2.860199,
          -2.884144,
          -3.7296057,
          -3.2122576,
          2.0872319,
          -2.8742955,
          -3.1394005,
          -2.8556006,
          -2.9787061,
          -2.7951138,
          -2.689015,
          -2.2021773,
          -2.3887649,
          -2.3648562,
          -3.0241568,
          -4.0160465,
          -3.3899505,
          -3.6841643,
          -2.3889349,
          -1.5735487,
          -2.6926036,
          -0.2901165,
          -0.22136489,
          -0.89845467,
          -1.4170605,
          -1.0138292,
          -1.5286423,
          -5.6412272,
          -2.7173736,
          -2.7100308,
          -0.9583168,
          -1.4418405,
          -1.1888657,
          -0.5404417,
          -0.46611083,
          -0.09513464,
          -0.38957432,
          -0.5107151,
          -0.48306647,
          0.58010226,
          0.67140025,
          1.4997954,
          1.1096953,
          0.1349078,
          -0.17264472,
          -2.6604433,
          -2.536418,
          -2.6441,
          -1.0994301,
          0.022234209,
          0.9696235,
          0.9696608,
          -0.28519273,
          -2.9900477,
          -1.9523921,
          -2.679063,
          -2.7692988,
          -2.6757276,
          -4.1550627,
          -1.0161071,
          1.1896603,
          2.015252,
          -2.868905,
          -6.646303,
          0.3412569,
          5.898815,
          1.0823804,
          1.425082,
          1.1187673,
          1.0160356,
          1.141972,
          1.138899,
          1.1490633,
          0.43734363,
          0.9912119,
          1.1341887,
          0.9832488,
          0.96445036,
          6.279576,
          6.033006,
          -7.140411,
          -0.037852313,
          0.05623877,
          0.0044744206,
          0.142135,
          -0.009546019,
          0.012292577,
          -0.07776284,
          0.069741435,
          0.041035134,
          9.500344,
          3.3745687,
          10.075086,
          0.92692393,
          14.237089,
          10.581881,
          6.9816155,
          9.863455,
          8.729048,
          14.505904
         ],
         "xaxis": "x",
         "y": [
          -1.7857839,
          -0.17729345,
          0.96510375,
          0.2464938,
          0.8207665,
          0.75200254,
          0.7762586,
          0.46012664,
          -0.041555725,
          -6.179041,
          -2.1230376,
          -5.9923916,
          -2.3896809,
          -7.642247,
          -7.2371745,
          -7.9094925,
          -7.426556,
          -7.479112,
          3.8283,
          3.0301034,
          -5.236807,
          6.058465,
          -5.9063864,
          3.755134,
          1.6411265,
          0.45971918,
          1.7616482,
          1.7876539,
          1.6382645,
          1.5746229,
          1.9135216,
          1.913521,
          2.0227804,
          1.7441148,
          2.2810524,
          2.6235304,
          3.066727,
          4.4686465,
          2.2061095,
          1.9147528,
          2.1026409,
          1.7870333,
          2.5019255,
          2.3507218,
          -4.741242,
          -0.26969367,
          -0.51337767,
          -3.938579,
          -0.81089926,
          0.5443754,
          -4.7770047,
          -1.8117846,
          0.9731548,
          -1.3377254,
          -1.4595598,
          -1.425196,
          -1.3922515,
          -1.1908516,
          -1.399504,
          -1.3778061,
          -1.4772496,
          -1.589083,
          -1.0712487,
          -1.1420653,
          -1.401025,
          -1.3818238,
          2.9190133,
          -1.1088922,
          -1.336272,
          -1.1404558,
          -1.2741143,
          1.1632993,
          -0.953757,
          -0.3521045,
          -0.56957746,
          -0.4535885,
          -1.1577895,
          -1.6980196,
          -1.4105083,
          -1.2997772,
          -0.56013423,
          0.3838419,
          -0.8113033,
          2.3824422,
          2.5081816,
          1.638756,
          1.5615559,
          1.3472189,
          0.9432314,
          -7.3763595,
          1.252345,
          1.2522302,
          1.5600258,
          0.92098343,
          1.2387218,
          2.6913078,
          2.3810525,
          2.3877556,
          2.4840784,
          2.208145,
          2.183794,
          3.359865,
          3.2421086,
          4.0682373,
          3.662138,
          2.8817976,
          2.5519772,
          1.2989424,
          1.3686407,
          1.3124931,
          1.9589449,
          2.6181314,
          2.9940488,
          2.6407337,
          1.9893721,
          2.844899,
          1.8245174,
          1.2287582,
          1.2738398,
          1.478609,
          2.8947237,
          1.9851868,
          2.815347,
          2.7900698,
          3.448954,
          3.2880445,
          2.340473,
          1.8215581,
          1.9504825,
          2.2230513,
          2.0450885,
          1.802244,
          2.1315062,
          1.827677,
          1.758776,
          2.9285355,
          1.7944022,
          1.8295561,
          1.7741855,
          1.864078,
          1.6638054,
          1.7170912,
          -0.008291432,
          1.4793967,
          1.6937664,
          2.5532136,
          1.8058515,
          1.7076752,
          1.6208005,
          1.6448483,
          1.9698718,
          1.5062914,
          -1.6027161,
          2.639491,
          -1.5240887,
          3.9469817,
          -4.671846,
          -1.7080617,
          0.09120344,
          -1.9853294,
          -0.38511533,
          -4.776162
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "1. Let’s Discuss Learning - Machine Learning with Python for Everyone [Book]\n\nSkip to main content\n\n..."
          ],
          [
           "Get Machine Learning with Python for Everyone now with the O’Reilly learning platform. O’Reilly memb..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n2. Some Technical Background\n\n2.1 About Our Setup We’re about to get down—fun..."
          ],
          [
           "logo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJ..."
          ],
          [
           "Features\n\nAll features\n\nCourses\n\nCertifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsight..."
          ],
          [
           "Close\n\n4. Predicting Numerical Values: Getting Started with Regression - Machine Learning with Pytho..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "5.1 Evaluation and Why Less Is More Lao Tzu: Those that know others are wise. Those that know themse..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Answers\n\nInsights reporting\n\nBlog\n\nContent sponsorship\n\nMachine Learning with Python for Everyone by..."
          ],
          [
           "Close\n\n7. Evaluating Regressors - Machine Learning with Python for Everyone [Book]\n\nSkip to main con..."
          ],
          [
           "diabetes.target,\n\ntest_size=.25,\n\nrandom_state=42)\n\n(diabetes_train_ftrs, diabetes_test_ftrs, diabet..."
          ],
          [
           "International\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJapan\n\nDownload the O’..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "8.1 Revisiting Classification So far, we’ve discussed two classifiers: Naive Bayes (NB) and k-Neares..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "d_tts = skms.train_test_split(diabetes.data,\n\ndiabetes.target,\n\ntest_size=.25,\n\nrandom_state=42)\n\n(d..."
          ],
          [
           "International\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJapan\n\nDownload the O’..."
          ],
          [
           "Courses\n\nCertifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nConte..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "11. Tuning Hyperparameters and Pipelines In [1]: Click here to view code image # setup from mlwpy im..."
          ],
          [
           "Privacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & T..."
          ],
          [
           "For higher ed\n\nIndividuals\n\nFeatures\n\nAll features\n\nCourses\n\nCertifications\n\nInteractive learning\n\nL..."
          ],
          [
           "(iris_train_ftrs, iris_test_ftrs,\n\niris_train_tgt, iris_test_tgt) = tts\n\n12.1 Ensembles Up to this p..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\n13. Models That Engineer Features for Us In [1]: Click here to view code imag..."
          ],
          [
           "Close\n\n14. Feature Engineering for Domains: Domain-Specific Learning - Machine Learning with Python ..."
          ],
          [
           "Issues 1 and 2 are specific to a learning problem you are focused on. We discussed issue 3 in Chapte..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\n15. Connections, Extensions, and Further Directions In [1]: from mlwpy import..."
          ],
          [
           "Privacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & T..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\MLwithPythonforEveryone-Fenner.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\MLwithPythonforEveryone-Fenner.txt, circle",
         "marker": {
          "color": "#FFA15A",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\MLwithPythonforEveryone-Fenner.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          8.830406,
          12.077126,
          10.669792,
          9.8306265,
          14.561902,
          9.70449,
          9.89647,
          10.475192,
          9.627631,
          15.4673815,
          9.996405,
          10.02671,
          10.163541,
          15.14187,
          9.980089,
          9.127321,
          10.3071165,
          10.086799,
          15.062837,
          9.783004,
          10.230825,
          9.967561,
          14.054735,
          10.057267,
          9.980427,
          12.758782,
          10.101043,
          9.761713,
          9.257572,
          13.026996,
          10.284866,
          14.58863
         ],
         "xaxis": "x",
         "y": [
          0.2238337,
          -3.1779385,
          -1.6824888,
          -1.5339829,
          -4.770858,
          -1.0242144,
          -2.2767336,
          -1.8421737,
          -0.43286577,
          -4.954413,
          -1.3034157,
          -2.4511757,
          -2.6286447,
          -4.9116917,
          -1.1784698,
          -1.1661239,
          -2.4672513,
          -2.569394,
          -4.8720565,
          -1.4866732,
          -1.4010669,
          -2.7569146,
          -4.633714,
          -1.9144541,
          -0.8837684,
          -4.0109444,
          -2.21464,
          -1.5242776,
          -0.44165942,
          -4.6357207,
          -0.9819951,
          -4.795398
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Archives | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAbout\n\nArchive\n\nArchives and ..."
          ],
          [
           "4. Visualization with Matplotlib¶ Simple Line Plots Simple Scatter Plots Visualizing Errors Density ..."
          ],
          [
           "Preface\n\n| Contents | IPython: Beyond Normal Python >\n\nWhat Is Data Science?¶This is a book about do..."
          ],
          [
           "data\n\nscience\n\nvenn\n\ndiagram). Used by permission.)\n\nWhile some of the intersection labels are a bit..."
          ],
          [
           "Who Is This Book For?¶In my teaching both at the University of Washington and at various tech-focuse..."
          ],
          [
           "Why Python?¶Python has emerged over the last couple decades as a first-class tool for scientific com..."
          ],
          [
           "Python 2 vs Python 3¶This book uses the syntax of Python 3, which contains language enhancements tha..."
          ],
          [
           "The PyData world is certainly much larger than these five packages, and is growing every day. With t..."
          ],
          [
           "If you feel your use of code examples falls outside fair use or the per‐ mission given above, feel f..."
          ],
          [
           "Any of the packages included with Anaconda can also be installed manually on top of Miniconda; for t..."
          ],
          [
           "2. Introduction to NumPy¶ Understanding Data Types in Python The Basics of NumPy Arrays Computation ..."
          ],
          [
           "Appendix: Figure Code¶\n\nIPython: Beyond Normal Python | Python Data Science Handbook\n\nPython Data Sc..."
          ],
          [
           "IPython: Beyond Normal Python\n\n< Preface | Contents | Help and Documentation in IPython >\n\nThere are..."
          ],
          [
           "This chapter will start by stepping through some of the IPython features that are useful to the prac..."
          ],
          [
           "Launching the IPython Shell¶This chapter, like most of this book, is not designed to be absorbed pas..."
          ],
          [
           "Launching the Jupyter Notebook¶The Jupyter notebook is a browser-based graphical interface to the IP..."
          ],
          [
           "< Preface | Contents | Help and Documentation in IPython >\n\nPython Data Science Handbook | Python Da..."
          ],
          [
           "4. Visualization with Matplotlib¶ Simple Line Plots Simple Scatter Plots Visualizing Errors Density ..."
          ],
          [
           "Help and Documentation in IPython\n\n< IPython: Beyond Normal Python | Contents | Keyboard Shortcuts i..."
          ],
          [
           "Here we'll discuss IPython's tools to quickly access this information, namely the ? character to exp..."
          ],
          [
           "Return the number of items of a sequence or mapping.\n\nThis notation works for just about anything, i..."
          ],
          [
           "This quick access to documentation via docstrings is one reason you should get in the habit of alway..."
          ],
          [
           "Using ? and/or ? ? gives a powerful and quick interface for finding information about what any Pytho..."
          ],
          [
           "Though Python has no strictly-enforced distinction between public/external attributes and private/in..."
          ],
          [
           "Beyond tab completion: wildcard matching¶Tab completion is useful if you know the first few characte..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "Keyboard Shortcuts in the IPython Shell\n\n< Help and Documentation in IPython | Contents | IPython Ma..."
          ],
          [
           "Navigation shortcuts¶While the use of the left and right arrow keys to move backward and forward in ..."
          ],
          [
           "Ctrl-t Transpose (i.e., switch) previous two characters\n\nCommand History Shortcuts¶Perhaps the most ..."
          ],
          [
           "At any point, you can add more characters to refine the search, or press Ctrl-r again to search furt..."
          ],
          [
           "Ctrl\n\nc\n\nInterrupt current Python command\n\nCtrl\n\nd\n\nExit IPython session\n\nThe Ctrl-c in particular c..."
          ],
          [
           "IPython Magic Commands\n\n< Keyboard Shortcuts in the IPython Shell | Contents | Input and Output Hist..."
          ],
          [
           "The code is formatted as it would appear in the Python interpreter, and if you copy and paste this d..."
          ],
          [
           "These magic commands, like others we'll see, make available functionality that would be difficult or..."
          ],
          [
           "There are several options to fine-tune how your code is run; you can see the documentation in the no..."
          ],
          [
           "Help on Magic Functions: ?, %magic, and %lsmagic¶Like normal Python functions, IPython magic functio..."
          ],
          [
           "Input and Output History\n\n< IPython Magic Commands | Contents | IPython and Shell Commands >\n\nPrevio..."
          ],
          [
           "Out[3]:\n\n0.4161468365471424\n\nWe've imported the built-in math package, then computed the sine and th..."
          ],
          [
           "Note that not all operations have outputs: for example, import statements and print statements don't..."
          ],
          [
           "In [11]: print(___)\n\n0.9092974268256817\n\nIPython stops there: more than three underscores starts to ..."
          ],
          [
           "Related Magic Commands¶For accessing a batch of previous inputs at once, the %history magic command ..."
          ],
          [
           "IPython and Shell Commands\n\n< Input and Output History | Contents | Errors and Debugging >\n\nWhen wor..."
          ],
          [
           "Quick Introduction to the Shell¶A full intro to using the shell/terminal/command-line is well beyond..."
          ],
          [
           "osx:~ $ pwd                            # pwd = print working directory /home/jake                   ..."
          ],
          [
           "Shell Commands in IPython¶Any command that works at the command-line can be used in IPython by prefi..."
          ],
          [
           "Communication in the other direction–passing Python variables into the shell–is possible using the {..."
          ],
          [
           "In fact, by default you can even use this without the % sign: In [15]: cd myproject /home/jake/proje..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "1\n\nreturn func1(a, b)\n\nIn [2]:\n\nfunc2(1)\n\n----------------------------------------------------------..."
          ],
          [
           "ZeroDivisionError: division by zero\n\nCalling func2 results in an error, and reading the printed trac..."
          ],
          [
           "In [5]:\n\n%xmode Verbose\n\nException reporting mode: Verbose\n\nIn [6]:\n\nfunc2(1)\n\n---------------------..."
          ],
          [
           "ZeroDivisionError: division by zero\n\nThis extra information can help narrow-in on why the exception ..."
          ],
          [
           "ipdb> print(a)\n\n1\n\nipdb> print(b)\n\n0\n\nipdb> quit\n\nThe interactive debugger allows much more than thi..."
          ],
          [
           "ipdb> quit\n\nThis allows you to quickly find out not only what caused the error, but what function ca..."
          ],
          [
           "ipdb> print(b)\n\n0\n\nipdb> quit\n\nFinally, if you have a script that you'd like to run from the beginni..."
          ],
          [
           "Profiling and Timing Code | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAbout\n\nArchi..."
          ],
          [
           "%time: Time the execution of a single statement %timeit: Time repeated execution of a single stateme..."
          ],
          [
           "total += i\n\n(\n\n1) *\n\nj\n\n1 loops, best of 3: 407 ms per loop\n\nSometimes repeating an operation is not..."
          ],
          [
           "In [5]:\n\nprint(\"sorting an already sorted list:\") %time L.sort()\n\nsorting an already sorted list: CP..."
          ],
          [
           "Profiling Full Scripts: %prun¶A program is made of many single statements, and sometimes timing thes..."
          ],
          [
           "Ordered by: internal time\n\nncalls  tottime  percall  cumtime  percall filename:lineno(function) 5   ..."
          ],
          [
           "Line-By-Line Profiling with %lprun¶The function-by-function profiling of %prun is useful, but someti..."
          ],
          [
           "Line #      Hits         Time  Per Hit   % Time  Line Contents =====================================..."
          ],
          [
           "In [12]:\n\n%load_ext memory_profiler\n\nThe memory profiler extension contains two useful magic functio..."
          ],
          [
           "In [15]:\n\nfrom mprun_demo import sum_of_lists\n\n%mprun\n\nf sum_of_lists sum_of_lists(1000000)\n\nThe res..."
          ],
          [
           "Filename: ./mprun_demo.py\n\nLine #    Mem usage    Increment   Line Contents ========================..."
          ],
          [
           "More IPython Resources | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAbout\n\nArchive\n..."
          ],
          [
           "Web Resources¶ The IPython website: The IPython website links to documentation, examples, tutorials,..."
          ],
          [
           "Finally, a reminder that you can find help on your own: IPython's ?-based help functionality (discus..."
          ],
          [
           "Introduction to NumPy\n\n< More IPython Resources | Contents | Understanding Data Types in Python >\n\nT..."
          ],
          [
           "NumPy (short for Numerical Python) provides an efficient interface to store and operate on dense dat..."
          ],
          [
           "Throughout this chapter, and indeed the rest of the book, you'll find that this is the way we will i..."
          ],
          [
           "Table of Contents¶Preface¶1. IPython: Beyond Normal Python¶ Help and Documentation in IPython Keyboa..."
          ],
          [
           "5. Machine Learning¶ What Is Machine Learning? Introducing Scikit-Learn Hyperparameters and Model Va..."
          ],
          [
           "Understanding Data Types in Python\n\n< Introduction to NumPy | Contents | The Basics of NumPy Arrays ..."
          ],
          [
           "This sort of flexibility is one piece that makes Python and other dynamically-typed languages conven..."
          ],
          [
           "This means that there is some overhead in storing an integer in Python as compared to an integer in ..."
          ],
          [
           "In [3]:\n\nL2 = [str(c) for c in L] L2\n\nOut[3]:\n\n['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n\nI..."
          ],
          [
           "At the implementation level, the array essentially contains a single pointer to one contiguous block..."
          ],
          [
           "In [7]:\n\nimport numpy as np\n\nCreating Arrays from Python Lists¶First, we can use np.array to create ..."
          ],
          [
           "In [11]:\n\n# nested lists result in multi-dimensional arrays np.array([range(i, i + 3) for i in [2, 4..."
          ],
          [
           "# Create a 3x5 array filled with 3.14 np.full((3, 5), 3.14)\n\nOut[14]:\n\narray([[ 3.14,  3.14,  3.14, ..."
          ],
          [
           "Out[17]:\n\narray([[ 0.99844933,  0.52183819,  0.22421193], [ 0.08007488,  0.45429293,  0.20941444], [..."
          ],
          [
           "In [20]:\n\n# Create a 3x3 identity matrix np.eye(3)\n\nOut[20]:\n\narray([[ 1.,  0.,  0. ], [ 0.,  1.,  0..."
          ],
          [
           "intp Integer used for indexing (same as C ssize_t; normally either int32 or int64)\n\nint8\n\nByte (\n\n12..."
          ],
          [
           "complex64 Complex number, represented by two 32-bit floats\n\ncomplex128 Complex number, represented b..."
          ],
          [
           "Attributes of arrays: Determining the size, shape, memory consumption, and data types of arrays Inde..."
          ],
          [
           "print(\"x3 shape:\", x3.shape)\n\nprint(\"x3 size: \", x3.size)\n\nx3 ndim:  3 x3 shape: (3, 4, 5) x3 size: ..."
          ],
          [
           "In [5]:\n\nx1\n\nOut[5]:\n\narray([5, 0, 3, 3, 7, 9])\n\nIn [6]:\n\nx1[0]\n\nOut[6]:\n\n5\n\nIn [7]:\n\nx1[4]\n\nOut[7]:..."
          ],
          [
           "Out[12]:\n\n1\n\nIn [13]:\n\nx2[2,\n\n1]\n\nOut[13]:\n\n7\n\nValues can also be modified using any of the above in..."
          ],
          [
           "If any of these are unspecified, they default to the values start=0, stop=size of dimension, step=1...."
          ],
          [
           "Out[21]:\n\narray([1, 3, 5, 7, 9])\n\nA potentially confusing case is when the step value is negative. I..."
          ],
          [
           "In [26]:\n\nx2[:3, ::2]  # all rows, every other column\n\nOut[26]:\n\narray([[12,  2],\n\n[ 7,  8],\n\n[ 1,  ..."
          ],
          [
           "print(x2[0])  # equivalent to x2[0, :]\n\n[12  5  2  4]\n\nSubarrays as no-copy views¶One important–and ..."
          ],
          [
           "print(x2)\n\n[[99  5  2  4] [ 7  6  8  8] [ 1  6  7  7]]\n\nThis default behavior is actually quite usef..."
          ],
          [
           "In [38]:\n\ngrid = np.arange(1, 10).reshape((3, 3)) print(grid)\n\n[[1 2 3]\n\n[4 5 6]\n\n[7 8 9]]\n\nNote tha..."
          ],
          [
           "Out[41]:\n\narray([[1],\n\n[2],\n\n[3]])\n\nIn [42]:\n\n# column vector via newaxis x[:, np.newaxis]\n\nOut[42]:..."
          ],
          [
           "You can also concatenate more than two arrays at once:\n\nIn [44]:\n\nz = [99, 99, 99] print(np.concaten..."
          ],
          [
           "In [48]:\n\nx = np.array([1, 2, 3]) grid = np.array([[9, 8, 7], [6, 5, 4]])\n\n# vertically stack the ar..."
          ],
          [
           "[1 2 3] [99 99] [3 2 1]\n\nNotice that N split-points, leads to N + 1 subarrays. The related functions..."
          ],
          [
           "Computation on NumPy Arrays: Universal Functions | Python Data Science Handbook\n\nPython Data Science..."
          ],
          [
           "The Slowness of Loops¶Python's default implementation (known as CPython) does some operations very s..."
          ],
          [
           "values = np.random.randint(1, 10, size=5) compute_reciprocals(values)\n\nOut[1]:\n\narray([ 0.16666667, ..."
          ],
          [
           "Introducing UFuncs¶For many types of operations, NumPy provides a convenient interface into just thi..."
          ],
          [
           "Out[5]:\n\narray([ 0.        ,  0.5       ,  0.66666667,  0.75      ,  0.8       ])\n\nAnd ufunc operati..."
          ],
          [
           "In [7]:\n\nx = np.arange(4) print(\"x     =\", x) print(\"x + 5 =\", x + 5) print(\"x - 5 =\", x - 5) print(..."
          ],
          [
           "(0.5\n\nx + 1)\n\n** 2\n\nOut[9]:\n\narray([\n\n1.  ,\n\n2.25,\n\n4.  ,\n\n6.25])\n\nEach of these arithmetic operatio..."
          ],
          [
           "np.power\n\nExponentiation (e.g., 2 *\n\n3 = 8)\n\n% np.mod Modulus/remainder (e.g., 9 % 4 = 1)\n\nAdditiona..."
          ],
          [
           "x = np.array([3 - 4j, 4 - 3j, 2 + 0j, 0 + 1j]) np.abs(x)\n\nOut[14]:\n\narray([ 5.,  5.,  2.,  1.])\n\nTri..."
          ],
          [
           "The values are computed to within machine precision, which is why values that should be zero do not ..."
          ],
          [
           "x     = [1, 2, 3] e^x   = [  2.71828183   7.3890561   20.08553692] 2^x   = [ 2. 4. 8.] 3^x   = [ 3  ..."
          ],
          [
           "There are also some specialized versions that are useful for maintaining precision with very small i..."
          ],
          [
           "In [21]:\n\nfrom scipy import special\n\nIn [22]:\n\n# Gamma functions (generalized factorials) and relate..."
          ],
          [
           "erf(x)  = [ 0. 0.32862676  0.67780119  0.84270079] erfc(x) = [ 1. 0.67137324  0.32219881  0.15729921..."
          ],
          [
           "This can even be used with array views. For example, we can write the results of a computation to ev..."
          ],
          [
           "15\n\nSimilarly, calling reduce on the multiply ufunc results in the product of all array elements:\n\nI..."
          ],
          [
           "x = np.arange(1, 6)\n\nnp.multiply.outer(x, x)\n\nOut[30]:\n\narray([[ 1,  2,  3,  4,  5], [ 2,  4,  6,  8..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "The syntax is quite similar to that of NumPy's sum function, and the result is the same in the simpl..."
          ],
          [
           "NumPy's corresponding functions have similar syntax, and again operate much more quickly:\n\nIn [6]:\n\n..."
          ],
          [
           "In [9]:\n\nM = np.random.random((3, 4))\n\nprint(M)\n\n[[ 0.8967576   0.03783739  0.75952519  0.06682827] ..."
          ],
          [
           "In [12]:\n\nM.max(axis=1)\n\nOut[12]:\n\narray([ 0.8967576 ,  0.99196818,  0.6687194 ])\n\nThe way the axis ..."
          ],
          [
           "Compute mean of elements\n\nnp.std\n\nnp.nanstd\n\nCompute standard deviation\n\nnp.var\n\nnp.nanvar\n\nCompute ..."
          ],
          [
           "order,name,height(cm)\n\n1,George Washington,189\n\n2,John Adams,170\n\n3,Thomas Jefferson,189\n\nWe'll use ..."
          ],
          [
           "In [16]:\n\nprint(\"25th percentile:   \", np.percentile(heights, 25)) print(\"Median:            \", np.m..."
          ],
          [
           "Computation on Arrays: Broadcasting | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAb..."
          ],
          [
           "Out[2]:\n\narray([5, 6, 7])\n\nBroadcasting allows these types of binary operations to be performed on a..."
          ],
          [
           "Here the one-dimensional array a is stretched, or broadcast across the second dimension in order to ..."
          ],
          [
           "Rules of Broadcasting¶Broadcasting in NumPy follows a strict set of rules to determine the interacti..."
          ],
          [
           "M.shape\n\n> (2, 3)\n\na.shape\n\n> (2, 3)\n\nThe shapes match, and we see that the final shape will be (2, ..."
          ],
          [
           "In [11]:\n\na + b\n\nOut[11]:\n\narray([[0, 1, 2],\n\n[1, 2, 3],\n\n[2, 3, 4]])\n\nBroadcasting example 3¶Now le..."
          ],
          [
           "In [13]:\n\nM + a\n\n--------------------------------------------------------------------------- ValueEr..."
          ],
          [
           "M + a[:, np.newaxis]\n\nOut[15]:\n\narray([[ 1.,  1. ],\n\n[ 2.,  2. ],\n\n[ 3.,  3.]])\n\nAlso note that whil..."
          ],
          [
           "Centering an array¶\n\nIn the previous section, we saw that ufuncs allow a NumPy user to remove the ne..."
          ],
          [
           "17,\n\n7.77156117e\n\n17,\n\n1.66533454e\n\n17])\n\nTo within machine precision, the mean is now zero.\n\nPlotti..."
          ],
          [
           "The result is a compelling visualization of the two-dimensional function.\n\n< Aggregations: Min, Max,..."
          ],
          [
           "In [1]:\n\nimport numpy as np\n\nimport pandas as pd\n\n# use pandas to extract rainfall inches as a NumPy..."
          ],
          [
           "Digging into the data¶One approach to this would be to answer these questions by hand: loop through ..."
          ],
          [
           "Out[5]:\n\narray([ True,  True, False, False, False], dtype=bool)\n\nIn [6]:\n\nx > 3  # greater than\n\nOut..."
          ],
          [
           "(2\n\nx) == (x *\n\n2)\n\nOut[11]:\n\narray([False,  True, False, False, False], dtype=bool)\n\nAs in the case..."
          ],
          [
           "[2, 4, 7, 6]])\n\nIn [13]:\n\nx < 6\n\nOut[13]:\n\narray([[ True,  True,  True,  True], [False, False,  True..."
          ],
          [
           "In [16]:\n\nnp.sum(x < 6)\n\nOut[16]:\n\n8\n\nThe benefit of sum() is that like with other NumPy aggregation..."
          ],
          [
           "Out[21]:\n\nFalse\n\nnp.all and np.any can be used along particular axes as well. For example:\n\nIn [22]:..."
          ],
          [
           "In [23]:\n\nnp.sum((inches > 0.5) & (inches < 1))\n\nOut[23]:\n\n29\n\nSo we see that there are 29 days with..."
          ],
          [
           "In [25]:\n\nprint(\"Number days without rain:      \", np.sum(inches == 0)) print(\"Number days with rain..."
          ],
          [
           "Now to select these values from the array, we can simply index on this Boolean array; this is known ..."
          ],
          [
           "Median precip on rainy days in 2014 (inches):    0.194881889764 Median precip on summer days in 2014..."
          ],
          [
           "False\n\nIn [32]:\n\nbool(42 or 0)\n\nOut[32]:\n\nTrue\n\nWhen you use & and | on integers, the expression ope..."
          ],
          [
           "Out[37]:\n\narray([ True,  True,  True, False,  True,  True], dtype=bool)\n\nUsing or on these arrays wi..."
          ],
          [
           "Trying to evaluate the truth or falsehood of the entire array will give the same ValueError we saw p..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "[51 92 14 71 60 20 82 86 74 74]\n\nSuppose we want to access three different elements. We could do it ..."
          ],
          [
           "array([[ 0,  1,  2,  3], [ 4,  5,  6,  7], [ 8,  9, 10, 11]])\n\nLike with standard indexing, the firs..."
          ],
          [
           "Out[8]:\n\narray([[0, 0, 0],\n\n[2, 1, 3],\n\n[4, 2, 6]])\n\nIt is always important to remember with fancy i..."
          ],
          [
           "Out[12]:\n\narray([[ 0,  2],\n\n[ 4,  6],\n\n[ 8, 10]])\n\nAll of these indexing options combined lead to a ..."
          ],
          [
           "In [15]:\n\nindices = np.random.choice(X.shape[0], 20, replace=False) indices\n\nOut[15]:\n\narray([93, 45..."
          ],
          [
           "In [18]:\n\nx = np.arange(10) i = np.array([2, 1, 8, 4]) x[i] = 99 print(x)\n\n[ 0 99 99  3 99  5  6  7 ..."
          ],
          [
           "array([ 6.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.])\n\nYou might expect that x[3] would contain ..."
          ],
          [
           "Example: Binning Data¶You can use these ideas to efficiently bin data to create a histogram by hand...."
          ],
          [
           "This function will create a nearly identical plot to the one seen here. To compute the binning, matp..."
          ],
          [
           "print(\"Custom routine:\") %timeit np.add.at(counts, np.searchsorted(bins, x), 1)\n\nNumPy routine: 10 l..."
          ],
          [
           "Sorting Arrays\n\n< Fancy Indexing | Contents | Structured Data: NumPy's Structured Arrays >\n\nUp to th..."
          ],
          [
           "Out[2]:\n\narray([1, 2, 3, 4, 5])\n\nAs any first-year computer science major will tell you, the selecti..."
          ],
          [
           "Out[4]:\n\narray([1, 2, 3, 4, 5])\n\nThis silly sorting method relies on pure chance: it repeatedly appl..."
          ],
          [
           "Out[5]:\n\narray([1, 2, 3, 4, 5])\n\nIf you prefer to sort the array in-place, you can instead use the s..."
          ],
          [
           "rand = np.random.RandomState(42) X = rand.randint(0, 10, (4, 6)) print(X)\n\n[[6 3 7 4 6 9] [2 6 7 4 3..."
          ],
          [
           "Keep in mind that this treats each row or column as an independent array, and any relationships betw..."
          ],
          [
           "The result is an array where the first two slots in each row contain the smallest values from that r..."
          ],
          [
           "In [16]:\n\ndist_sq = np.sum((X[:, np.newaxis, :] - X[np.newaxis, :, :]) ** 2, axis=-1)\n\nThis operatio..."
          ],
          [
           "In [20]:\n\ndist_sq.diagonal()\n\nOut[20]:\n\narray([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n\nI..."
          ],
          [
           "Notice that the first column gives the numbers 0 through 9 in order: this is due to the fact that ea..."
          ],
          [
           "Each point in the plot has lines drawn to its two nearest neighbors. At first glance, it might seem ..."
          ],
          [
           "Aside: Big-O Notation¶Big-O notation is a means of describing how the number of operations required ..."
          ],
          [
           "When trying to analyze billions or trillions of samples, the difference between $\\mathcal{O}[N]$ and..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "But this is a bit clumsy. There's nothing here that tells us that the three arrays are related; it w..."
          ],
          [
           "In [5]:\n\ndata['name'] = name\n\ndata['age'] = age\n\ndata['weight'] = weight\n\nprint(data)\n\n[('Alice', 25..."
          ],
          [
           "# Get names where age is under 30 data[data['age'] < 30]['name']\n\nOut[9]:\n\narray(['Alice', 'Doug'],\n..."
          ],
          [
           "In [11]:\n\nnp.dtype({'names':('name', 'age', 'weight'),\n\n'formats':((np.str_, 10), int, np.float32)})..."
          ],
          [
           "The shortened string format codes may seem confusing, but they are built on simple principles. The f..."
          ],
          [
           "'V'\n\nRaw data (void)\n\nnp.dtype('V') == np.void\n\nMore Advanced Compound Types¶It is possible to defin..."
          ],
          [
           "RecordArrays: Structured Arrays with a Twist¶NumPy also provides the np.recarray class, which is alm..."
          ],
          [
           "Whether the more convenient notation is worth the additional overhead will depend on your own applic..."
          ],
          [
           "Data Manipulation with Pandas\n\n< Structured Data: NumPy's Structured Arrays | Contents | Introducing..."
          ],
          [
           "In this chapter, we will focus on the mechanics of using Series, DataFrame, and related structures e..."
          ],
          [
           "And to display Pandas's built-in documentation, you can use this: In [4]: pd?\n\nMore detailed documen..."
          ],
          [
           "3. Data Manipulation with Pandas¶ Introducing Pandas Objects Data Indexing and Selection Operating o..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "Out[2]:\n\n0    0.25 1    0.50 2    0.75 3    1.00 dtype: float64\n\nAs we see in the output, the Series..."
          ],
          [
           "Series as generalized NumPy array¶\n\nFrom what we've seen so far, it may look like the Series object ..."
          ],
          [
           "2    0.25 5    0.50 3    0.75 7    1.00 dtype: float64\n\nIn [10]:\n\ndata[5]\n\nOut[10]:\n\n0.5\n\nSeries as ..."
          ],
          [
           "In [12]:\n\npopulation['California']\n\nOut[12]:\n\n38332521\n\nUnlike a dictionary, though, the Series also..."
          ],
          [
           "data can be a dictionary, in which index defaults to the sorted dictionary keys:\n\nIn [16]:\n\npd.Serie..."
          ],
          [
           "DataFrame as a generalized NumPy array¶If a Series is an analog of a one-dimensional array with flex..."
          ],
          [
           "423967\n\n38332521\n\nFlorida\n\n170312\n\n19552860\n\nIllinois\n\n149995\n\n12882135\n\nNew York\n\n141297\n\n19651127\n..."
          ],
          [
           "In [22]:\n\nstates['area']\n\nOut[22]:\n\nCalifornia    423967 Florida       170312 Illinois      149995 N..."
          ],
          [
           "From a list of dicts¶Any list of dictionaries can be made into a DataFrame. We'll use a simple list ..."
          ],
          [
           "'area': area})\n\nOut[26]:\n\narea\n\npopulation\n\nCalifornia\n\n423967\n\n38332521\n\nFlorida\n\n170312\n\n19552860\n..."
          ],
          [
           "In [28]:\n\nA = np.zeros(3, dtype=[('A', 'i8'), ('B', 'f8')]) A\n\nOut[28]:\n\narray([(0, 0.0), (0, 0.0), ..."
          ],
          [
           "ind = pd.Index([2, 3, 5, 7, 11]) ind\n\nOut[30]:\n\nInt64Index([2, 3, 5, 7, 11], dtype='int64')\n\nIndex a..."
          ],
          [
           "In [34]:\n\nind[1] = 0\n\n--------------------------------------------------------------------------- Ty..."
          ],
          [
           "In [35]:\n\nindA = pd.Index([1, 3, 5, 7, 9]) indB = pd.Index([2, 3, 5, 7, 11])\n\nIn [36]:\n\nindA & indB ..."
          ],
          [
           "Data Indexing and Selection\n\n< Introducing Pandas Objects | Contents | Operating on Data in Pandas >..."
          ],
          [
           "Series as dictionary¶Like a dictionary, the Series object provides a mapping from a collection of ke..."
          ],
          [
           "Series objects can even be modified with a dictionary-like syntax. Just as you can extend a dictiona..."
          ],
          [
           "# masking data[(data > 0.3) & (data < 0.8)]\n\nOut[9]:\n\nb    0.50 c    0.75 dtype: float64\n\nIn [10]:\n\n..."
          ],
          [
           "# explicit index when indexing data[1]\n\nOut[12]:\n\n'a'\n\nIn [13]:\n\n# implicit index when slicing data[..."
          ],
          [
           "data.iloc[1:3]\n\nOut[17]:\n\n3    b 5    c dtype: object\n\nA third indexing attribute, ix, is a hybrid o..."
          ],
          [
           "In [18]:\n\narea = pd.Series({'California': 423967, 'Texas': 695662, 'New York': 141297, 'Florida': 17..."
          ],
          [
           "Equivalently, we can use attribute-style access with column names that are strings:\n\nIn [20]:\n\ndata...."
          ],
          [
           "data['density'] = data['pop'] / data['area'] data\n\nOut[23]:\n\narea\n\npop\n\ndensity\n\nCalifornia\n\n423967\n..."
          ],
          [
           "In [24]:\n\ndata.values\n\nOut[24]:\n\narray([[  4.23967000e+05,   3.83325210e+07,   9.04139261e+01], [  1..."
          ],
          [
           "6.956620e+05\n\npop\n\n3.833252e+07\n\n1.955286e+07\n\n1.288214e+07\n\n1.965113e+07\n\n2.644819e+07\n\ndensity\n\n9...."
          ],
          [
           "California    423967 Florida       170312 Illinois      149995 New York      141297 Texas         69..."
          ],
          [
           "Illinois\n\n149995\n\n12882135\n\nThe ix indexer allows a hybrid of these two approaches:\n\nIn [30]:\n\ndata...."
          ],
          [
           "In [32]:\n\ndata.iloc[0, 2] = 90\n\ndata\n\nOut[32]:\n\narea\n\npop\n\ndensity\n\nCalifornia\n\n423967\n\n38332521\n\n90..."
          ],
          [
           "density\n\nFlorida\n\n170312\n\n19552860\n\n114.806121\n\nIllinois\n\n149995\n\n12882135\n\n85.883763\n\nSuch slices c..."
          ],
          [
           "< Introducing Pandas Objects | Contents | Operating on Data in Pandas >\n\nOperating on Data in Pandas..."
          ],
          [
           "Ufuncs: Index Preservation¶Because Pandas is designed to work with NumPy, any NumPy ufunc will work ..."
          ],
          [
           "In [4]:\n\nnp.exp(ser)\n\nOut[4]:\n\n0     403.428793 1      20.085537 2    1096.633158 3      54.598150 d..."
          ],
          [
           "Index alignment in Series¶As an example, suppose we are combining two different data sources, and fi..."
          ],
          [
           "In [9]:\n\nA = pd.Series([2, 4, 6], index=[0, 1, 2]) B = pd.Series([1, 3, 5], index=[1, 2, 3]) A + B\n\n..."
          ],
          [
           "0\n\n1\n\n11\n\n1\n\n5\n\n1\n\nIn [12]:\n\nB = pd.DataFrame(rng.randint(0, 10, (3, 3)), columns=list('BAC')) B\n\nOu..."
          ],
          [
           "In [14]:\n\nfill = A.stack().mean()\n\nA.add(B, fill_value=fill)\n\nOut[14]:\n\nA\n\nB\n\nC\n\n0\n\n1.0\n\n15.0\n\n13.5\n..."
          ],
          [
           "In [15]:\n\nA = rng.randint(10, size=(3, 4)) A\n\nOut[15]:\n\narray([[3, 8, 2, 4],\n\n[2, 6, 4, 8],\n\n[6, 1, ..."
          ],
          [
           "2\n\n2\n\n4\n\n2\n\n3\n\n7\n\n1\n\n4\n\nIf you would instead like to operate column-wise, you can use the object met..."
          ],
          [
           "T\n\n0\n\n0.0\n\nNaN\n\n0.0\n\nNaN\n\n1\n\n1.0\n\nNaN\n\n2.0\n\nNaN\n\n2\n\n3.0\n\nNaN\n\n1.0\n\nNaN\n\nThis preservation and alignm..."
          ],
          [
           "Handling Missing Data\n\n< Operating on Data in Pandas | Contents | Hierarchical Indexing >\n\nThe diffe..."
          ],
          [
           "Trade-Offs in Missing Data Conventions¶There are a number of schemes that have been developed to ind..."
          ],
          [
           "Missing Data in Pandas¶The way in which Pandas handles missing values is constrained by its reliance..."
          ],
          [
           "None: Pythonic missing data¶The first sentinel value used by Pandas is None, a Python singleton obje..."
          ],
          [
           "dtype = int 100 loops, best of 3: 3.06 ms per loop\n\nThe use of Python objects in an array also means..."
          ],
          [
           "TypeError: unsupported operand type(s) for +: 'int' and 'NoneType'\n\nThis reflects the fact that addi..."
          ],
          [
           "In [8]:\n\nvals2.sum(), vals2.min(), vals2.max()\n\nOut[8]:\n\n(nan, nan, nan)\n\nNumPy does provide some sp..."
          ],
          [
           "x = pd.Series(range(2), dtype=int)\n\nx\n\nOut[11]:\n\n0    0 1    1 dtype: int64\n\nIn [12]:\n\nx[0] = None\n\n..."
          ],
          [
           "Cast to object\n\nNone or np.nan\n\nKeep in mind that in Pandas, string data is always stored with an ob..."
          ],
          [
           "data[data.notnull()]\n\nOut[15]:\n\n0        1 2    hello dtype: object\n\nThe isnull() and notnull() meth..."
          ],
          [
           "3.0\n\n5\n\n2\n\nNaN\n\n4.0\n\n6\n\nWe cannot drop single values from a DataFrame; we can only drop full rows or..."
          ],
          [
           "In [20]:\n\ndf[3] = np.nan\n\ndf\n\nOut[20]:\n\n0\n\n1\n\n2\n\n3\n\n0\n\n1.0\n\nNaN\n\n2\n\nNaN\n\n1\n\n2.0\n\n3.0\n\n5\n\nNaN\n\n2\n\nNaN..."
          ],
          [
           "2\n\n3\n\n1\n\n2.0\n\n3.0\n\n5\n\nNaN\n\nHere the first and last row have been dropped, because they contain only ..."
          ],
          [
           "In [25]:\n\n# forward\n\nfill\n\ndata.fillna(method='ffill')\n\nOut[25]:\n\na    1.0 b    1.0 c    2.0 d    2...."
          ],
          [
           "Out[28]:\n\n0\n\n1\n\n2\n\n3\n\n0\n\n1.0\n\n1.0\n\n2.0\n\n2.0\n\n1\n\n2.0\n\n3.0\n\n5.0\n\n5.0\n\n2\n\nNaN\n\n4.0\n\n6.0\n\n6.0\n\nNotice th..."
          ],
          [
           "Hierarchical Indexing\n\n< Handling Missing Data | Contents | Combining Datasets: Concat and Append >\n..."
          ],
          [
           "In [2]:\n\nindex = [('California', 2000), ('California', 2010), ('New York', 2000), ('New York', 2010)..."
          ],
          [
           "pop[[i for i in pop.index if i[1] == 2010]]\n\nOut[4]:\n\n(California, 2010)    37253956 (New York, 2010..."
          ],
          [
           "In [6]:\n\npop = pop.reindex(index)\n\npop\n\nOut[6]:\n\nCalifornia  2000    33871648 2010    37253956 New Y..."
          ],
          [
           "In [8]:\n\npop_df = pop.unstack()\n\npop_df\n\nOut[8]:\n\n2000\n\n2010\n\nCalifornia\n\n33871648\n\n37253956\n\nNew Yo..."
          ],
          [
           "In [10]:\n\npop_df = pd.DataFrame({'total': pop,\n\n'under18': [9267089, 9284094,\n\n4687374, 4318033,\n\n59..."
          ],
          [
           "Out[11]:\n\n2000\n\n2010\n\nCalifornia\n\n0.273594\n\n0.249211\n\nNew York\n\n0.247010\n\n0.222831\n\nTexas\n\n0.283251\n..."
          ],
          [
           "0.610054\n\n2\n\n0.171495\n\n0.886688\n\nThe work of creating the MultiIndex is done in the background. Simi..."
          ],
          [
           "Out[14]:\n\nMultiIndex(levels=[['a', 'b'], [1, 2]], labels=[[0, 0, 1, 1], [0, 1, 0, 1]])\n\nYou can cons..."
          ],
          [
           "In [17]:\n\npd.MultiIndex(levels=[['a', 'b'], [1, 2]], labels=[[0, 0, 1, 1], [0, 1, 0, 1]])\n\nOut[17]:\n..."
          ],
          [
           "With more involved datasets, this can be a useful way to keep track of the meaning of various index ..."
          ],
          [
           "visit\n\n2013\n\n1\n\n31.0\n\n38.7\n\n32.0\n\n36.7\n\n35.0\n\n37.2\n\n2\n\n44.0\n\n37.7\n\n50.0\n\n35.0\n\n29.0\n\n36.7\n\n2014\n\n1\n\n..."
          ],
          [
           "2013\n\n1\n\n32.0\n\n36.7\n\n2\n\n50.0\n\n35.0\n\n2014\n\n1\n\n39.0\n\n37.8\n\n2\n\n48.0\n\n37.3\n\nFor complicated records cont..."
          ],
          [
           "In [23]:\n\npop['California']\n\nOut[23]:\n\nyear 2000    33871648 2010    37253956 dtype: int64\n\nPartial ..."
          ],
          [
           "In [27]:\n\npop[['California', 'Texas']]\n\nOut[27]:\n\nstate       year California  2000    33871648 2010..."
          ],
          [
           "2\n\n47.0\n\n37.8\n\n48.0\n\n37.3\n\n51.0\n\n36.5\n\nRemember that columns are primary in a DataFrame, and the syn..."
          ],
          [
           "In [31]:\n\nhealth_data.loc[:, ('Bob', 'HR')]\n\nOut[31]:\n\nyear  visit 2013  1        31.0 2        44.0..."
          ],
          [
           "Bob\n\nGuido\n\nSue\n\ntype\n\nHR\n\nHR\n\nHR\n\nyear\n\nvisit\n\n2013\n\n1\n\n31.0\n\n32.0\n\n35.0\n\n2014\n\n1\n\n30.0\n\n39.0\n\n61.0..."
          ],
          [
           "In [34]:\n\nindex = pd.MultiIndex.from_product([['a', 'c', 'b'], [1, 2]]) data = pd.Series(np.random.r..."
          ],
          [
           "In [36]:\n\ndata = data.sort_index()\n\ndata\n\nOut[36]:\n\nchar  int a     1      0.003001 2      0.164974 ..."
          ],
          [
           "pop.unstack(level=1)\n\nOut[39]:\n\nyear\n\n2000\n\n2010\n\nstate\n\nCalifornia\n\n33871648\n\n37253956\n\nNew York\n\n1..."
          ],
          [
           "year\n\npopulation\n\n0\n\nCalifornia\n\n2000\n\n33871648\n\n1\n\nCalifornia\n\n2010\n\n37253956\n\n2\n\nNew York\n\n2000\n\n1..."
          ],
          [
           "19378102\n\nTexas\n\n2000\n\n20851820\n\n2010\n\n25145561\n\nIn practice, I find this type of reindexing to be o..."
          ],
          [
           "2014\n\n1\n\n30.0\n\n37.4\n\n39.0\n\n37.8\n\n61.0\n\n36.9\n\n2\n\n47.0\n\n37.8\n\n48.0\n\n37.3\n\n51.0\n\n36.5\n\nPerhaps we'd lik..."
          ],
          [
           "By further making use of the axis keyword, we can take the mean among levels on the columns as well:..."
          ],
          [
           "Aside: Panel Data¶Pandas has a few other fundamental data structures that we have not yet discussed,..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "For convenience, we'll define this function which creates a DataFrame of a particular form that will..."
          ],
          [
           "def _repr_html_(self):\n\nreturn '\\n'.join(self.template.format(a, eval(a)._repr_html_())\n\nfor a in se..."
          ],
          [
           "In [5]:\n\nx = [[1, 2],\n\n[3, 4]]\n\nnp.concatenate([x, x], axis=1)\n\nOut[5]:\n\narray([[1, 2, 1, 2],\n\n[3, 4..."
          ],
          [
           "Out[6]:\n\n1    A 2    B 3    C 4    D 5    E 6    F dtype: object\n\nIt also works to concatenate highe..."
          ],
          [
           "B2\n\n3\n\nA3\n\nB3\n\n4\n\nA4\n\nB4\n\nBy default, the concatenation takes place row-wise within the DataFrame (i..."
          ],
          [
           "0\n\nA0\n\nB0\n\nC0\n\nD0\n\n1\n\nA1\n\nB1\n\nC1\n\nD1\n\nWe could have equivalently specified axis=1; here we've used t..."
          ],
          [
           "A0\n\nB0\n\n1\n\nA1\n\nB1\n\n0\n\nA2\n\nB2\n\n1\n\nA3\n\nB3\n\nNotice the repeated indices in the result. While this is va..."
          ],
          [
           "Out[11]:\n\nx\n\nA\n\nB\n\n0\n\nA0\n\nB0\n\n1\n\nA1\n\nB1\n\ny\n\nA\n\nB\n\n0\n\nA2\n\nB2\n\n1\n\nA3\n\nB3\n\npd.concat([x, y], ignore_ind..."
          ],
          [
           "y\n\nA\n\nB\n\n0\n\nA2\n\nB2\n\n1\n\nA3\n\nB3\n\npd.concat([x, y], keys=['x', 'y'])\n\nA\n\nB\n\nx\n\n0\n\nA0\n\nB0\n\n1\n\nA1\n\nB1\n\ny\n..."
          ],
          [
           "Out[13]:\n\ndf5\n\nA\n\nB\n\nC\n\n1\n\nA1\n\nB1\n\nC1\n\n2\n\nA2\n\nB2\n\nC2\n\ndf6\n\nB\n\nC\n\nD\n\n3\n\nB3\n\nC3\n\nD3\n\n4\n\nB4\n\nC4\n\nD4\n\npd..."
          ],
          [
           "In [14]:\n\ndisplay('df5', 'df6',\n\n\"pd.concat([df5, df6], join='inner')\")\n\nOut[14]:\n\ndf5\n\nA\n\nB\n\nC\n\n1\n\n..."
          ],
          [
           "In [15]:\n\ndisplay('df5', 'df6',\n\n\"pd.concat([df5, df6], join_axes=[df5.columns])\")\n\nOut[15]:\n\ndf5\n\nA..."
          ],
          [
           "The append() method¶Because direct array concatenation is so common, Series and DataFrame objects ha..."
          ],
          [
           "B2\n\n3\n\nA3\n\nB3\n\n4\n\nA4\n\nB4\n\nKeep in mind that unlike the append() and extend() methods of Python lists..."
          ],
          [
           "Combining Datasets: Merge and Join\n\n< Combining Datasets: Concat and Append | Contents | Aggregation..."
          ],
          [
           "Relational Algebra¶The behavior implemented in pd.merge() is a subset of what is known as relational..."
          ],
          [
           "In [2]:\n\ndf1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'], 'group': ['Accounting', 'En..."
          ],
          [
           "df3\n\nOut[3]:\n\nemployee\n\ngroup\n\nhire_date\n\n0\n\nBob\n\nAccounting\n\n2008\n\n1\n\nJake\n\nEngineering\n\n2012\n\n2\n\nL..."
          ],
          [
           "In [4]:\n\ndf4 = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'], 'supervisor': ['Carly', '..."
          ],
          [
           "2012\n\nGuido\n\n2\n\nLisa\n\nEngineering\n\n2004\n\nGuido\n\n3\n\nSue\n\nHR\n\n2014\n\nSteve\n\nThe resulting DataFrame has..."
          ],
          [
           "employee\n\ngroup\n\n0\n\nBob\n\nAccounting\n\n1\n\nJake\n\nEngineering\n\n2\n\nLisa\n\nEngineering\n\n3\n\nSue\n\nHR\n\ndf5\n\ngr..."
          ],
          [
           "Sue\n\nHR\n\nspreadsheets\n\n7\n\nSue\n\nHR\n\norganization\n\nThese three types of joins can be used with other P..."
          ],
          [
           "Engineering\n\n3\n\nSue\n\nHR\n\ndf2\n\nemployee\n\nhire_date\n\n0\n\nLisa\n\n2004\n\n1\n\nBob\n\n2008\n\n2\n\nJake\n\n2012\n\n3\n\nSu..."
          ],
          [
           "In [7]:\n\ndf3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'], 'salary': [70000, 80000, 120000..."
          ],
          [
           "70000\n\n1\n\nJake\n\nEngineering\n\nJake\n\n80000\n\n2\n\nLisa\n\nEngineering\n\nLisa\n\n120000\n\n3\n\nSue\n\nHR\n\nSue\n\n90000..."
          ],
          [
           "df2a = df2.set_index('employee')\n\ndisplay('df1a', 'df2a')\n\nOut[9]:\n\ndf1a\n\ngroup\n\nemployee\n\nBob\n\nAcco..."
          ],
          [
           "employee\n\nLisa\n\n2004\n\nBob\n\n2008\n\nJake\n\n2012\n\nSue\n\n2014\n\npd.merge(df1a, df2a, left_index=True, right_..."
          ],
          [
           "2014\n\ndf1a.join(df2a)\n\ngroup\n\nhire_date\n\nemployee\n\nBob\n\nAccounting\n\n2008\n\nJake\n\nEngineering\n\n2012\n\nL..."
          ],
          [
           "group\n\nname\n\nsalary\n\n0\n\nAccounting\n\nBob\n\n70000\n\n1\n\nEngineering\n\nJake\n\n80000\n\n2\n\nEngineering\n\nLisa\n\n1..."
          ],
          [
           "Out[13]:\n\ndf6\n\nname\n\nfood\n\n0\n\nPeter\n\nfish\n\n1\n\nPaul\n\nbeans\n\n2\n\nMary\n\nbread\n\ndf7\n\nname\n\ndrink\n\n0\n\nMary..."
          ],
          [
           "In [15]:\n\ndisplay('df6', 'df7', \"pd.merge(df6, df7, how='outer')\")\n\nOut[15]:\n\ndf6\n\nname\n\nfood\n\n0\n\nPe..."
          ],
          [
           "Out[16]:\n\ndf6\n\nname\n\nfood\n\n0\n\nPeter\n\nfish\n\n1\n\nPaul\n\nbeans\n\n2\n\nMary\n\nbread\n\ndf7\n\nname\n\ndrink\n\n0\n\nMary..."
          ],
          [
           "Finally, you may end up in a case where your two input DataFrames have conflicting column names. Con..."
          ],
          [
           "name\n\nrank_x\n\nrank_y\n\n0\n\nBob\n\n1\n\n3\n\n1\n\nJake\n\n2\n\n1\n\n2\n\nLisa\n\n3\n\n4\n\n3\n\nSue\n\n4\n\n2\n\nBecause the output w..."
          ],
          [
           "Jake\n\n1\n\n2\n\nLisa\n\n4\n\n3\n\nSue\n\n2\n\npd.merge(df8, df9, on=\"name\", suffixes=[\"_L\", \"_R\"])\n\nname\n\nrank_L\n\n..."
          ],
          [
           "In [19]:\n\n# Following are shell commands to download the data # !curl -O https://raw.githubuserconte..."
          ],
          [
           "under18\n\n2012\n\n1117489.0\n\n1\n\nAL\n\ntotal\n\n2012\n\n4817528.0\n\n2\n\nAL\n\nunder18\n\n2010\n\n1130966.0\n\n3\n\nAL\n\ntot..."
          ],
          [
           "Arizona\n\nAZ\n\n3\n\nArkansas\n\nAR\n\n4\n\nCalifornia\n\nCA\n\nGiven this information, say we want to compute a re..."
          ],
          [
           "2\n\nAL\n\nunder18\n\n2010\n\n1130966.0\n\nAlabama\n\n3\n\nAL\n\ntotal\n\n2010\n\n4785570.0\n\nAlabama\n\n4\n\nAL\n\nunder18\n\n20..."
          ],
          [
           "PR\n\ntotal\n\n1991\n\nNaN\n\nNaN\n\n2451\n\nPR\n\nunder18\n\n1991\n\nNaN\n\nNaN\n\n2452\n\nPR\n\ntotal\n\n1993\n\nNaN\n\nNaN\n\nIt ap..."
          ],
          [
           "Out[25]:\n\nstate/region    False ages            False year            False population       True st..."
          ],
          [
           "4\n\nAL\n\nunder18\n\n2011\n\n1125763.0\n\nAlabama\n\n52423.0\n\nAgain, let's check for nulls to see if there were..."
          ],
          [
           "ages\n\nyear\n\npopulation\n\nstate\n\narea (sq. mi)\n\n0\n\nAL\n\nunder18\n\n2012\n\n1117489.0\n\nAlabama\n\n52423.0\n\n1\n\n..."
          ],
          [
           "data2010 = final.query(\"year == 2010 & ages == 'total'\") data2010.head()\n\nOut[30]:\n\nstate/region\n\nag..."
          ],
          [
           "In [31]:\n\ndata2010.set_index('state', inplace=True) density = data2010['population'] / data2010['are..."
          ],
          [
           "We see that the least dense state, by far, is Alaska, averaging slightly over one resident per squar..."
          ],
          [
           "In [1]:\n\nimport numpy as np\n\nimport pandas as pd\n\nclass display(object): \"\"\"Display HTML representat..."
          ],
          [
           "planets.shape\n\nOut[2]:\n\n(1035, 6)\n\nIn [3]:\n\nplanets.head()\n\nOut[3]:\n\nmethod\n\nnumber\n\norbital_period\n..."
          ],
          [
           "2009\n\nThis has some details on the 1,000+ extrasolar planets discovered up to 2014.\n\nSimple Aggregat..."
          ],
          [
           "df\n\nOut[7]:\n\nA\n\nB\n\n0\n\n0.155995\n\n0.020584\n\n1\n\n0.058084\n\n0.969910\n\n2\n\n0.866176\n\n0.832443\n\n3\n\n0.601115\n..."
          ],
          [
           "In [10]:\n\nplanets.dropna().describe()\n\nOut[10]:\n\nnumber\n\norbital_period\n\nmass\n\ndistance\n\nyear\n\ncount..."
          ],
          [
           "39.940000\n\n2009.000000\n\n75%\n\n2.00000\n\n999.600000\n\n2.867500\n\n59.332500\n\n2011.000000\n\nmax\n\n6.00000\n\n17..."
          ],
          [
           "Product of all items\n\nsum()\n\nSum of all items\n\nThese are all methods of DataFrame and Series objects..."
          ],
          [
           "While this could certainly be done manually using some combination of the masking, aggregation, and ..."
          ],
          [
           "The most basic split-apply-combine operation can be computed with the groupby() method of DataFrames..."
          ],
          [
           "The GroupBy object¶The GroupBy object is a very flexible abstraction. In many ways, you can simply t..."
          ],
          [
           "planets.groupby('method')['orbital_period'].median()\n\nOut[16]:\n\nmethod Astrometry                   ..."
          ],
          [
           "This can be useful for doing certain things manually, though it is often much faster to use the buil..."
          ],
          [
           "2009.131579\n\n2.781901\n\n2004.0\n\n2008.00\n\n2009.0\n\n2011.00\n\n2013.0\n\nMicrolensing\n\n23.0\n\n2009.782609\n\n2...."
          ],
          [
           "4.249052\n\n1989.0\n\n2005.00\n\n2009.0\n\n2011.00\n\n2014.0\n\nTransit\n\n397.0\n\n2011.236776\n\n2.077867\n\n2002.0\n\n2..."
          ],
          [
           "Aggregate, filter, transform, apply¶The preceding discussion focused on aggregation for the combine ..."
          ],
          [
           "4\n\nB\n\n4\n\n7\n\n5\n\nC\n\n5\n\n9\n\nAggregation¶We're now familiar with GroupBy aggregations with sum(), median(..."
          ],
          [
           "In [21]:\n\ndf.groupby('key').aggregate({'data1': 'min',\n\n'data2': 'max'})\n\nOut[21]:\n\ndata1\n\ndata2\n\nke..."
          ],
          [
           "3\n\nA\n\n3\n\n3\n\n4\n\nB\n\n4\n\n7\n\n5\n\nC\n\n5\n\n9\n\ndf.groupby('key').std()\n\ndata1\n\ndata2\n\nkey\n\nA\n\n2.12132\n\n1.414214..."
          ],
          [
           "Transformation¶While aggregation must return a reduced version of the data, transformation can retur..."
          ],
          [
           "In [24]:\n\ndef norm_by_data2(x): # x is a DataFrame of group values x['data1'] /= x['data2'].sum() re..."
          ],
          [
           "3\n\n3\n\nA\n\n0.375000\n\n3\n\n4\n\nB\n\n0.571429\n\n7\n\n5\n\nC\n\n0.416667\n\n9\n\napply() within a GroupBy is quite flexib..."
          ],
          [
           "2\n\nC\n\n2\n\n3\n\n3\n\nA\n\n3\n\n3\n\n4\n\nB\n\n4\n\n7\n\n5\n\nC\n\n5\n\n9\n\ndf.groupby(L).sum()\n\ndata1\n\ndata2\n\n0\n\n7\n\n17\n\n1\n\n4\n\n3..."
          ],
          [
           "4\n\nB\n\n4\n\n7\n\n5\n\nC\n\n5\n\n9\n\ndf.groupby(df['key']).sum()\n\ndata1\n\ndata2\n\nkey\n\nA\n\n3\n\n8\n\nB\n\n5\n\n7\n\nC\n\n7\n\n12\n\n..."
          ],
          [
           "5\n\n9\n\ndf2.groupby(mapping).sum()\n\ndata1\n\ndata2\n\nconsonant\n\n12\n\n19\n\nvowel\n\n3\n\n8\n\nAny Python function¶..."
          ],
          [
           "6.0\n\nA list of valid keys¶Further, any of the preceding key choices can be combined to group on a mu..."
          ],
          [
           "2.0\n\nEclipse Timing Variations\n\n0.0\n\n0.0\n\n5.0\n\n10.0\n\nImaging\n\n0.0\n\n0.0\n\n29.0\n\n21.0\n\nMicrolensing\n\n0...."
          ],
          [
           "Transit Timing Variations\n\n0.0\n\n0.0\n\n0.0\n\n9.0\n\nThis shows the power of combining many of the operati..."
          ],
          [
           "Pivot Tables\n\n< Aggregation and Grouping | Contents | Vectorized String Operations >\n\nWe have seen h..."
          ],
          [
           "embarked\n\nclass\n\nwho\n\nadult_male\n\ndeck\n\nembark_town\n\nalive\n\nalone\n\n0\n\n0\n\n3\n\nmale\n\n22.0\n\n1\n\n0\n\n7.2500..."
          ],
          [
           "S\n\nFirst\n\nwoman\n\nFalse\n\nC\n\nSouthampton\n\nyes\n\nFalse\n\n4\n\n0\n\n3\n\nmale\n\n35.0\n\n0\n\n0\n\n8.0500\n\nS\n\nThird\n\nman..."
          ],
          [
           "survived\n\nsex\n\nfemale\n\n0.742038\n\nmale\n\n0.188908\n\nThis immediately gives us some insight: overall, th..."
          ],
          [
           "male\n\n0.368852\n\n0.157407\n\n0.135447\n\nThis gives us a better idea of how both gender and class affecte..."
          ],
          [
           "Multi-level pivot tables¶Just as in the GroupBy, the grouping in pivot tables can be specified with ..."
          ],
          [
           "In [7]:\n\nfare = pd.qcut(titanic['fare'], 2) titanic.pivot_table('survived', ['sex', age], [fare, 'cl..."
          ],
          [
           "0.098039\n\n0.125000\n\n0.391304\n\n0.030303\n\n0.192308\n\nThe result is a four-dimensional aggregation with ..."
          ],
          [
           "In [8]:\n\ntitanic.pivot_table(index='sex', columns='class',\n\naggfunc={'survived':sum, 'fare':'mean'})..."
          ],
          [
           "Third\n\nAll\n\nsex\n\nfemale\n\n0.968085\n\n0.921053\n\n0.500000\n\n0.742038\n\nmale\n\n0.368852\n\n0.157407\n\n0.135447\n..."
          ],
          [
           "In [11]:\n\nbirths = pd.read_csv('data/births.csv')\n\nTaking a look at the data, we see that it's relat..."
          ],
          [
           "births.pivot_table('births', index='decade', columns='gender', aggfunc='sum')\n\nOut[13]:\n\ngender\n\nF\n\n..."
          ],
          [
           "Further data exploration¶Though this doesn't necessarily relate to the pivot table, there are a few ..."
          ],
          [
           "births = births.query('(births > @mu - 5 * @sig) & (births < @mu + 5 * @sig)')\n\nNext we set the day ..."
          ],
          [
           "In [19]:\n\nimport matplotlib.pyplot as plt\n\nimport matplotlib as mpl\n\nbirths.pivot_table('births', in..."
          ],
          [
           "In [21]:\n\nbirths_by_date.index = [pd.datetime(2012, month, day) for (month, day) in births_by_date.i..."
          ],
          [
           "In particular, the striking feature of this graph is the dip in birthrate on US holidays (e.g., Inde..."
          ],
          [
           "Vectorized String Operations\n\n< Pivot Tables | Contents | Working with Time Series >\n\nOne strength o..."
          ],
          [
           "Out[2]:\n\n['Peter', 'Paul', 'Mary', 'Guido']\n\nThis is perhaps sufficient to work with some data, but ..."
          ],
          [
           "AttributeError: 'NoneType' object has no attribute 'capitalize'\n\nPandas includes features to address..."
          ],
          [
           "Methods similar to Python string methods¶Nearly all Python's built-in string methods are mirrored by..."
          ],
          [
           "In [7]:\n\nmonte.str.lower()\n\nOut[7]:\n\n0    graham chapman 1       john cleese 2     terry gilliam 3  ..."
          ],
          [
           "Method\n\nDescription\n\nmatch() Call re.match() on each element, returning a boolean.\n\nextract() Call r..."
          ],
          [
           "monte.str.findall(r'^[^AEIOU].\n\n[^aeiou]$')\n\nOut[12]:\n\n0    [Graham Chapman] 1                  [] 2..."
          ],
          [
           "join() Join strings in each element of the Series with passed separator\n\nget_dummies() extract dummy..."
          ],
          [
           "1)\n\nOut[14]:\n\n0    Chapman 1     Cleese 2    Gilliam 3       Idle 4      Jones 5      Palin dtype: o..."
          ],
          [
           "4\n\nB|C\n\nTerry Jones\n\n5\n\nB|C|D\n\nMichael Palin\n\nThe get_dummies() routine lets you quickly split-out t..."
          ],
          [
           "Example: Recipe Database¶These vectorized string operations become most useful in the process of cle..."
          ],
          [
           "except ValueError as e:\n\nprint(\"ValueError:\", e)\n\nValueError: Trailing data\n\nOops! We get a ValueErr..."
          ],
          [
           "In [21]:\n\nrecipes.shape\n\nOut[21]:\n\n(173278, 17)\n\nWe see there are nearly 200,000 recipes, and 17 col..."
          ],
          [
           "In [23]:\n\nrecipes.ingredients.str.len().describe()\n\nOut[23]:\n\ncount    173278.000000 mean        244..."
          ],
          [
           "Out[26]:\n\n10526\n\nWe could even look to see whether any recipes misspell the ingredient as \"cinamon\":..."
          ],
          [
           "We can then build a Boolean DataFrame consisting of True and False values, indicating whether this i..."
          ],
          [
           "False\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\n4\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n..."
          ],
          [
           "In [31]:\n\nrecipes.name[selection.index]\n\nOut[31]:\n\n2069      All cremat with a Little Gem, dandelion..."
          ],
          [
           "< Pivot Tables | Contents | Working with Time Series >\n\nWorking with Time Series | Python Data Scien..."
          ],
          [
           "In this section, we will introduce how to work with each of these types of date/time data in Pandas...."
          ],
          [
           "Or, using the dateutil module, you can parse dates from a variety of string formats:\n\nIn [2]:\n\nfrom ..."
          ],
          [
           "Typed arrays of times: NumPy's datetime64¶The weaknesses of Python's datetime format inspired the Nu..."
          ],
          [
           "07\n\n11',\n\n'2015\n\n07\n\n12', '2015\n\n07\n\n13', '2015\n\n07\n\n14', '2015\n\n07\n\n15'], dtype='datetime64[D]')\n\nB..."
          ],
          [
           "07\n\n04')\n\nHere is a minute\n\nbased datetime:\n\nIn [7]:\n\nnp.datetime64('2015\n\n07\n\n04 12:00')\n\nOut[7]:\n\n..."
          ],
          [
           "[9.2e18 BC, 9.2e18 AD]\n\nM\n\nMonth\n\n± 7.6e17 years\n\n[7.6e17 BC, 7.6e17 AD]\n\nW\n\nWeek\n\n± 1.7e17 years\n\n[..."
          ],
          [
           "fs Femtosecond ± 2.6 hours [ 1969 AD, 1970 AD]\n\nas Attosecond ± 9.2 seconds [ 1969 AD, 1970 AD]\n\nFor..."
          ],
          [
           "Timestamp('2015\n\n07\n\n04 00:00:00')\n\nIn [10]:\n\ndate.strftime('%A')\n\nOut[10]:\n\n'Saturday'\n\nAdditionall..."
          ],
          [
           "In the next section, we will take a closer look at manipulating time series data with the tools prov..."
          ],
          [
           "In [14]:\n\ndata['2015']\n\nOut[14]:\n\n2015-07-04    2 2015-08-04    3 dtype: int64\n\nLater, we will see a..."
          ],
          [
           "In [15]:\n\ndates = pd.to_datetime([datetime(2015, 7, 3), '4th of July, 2015', '2015-Jul-6', '07-07-20..."
          ],
          [
           "'2015\n\n07\n\n08'],\n\ndtype='int64', freq='D')\n\nA TimedeltaIndex is created, for example, when a date is..."
          ],
          [
           "Out[18]:\n\nDatetimeIndex(['2015\n\n07\n\n03', '2015\n\n07\n\n04', '2015\n\n07\n\n05', '2015\n\n07\n\n06',\n\n'2015\n\n07\n..."
          ],
          [
           "08', '2015\n\n07\n\n09', '2015\n\n07\n\n10'],\n\ndtype='datetime64[ns]', freq='D')\n\nThe spacing can be modifie..."
          ],
          [
           "03 07:00:00'],\n\ndtype='datetime64[ns]', freq='H')\n\nTo create regular sequences of Period or Timedelt..."
          ],
          [
           "pd.timedelta_range(0, periods=10, freq='H')\n\nOut[22]:\n\nTimedeltaIndex(['00:00:00', '01:00:00', '02:0..."
          ],
          [
           "A\n\nYear end\n\nBA\n\nBusiness year end\n\nH\n\nHours\n\nBH\n\nBusiness hours\n\nT\n\nMinutes\n\nS\n\nSeconds\n\nL\n\nMillise..."
          ],
          [
           "W\n\nSUN, W\n\nMON, W\n\nTUE, W\n\nWED, etc.\n\nOn top of this, codes can be combined with numbers to specify ..."
          ],
          [
           "Out[24]:\n\nDatetimeIndex(['2015\n\n07\n\n01', '2015\n\n07\n\n02', '2015\n\n07\n\n03', '2015\n\n07\n\n06',\n\n'2015\n\n07\n..."
          ],
          [
           "In [25]:\n\nfrom pandas_datareader import data\n\ngoog = data.DataReader('GOOG', start='2004', end='2016..."
          ],
          [
           "For simplicity, we'll use just the closing price:\n\nIn [26]:\n\ngoog = goog['Close']\n\nWe can visualize ..."
          ],
          [
           "');\n\nplt.legend(['input', 'resample', 'asfreq'],\n\nloc='upper left');\n\nNotice the difference: at each..."
          ],
          [
           "o')\n\nax[1].legend([\"back\n\nfill\", \"forward\n\nfill\"]);\n\nThe top panel is the default: non-business days..."
          ],
          [
           "11\n\n05')\n\noffset = pd.Timedelta(900, 'D')\n\nax[0].legend(['input'], loc=2)\n\nax[0].get_xticklabels()[2..."
          ],
          [
           "In [32]:\n\nROI = 100\n\n(goog.tshift(\n\n365) / goog\n\n1)\n\nROI.plot()\n\nplt.ylabel('% Return on Investment'..."
          ],
          [
           "', '-\n\n', ':'])\n\nax.lines[0].set_alpha(0.3)\n\nAs with group-by operations, the aggregate() and apply(..."
          ],
          [
           "In [34]:\n\n# !curl\n\no FremontBridge.csv https://data.seattle.gov/api/views/65db\n\nxm6k/rows.csv?access..."
          ],
          [
           "2012\n\n10\n\n03 04:00:00\n\n6.0\n\n1.0\n\nFor convenience, we'll further process this dataset by shortening t..."
          ],
          [
           "50%\n\n33.000000\n\n28.000000\n\n65.000000\n\n75%\n\n79.000000\n\n67.000000\n\n151.000000\n\nmax\n\n825.000000\n\n717.00..."
          ],
          [
           "', '\n\n'])\n\nplt.ylabel('Weekly bicycle count');\n\nThis shows us some interesting seasonal trends: as y..."
          ],
          [
           "', '\n\n']);\n\nDigging into the data¶While these smoothed data views are useful to get an idea of the g..."
          ],
          [
           "In [44]:\n\nby_weekday = data.groupby(data.index.dayofweek).mean() by_weekday.index = ['Mon', 'Tues', ..."
          ],
          [
           "Now we'll use some of the Matplotlib tools described in Multiple Subplots to plot two panels side by..."
          ],
          [
           "Python Data Science Handbook\n\nAbout\n\nArchive\n\nThis is an excerpt from the Python Data Science Handbo..."
          ],
          [
           "In [1]:\n\nimport numpy as np\n\nrng = np.random.RandomState(42)\n\nx = rng.rand(1000000)\n\ny = rng.rand(10..."
          ],
          [
           "tmp1 = (x > 0.5) tmp2 = (y < 0.5) mask = tmp1 & tmp2\n\nIn other words, every intermediate step is exp..."
          ],
          [
           "In [6]:\n\nimport pandas as pd nrows, ncols = 100000, 100 rng = np.random.RandomState(42) df1, df2, df..."
          ],
          [
           "Out[9]:\n\nTrue\n\nOperations supported by pd.eval()¶As of Pandas v0.16, pd.eval() supports a wide range..."
          ],
          [
           "Out[12]:\n\nTrue\n\nBitwise operators¶pd.eval() supports the & and | bitwise operators:\n\nIn [13]:\n\nresul..."
          ],
          [
           "Out[15]:\n\nTrue\n\nOther operations¶Other operations such as function calls, conditional statements, lo..."
          ],
          [
           "0.808055\n\n0.347197\n\n4\n\n0.589161\n\n0.252418\n\n0.557789\n\nUsing pd.eval() as above, we can compute expres..."
          ],
          [
           "In [19]:\n\ndf.head()\n\nOut[19]:\n\nA\n\nB\n\nC\n\n0\n\n0.375506\n\n0.406939\n\n0.069938\n\n1\n\n0.069087\n\n0.235615\n\n0.15..."
          ],
          [
           "11.187620\n\n1\n\n0.069087\n\n0.235615\n\n0.154374\n\n1.973796\n\n2\n\n0.677945\n\n0.433839\n\n0.652324\n\n1.704344\n\n3\n\n..."
          ],
          [
           "0.154374\n\n1.078728\n\n2\n\n0.677945\n\n0.433839\n\n0.652324\n\n0.374209\n\n3\n\n0.264038\n\n0.808055\n\n0.347197\n\n1.56..."
          ],
          [
           "DataFrame.query() Method¶The DataFrame has another method based on evaluated strings, called the que..."
          ],
          [
           "In [25]:\n\nCmean = df['C'].mean() result1 = df[(df.A < Cmean) & (df.B < Cmean)] result2 = df.query('A..."
          ],
          [
           "In [28]:\n\ndf.values.nbytes\n\nOut[28]:\n\n32000\n\nOn the performance side, eval() can be faster even when..."
          ],
          [
           "Further Resources\n\n< High-Performance Pandas: eval() and query() | Contents | Visualization with Mat..."
          ],
          [
           "Pandas on PyVideo: From PyCon to SciPy to PyData, many conferences have featured tutorials from Pand..."
          ],
          [
           "Visualization with Matplotlib\n\n< Further Resources | Contents | Simple Line Plots >\n\nWe'll now take ..."
          ],
          [
           "In recent years, however, the interface and style of Matplotlib have begun to show their age. Newer ..."
          ],
          [
           "In [1]:\n\nimport matplotlib as mpl\n\nimport matplotlib.pyplot as plt\n\nThe plt interface is what we wil..."
          ],
          [
           "Plotting from a script¶If you are using Matplotlib from within a script, the function plt.show() is ..."
          ],
          [
           "Plotting from an IPython shell¶It can be very convenient to use Matplotlib interactively within an I..."
          ],
          [
           "For this book, we will generally opt for %matplotlib inline:\n\nIn [3]:\n\n%matplotlib inline\n\nAfter run..."
          ],
          [
           "r\n\n--r\n\n--  1 jakevdp  staff    16K Aug 11 10:59 my_figure.png\n\nTo confirm that it contains what we ..."
          ],
          [
           "Note that when saving your figure, it's not necessary to use plt.show() or related commands discusse..."
          ],
          [
           "It is important to note that this interface is stateful: it keeps track of the \"current\" figure and ..."
          ],
          [
           "For more simple plots, the choice of which style to use is largely a matter of preference, but the o..."
          ],
          [
           "2. Introduction to NumPy¶ Understanding Data Types in Python The Basics of NumPy Arrays Computation ..."
          ],
          [
           "Appendix: Figure Code¶\n\nSimple Line Plots | Python Data Science Handbook\n\nPython Data Science Handbo..."
          ],
          [
           "In [2]:\n\nfig = plt.figure()\n\nax = plt.axes()\n\nIn Matplotlib, the figure (an instance of the class pl..."
          ],
          [
           "In [5]:\n\nplt.plot(x, np.sin(x))\n\nplt.plot(x, np.cos(x));\n\nThat's all there is to plotting simple fun..."
          ],
          [
           "In [6]:\n\nplt.plot(x, np.sin(x - 0), color='blue')        # specify color by name plt.plot(x, np.sin(..."
          ],
          [
           "# For short, you can use the following codes: plt.plot(x, x + 4, linestyle='-')  # solid plt.plot(x,..."
          ],
          [
           "Adjusting the Plot: Axes Limits¶Matplotlib does a decent job of choosing default axes limits for you..."
          ],
          [
           "plt.axis([\n\n1, 11,\n\n1.5, 1.5]);\n\nThe plt.axis() method goes even beyond this, allowing you to do thi..."
          ],
          [
           "plt.xlabel(\"x\")\n\nplt.ylabel(\"sin(x)\");\n\nThe position, size, and style of these labels can be adjuste..."
          ],
          [
           "Aside: Matplotlib Gotchas¶While most plt functions translate directly to ax methods (such as plt.plo..."
          ],
          [
           "< Visualization with Matplotlib | Contents | Simple Scatter Plots >\n\nSimple Scatter Plots | Python D..."
          ],
          [
           "In [2]:\n\nx = np.linspace(0, 10, 30) y = np.sin(x)\n\nplt.plot(x, y, 'o', color='black');\n\nThe third ar..."
          ],
          [
           "In [4]:\n\nplt.plot(x, y, '\n\nok');\n\nAdditional keyword arguments to plt.plot specify a wide range of p..."
          ],
          [
           "In [6]:\n\nplt.scatter(x, y, marker='o');\n\nThe primary difference of plt.scatter from plt.plot is that..."
          ],
          [
           "In [8]:\n\nfrom sklearn.datasets import load_iris\n\niris = load_iris()\n\nfeatures = iris.data.T\n\nplt.sca..."
          ],
          [
           "plot Versus scatter: A Note on Efficiency¶Aside from the different features available in plt.plot an..."
          ],
          [
           "Visualizing Errors\n\n< Simple Scatter Plots | Contents | Density and Contour Plots >\n\nFor any scienti..."
          ],
          [
           "whitegrid')\n\nimport numpy as np\n\nIn [2]:\n\nx = np.linspace(0, 10, 50) dy = 0.8 y = np.sin(x) + dy * n..."
          ],
          [
           "Continuous Errors¶In some situations it is desirable to show errorbars on continuous quantities. Tho..."
          ],
          [
           "xfit = np.linspace(0, 10, 1000) yfit, MSE = gp.predict(xfit[:, np.newaxis], eval_MSE=True) dyfit = 2..."
          ],
          [
           "color='gray', alpha=0.2)\n\nplt.xlim(0, 10);\n\nNote what we've done here with the fill_between function..."
          ],
          [
           "Density and Contour Plots\n\n< Visualizing Errors | Contents | Histograms, Binnings, and Density >\n\nSo..."
          ],
          [
           "A contour plot can be created with the plt.contour function. It takes three arguments: a grid of x v..."
          ],
          [
           "In [5]:\n\nplt.contour(X, Y, Z, 20, cmap='RdGy');\n\nHere we chose the RdGy (short for Red-Gray) colorma..."
          ],
          [
           "plt.contourf(X, Y, Z, 20, cmap='RdGy') plt.colorbar();\n\nThe colorbar makes it clear that the black r..."
          ],
          [
           "There are a few potential gotchas with imshow(), however:\n\nplt.imshow() doesn't accept an x and y gr..."
          ],
          [
           "The combination of these three functions—plt.contour, plt.contourf, and plt.imshow—gives nearly limi..."
          ],
          [
           "In [1]:\n\n%matplotlib inline\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('sea..."
          ],
          [
           "plt.hist(x1, *\n\nkwargs)\n\nplt.hist(x2, *\n\nkwargs)\n\nplt.hist(x3, *\n\nkwargs);\n\nIf you would like to sim..."
          ],
          [
           "In [12]:\n\nplt.hist2d(x, y, bins=30, cmap='Blues')\n\ncb = plt.colorbar()\n\ncb.set_label('counts in bin'..."
          ],
          [
           "plt.hexbin has a number of interesting options, including the ability to specify weights for each po..."
          ],
          [
           "# Plot the result as an image plt.imshow(Z.reshape(Xgrid.shape), origin='lower', aspect='auto', exte..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "But there are many ways we might want to customize such a legend. For example, we can specify the lo..."
          ],
          [
           "In [7]:\n\ny = np.sin(x[:, np.newaxis] + np.pi * np.arange(0, 2, 0.5)) lines = plt.plot(x, y)\n\n# lines..."
          ],
          [
           "In [9]:\n\nimport pandas as pd\n\ncities = pd.read_csv('data/california_cities.csv')\n\n# Extract the data..."
          ],
          [
           "plt.title('California Cities: Area and Population');\n\nThe legend will always reference some object t..."
          ],
          [
           "In [10]:\n\nfig, ax = plt.subplots()\n\nlines = [] styles = ['-', '--', '-. ', ':'] x = np.linspace(0, 1..."
          ],
          [
           "< Histograms, Binnings, and Density | Contents | Customizing Colorbars >\n\nCustomizing Colorbars | Py..."
          ],
          [
           "In [2]:\n\n%matplotlib inline\n\nimport numpy as np\n\nAs we have seen several times throughout this secti..."
          ],
          [
           "Choosing the Colormap¶A full treatment of color choice within visualization is beyond the scope of t..."
          ],
          [
           "# convert RGBA to perceived grayscale luminance # cf. http://alienryderflex.com/hsp.html RGB_weight ..."
          ],
          [
           "In [6]:\n\nview_colormap('jet')\n\nNotice the bright stripes in the grayscale image. Even in full color,..."
          ],
          [
           "In [9]:\n\nview_colormap('RdBu')\n\nWe'll see examples of using some of these color maps as we continue...."
          ],
          [
           "plt.imshow(I, cmap='RdBu')\n\nplt.colorbar()\n\nplt.subplot(1, 2, 2)\n\nplt.imshow(I, cmap='RdBu')\n\nplt.co..."
          ],
          [
           "1, 1);\n\nThe discrete version of a colormap can be used just like any other colormap.\n\nExample: Handw..."
          ],
          [
           "Because each digit is defined by the hue of its 64 pixels, we can consider each digit to be a point ..."
          ],
          [
           "The projection also gives us some interesting insights on the relationships within the dataset: for ..."
          ],
          [
           "In [1]:\n\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn\n\nwhite')\n\nimpor..."
          ],
          [
           "In [3]:\n\nfig = plt.figure() ax1 = fig.add_axes([0.1, 0.5, 0.8, 0.4], xticklabels=[], ylim=(-1.2, 1.2..."
          ],
          [
           "In [4]:\n\nfor i in range(1, 7): plt.subplot(2, 3, i) plt.text(0.5, 0.5, str((2, 3, i)), fontsize=18, ..."
          ],
          [
           "plt.subplots: The Whole Grid in One Go¶The approach just described can become quite tedious when cre..."
          ],
          [
           "In [7]:\n\n# axes are in a two-dimensional array, indexed by [row, col] for i in range(2): for j in ra..."
          ],
          [
           "plt.subplot(grid[0, 1:])\n\nplt.subplot(grid[1, :2])\n\nplt.subplot(grid[1, 2]);\n\nThis type of flexible ..."
          ],
          [
           "# scatter points on the main axes main_ax.plot(x, y, 'ok', markersize=3, alpha=0.2)\n\n# histogram on ..."
          ],
          [
           "Text and Annotation\n\n< Multiple Subplots | Contents | Customizing Ticks >\n\nCreating a good visualiza..."
          ],
          [
           "In [2]:\n\nbirths = pd.read_csv('data/births.csv')\n\nquartiles = np.percentile(births['births'], [25, 5..."
          ],
          [
           "In [4]:\n\nfig, ax = plt.subplots(figsize=(12, 4)) births_by_date.plot(ax=ax)\n\n# Add labels to the plo..."
          ],
          [
           "# Label the axes ax.set(title='USA births by day of year (1969-1988)', ylabel='average daily births'..."
          ],
          [
           "Transforms and Text Position¶In the previous example, we have anchored our text annotations to data ..."
          ],
          [
           "ax.axis([0, 10, 0, 10])\n\n# transform=ax.transData is the default, but we'll specify it anyway ax.tex..."
          ],
          [
           "ax.set_ylim(\n\n6, 6)\n\nfig\n\nOut[6]:\n\nThis behavior can be seen more clearly by changing the axes limit..."
          ],
          [
           "ax.annotate('local minimum', xy=(5\n\nnp.pi,\n\n1), xytext=(2,\n\n6),\n\narrowprops=dict(arrowstyle=\"\n\n>\",\n\n..."
          ],
          [
           "7\n\n4', 4250),  xycoords='data',\n\nbbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\"),\n\nxytext=(10,\n\n40..."
          ],
          [
           "31', 4600),  xycoords='data',\n\nxytext=(\n\n80,\n\n40), textcoords='offset points',\n\narrowprops=dict(arro..."
          ],
          [
           "30, 0), textcoords='offset points',\n\nsize=13, ha='right', va=\"center\",\n\nbbox=dict(boxstyle=\"round\", ..."
          ],
          [
           "ax.set_ylim(3600, 5400);\n\nYou'll notice that the specifications of the arrows and text boxes are ver..."
          ],
          [
           "Customizing Ticks\n\n< Text and Annotation | Contents | Customizing Matplotlib: Configurations and Sty..."
          ],
          [
           "plt.style.use('classic')\n\n%matplotlib inline\n\nimport numpy as np\n\nIn [2]:\n\nax = plt.axes(xscale='log..."
          ],
          [
           "<matplotlib.ticker.NullFormatter object at 0x10db9af60>\n\nWe see that both major and minor tick label..."
          ],
          [
           "In [6]:\n\nfig, ax = plt.subplots(5, 5, figsize=(5, 5)) fig.subplots_adjust(hspace=0, wspace=0)\n\n# Get..."
          ],
          [
           "In [7]:\n\nfig, ax = plt.subplots(4, 4, sharex=True, sharey=True)\n\nParticularly for the x ticks, the n..."
          ],
          [
           "In [9]:\n\n# Plot a sine and cosine curve fig, ax = plt.subplots() x = np.linspace(0, 3 * np.pi, 1000)..."
          ],
          [
           "fig\n\nOut[10]:\n\nBut now these tick labels look a little bit silly: we can see that they are multiples..."
          ],
          [
           "fig\n\nOut[11]:\n\nThis is much better! Notice that we've made use of Matplotlib's LaTeX support, specif..."
          ],
          [
           "AutoLocator (Default.) MaxNLocator with simple defaults.\n\nAutoMinorLocator\n\nLocator for minor ticks\n..."
          ],
          [
           "Customizing Matplotlib: Configurations and Stylesheets\n\n< Customizing Ticks | Contents | Three-Dimen..."
          ],
          [
           "# use a gray background ax = plt.axes(axisbg='#E6E6E6') ax.set_axisbelow(True)\n\n# draw solid white g..."
          ],
          [
           "Changing the Defaults: rcParams¶Each time Matplotlib loads, it defines a runtime configuration (rc) ..."
          ],
          [
           "plt.rc('ytick', direction='out', color='gray')\n\nplt.rc('patch', edgecolor='#E6E6E6')\n\nplt.rc('lines'..."
          ],
          [
           "Stylesheets¶The version 1.4 release of Matplotlib in August 2014 added a very convenient style modul..."
          ],
          [
           "Let's create a function that will make two basic types of plot:\n\nIn [9]:\n\ndef hist_and_lines(): np.r..."
          ],
          [
           "with plt.style.context('fivethirtyeight'):\n\nhist_and_lines()\n\nggplot¶The ggplot package in the R lan..."
          ],
          [
           "In [16]:\n\nwith plt.style.context('grayscale'):\n\nhist_and_lines()\n\nSeaborn style¶Matplotlib also has ..."
          ],
          [
           "Dimensional Plotting in Matplotlib\n\n< Customizing Matplotlib: Configurations and Stylesheets | Conte..."
          ],
          [
           "Three-dimensional Points and Lines¶The most basic three-dimensional plot is a line or collection of ..."
          ],
          [
           "Notice that by default, the scatter points have their transparency adjusted to give a sense of depth..."
          ],
          [
           "Sometimes the default viewing angle is not optimal, in which case we can use the view_init method to..."
          ],
          [
           "In [9]:\n\nax = plt.axes(projection='3d') ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='viridis..."
          ],
          [
           "In [11]:\n\ntheta = 2\n\nnp.pi\n\nnp.random.random(1000)\n\nr = 6\n\nnp.random.random(1000)\n\nx = np.ravel(r\n\nn..."
          ],
          [
           "ax.plot_trisurf(x, y, z,\n\ncmap='viridis', edgecolor='none');\n\nThe result is certainly not as clean a..."
          ],
          [
           "Now from this parametrization, we must determine the (x, y, z) positions of the embedded strip. Thin..."
          ],
          [
           "In [17]:\n\n# triangulate in the underlying parametrization from matplotlib.tri import Triangulation t..."
          ],
          [
           "Geographic Data with Basemap\n\n< Three-Dimensional Plotting in Matplotlib | Contents | Visualization ..."
          ],
          [
           "In [2]:\n\nplt.figure(figsize=(8, 8)) m = Basemap(projection='ortho', resolution=None, lat_0=50, lon_0..."
          ],
          [
           "This gives you a brief glimpse into the sort of geographic visualizations that are possible with jus..."
          ],
          [
           "# keys contain the plt.Line2D instances lat_lines = chain(*(tup[1][0] for tup in lats.items())) lon_..."
          ],
          [
           "The additional arguments to Basemap for this view specify the latitude (lat) and longitude (lon) of ..."
          ],
          [
           "The extra arguments to Basemap here refer to the central latitude (lat_0) and longitude (lon_0) for ..."
          ],
          [
           "lat_0=50, lon_0=0)\n\ndraw_map(m);\n\nConic projections¶A Conic projection projects the map onto a singl..."
          ],
          [
           "width=1.6E7, height=1.2E7)\n\ndraw_map(m)\n\nOther projections¶If you're going to do much with map-based..."
          ],
          [
           "Political boundaries\n\ndrawcountries(): Draw country boundaries drawstates(): Draw US state boundarie..."
          ],
          [
           "In [9]:\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 8))\n\nfor i, res in enumerate(['l', 'h']): m = Bas..."
          ],
          [
           "Plotting Data on Maps¶Perhaps the most useful piece of the Basemap toolkit is the ability to over-pl..."
          ],
          [
           "We'll see some examples of a few of these as we continue. For more information on these functions, i..."
          ],
          [
           "# 2. scatter city data, with color reflecting population # and size reflecting area m.scatter(lon, l..."
          ],
          [
           "In [12]:\n\n# !curl\n\nO http://data.giss.nasa.gov/pub/gistemp/gistemp250.nc.gz\n\n# !gunzip gistemp250.nc..."
          ],
          [
           "Finally, we'll use the pcolormesh() method to draw a color mesh of the data. We'll look at North Ame..."
          ],
          [
           "< Three-Dimensional Plotting in Matplotlib | Contents | Visualization with Seaborn >\n\nVisualization ..."
          ],
          [
           "An answer to these problems is Seaborn. Seaborn provides an API on top of Matplotlib that offers san..."
          ],
          [
           "And do a simple plot:\n\nIn [3]:\n\n# Plot the data with Matplotlib defaults plt.plot(x, y) plt.legend('..."
          ],
          [
           "Ah, much better!\n\nExploring Seaborn Plots¶The main idea of Seaborn is that it provides high-level co..."
          ],
          [
           "Histograms and KDE can be combined using distplot:\n\nIn [8]:\n\nsns.distplot(data['x'])\n\nsns.distplot(d..."
          ],
          [
           "sns.jointplot(\"x\", \"y\", data, kind='hex')\n\nPair plots¶When you generalize joint plots to datasets of..."
          ],
          [
           "setosa\n\n4\n\n5.0\n\n3.6\n\n1.4\n\n0.2\n\nsetosa\n\nVisualizing the multidimensional relationships among the samp..."
          ],
          [
           "2\n\n21.01\n\n3.50\n\nMale\n\nNo\n\nSun\n\nDinner\n\n3\n\n3\n\n23.68\n\n3.31\n\nMale\n\nNo\n\nSun\n\nDinner\n\n2\n\n4\n\n24.59\n\n3.61\n\n..."
          ],
          [
           "Joint distributions¶Similar to the pairplot we saw earlier, we can use sns.jointplot to show the joi..."
          ],
          [
           "2.21\n\n56.95\n\n2008\n\n2\n\nRadial Velocity\n\n1\n\n763.000\n\n2.60\n\n19.84\n\n2011\n\n3\n\nRadial Velocity\n\n1\n\n326.030..."
          ],
          [
           "For more information on plotting with Seaborn, see the Seaborn documentation, a tutorial, and the Se..."
          ],
          [
           "M\n\n01:06:49\n\n02:10:42\n\n3\n\n38\n\nM\n\n01:06:16\n\n02:13:45\n\n4\n\n31\n\nM\n\n01:06:32\n\n02:13:59\n\nBy default, Panda..."
          ],
          [
           "33\n\nM\n\n01:05:38\n\n02:08:51\n\n1\n\n32\n\nM\n\n01:06:26\n\n02:09:28\n\n2\n\n31\n\nM\n\n01:06:49\n\n02:10:42\n\n3\n\n38\n\nM\n\n01:..."
          ],
          [
           "split_sec\n\nfinal_sec\n\n0\n\n33\n\nM\n\n01:05:38\n\n02:08:51\n\n3938.0\n\n7731.0\n\n1\n\n32\n\nM\n\n01:06:26\n\n02:09:28\n\n39..."
          ],
          [
           "The dotted line shows where someone's time would lie if they ran the marathon at a perfectly steady ..."
          ],
          [
           "0.026262\n\n2\n\n31\n\nM\n\n01:06:49\n\n02:10:42\n\n4009.0\n\n7842.0\n\n0.022443\n\n3\n\n38\n\nM\n\n01:06:16\n\n02:13:45\n\n3976..."
          ],
          [
           "In [31]:\n\nsum(data.split_frac < 0)\n\nOut[31]:\n\n251\n\nOut of nearly 40,000 participants, there were onl..."
          ],
          [
           "sns.kdeplot(data.split_frac[data.gender=='M'], label='men', shade=True)\n\nsns.kdeplot(data.split_frac..."
          ],
          [
           "age\n\ngender\n\nsplit\n\nfinal\n\nsplit_sec\n\nfinal_sec\n\nsplit_frac\n\nage_dec\n\n0\n\n33\n\nM\n\n01:05:38\n\n02:08:51\n\n..."
          ],
          [
           "8039.0\n\n0.006842\n\n30\n\nIn [36]:\n\nmen = (data.gender == 'M') women = (data.gender == 'W')\n\nwith sns.ax..."
          ],
          [
           "In [37]:\n\ng = sns.lmplot('final_sec', 'split_frac', col='gender', data=data, markers=\". \", scatter_k..."
          ],
          [
           "Further Resources\n\n< Visualization with Seaborn | Contents | Machine Learning >\n\nMatplotlib Resource..."
          ],
          [
           "Bokeh is a JavaScript visualization library with a Python frontend that creates highly interactive v..."
          ],
          [
           "Machine Learning | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAbout\n\nArchive\n\nThis ..."
          ],
          [
           "Machine Learning\n\n< Further Resources | Contents | What Is Machine Learning? >\n\nIn many ways, machin..."
          ],
          [
           "Much of this material is drawn from the Scikit-Learn tutorials and workshops I have given on several..."
          ],
          [
           "2. Introduction to NumPy¶ Understanding Data Types in Python The Basics of NumPy Arrays Computation ..."
          ],
          [
           "Appendix: Figure Code¶\n\nWhat Is Machine Learning? | Python Data Science Handbook\n\nPython Data Scienc..."
          ],
          [
           "What Is Machine Learning?\n\n< Machine Learning | Contents | Introducing Scikit-Learn >\n\nBefore we tak..."
          ],
          [
           "Categories of Machine Learning¶At the most fundamental level, machine learning can be categorized in..."
          ],
          [
           "Classification: Predicting discrete labels¶We will first take a look at a simple classification task..."
          ],
          [
           "figure source in Appendix\n\nNow that this model has been trained, it can be generalized to new, unlab..."
          ],
          [
           "For the training set, these labels might be determined by individual inspection of a small represent..."
          ],
          [
           "figure source in Appendix\n\nNotice that the feature 1-feature 2 plane here is the same as in the two-..."
          ],
          [
           "The distances for a small number of these galaxies might be determined through an independent set of..."
          ],
          [
           "figure source in Appendix\n\nk-means fits a model consisting of k cluster centers; the optimal centers..."
          ],
          [
           "figure source in Appendix\n\nVisually, it is clear that there is some structure in this data: it is dr..."
          ],
          [
           "Summary¶Here we have seen a few simple examples of some of the basic types of machine learning appro..."
          ],
          [
           "Introducing Scikit\n\nLearn\n\n< What Is Machine Learning? | Contents | Hyperparameters and Model Valida..."
          ],
          [
           "In [1]:\n\nimport seaborn as sns\n\niris = sns.load_dataset('iris')\n\niris.head()\n\nOut[1]:\n\nsepal_length\n..."
          ],
          [
           "4\n\n5.0\n\n3.6\n\n1.4\n\n0.2\n\nsetosa\n\nHere each row of the data refers to a single observed flower, and the..."
          ],
          [
           "Target array¶In addition to the feature matrix X, we also generally work with a label or target arra..."
          ],
          [
           "In [3]:\n\nX_iris = iris.drop('species', axis=1)\n\nX_iris.shape\n\nOut[3]:\n\n(150, 4)\n\nIn [4]:\n\ny_iris = i..."
          ],
          [
           "Sensible defaults: When models require user-specified parameters, the library defines an appropriate..."
          ],
          [
           "In [5]:\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\nrng = np.random.RandomState(42)\n\nx = 1..."
          ],
          [
           "Would we like to fit for the offset (i.e., y-intercept)? Would we like the model to be normalized? W..."
          ],
          [
           "3. Arrange data into a features matrix and target vector¶Previously we detailed the Scikit-Learn dat..."
          ],
          [
           "model.coef_\n\nOut[10]:\n\narray([ 1.9776566])\n\nIn [11]:\n\nmodel.intercept_\n\nOut[11]:\n\n0.9033107255311163..."
          ],
          [
           "In [13]:\n\nXfit = xfit[:, np.newaxis]\n\nyfit = model.predict(Xfit)\n\nFinally, let's visualize the resul..."
          ],
          [
           "In [15]:\n\nfrom sklearn.cross_validation import train_test_split Xtrain, Xtest, ytrain, ytest = train..."
          ],
          [
           "With an accuracy topping 97%, we see that even this very naive classification algorithm is effective..."
          ],
          [
           "In [19]:\n\niris['PCA1'] = X_2D[:, 0] iris['PCA2'] = X_2D[:, 1] sns.lmplot(\"PCA1\", \"PCA2\", hue='specie..."
          ],
          [
           "As before, we will add the cluster label to the Iris DataFrame and use Seaborn to plot the results:\n..."
          ],
          [
           "In [22]:\n\nfrom sklearn.datasets import load_digits\n\ndigits = load_digits()\n\ndigits.images.shape\n\nOut..."
          ],
          [
           "In order to work with this data within Scikit-Learn, we need a two-dimensional, [n_samples, n_featur..."
          ],
          [
           "iso = Isomap(n_components=2)\n\niso.fit(digits.data)\n\ndata_projected = iso.transform(digits.data)\n\ndat..."
          ],
          [
           "This plot gives us some good intuition into how well various numbers are separated in the larger 64-..."
          ],
          [
           "In [30]:\n\nfrom sklearn.metrics import accuracy_score\n\naccuracy_score(ytest, y_model)\n\nOut[30]:\n\n0.83..."
          ],
          [
           "In [32]:\n\nfig, axes = plt.subplots(10, 10, figsize=(8, 8), subplot_kw={'xticks':[], 'yticks':[]}, gr..."
          ],
          [
           "Summary¶\n\nIn this section we have covered the essential features of the Scikit-Learn data representa..."
          ],
          [
           "Choose a class of model Choose model hyperparameters Fit the model to the training data Use the mode..."
          ],
          [
           "In [2]:\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nmodel = KNeighborsClassifier(n_neighbor..."
          ],
          [
           "Model validation the right way: Holdout sets¶So what can be done? A better sense of a model's perfor..."
          ],
          [
           "Model validation via cross-validation¶One disadvantage of using a holdout set for model validation i..."
          ],
          [
           "(0.95999999999999996, 0.90666666666666662)\n\nWhat comes out are two accuracy scores, which we could c..."
          ],
          [
           "Repeating the validation across different subsets of the data gives us an even better idea of the pe..."
          ],
          [
           "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  1.,  1.,  1.,  1.,..."
          ],
          [
           "1.,  1.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 1...."
          ],
          [
           "1., 1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  1.,  1.,  1.,  0.,  1...."
          ],
          [
           "1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1..."
          ],
          [
           "1.,  1., 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 1.,  1.,  1.,  1.,  1.,  1...."
          ],
          [
           "Because we have 150 samples, the leave one out cross-validation yields scores for 150 trials, and th..."
          ],
          [
           "The Bias-variance trade-off¶Fundamentally, the question of \"the best model\" is about finding a sweet..."
          ],
          [
           "figure source in Appendix The score here is the $R^2$ score, or coefficient of determination, which ..."
          ],
          [
           "The means of tuning the model complexity varies from model to model; when we discuss individual mode..."
          ],
          [
           "LinearRegression(*\n\nkwargs))\n\nNow let's create some data to which we will fit our model:\n\nIn [11]:\n\n..."
          ],
          [
           "X_test = np.linspace(\n\n0.1, 1.1, 500)[:, None]\n\nplt.scatter(X.ravel(), y, color='black') axis = plt...."
          ],
          [
           "plt.plot(degree, np.median(train_score, 1), color='blue', label='training score') plt.plot(degree, n..."
          ],
          [
           "Learning Curves¶One important aspect of model complexity is that the optimal model will generally de..."
          ],
          [
           "The solid lines show the new results, while the fainter dashed lines show the results of the previou..."
          ],
          [
           "With these features in mind, we would expect a learning curve to look qualitatively like that shown ..."
          ],
          [
           "ax[i].plot(N, np.mean(train_lc, 1), color='blue', label='training score') ax[i].plot(N, np.mean(val_..."
          ],
          [
           "ax[i].legend(loc='best')\n\nThis is a valuable diagnostic, because it gives us a visual depiction of h..."
          ],
          [
           "Validation in Practice: Grid Search¶The preceding discussion is meant to give you some intuition int..."
          ],
          [
           "In [19]:\n\ngrid.fit(X, y);\n\nNow that this is fit, we can ask for the best parameters as follows:\n\nIn ..."
          ],
          [
           "Summary¶In this section, we have begun to explore the concept of model validation and hyperparameter..."
          ],
          [
           "Feature Engineering\n\n< Hyperparameters and Model Validation | Contents | In Depth: Naive Bayes Class..."
          ],
          [
           "You might be tempted to encode this data with a straightforward numerical mapping:\n\nIn [2]:\n\n{'Queen..."
          ],
          [
           "Notice that the 'neighborhood' column has been expanded into three separate columns, representing th..."
          ],
          [
           "Text Features¶Another common need in feature engineering is to convert text to a set of representati..."
          ],
          [
           "In [8]:\n\nimport pandas as pd\n\npd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n\nOut[8]:\n\ne..."
          ],
          [
           "Out[9]:\n\nevil\n\nhorizon\n\nof\n\nproblem\n\nqueen\n\n0\n\n0.517856\n\n0.000000\n\n0.680919\n\n0.517856\n\n0.000000\n\n1\n\n..."
          ],
          [
           "Derived Features¶Another useful type of feature is one that is mathematically derived from some inpu..."
          ],
          [
           "plt.scatter(x, y)\n\nplt.plot(x, yfit);\n\nIt's clear that we need a more sophisticated model to describ..."
          ],
          [
           "plt.scatter(x, y)\n\nplt.plot(x, yfit);\n\nThis idea of improving a model not by changing the model, but..."
          ],
          [
           "When applying a typical machine learning model to such data, we will need to first replace such miss..."
          ],
          [
           "model = LinearRegression().fit(X2, y)\n\nmodel.predict(X2)\n\nOut[16]:\n\narray([ 13.14869292,  14.3784627..."
          ],
          [
           "1  8\n\n5]\n\n[ 14. 16.\n\n1. 8.\n\n5.]\n\nAll the steps of the model are applied automatically. Notice that f..."
          ],
          [
           "In Depth: Naive Bayes Classification\n\n< Feature Engineering | Contents | In Depth: Linear Regression..."
          ],
          [
           "Bayesian Classification¶Naive Bayes classifiers are built on Bayesian classification methods. These ..."
          ],
          [
           "quantities we can compute more directly: $$ P(L~|~{\\rm features}) = \\frac{P({\\rm features}~|~L)P(L)}..."
          ],
          [
           "= \\frac{P({\\rm features}~|~L_1)}{P({\\rm features}~|~L_2)}\\frac{P(L_1)}{P(L_2)} $$ All we need now is..."
          ],
          [
           "of such a Bayesian classifier. The general version of such a training step is a very difficult task,..."
          ],
          [
           "This is where the \"naive\" in \"naive Bayes\" comes in: if we make very naive assumptions about the gen..."
          ],
          [
           "figure source in Appendix\n\nThe ellipses here represent the Gaussian generative model for each label,..."
          ],
          [
           "Now we can plot this new data to get an idea of where the decision boundary is:\n\nIn [5]:\n\nplt.scatte..."
          ],
          [
           "The columns give the posterior probabilities of the first and second label, respectively. If you are..."
          ],
          [
           "In [7]:\n\nfrom sklearn.datasets import fetch_20newsgroups\n\ndata = fetch_20newsgroups()\n\ndata.target_n..."
          ],
          [
           "In [8]:\n\ncategories = ['talk.religion.misc', 'soc.religion.christian',\n\n'sci.space', 'comp.graphics'..."
          ],
          [
           "In [10]:\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.naive_bayes impo..."
          ],
          [
           "Evidently, even this very simple classifier can successfully separate space talk from computer talk,..."
          ],
          [
           "When to Use Naive Bayes¶Because naive Bayesian classifiers make such stringent assumptions about dat..."
          ],
          [
           "< Feature Engineering | Contents | In Depth: Linear Regression >\n\nIn Depth: Linear Regression | Pyth..."
          ],
          [
           "Simple Linear Regression¶We will start with the most familiar linear regression, a straight-line fit..."
          ],
          [
           "plt.scatter(x, y)\n\nplt.plot(xfit, yfit);\n\nThe slope and intercept of the data are contained in the m..."
          ],
          [
           "In [5]:\n\nrng = np.random.RandomState(1) X = 10 * rng.rand(100, 3) y = 0.5 + np.dot(X, [1.5, -2., 1.]..."
          ],
          [
           "Basis Function Regression¶One trick you can use to adapt linear regression to nonlinear relationship..."
          ],
          [
           "In [6]:\n\nfrom sklearn.preprocessing import PolynomialFeatures x = np.array([2, 3, 4]) poly = Polynom..."
          ],
          [
           "poly_model.fit(x[:, np.newaxis], y)\n\nyfit = poly_model.predict(xfit[:, np.newaxis])\n\nplt.scatter(x, ..."
          ],
          [
           "def __init__(self, N, width_factor=2.0):\n\nself.N = N\n\nself.width_factor = width_factor\n\n@staticmetho..."
          ],
          [
           "plt.plot(xfit, yfit)\n\nplt.xlim(0, 10);\n\nWe put this example here just to make clear that there is no..."
          ],
          [
           "In [11]:\n\ndef basis_plot(model, title=None): fig, ax = plt.subplots(2, sharex=True) model.fit(x[:, n..."
          ],
          [
           "Ridge regression ($L_2$ Regularization)¶Perhaps the most common form of regularization is known as r..."
          ],
          [
           "Lasso regression ($L_1$ regularization)¶Another very common type of regularization is known as lasso..."
          ],
          [
           "Example: Predicting Bicycle Traffic¶\n\nAs an example, let's take a look at whether we can predict the..."
          ],
          [
           "xm6k/rows.csv?accessType=DOWNLOAD\n\nIn [15]:\n\nimport pandas as pd counts = pd.read_csv('FremontBridge..."
          ],
          [
           "Similarly, we might expect riders to behave differently on holidays; let's add an indicator of this ..."
          ],
          [
           "plt.ylim(8, 17)\n\nOut[19]:\n\n(8, 17)\n\nWe can also add the average temperature and total precipitation ..."
          ],
          [
           "In [22]:\n\ndaily.head()\n\nOut[22]:\n\nTotal\n\nMon\n\nTue\n\nWed\n\nThu\n\nFri\n\nSat\n\nSun\n\nholiday\n\ndaylight_hrs\n\nP..."
          ],
          [
           "0.002740\n\n2012\n\n10\n\n05\n\n3148.0\n\n0.0\n\n0.0\n\n0.0\n\n0.0\n\n1.0\n\n0.0\n\n0.0\n\n0.0\n\n11.161038\n\n0.0\n\n15.30\n\n1.0\n\n..."
          ],
          [
           "0.0\n\n15.85\n\n1.0\n\n0.010959\n\nWith this in place, we can choose the columns to use, and fit a linear re..."
          ],
          [
           "In [24]:\n\ndaily[['Total', 'predicted']].plot(alpha=0.5);\n\nIt is evident that we have missed some key..."
          ],
          [
           "In [26]:\n\nfrom sklearn.utils import resample np.random.seed(1) err = np.std([model.fit(*resample(X, ..."
          ],
          [
           "We first see that there is a relatively stable trend in the weekly baseline: there are many more rid..."
          ],
          [
           "Archive\n\nThis is an excerpt from the Python Data Science Handbook by Jake VanderPlas; Jupyter notebo..."
          ],
          [
           "# use seaborn plotting defaults import seaborn as sns; sns.set()\n\nMotivating Support Vector Machines..."
          ],
          [
           "In [3]:\n\nxfit = np.linspace(-1, 3.5) plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn') plt.plo..."
          ],
          [
           "In [4]:\n\nxfit = np.linspace(-1, 3.5) plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n\nfor m,..."
          ],
          [
           "In [5]:\n\nfrom sklearn.svm import SVC # \"Support vector classifier\" model = SVC(kernel='linear', C=1E..."
          ],
          [
           "# create grid to evaluate model x = np.linspace(xlim[0], xlim[1], 30) y = np.linspace(ylim[0], ylim[..."
          ],
          [
           "This is the dividing line that maximizes the margin between the two sets of points. Notice that a fe..."
          ],
          [
           "In [9]:\n\ndef plot_svm(N=10, ax=None): X, y = make_blobs(n_samples=200, centers=2, random_state=0, cl..."
          ],
          [
           "If you are running this notebook live, you can use IPython's interactive widgets to view this featur..."
          ],
          [
           "It is clear that no linear discrimination will ever be able to separate this data. But we can draw a..."
          ],
          [
           "180, 180),\n\nX=fixed(X), y=fixed(y));\n\nWe can see that with this additional dimension, the data becom..."
          ],
          [
           "clf = SVC(kernel='rbf', C=1E6)\n\nclf.fit(X, y)\n\nOut[14]:\n\nSVC(C=1000000.0, cache_size=200, class_weig..."
          ],
          [
           "In [16]:\n\nX, y = make_blobs(n_samples=100, centers=2, random_state=0, cluster_std=1.2) plt.scatter(X..."
          ],
          [
           "for axi, C in zip(ax, [10.0, 0.1]): model = SVC(kernel='linear', C=C).fit(X, y) axi.scatter(X[:, 0],..."
          ],
          [
           "print(faces.target_names)\n\nprint(faces.images.shape)\n\n['Ariel Sharon' 'Colin Powell' 'Donald Rumsfel..."
          ],
          [
           "from sklearn.decomposition import RandomizedPCA\n\nfrom sklearn.pipeline import make_pipeline\n\npca = R..."
          ],
          [
           "%time grid.fit(Xtrain, ytrain)\n\nprint(grid.best_params_)\n\nCPU times: user 47.8 s, sys: 4.08 s, total..."
          ],
          [
           "Out of this small sample, our optimal estimator mislabeled only a single face (Bush’s face in the bo..."
          ],
          [
           "We might also display the confusion matrix between these classes:\n\nIn [26]:\n\nfrom sklearn.metrics im..."
          ],
          [
           "Support Vector Machine Summary¶We have seen here a brief intuitive introduction to the principals be..."
          ],
          [
           "< In Depth: Linear Regression | Contents | In-Depth: Decision Trees and Random Forests >\n\nIn-Depth: ..."
          ],
          [
           "In [1]:\n\n%matplotlib inline import numpy as np import matplotlib.pyplot as plt import seaborn as sns..."
          ],
          [
           "In [2]:\n\nfrom sklearn.datasets import make_blobs\n\nX, y = make_blobs(n_samples=300, centers=4, random..."
          ],
          [
           "Let's write a quick utility function to help us visualize the output of the classifier:\n\nIn [4]:\n\nde..."
          ],
          [
           "Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n\n# Create a color plot with the r..."
          ],
          [
           "Notice that as the depth increases, we tend to get very strangely shaped classification regions; for..."
          ],
          [
           "In [7]:\n\n# helpers_05_08 is found in the online appendix import helpers_05_08 helpers_05_08.randomiz..."
          ],
          [
           "bag.fit(X, y)\n\nvisualize_classifier(bag, X, y)\n\nIn this example, we have randomized the data by fitt..."
          ],
          [
           "We see that by averaging over 100 randomly perturbed models, we end up with an overall model that is..."
          ],
          [
           "from sklearn.ensemble import RandomForestRegressor\n\nforest = RandomForestRegressor(200)\n\nforest.fit(..."
          ],
          [
           "dict_keys(['target', 'data', 'target_names', 'DESCR', 'images'])\n\nTo remind us what we're looking at..."
          ],
          [
           "We can take a look at the classification report for this classifier:\n\nIn [15]:\n\nfrom sklearn import ..."
          ],
          [
           "Both training and prediction are very fast, because of the simplicity of the underlying decision tre..."
          ],
          [
           "In Depth: Principal Component Analysis\n\n< In-Depth: Decision Trees and Random Forests | Contents | I..."
          ],
          [
           "In [2]:\n\nrng = np.random.RandomState(1) X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T plt.scatter(..."
          ],
          [
           "[[ 0.94446029  0.32862557]\n\n[ 0.32862557\n\n0.94446029]]\n\nIn [5]:\n\nprint(pca.explained_variance_)\n\n[ 0..."
          ],
          [
           "These vectors represent the principal axes of the data, and the length of the vector is an indicatio..."
          ],
          [
           "In [8]:\n\nX_new = pca.inverse_transform(X_pca) plt.scatter(X[:, 0], X[:, 1], alpha=0.2) plt.scatter(X..."
          ],
          [
           "digits = load_digits()\n\ndigits.data.shape\n\nOut[9]:\n\n(1797, 64)\n\nRecall that the data consists of 8×8..."
          ],
          [
           "plt.ylabel('component 2')\n\nplt.colorbar();\n\nRecall what these components mean: the full data is a 64..."
          ],
          [
           "What do the components mean?¶We can go a bit further here, and begin to ask what the reduced dimensi..."
          ],
          [
           "But the pixel-wise representation is not the only choice of basis. We can also use other basis funct..."
          ],
          [
           "In [12]:\n\npca = PCA().fit(digits.data)\n\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\n\nplt.xlab..."
          ],
          [
           "In [13]:\n\ndef plot_digits(data): fig, axes = plt.subplots(4, 10, figsize=(10, 4), subplot_kw={'xtick..."
          ],
          [
           "In [16]:\n\ncomponents = pca.transform(noisy)\n\nfiltered = pca.inverse_transform(components)\n\nplot_digi..."
          ],
          [
           "Let's take a look at the principal axes that span this dataset. Because this is a large dataset, we ..."
          ],
          [
           "In [19]:\n\nfig, axes = plt.subplots(3, 8, figsize=(9, 4), subplot_kw={'xticks':[], 'yticks':[]}, grid..."
          ],
          [
           "In [21]:\n\n# Compute the components and projected faces pca = RandomizedPCA(150).fit(faces.data) comp..."
          ],
          [
           "ax[1, 0].set_ylabel('150\n\ndim\\nreconstruction');\n\nThe top row here shows the input images, while the..."
          ],
          [
           "Principal Component Analysis Summary¶In this section we have discussed the use of principal componen..."
          ],
          [
           "< In-Depth: Decision Trees and Random Forests | Contents | In-Depth: Manifold Learning >\n\nIn-Depth: ..."
          ],
          [
           "In\n\nDepth: Manifold Learning\n\n< In Depth: Principal Component Analysis | Contents | In Depth: k-Mean..."
          ],
          [
           "Here we will demonstrate a number of manifold methods, going most deeply into a couple techniques: m..."
          ],
          [
           "# Open this PNG and draw random points from it from matplotlib.image import imread data = imread('he..."
          ],
          [
           "Multidimensional Scaling (MDS)¶Looking at data like this, we can see that the particular choice of x..."
          ],
          [
           "In [5]:\n\nfrom sklearn.metrics import pairwise_distances\n\nD = pairwise_distances(X)\n\nD.shape\n\nOut[5]:..."
          ],
          [
           "np.allclose(D, D2)\n\nOut[7]:\n\nTrue\n\nThis distance matrix gives us a representation of our data that i..."
          ],
          [
           "MDS as Manifold Learning¶The usefulness of this becomes more apparent when we consider the fact that..."
          ],
          [
           "We can now ask the MDS estimator to input this three-dimensional data, compute the distance matrix, ..."
          ],
          [
           "0.75\n\nnp.pi\n\nx = np.sin(t)\n\ny = X[:, 1]\n\nz = np.sign(t)\n\n(np.cos(t)\n\n1)\n\nreturn np.vstack((x, y, z))..."
          ],
          [
           "The best two-dimensional linear embeding does not unwrap the S-curve, but instead throws out the ori..."
          ],
          [
           "figure source in Appendix\n\nHere each faint line represents a distance that should be preserved in th..."
          ],
          [
           "fig, ax = plt.subplots() ax.scatter(out[:, 0], out[:, 1], **colorize) ax.set_ylim(0.15, -0.15);\n\nThe..."
          ],
          [
           "In manifold learning, there is no good framework for handling missing data. In contrast, there are s..."
          ],
          [
           "For toy problems such as the S-curve we saw before, locally linear embedding (LLE) and its variants ..."
          ],
          [
           "In [16]:\n\nfrom sklearn.datasets import fetch_lfw_people\n\nfaces = fetch_lfw_people(min_faces_per_pers..."
          ],
          [
           "plt.plot(np.cumsum(model.explained_variance_ratio_))\n\nplt.xlabel('n components')\n\nplt.ylabel('cumula..."
          ],
          [
           "proj = model.fit_transform(data) ax.plot(proj[:, 0], proj[:, 1], '.k')\n\nif images is not None: min_d..."
          ],
          [
           "The result is interesting: the first two Isomap dimensions seem to describe global image features: t..."
          ],
          [
           "In [23]:\n\nfig, ax = plt.subplots(6, 8, subplot_kw=dict(xticks=[], yticks=[])) for i, axi in enumerat..."
          ],
          [
           "The resulting scatter plot shows some of the relationships between the data points, but is a bit cro..."
          ],
          [
           "< In Depth: Principal Component Analysis | Contents | In Depth: k-Means Clustering >\n\nIn Depth: k-Me..."
          ],
          [
           "Introducing k\n\nMeans¶\n\nThe k-means algorithm searches for a pre-determined number of clusters within..."
          ],
          [
           "kmeans = KMeans(n_clusters=4)\n\nkmeans.fit(X)\n\ny_kmeans = kmeans.predict(X)\n\nLet's visualize the resu..."
          ],
          [
           "k\n\nMeans Algorithm: Expectation–Maximization¶\n\nExpectation–maximization (E–M) is a powerful algorith..."
          ],
          [
           "In [5]:\n\nfrom sklearn.metrics import pairwise_distances_argmin\n\ndef find_clusters(X, n_clusters, rse..."
          ],
          [
           "Caveats of expectation–maximization¶There are a few issues to be aware of when using the expectation..."
          ],
          [
           "Whether the result is meaningful is a question that is difficult to answer definitively; one approac..."
          ],
          [
           "This situation is reminiscent of the discussion in In-Depth: Support Vector Machines, where we used ..."
          ],
          [
           "We see that with this kernel transform approach, the kernelized k-means is able to find the more com..."
          ],
          [
           "In [11]:\n\nfrom sklearn.datasets import load_digits\n\ndigits = load_digits()\n\ndigits.data.shape\n\nOut[1..."
          ],
          [
           "We see that even without the labels, KMeans is able to find clusters whose centers are recognizable ..."
          ],
          [
           "In [16]:\n\nfrom sklearn.metrics import confusion_matrix mat = confusion_matrix(digits.target, labels)..."
          ],
          [
           "clusters = kmeans.fit_predict(digits_proj)\n\n# Permute the labels labels = np.zeros_like(clusters) fo..."
          ],
          [
           "The image itself is stored in a three-dimensional array of size (height, width, RGB), containing red..."
          ],
          [
           "fig, ax = plt.subplots(1, 2, figsize=(16, 6)) ax[0].scatter(R, G, color=colors, marker='.') ax[0].se..."
          ],
          [
           "kmeans = MiniBatchKMeans(16)\n\nkmeans.fit(data)\n\nnew_colors = kmeans.cluster_centers_[kmeans.predict(..."
          ],
          [
           "< In-Depth: Manifold Learning | Contents | In Depth: Gaussian Mixture Models >\n\nIn Depth: Gaussian M..."
          ],
          [
           "Motivating GMM: Weaknesses of k-Means¶Let's take a look at some of the weaknesses of k-means and thi..."
          ],
          [
           "From an intuitive standpoint, we might expect that the clustering assignment for some points is more..."
          ],
          [
           "# plot the representation of the KMeans model centers = kmeans.cluster_centers_ radii = [cdist(X[lab..."
          ],
          [
           "plot_kmeans(kmeans, X_stretched)\n\nBy eye, we recognize that these transformed clusters are non-circu..."
          ],
          [
           "In [7]:\n\nfrom sklearn.mixture import GMM gmm = GMM(n_components=4).fit(X) labels = gmm.predict(X) pl..."
          ],
          [
           "In [9]:\n\nsize = 50 * probs.max(1) ** 2  # square emphasizes differences plt.scatter(X[:, 0], X[:, 1]..."
          ],
          [
           "# Convert covariance to principal axes if covariance.shape == (2, 2): U, s, Vt = np.linalg.svd(covar..."
          ],
          [
           "With this in place, we can take a look at what the four-component GMM gives us for our initial data:..."
          ],
          [
           "This makes clear that GMM addresses the two main practical issues with k-means encountered before.\n\n..."
          ],
          [
           "In [13]:\n\nfrom sklearn.datasets import make_moons Xmoon, ymoon = make_moons(200, noise=.05, random_s..."
          ],
          [
           "In [16]:\n\nXnew = gmm16.sample(400, random_state=42)\n\nplt.scatter(Xnew[:, 0], Xnew[:, 1]);\n\nGMM is co..."
          ],
          [
           "plt.plot(n_components, [m.bic(Xmoon) for m in models], label='BIC') plt.plot(n_components, [m.aic(Xm..."
          ],
          [
           "digits = load_digits()\n\ndigits.data.shape\n\nOut[18]:\n\n(1797, 64)\n\nNext let's plot the first 100 of th..."
          ],
          [
           "data.shape\n\nOut[20]:\n\n(1797, 41)\n\nThe result is 41 dimensions, a reduction of nearly 1/3 with almost..."
          ],
          [
           "Finally, we can use the inverse transform of the PCA object to construct the new digits:\n\nIn [24]:\n\n..."
          ],
          [
           "In\n\nDepth: Kernel Density Estimation\n\n< In Depth: Gaussian Mixture Models | Contents | Application: ..."
          ],
          [
           "In [2]:\n\ndef make_data(N, f=0.3, rseed=1):\n\nrand = np.random.RandomState(rseed)\n\nx = rand.randn(N)\n\n..."
          ],
          [
           "Out[4]:\n\n1.0\n\nOne of the issues with using a histogram as a density estimator is that the choice of ..."
          ],
          [
           "On the left, the histogram makes clear that this is a bimodal distribution. On the right, we see a u..."
          ],
          [
           "Out[7]:\n\n(\n\n0.2, 8)\n\nThe problem with our two binnings stems from the fact that the height of the bl..."
          ],
          [
           "plt.axis([\n\n4, 8,\n\n0.2, 8]);\n\nThe result looks a bit messy, but is a much more robust reflection of ..."
          ],
          [
           "plt.axis([\n\n4, 8,\n\n0.2, 5]);\n\nThis smoothed-out plot, with a Gaussian distribution contributed at th..."
          ],
          [
           "Kernel Density Estimation in Practice¶The free parameters of kernel density estimation are the kerne..."
          ],
          [
           "# score_samples returns the log of the probability density logprob = kde.score_samples(x_d[:, None])..."
          ],
          [
           "(\n\n0.02, 0.22)\n\nThe result here is normalized such that the area under the curve is equal to 1.\n\nSel..."
          ],
          [
           "from sklearn.grid_search import GridSearchCV\n\nfrom sklearn.cross_validation import LeaveOneOut\n\nband..."
          ],
          [
           "Example: KDE on a Sphere¶Perhaps the most common use of KDE is in graphically representing distribut..."
          ],
          [
           "In [14]:\n\nfrom mpl_toolkits.basemap import Basemap\n\nfrom sklearn.datasets.species_distributions impo..."
          ],
          [
           "Unfortunately, this doesn't give a very good idea of the density of the species, because points in t..."
          ],
          [
           "for i, axi in enumerate(ax): axi.set_title(species_names[i])\n\n# plot coastlines with basemap m = Bas..."
          ],
          [
           "Compared to the simple scatter plot we initially used, this visualization paints a much clearer pict..."
          ],
          [
           "The algorithm is straightforward and intuitive to understand; the more difficult piece is couching i..."
          ],
          [
           "def predict_proba(self, X): logprobs = np.array([model.score_samples(X) for model in self.models_])...."
          ],
          [
           "Next comes the class initialization method: def __init__(self, bandwidth=1.0, kernel='gaussian'): se..."
          ],
          [
           "Notice that each persistent result of the fit is stored with a trailing underscore (e.g., self.logpr..."
          ],
          [
           "Using our custom estimator¶Let's try this custom estimator on a problem we have seen before: the cla..."
          ],
          [
           "{'bandwidth': 7.0548023107186433}\n\naccuracy = 0.966611018364\n\nWe see that this not-so-naive Bayesian..."
          ],
          [
           "Finally, if you want some practice building your own estimator, you might tackle building a similar ..."
          ],
          [
           "Application: A Face Detection Pipeline\n\n< In-Depth: Kernel Density Estimation | Contents | Further M..."
          ],
          [
           "HOG Features¶The Histogram of Gradients is a straightforward feature extraction procedure that was d..."
          ],
          [
           "ax[1].imshow(hog_vis)\n\nax[1].set_title('visualization of HOG features');\n\nHOG in Action: A Simple Fa..."
          ],
          [
           "positive_patches.shape\n\nOut[3]:\n\n(13233, 62, 47)\n\nThis gives us a sample of 13,000 face images to us..."
          ],
          [
           "In [5]:\n\nfrom sklearn.feature_extraction.image import PatchExtractor\n\ndef extract_patches(img, N, sc..."
          ],
          [
           "Our hope is that these would sufficiently cover the space of \"non-faces\" that our algorithm is likel..."
          ],
          [
           "In [9]:\n\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.cross_validation import cross_val_..."
          ],
          [
           "In [12]:\n\nmodel = grid.best_estimator_\n\nmodel.fit(X_train, y_train)\n\nOut[12]:\n\nLinearSVC(C=4.0, clas..."
          ],
          [
           "Next, let's create a window that iterates over patches of this image, and compute HOG features for e..."
          ],
          [
           "In [16]:\n\nfig, ax = plt.subplots()\n\nax.imshow(test_image, cmap='gray')\n\nax.axis('off')\n\nNi, Nj = pos..."
          ],
          [
           "All of the detected patches overlap and found the face in the image! Not bad for a few lines of Pyth..."
          ],
          [
           "In fact, the sliding_window() utility used here is already built with this in mind. We should combin..."
          ],
          [
           "An intro to these deep neural net methods is conceptually (and computationally!) beyond the scope of..."
          ],
          [
           "Machine Learning in Python¶To learn more about machine learning in Python, I'd suggest some of the f..."
          ],
          [
           "Machine Learning: Taught by Andrew Ng (Coursera), this is a very clearly-taught free online course w..."
          ],
          [
           "Appendix: Figure Code\n\n< Further Machine Learning Resources | Contents |\n\nMany of the figures used t..."
          ],
          [
           "def draw_cube(ax, xy, size, depth=0.4, edges=None, label=None, label_kwargs=None, **kwargs): \"\"\"draw..."
          ],
          [
           "if 9 in edges: ax.plot([x + depth, x + depth + size], [y + depth + size, y + depth + size], **kwargs..."
          ],
          [
           "label_kwargs=dict(color='gray'))\n\ndepth = 0.3\n\n#----------------------------------------------------..."
          ],
          [
           "draw_cube(ax, (12, 10), 1, depth, [1, 2, 3, 4, 5, 6, 9], '5', **solid) draw_cube(ax, (13, 10), 1, de..."
          ],
          [
           "# first block draw_cube(ax, (1, 7.5), 1, depth, [1, 2, 3, 4, 5, 6, 9], '1', **solid) draw_cube(ax, (..."
          ],
          [
           "# second block draw_cube(ax, (6, 7.5), 1, depth, [1, 2, 3, 4, 5, 6, 9], '0', **solid) draw_cube(ax, ..."
          ],
          [
           "# third block draw_cube(ax, (12, 7.5), 1, depth, [1, 2, 3, 4, 5, 6, 9], '1', **solid) draw_cube(ax, ..."
          ],
          [
           "ax.text(5, 7.0, '+', size=12, ha='center', va='center') ax.text(10.5, 7.0, '=', size=12, ha='center'..."
          ],
          [
           "draw_cube(ax, (2, 3), 1, depth, [1, 2, 3, 6, 7, 9, 10, 11], '0', **dotted) draw_cube(ax, (2, 2), 1, ..."
          ],
          [
           "draw_cube(ax, (6, 2), 1, depth, range(2, 13), '0', **dotted) draw_cube(ax, (7, 2), 1, depth, [2, 3, ..."
          ],
          [
           "draw_cube(ax, (12, 2), 1, depth, [2, 3, 4], '1', **solid) draw_cube(ax, (13, 2), 1, depth, [2, 3], '..."
          ],
          [
           "ax.set_ylim(0.5, 12.5)\n\nfig.savefig('figures/02.05\n\nbroadcasting.png')\n\nAggregation and Grouping¶Fig..."
          ],
          [
           "# draw horizontal lines for i in range(nrows + 1): plt.plot([x, x + dx * ncols], 2 * [y + i * dy], *..."
          ],
          [
           "#---------------------------------------------------------\n\n# Draw figure\n\nimport pandas as pd df = ..."
          ],
          [
           "result = df.groupby(df.index).sum()\n\ndraw_dataframe(result, [6, 0.75])\n\nstyle = dict(fontsize=14, ha..."
          ],
          [
           "plt.annotate('', (3.8, 3.8), (3.2, 3.8), arrowprops=arrowprops) plt.annotate('', (3.8, 1.75), (3.2, ..."
          ],
          [
           "split\n\napply\n\ncombine.png')\n\nWhat Is Machine Learning?¶\n\nIn [5]:\n\n# common plot formatting for below..."
          ],
          [
           "# predict the labels\n\ny2 = clf.predict(X2)\n\nClassification Example Figure 1¶\n\nIn [7]:\n\n# plot the da..."
          ],
          [
           "# plot points and model fig, ax = plt.subplots(figsize=(8, 6)) line_style = dict(levels = [-1.0, 0.0..."
          ],
          [
           "ax[1].scatter(X2[:, 0], X2[:, 1], c=y2, **point_style) ax[1].contour(xy1, xy2, Z, **line_style) ax[1..."
          ],
          [
           "# predict the labels\n\ny2 = model.predict(X2)\n\nRegression Example Figure 1¶\n\nIn [11]:\n\n# plot data po..."
          ],
          [
           "# plot points in 3D fig = plt.figure() ax = fig.add_subplot(111, projection='3d') ax.scatter(X[:, 0]..."
          ],
          [
           "# Hide axes (is there a better way?) ax.w_xaxis.line.set_visible(False) ax.w_yaxis.line.set_visible(..."
          ],
          [
           "# compute and plot model color mesh xx, yy = np.meshgrid(np.linspace(-4, 4), np.linspace(-3, 3)) Xfi..."
          ],
          [
           "ax[1].scatter(X2[:, 0], X2[:, 1], c=y2, s=50, cmap='viridis', norm=pts.norm) ax[1].axis([-4, 4, -3, ..."
          ],
          [
           "# format the plot\n\nformat_plot(ax, 'Input Data')\n\nfig.savefig('figures/05.01\n\nclustering\n\n1.png')\n\nC..."
          ],
          [
           "# format the plot\n\nformat_plot(ax, 'Input Data')\n\nfig.savefig('figures/05.01\n\ndimesionality\n\n1.png')..."
          ],
          [
           "Learn¶\n\nFeatures and Labels Grid¶The following is the code generating the diagram showing the featur..."
          ],
          [
           "# Draw labels vector ax.vlines(range(8, 10), ymin=0, ymax=9, lw=1) ax.hlines(range(10), xmin=8, xmax..."
          ],
          [
           "Hyperparameters and Model Validation¶\n\nCross\n\nValidation Figures¶\n\nIn [21]:\n\ndef draw_rects(N, ax, t..."
          ],
          [
           "fig.savefig('figures/05.03\n\n2\n\nfold\n\nCV.png')\n\n5\n\nFold Cross\n\nValidation¶\n\nIn [23]:\n\nfig = plt.figur..."
          ],
          [
           "from sklearn.pipeline import make_pipeline\n\ndef PolynomialRegression(degree=2, *\n\nkwargs):\n\nreturn m..."
          ],
          [
           "ax[1].scatter(X.ravel(), y, s=40) ax[1].plot(xfit.ravel(), model20.predict(xfit), color='gray') ax[1..."
          ],
          [
           "X2, y2 = make_data(10, rseed=42)\n\nax[0].scatter(X.ravel(), y, s=40, c='blue') ax[0].plot(xfit.ravel(..."
          ],
          [
           "ax[1].scatter(X.ravel(), y, s=40, c='blue') ax[1].plot(xfit.ravel(), model20.predict(xfit), color='g..."
          ],
          [
           "bias\n\nvariance\n\n2.png')\n\nValidation Curve¶\n\nIn [28]:\n\nx = np.linspace(0, 1, 1000) y1 = -(x - 0.5) **..."
          ],
          [
           "ax.set_xlim(0, 1)\n\nax.set_ylim(\n\n0.3, 0.5)\n\nax.set_xlabel(r'model complexity $\\longrightarrow$', siz..."
          ],
          [
           "ax.text(0.2, 0.88, \"training score\", rotation=-10, size=16, color='blue') ax.text(0.2, 0.5, \"validat..."
          ],
          [
           "curve.png')\n\nGaussian Naive Bayes¶Gaussian Naive Bayes Example¶Figure Context\n\nIn [30]:\n\nfrom sklear..."
          ],
          [
           "for label, color in enumerate(['red', 'blue']): mask = (y == label) mu, std = X[mask].mean(0), X[mas..."
          ],
          [
           "class GaussianFeatures(BaseEstimator, TransformerMixin): \"\"\"Uniformly-spaced Gaussian Features for 1..."
          ],
          [
           "gauss_model = make_pipeline(GaussianFeatures(10, 1.0),\n\nLinearRegression())\n\ngauss_model.fit(x[:, np..."
          ],
          [
           "fig.savefig('figures/05.06\n\ngaussian\n\nbasis.png')\n\nRandom Forests¶\n\nHelper Code¶The following will c..."
          ],
          [
           "xx, yy = np.meshgrid(np.linspace(\n\nxlim, num=200),\n\nnp.linspace(\n\nylim, num=200))\n\nZ = estimator.pre..."
          ],
          [
           "[xlim[0], tree.threshold[i]], ylim)\n\nplot_boundaries(tree.children_right[i],\n\n[tree.threshold[i], xl..."
          ],
          [
           "def randomized_tree_interactive(X, y):\n\nN = int(0.75\n\nX.shape[0])\n\nxlim = (X[:, 0].min(), X[:, 0].ma..."
          ],
          [
           "def text(ax, x, y, t, size=20, **kwargs): ax.text(x, y, t, ha='center', va='center', size=size, bbox..."
          ],
          [
           "text(ax, 0.66, 0.45, \"yes\", 12, alpha=0.4) text(ax, 0.79, 0.45, \"no\", 12, alpha=0.4)\n\nax.plot([0.3, ..."
          ],
          [
           "decision\n\ntree.png')\n\nDecision Tree Levels¶\n\nIn [34]:\n\nfrom helpers_05_08 import visualize_tree\n\nfro..."
          ],
          [
           "Decision Tree Overfitting¶\n\nIn [35]:\n\nmodel = DecisionTreeClassifier()\n\nfig, ax = plt.subplots(1, 2,..."
          ],
          [
           "In [38]:\n\nrng = np.random.RandomState(1) X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T pca = PCA(n..."
          ],
          [
           "# plot principal components X_pca = pca.transform(X) ax[1].scatter(X_pca[:, 0], X_pca[:, 1], alpha=0..."
          ],
          [
           "components = np.eye(len(coefficients), len(x))\n\nmean = np.zeros_like(x) + mean\n\nfig = plt.figure(fig..."
          ],
          [
           "for i in range(n_components): approx = approx + coefficients[i] * components[i] show(0, i + counter,..."
          ],
          [
           "Xproj = pca.fit_transform(digits.data)\n\nsns.set_style('white')\n\nfig = plot_pca_components(digits.dat..."
          ],
          [
           "# Open this PNG and draw random points from it from matplotlib.image import imread data = imread('he..."
          ],
          [
           "In [44]:\n\nfrom mpl_toolkits.mplot3d.art3d import Line3DCollection\n\nfrom sklearn.neighbors import Nea..."
          ],
          [
           "for axi, title, lines in zip(ax, titles, [lines_MDS, lines_LLE]): axi.scatter3D(XS[:, 0], XS[:, 1], ..."
          ],
          [
           "rng = np.random.RandomState(42) centers = [0, 4] + rng.randn(4, 2)\n\ndef draw_points(ax, c, factor=1)..."
          ],
          [
           "ax.yaxis.set_major_formatter(plt.NullFormatter())\n\nreturn ax\n\nfig = plt.figure(figsize=(15, 4)) gs =..."
          ],
          [
           "draw_points(ax1, y_pred)\n\ndraw_centers(ax1, centers)\n\n# M-step new_centers = np.array([X[y_pred == i..."
          ],
          [
           "fig.savefig('figures/05.11\n\nexpectation\n\nmaximization.png')\n\nInteractive K-Means¶The following scrip..."
          ],
          [
           "def plot_centers(centers): plt.scatter(centers[:, 0], centers[:, 1], marker='o', c=np.arange(centers..."
          ],
          [
           "# plot the data and cluster centers plot_points(X, labels, n_clusters) plot_centers(old_centers)\n\n# ..."
          ],
          [
           "In [47]:\n\nfrom sklearn.mixture import GMM\n\nfrom matplotlib.patches import Ellipse\n\ndef draw_ellipse(..."
          ],
          [
           "for i, cov_type in enumerate(['diag', 'spherical', 'full']): model = GMM(1, covariance_type=cov_type..."
          ],
          [
           "Python Data Science Handbook\n\nAbout\n\nArchive\n\nPython Data Science Handbook\n\nJake VanderPlas\n\nThis we..."
          ],
          [
           "4. Visualization with Matplotlib¶ Simple Line Plots Simple Scatter Plots Visualizing Errors Density ..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt, circle",
         "marker": {
          "color": "#19d3f3",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -4.959843,
          8.835573,
          -4.089947,
          10.135447,
          -3.9900734,
          -4.223947,
          -4.642202,
          -4.277729,
          -4.412727,
          -4.4943037,
          8.8205385,
          -4.6991763,
          -3.8506603,
          -3.8602076,
          -2.9551268,
          -2.6564205,
          -5.0196934,
          8.785515,
          -3.1790721,
          -3.2935026,
          -3.9267395,
          -3.2341504,
          -3.293395,
          -3.9151418,
          -3.3963783,
          -4.382006,
          -2.5652082,
          -2.477131,
          -2.6056285,
          -2.703534,
          -2.452722,
          -2.694356,
          -2.496481,
          -2.713882,
          -4.6115055,
          -3.2218254,
          -2.4582176,
          -2.4800477,
          -2.6586902,
          -2.5106025,
          -2.543427,
          -2.529525,
          -2.9142025,
          -2.4524746,
          -2.55839,
          -2.4755533,
          -2.54003,
          -2.6075263,
          -2.2124133,
          -2.1954138,
          -2.1697547,
          -2.3179798,
          -2.3005888,
          -2.2540848,
          -2.3812337,
          -4.3024063,
          -4.457636,
          -4.8805575,
          -4.8491163,
          -4.491782,
          -4.5199733,
          -4.510205,
          -4.431869,
          -4.541817,
          -4.546164,
          -4.4711375,
          -4.488488,
          -3.7661679,
          -4.716577,
          -6.0843453,
          -4.6200953,
          -4.5519233,
          -4.7622104,
          8.863963,
          -5.742009,
          -5.3646965,
          -5.5086894,
          -5.5806465,
          -6.072934,
          -6.408038,
          -6.8876,
          -6.2304773,
          -5.6977463,
          -6.1503096,
          -5.3917475,
          -6.2687545,
          -7.003032,
          -7.4082265,
          -7.5477157,
          -7.322723,
          -7.439018,
          -7.573882,
          -7.5209465,
          -7.4716935,
          -7.462485,
          -7.344885,
          -7.146788,
          -7.462127,
          -7.163307,
          -7.2158546,
          -6.0394816,
          -5.2551823,
          -5.2730517,
          -5.725092,
          -5.9425907,
          -6.1636477,
          -6.0445027,
          -5.962252,
          -5.7713404,
          -5.8266277,
          -5.9222794,
          -5.811817,
          -1.650202,
          -5.8463287,
          -5.845935,
          -6.055647,
          -6.348111,
          -5.8199773,
          -5.448609,
          -5.7735066,
          -5.5321674,
          -5.7765536,
          -5.5287876,
          -6.4699574,
          -7.048292,
          -6.310785,
          -6.702162,
          -6.9176617,
          -6.7342186,
          -6.812806,
          -6.9620075,
          -6.55607,
          -6.329889,
          -6.2764854,
          -4.637328,
          -6.314667,
          -7.1155353,
          -6.192157,
          -6.1456633,
          -6.140514,
          -6.163957,
          -6.141505,
          -6.211232,
          -6.2437305,
          -6.259703,
          -6.3041873,
          -6.2538056,
          -6.151237,
          -6.1499553,
          -6.134719,
          -7.2094755,
          -7.478408,
          -7.357719,
          -7.347695,
          -7.371902,
          -7.1967745,
          -7.2334924,
          -6.759074,
          -5.508056,
          -4.547737,
          -6.3116984,
          -6.932723,
          -6.53963,
          -6.807618,
          -6.913918,
          -6.714934,
          -7.0429797,
          -6.717782,
          -0.38911274,
          -6.170135,
          -0.23711127,
          -0.21096799,
          5.574908,
          -5.442358,
          -6.3791947,
          -6.266987,
          -6.4592032,
          -6.489405,
          -5.9479094,
          -5.4850135,
          -5.9505606,
          -6.299197,
          -6.131385,
          -6.731586,
          -5.2643175,
          -5.5746393,
          8.794229,
          -7.09151,
          -8.756392,
          -8.683693,
          -9.07891,
          -9.487315,
          -8.874846,
          -9.571557,
          -9.316919,
          -9.617462,
          -8.785686,
          -9.528576,
          -8.603612,
          -8.27353,
          -8.774488,
          -8.761731,
          -8.624895,
          -8.8535185,
          -8.840682,
          -8.686816,
          -8.670771,
          -9.554313,
          -9.632545,
          -9.174892,
          -9.684307,
          -8.67669,
          -8.937814,
          -9.682834,
          -9.4492035,
          -9.859117,
          -9.0815735,
          -5.9414263,
          -8.545407,
          -5.8991747,
          -9.983044,
          -8.320856,
          -7.9129353,
          -7.9193554,
          -7.532,
          -8.038486,
          -7.2319183,
          -7.5333033,
          -7.3675113,
          -7.493343,
          -7.5293145,
          -5.9363017,
          -5.9131284,
          -7.591575,
          -7.6083975,
          -7.5640335,
          -7.6426764,
          -7.659077,
          -7.672561,
          -7.667406,
          -7.77707,
          -7.4119577,
          -10.0547495,
          -9.76275,
          -9.981708,
          -9.962926,
          -9.965097,
          -10.203211,
          -9.705969,
          -9.895789,
          -9.671364,
          -9.978848,
          -9.699701,
          -9.393399,
          -9.720749,
          -9.628942,
          -9.888183,
          -9.4591675,
          -7.9191403,
          -9.57273,
          -8.953764,
          -9.114404,
          -10.080515,
          -10.054826,
          -9.743361,
          -7.225621,
          -7.0540924,
          -9.589407,
          -11.055008,
          -11.584166,
          -11.385035,
          -11.5424795,
          -11.773532,
          -11.740204,
          -11.399509,
          -11.636095,
          -11.557052,
          -11.71261,
          -11.733012,
          -11.748364,
          -11.948806,
          -11.694144,
          -11.413993,
          -11.661498,
          -12.292418,
          -12.849607,
          -12.612297,
          -12.842038,
          -12.723897,
          -12.896546,
          -12.781535,
          -12.868514,
          -12.784341,
          -12.728677,
          -12.851564,
          -12.776927,
          -12.863397,
          -12.658266,
          -12.427138,
          -12.348433,
          -12.430192,
          -12.075096,
          -12.397848,
          -12.24031,
          -10.893811,
          -10.894705,
          -11.120593,
          -10.94417,
          -11.019887,
          -10.83937,
          -10.734396,
          -10.832275,
          -10.732203,
          -10.538376,
          -10.844625,
          -7.372771,
          -7.756592,
          -7.744712,
          -7.483304,
          -7.679184,
          -7.466793,
          -7.5061526,
          -7.6856437,
          -7.6676984,
          -7.682335,
          -7.9581394,
          -7.7292733,
          -8.010843,
          -7.85079,
          -7.7621226,
          -7.687627,
          -7.708047,
          -7.7176304,
          -7.6477957,
          -7.6576486,
          -7.6875324,
          -7.7474284,
          -7.7049036,
          -7.7168026,
          -7.7158375,
          -8.185959,
          -7.9610877,
          -6.3610086,
          -5.531374,
          -6.07558,
          -6.091672,
          -6.040071,
          -6.1141973,
          -6.0912213,
          -7.4090424,
          -6.083324,
          -6.073695,
          -8.328722,
          -8.131722,
          -8.189305,
          -8.21391,
          -8.185471,
          -8.233746,
          -8.157668,
          -5.9972043,
          -4.982657,
          -5.423116,
          -4.4249086,
          -4.664692,
          -4.569815,
          -5.0609937,
          -5.397024,
          -5.251101,
          -5.2056203,
          -5.1349387,
          -5.3731995,
          -5.148331,
          -5.0043902,
          -5.1862497,
          -5.17575,
          -5.524212,
          -5.3136373,
          -7.6210155,
          -9.792981,
          -9.871365,
          -9.9981165,
          -9.889131,
          -9.6803665,
          -8.657162,
          -9.869992,
          -9.94951,
          -9.816343,
          -9.995394,
          -10.029006,
          -9.966723,
          -9.971151,
          -10.015006,
          -9.93715,
          -9.889534,
          -8.3923025,
          -9.923141,
          -10.041463,
          -7.5090938,
          -7.161592,
          -7.478736,
          -7.601034,
          -7.5541387,
          -7.475514,
          -7.618688,
          -7.6171255,
          -7.041937,
          -7.0689144,
          -7.024118,
          -7.181126,
          -7.072821,
          -7.0676985,
          -5.9117293,
          -5.6917677,
          -6.9900045,
          -7.158165,
          -7.319799,
          -7.31457,
          -7.4140506,
          -7.511629,
          -7.740677,
          -7.756622,
          -7.5139093,
          -7.3164816,
          -7.2369223,
          -6.8196626,
          -6.027432,
          -5.138631,
          -6.4584713,
          -7.0116725,
          -7.1247835,
          -7.2160344,
          -6.9813647,
          -6.877341,
          -3.6410542,
          -7.3866916,
          -7.916416,
          -6.390516,
          8.86638,
          -6.0946164,
          -7.5782747,
          -7.5864654,
          -7.3525443,
          -7.3490276,
          -7.8934946,
          -7.7781053,
          -7.4616466,
          -7.745133,
          -6.1567583,
          -7.516314,
          -7.1520815,
          -5.44326,
          -5.2734885,
          -5.5848837,
          -4.667494,
          -4.575661,
          -4.162902,
          -3.6465518,
          -4.276306,
          -5.2755957,
          -5.2885976,
          -5.3078294,
          -5.206706,
          -5.286973,
          -5.160269,
          -5.2088523,
          -4.547703,
          -4.806038,
          -4.475475,
          -4.439413,
          -6.982949,
          -7.2943816,
          -7.11199,
          -7.024807,
          -6.945381,
          -7.272615,
          -5.6919146,
          -5.953144,
          -5.232585,
          -4.595177,
          -5.2856236,
          -5.2240295,
          -5.156989,
          -5.036844,
          -2.726893,
          -2.290523,
          -7.963951,
          -8.122327,
          -8.147423,
          -8.184663,
          -8.1695385,
          -7.995242,
          -5.250832,
          -8.070979,
          -8.166739,
          -7.871442,
          -7.6125884,
          -7.5797696,
          -7.81662,
          -7.9370713,
          -7.8162475,
          -7.268481,
          -3.6735291,
          -7.6282716,
          -7.7391076,
          -7.9484963,
          -7.998886,
          -8.005203,
          -8.195356,
          -8.092684,
          -7.988776,
          -8.0403595,
          -7.858793,
          -7.302338,
          -7.551406,
          -7.398067,
          -7.544577,
          -7.4659586,
          -7.4230366,
          -7.4770813,
          -7.5338187,
          -7.4533567,
          -6.3262963,
          -5.3815103,
          -5.3910446,
          -5.5162168,
          -5.2906537,
          -5.0330243,
          -5.257196,
          -5.3750563,
          -5.614397,
          -6.265858,
          -6.3026333,
          -6.31734,
          -6.1119566,
          -6.175607,
          -6.313319,
          -6.2918687,
          -6.2002764,
          -6.32559,
          -6.139461,
          -6.3301797,
          -6.3152113,
          -6.1193905,
          -7.2701097,
          -5.73767,
          -6.2198415,
          -7.24717,
          -7.2254605,
          -5.977059,
          -5.482281,
          -5.701057,
          -5.9660025,
          -6.172897,
          -6.725458,
          -7.612734,
          -6.7772565,
          -7.858482,
          -6.817058,
          -7.084531,
          -6.6817703,
          -6.7029295,
          -6.7317142,
          -6.7066584,
          -6.7307906,
          -6.662383,
          -6.797189,
          -6.7054515,
          -6.158975,
          9.561337,
          9.622255,
          9.086806,
          8.803216,
          9.569211,
          8.7056675,
          7.49721,
          6.1600127,
          6.2157245,
          6.3773904,
          -0.47435892,
          6.2427125,
          -1.8382305,
          -0.684538,
          7.937337,
          8.831702,
          -6.3971786,
          2.5461926,
          2.6828895,
          2.7886727,
          2.9438653,
          2.412635,
          3.1209607,
          2.5537376,
          2.8954613,
          3.0196273,
          2.785357,
          2.6563468,
          2.9510415,
          -2.7437737,
          -2.061791,
          -1.9506978,
          -2.273788,
          2.4383526,
          2.3440163,
          -0.64304155,
          8.611427,
          3.1579022,
          2.711835,
          3.738994,
          3.7652845,
          3.2745576,
          3.910358,
          -2.739151,
          -2.7554739,
          -2.7099328,
          -2.7112286,
          -2.776306,
          3.7986505,
          4.184233,
          3.722201,
          2.8628047,
          1.8000009,
          2.090936,
          2.1324823,
          2.2297795,
          2.6600277,
          1.9426452,
          -0.70899105,
          2.4483643,
          1.7450434,
          1.2950702,
          8.789148,
          6.9736032,
          -3.1382594,
          -2.8842676,
          -3.1927187,
          -4.149984,
          7.5640993,
          1.3466371,
          1.4855243,
          9.050545,
          -7.5306892,
          1.894407,
          7.6488485,
          6.846459,
          6.0591645,
          5.7777195,
          5.782908,
          6.047638,
          6.03869,
          5.4812365,
          1.7178577,
          5.9367466,
          4.381779,
          5.946998,
          2.8154383,
          6.2795534,
          6.0755444,
          9.105251,
          1.9282039,
          2.069678,
          1.7715101,
          1.4781862,
          1.083813,
          1.5395297,
          -1.742695,
          0.9899322,
          -0.29914314,
          4.11763,
          4.3143544,
          5.6456156,
          -7.0997787,
          -7.0324507,
          -7.25594,
          -7.3041368,
          -7.1960845,
          -6.812522,
          -6.8627195,
          -0.14294392,
          -0.0067089545,
          9.072351,
          0.34314507,
          0.056987874,
          0.6274715,
          0.90417063,
          -0.33841902,
          1.497249,
          0.63998544,
          0.9981043,
          0.22232795,
          0.6686151,
          0.94689363,
          0.35822204,
          0.8359535,
          0.6724632,
          0.6806373,
          0.7570187,
          0.8860361,
          0.67839617,
          8.593992,
          9.363996,
          -0.015604873,
          -0.35713518,
          0.70037097,
          -0.5814637,
          0.010836168,
          0.0930048,
          0.08731759,
          0.5738246,
          0.14257249,
          -0.9381512,
          1.4212464,
          0.14753671,
          -0.9429971,
          -0.8628484,
          -1.199806,
          -0.8193731,
          -0.8919394,
          -2.340442,
          -2.6053908,
          -0.73918885,
          -0.79596746,
          -1.0300385,
          -1.524655,
          -0.80825084,
          -0.94167167,
          -0.99258196,
          -1.3696225,
          -0.74644214,
          -0.9265781,
          -1.1068205,
          -0.89667183,
          -0.66988593,
          -3.7832253,
          -0.4040826,
          -0.5024313,
          -0.3936505,
          -0.5178639,
          -0.5234392,
          -0.55007446,
          -0.4814093,
          -0.5629433,
          -0.922777,
          -0.6605456,
          -0.59623194,
          -0.76081467,
          -1.0045136,
          -1.4905654,
          -0.7623286,
          -0.8242301,
          -2.1703477,
          -1.4477504,
          -2.367861,
          -2.7026162,
          -2.499438,
          -2.6462672,
          -2.723884,
          -2.8055792,
          -2.4090075,
          -2.7678974,
          -2.835629,
          -2.8799725,
          -2.849437,
          -2.7074115,
          -4.1120768,
          -2.6670992,
          -2.685375,
          -1.2828323,
          -2.7810647,
          -2.764362,
          -2.7277217,
          -2.757938,
          -2.7819712,
          -2.6630797,
          -2.3900313,
          -2.8235528,
          -2.9547513,
          -2.8346934,
          -2.6116145,
          -2.794389,
          -2.3072486,
          -2.5846188,
          -2.4443822,
          -3.7973685,
          -4.3867464,
          -4.538499,
          -4.3295465,
          -4.596901,
          -4.550579,
          -4.237855,
          -3.8773856,
          -4.0748034,
          -3.301011,
          1.1104438,
          -5.215156,
          -5.71799,
          -5.380724,
          -5.922378,
          5.6612196,
          1.7724535,
          2.2723575,
          1.9657365,
          2.6156373,
          1.4269711,
          1.7077988,
          0.82823735,
          0.72422624,
          0.44316936,
          0.64745796,
          0.6510878,
          0.19111599,
          0.58151805,
          1.3514538,
          0.739908,
          0.5364271,
          -0.3736836,
          0.63464975,
          0.7507445,
          8.733764,
          8.206624,
          8.187979,
          -3.233981,
          -4.5280857,
          -4.110385,
          -4.573111,
          -4.538235,
          -4.6179028,
          -4.5998874,
          -4.5741,
          -4.5892067,
          -4.5269027,
          -4.6259985,
          -4.1815886,
          -7.286303,
          -7.1545362,
          -6.980783,
          -7.0680666,
          -1.5878257,
          -0.07502843,
          -0.5946343,
          -1.2078353,
          -0.9016422,
          -1.0915351,
          -2.1078293,
          -7.6713543,
          -1.169321,
          -2.576295,
          -2.047914,
          -1.0872829,
          -1.8846694,
          -0.77775025,
          -0.44739777,
          0.65793186,
          -0.29434127,
          -0.9250853,
          -0.7282043,
          -0.68616617,
          -0.6294995,
          -0.6981981,
          -0.91051364,
          -1.8022431,
          -1.5818592,
          -1.5574872,
          -1.3016769,
          -0.79179084,
          -0.6199442,
          -0.7517086,
          -0.7512995,
          -3.4407306,
          -0.97278035,
          -0.7397963,
          -0.8605267,
          -1.3845543,
          -1.5101345,
          -1.9151615,
          -1.4332216,
          -1.2858127,
          -3.7218726,
          -1.8262409,
          -2.5372899,
          -2.849514,
          -2.5658953,
          -2.4378152,
          -2.5410862,
          -2.5810125,
          -2.4953992,
          -2.4229667,
          -1.8971164,
          -4.9571314,
          8.7999
         ],
         "xaxis": "x",
         "y": [
          -5.9927373,
          -3.15641,
          -6.1993628,
          -1.2202191,
          -6.157769,
          -6.115128,
          -6.026881,
          -6.116001,
          -6.0955005,
          -6.0356693,
          -3.1671476,
          -6.0830064,
          -6.268159,
          -6.319596,
          -7.0095744,
          -7.160156,
          -5.9587665,
          -3.1841161,
          -6.8024325,
          -6.982831,
          -6.547372,
          -6.9554243,
          -6.893794,
          -6.6430907,
          -6.738604,
          -6.1912036,
          -7.231585,
          -7.2899685,
          -7.2744184,
          -7.199477,
          -7.345136,
          -7.1789756,
          -7.355111,
          -7.1746798,
          -9.40977,
          -7.4022937,
          -7.3119965,
          -7.321606,
          -7.151135,
          -7.270183,
          -7.2986364,
          -7.2744355,
          -7.117228,
          -7.3186226,
          -7.220562,
          -7.3134418,
          -7.2512,
          -7.990859,
          -8.106953,
          -7.995765,
          -8.05235,
          -7.9852576,
          -7.8088217,
          -7.9167824,
          -7.5502048,
          -8.738218,
          -9.317448,
          -9.410757,
          -9.274363,
          -9.465376,
          -9.53427,
          -9.451275,
          -9.473523,
          -9.506194,
          -9.516186,
          -9.472617,
          -6.4541383,
          -6.368195,
          -7.591717,
          -7.073502,
          -6.3618555,
          -6.2988005,
          -5.795611,
          -2.842183,
          -7.5793724,
          -7.66956,
          -7.9058113,
          -7.494901,
          -7.791193,
          -8.143785,
          -8.811071,
          -9.044553,
          -8.876319,
          -7.7362313,
          -7.3450203,
          -7.6275005,
          -8.532428,
          -8.435511,
          -8.826622,
          -8.758835,
          -8.825403,
          -8.9075165,
          -8.893433,
          -9.022525,
          -8.8805485,
          -8.869231,
          -9.04901,
          -8.720454,
          -8.910677,
          -8.934691,
          -9.206592,
          -9.17764,
          -9.005448,
          -9.679102,
          -9.78096,
          -10.363948,
          -10.02019,
          -10.325066,
          -10.019735,
          -9.918496,
          -10.135945,
          -10.048936,
          4.660008,
          -10.016647,
          -9.727608,
          -9.805875,
          -9.561313,
          -9.377597,
          -9.236796,
          -9.216524,
          -9.467449,
          -9.396766,
          -9.146473,
          -0.997618,
          0.46610346,
          -9.740769,
          -9.542016,
          -9.520884,
          -9.588243,
          -9.67897,
          -9.611841,
          -9.857745,
          -9.832211,
          -9.511938,
          4.8649955,
          -11.314916,
          0.6113434,
          -11.378002,
          -11.377906,
          -11.187946,
          -11.419836,
          -11.351913,
          -11.412406,
          -11.280419,
          -11.390605,
          -11.208679,
          -11.359132,
          -11.342713,
          -11.302341,
          -11.305067,
          -8.892799,
          -8.676043,
          -9.02499,
          -8.944113,
          -8.822434,
          -8.984708,
          -8.99186,
          -9.470042,
          2.8705215,
          3.2686183,
          -8.960002,
          -8.888987,
          -8.988682,
          -8.987664,
          -8.971859,
          -8.934271,
          -8.932622,
          -8.792132,
          8.69921,
          -8.834111,
          9.092754,
          8.767196,
          4.677361,
          -8.079907,
          -6.394106,
          -6.997774,
          -6.199994,
          -6.1564293,
          -6.52779,
          -7.0427723,
          -7.4214272,
          -7.034453,
          -7.622254,
          -5.71006,
          -5.7787457,
          -5.3785515,
          -3.2093947,
          -6.0466332,
          -6.1591296,
          -6.293593,
          -6.0409803,
          -5.912147,
          -6.2050624,
          -5.8001127,
          -5.9435177,
          -5.850992,
          -5.862998,
          -5.7361956,
          -6.408359,
          -7.1086035,
          -6.362755,
          -5.8588514,
          -6.2071333,
          -6.1289096,
          -6.1531663,
          -6.3113637,
          -6.43602,
          -5.803572,
          -5.830163,
          -5.853866,
          -5.4549513,
          -5.524912,
          -6.083564,
          -5.9747753,
          -5.9359245,
          -5.6906033,
          -5.7347403,
          -6.176116,
          -6.3138075,
          -9.933452,
          -5.4770017,
          -5.0140686,
          -3.827816,
          -3.8867192,
          -8.065073,
          -4.391529,
          -5.6363797,
          -5.438222,
          -5.407564,
          -5.2897835,
          -5.453114,
          -9.322716,
          -9.280016,
          -5.2844887,
          -5.254003,
          -5.258207,
          -5.168167,
          -4.9653416,
          -5.124404,
          -5.019468,
          -4.7794337,
          -5.080019,
          -5.947032,
          -5.964553,
          -5.8915753,
          -5.9853687,
          -5.7975907,
          -5.555879,
          -5.911089,
          -5.948746,
          -6.251122,
          -5.9468093,
          -5.7722774,
          -5.3252525,
          -5.754138,
          -6.074233,
          -5.7488747,
          -5.61826,
          -5.7590084,
          -5.734599,
          -6.402805,
          -5.9033394,
          -5.754983,
          -5.861551,
          -5.695312,
          -0.8730722,
          -0.8687821,
          -5.918505,
          -6.7876954,
          -7.3529754,
          -7.4440513,
          -7.448055,
          -7.422564,
          -7.428552,
          -7.4333816,
          -7.3669376,
          -7.3566723,
          -7.4191256,
          -7.2863865,
          -7.412319,
          -7.4211583,
          -7.4076653,
          -6.896171,
          -7.2664638,
          -7.410322,
          -7.699304,
          -7.5605035,
          -7.6888266,
          -7.60531,
          -7.726787,
          -7.6553473,
          -7.692815,
          -7.6681294,
          -7.6254954,
          -7.7043633,
          -7.661365,
          -7.7075915,
          -7.589424,
          -7.4883056,
          -7.4693537,
          -7.491188,
          -7.3055186,
          -7.468398,
          -7.35127,
          -5.3298664,
          -5.375701,
          -6.0662265,
          -5.4658566,
          -5.446581,
          -5.4250307,
          -5.347811,
          -5.356944,
          -5.4542546,
          -5.379996,
          -5.438006,
          0.30831707,
          0.0920124,
          -0.26257208,
          -1.0247482,
          -0.05333995,
          -1.3096719,
          -2.1238296,
          -1.9588593,
          -2.055249,
          -1.3056495,
          -0.034555584,
          -0.62127966,
          0.053987954,
          -0.16467218,
          -2.1814833,
          -2.047883,
          -1.9606098,
          -2.0751882,
          -2.0042276,
          -2.2059312,
          -2.0300415,
          -2.120537,
          -2.021085,
          -2.0952415,
          -1.8139969,
          0.020022864,
          -0.042783312,
          -1.1162654,
          -0.89007336,
          -0.72940654,
          -0.75724804,
          -0.71887136,
          -0.86075014,
          -0.66830385,
          -2.0930252,
          -0.82373124,
          -0.58962244,
          1.5668576,
          1.5337298,
          1.5885487,
          1.54757,
          1.39602,
          1.5771172,
          1.362159,
          -4.9880824,
          -5.3833466,
          -4.988654,
          -5.9729667,
          -5.7967596,
          -5.4437394,
          -5.100915,
          -4.7615232,
          -4.5867486,
          -4.681358,
          -5.0045085,
          -4.8020754,
          -4.5292296,
          -4.6412106,
          -4.7819767,
          -4.718569,
          -4.680389,
          -4.670232,
          -0.59208417,
          -0.5177094,
          -0.4701472,
          -0.58627266,
          -0.48351556,
          -0.41117945,
          -0.2046222,
          -0.45933026,
          -0.4691502,
          -0.46237552,
          -0.51177067,
          -0.46611205,
          -0.46988916,
          -0.4566893,
          -0.45196533,
          -0.4493115,
          -0.41633308,
          0.12416641,
          -0.426361,
          -0.48306385,
          -0.67409456,
          0.753286,
          0.59883004,
          0.6291069,
          1.6541585,
          -0.43618178,
          -0.24406196,
          -0.33574834,
          -0.21038821,
          -0.042362016,
          -0.082506485,
          -0.15904859,
          -0.12657526,
          -0.106210776,
          -6.2286363,
          -9.505747,
          -4.365262,
          -4.053699,
          -3.784038,
          -3.9671543,
          -3.7862017,
          -3.7161655,
          -3.6492114,
          -3.666112,
          -3.7010248,
          -3.933323,
          -3.9545105,
          -4.2061386,
          -4.630659,
          -5.93209,
          3.9994845,
          3.9733915,
          4.0625157,
          3.859182,
          3.9606402,
          4.033728,
          5.747046,
          4.093138,
          3.8453488,
          3.8916445,
          -3.2730381,
          3.920591,
          4.12077,
          4.401797,
          4.406636,
          4.4647236,
          3.8873873,
          4.212171,
          4.0599737,
          4.055576,
          3.8850198,
          4.3490815,
          4.5206466,
          4.978961,
          3.2023928,
          4.541186,
          4.2665453,
          4.031831,
          4.1255627,
          4.1766443,
          4.020396,
          4.8291125,
          5.1641493,
          5.067911,
          5.1097775,
          5.2106843,
          4.0192094,
          3.2231634,
          3.2977688,
          3.2759097,
          3.392297,
          3.3122823,
          3.9886532,
          3.8932776,
          4.1681137,
          3.403038,
          4.0897307,
          3.9455552,
          3.6565418,
          4.814816,
          5.09151,
          5.47835,
          5.1650014,
          5.108268,
          5.062731,
          5.259587,
          6.683286,
          6.607112,
          3.6167843,
          3.5885067,
          3.442205,
          3.5536468,
          3.5238185,
          3.6282277,
          3.1896956,
          1.9213135,
          1.7712922,
          1.9557097,
          2.5558841,
          3.8232975,
          3.3372493,
          3.4758432,
          2.5713954,
          2.5185177,
          6.4772687,
          2.3894956,
          3.2864342,
          3.4779165,
          3.247645,
          3.4583561,
          3.4192448,
          3.5949128,
          3.7469547,
          3.343879,
          3.6155436,
          3.663312,
          4.1434956,
          3.80779,
          4.239819,
          4.2281656,
          4.3238955,
          4.139797,
          4.361936,
          4.1539917,
          4.9859138,
          5.283046,
          5.174964,
          5.190116,
          5.331397,
          5.2971745,
          5.3691745,
          5.6554236,
          5.3051133,
          5.6538863,
          5.988154,
          5.9529834,
          5.997058,
          6.094513,
          6.062481,
          6.120861,
          6.090319,
          6.008839,
          5.599526,
          5.896491,
          5.0717654,
          4.156898,
          0.005286574,
          4.8473964,
          4.1646132,
          4.150656,
          3.521023,
          2.9131405,
          2.7323172,
          2.5385246,
          2.4406166,
          2.1069455,
          1.4593484,
          0.40471205,
          1.1203038,
          -0.41614133,
          0.5807956,
          0.6252214,
          0.80445725,
          0.60757935,
          0.74061906,
          0.70746136,
          0.41602808,
          0.7558713,
          0.6503782,
          3.672589,
          3.2635002,
          -2.1313353,
          -1.8335751,
          -1.9815674,
          -3.2065196,
          -1.9377083,
          -0.518573,
          0.51380324,
          -0.036009077,
          0.19128956,
          0.048665047,
          7.120671,
          0.5897577,
          9.232798,
          8.192118,
          -0.09752195,
          -2.1688747,
          0.54456735,
          1.6747712,
          1.9713117,
          1.9011797,
          3.4116468,
          3.9905508,
          3.9016309,
          3.6313045,
          4.2066164,
          2.3863506,
          2.5950177,
          2.445904,
          2.1409898,
          8.762904,
          6.9386034,
          7.1358824,
          6.93331,
          2.6357224,
          3.1216953,
          6.1616936,
          -2.1774986,
          2.417562,
          2.743588,
          2.7699096,
          2.9180593,
          2.8308387,
          3.103963,
          1.3197175,
          1.2320021,
          1.2393088,
          1.195279,
          1.1693733,
          2.9865603,
          4.0461903,
          4.201676,
          4.3458614,
          4.3463273,
          4.9357367,
          4.792958,
          4.897247,
          4.6813326,
          4.760603,
          5.401936,
          4.609551,
          4.980232,
          4.7569623,
          -1.91994,
          0.1404451,
          -1.6555474,
          -1.2188952,
          -2.3255057,
          -3.5914445,
          1.2867551,
          2.9886909,
          4.251221,
          -2.0541306,
          -5.076339,
          3.6454482,
          -1.4468526,
          -1.0522739,
          -0.929982,
          -1.2447684,
          -1.0875242,
          -0.7801676,
          -1.0366032,
          -0.7206386,
          3.7163792,
          -1.0391194,
          -0.4481781,
          -0.53349584,
          2.6521947,
          -0.40708935,
          -0.80461025,
          -2.4715304,
          4.0244055,
          4.362632,
          4.444434,
          3.838885,
          3.7406986,
          4.0815654,
          5.591606,
          3.9304614,
          5.0511165,
          4.7981358,
          5.040487,
          2.478193,
          -0.12533177,
          -0.119323604,
          0.098039724,
          -0.039897863,
          0.0694506,
          -0.004674179,
          -0.028723743,
          2.8595462,
          1.4510504,
          -1.0297523,
          5.326368,
          5.665102,
          4.9712725,
          4.6452155,
          5.047097,
          4.4288025,
          4.8029165,
          4.7481513,
          5.2216053,
          4.9791884,
          4.848021,
          5.002028,
          5.242456,
          6.232154,
          5.399015,
          4.5851665,
          5.250518,
          5.9527287,
          -1.0716337,
          -0.4856803,
          3.4473794,
          3.834424,
          4.2671723,
          3.9750865,
          3.861883,
          3.269644,
          3.178031,
          2.90627,
          2.8838072,
          6.1878195,
          3.1977987,
          3.2270324,
          8.999088,
          8.015689,
          7.215808,
          7.854925,
          7.895488,
          7.0850587,
          6.457303,
          7.9537563,
          7.926926,
          7.7801714,
          7.437621,
          7.8273735,
          7.8110814,
          7.704638,
          7.2509546,
          7.699327,
          8.874036,
          9.179908,
          8.729497,
          8.281269,
          5.137999,
          8.493222,
          8.672037,
          8.745245,
          8.622434,
          8.673724,
          8.537412,
          8.8214655,
          8.690542,
          7.756794,
          8.579734,
          8.613106,
          7.8269725,
          7.435822,
          6.7067404,
          7.89916,
          6.5948467,
          6.985549,
          9.219781,
          9.279424,
          9.015251,
          9.190099,
          8.92786,
          9.079442,
          9.004314,
          9.099991,
          9.086634,
          8.781805,
          9.025545,
          9.040598,
          9.1295185,
          5.69387,
          8.775702,
          8.758006,
          9.200031,
          8.910866,
          9.057754,
          8.863963,
          8.927159,
          8.793107,
          8.542076,
          7.3700194,
          8.766183,
          8.770028,
          8.438173,
          8.049344,
          8.591967,
          7.2531767,
          8.186379,
          7.810045,
          3.3733263,
          3.2342517,
          3.222211,
          3.14223,
          3.2826304,
          3.2854176,
          3.441367,
          3.1816566,
          3.2936492,
          3.1939557,
          4.014991,
          3.2066374,
          4.22993,
          3.695239,
          3.6336405,
          -0.88370097,
          3.5503445,
          3.5185807,
          3.394656,
          3.2018492,
          3.5231364,
          3.2584307,
          5.360797,
          6.3365593,
          6.5098767,
          6.3806424,
          6.52541,
          6.693077,
          6.595334,
          3.8968625,
          6.288518,
          6.609078,
          6.5618906,
          6.488399,
          6.453911,
          0.6573037,
          -0.7114703,
          0.2631271,
          6.22096,
          7.428741,
          7.0046816,
          7.461483,
          7.461517,
          7.564499,
          7.4504523,
          7.4970036,
          7.4281096,
          7.472136,
          7.44008,
          7.1393557,
          2.694111,
          2.4127734,
          1.2672688,
          -0.63872755,
          5.574964,
          5.5262885,
          5.41678,
          5.8931785,
          5.493843,
          5.6036654,
          6.4707,
          2.7732494,
          5.5399714,
          8.534649,
          7.622284,
          6.5428057,
          6.0452485,
          5.499628,
          5.3968024,
          5.0847707,
          5.159764,
          5.617843,
          5.4804597,
          5.421489,
          5.5075746,
          5.4395776,
          5.425119,
          5.7442956,
          5.6518645,
          5.2354927,
          5.362813,
          4.1713862,
          4.3326373,
          4.194957,
          4.309449,
          5.9722195,
          4.599526,
          4.2938333,
          4.926907,
          6.8969765,
          6.811755,
          6.735472,
          6.966811,
          6.977101,
          5.7678328,
          7.116211,
          8.391861,
          6.8586965,
          6.546039,
          7.8648643,
          8.953341,
          8.463764,
          8.173129,
          7.017208,
          6.6157427,
          -6.005048,
          -2.9115808
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "CHAPTER 1: Introduction to Machine Learning - Python Machine Learning [Book]\n\nSkip to main content\n\n..."
          ],
          [
           "Start your free trial\n\nCHAPTER 1Introduction to Machine Learning\n\nWelcome to Python Machine Learning..."
          ],
          [
           "About O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nCommunity partners\n\nAffi..."
          ],
          [
           "Close\n\nCHAPTER 2: Extending Python Using NumPy - Python Machine Learning [Book]\n\nSkip to main conten..."
          ],
          [
           "Start your free trial\n\nCHAPTER 2Extending Python Using NumPy\n\nWhat Is NumPy? In Python, you usually ..."
          ],
          [
           "Get Python Machine Learning now with the O’Reilly learning platform. O’Reilly members experience boo..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "What Is Pandas? While NumPy arrays are a much‐improved N‐dimensional array object version over Pytho..."
          ],
          [
           "08:00:00,5.0 4,2016-06-02 12:00:00,4.9 5,2016-06-02 18:00:00,5.5 6,2016-06-03 08:00:00,5.6 7,2016-06..."
          ],
          [
           "18,2016-06-07 08:00:00,6.6 19,2016-06-07 12:00:00,4.1 20,2016-06-07 18:00:00,6.9 21,2016-06-08 08:00..."
          ],
          [
           "To be able to deal with data stored as tables, you need a new data type that is more suited to deal ..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nCHAPTER 4Data Visualization Using matplotlib\n\nWhat Is matplotlib? As the adag..."
          ],
          [
           "Plotting Line Charts To see how easy it is to use matplotlib, let's plot ...\n\nGet Python Machine Lea..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nCHAPTER 5Getting Started with Scikit‐learn for Machine Learning\n\nIntroduction..."
          ],
          [
           "Close\n\nCHAPTER 6: Supervised Learning—Linear Regression - Python Machine Learning [Book]\n\nSkip to ma..."
          ],
          [
           "Figure 6.1: Some terminologies for features and label\n\nTIP Features are also sometimes called explan..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nCHAPTER 7Supervised Learning—Classification Using Logistic Regression\n\nWhat I..."
          ],
          [
           "Close\n\nCHAPTER 8: Supervised Learning—Classification Using Support Vector Machines - Python Machine ..."
          ],
          [
           "Figure 8.1: Using SVM to separate two classes of animals\n\nOnce the line is drawn to separate the cla..."
          ],
          [
           "logo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJ..."
          ],
          [
           "Individuals\n\nFeatures\n\nAll features\n\nCourses\n\nCertifications\n\nInteractive learning\n\nLive events\n\nAns..."
          ],
          [
           "Figure 9.1: The classification of a point depends on the majority of its neighbors\n\nTIP KNN is also ..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Start your free trial\n\nCHAPTER 10Unsupervised Learning—Clustering Using K‐Means\n\nWhat Is Unsupervise..."
          ],
          [
           "Close\n\nCHAPTER 11: Using Azure Machine Learning Studio - Python Machine Learning [Book]\n\nSkip to mai..."
          ],
          [
           "Start your free trial\n\nCHAPTER 11Using Azure Machine Learning Studio\n\nWhat Is Microsoft Azure Machin..."
          ],
          [
           "Close\n\nCHAPTER 12: Deploying Machine Learning Models - Python Machine Learning [Book]\n\nSkip to main ..."
          ],
          [
           "Start your free trial\n\nCHAPTER 12Deploying Machine Learning Models\n\nDeploying ML The main goal of ma..."
          ],
          [
           "Start your free trial\n\nAbout O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nC..."
          ],
          [
           "Close\n\nIndex\n\nPython Machine Learning [Book]\n\nSkip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor bus..."
          ],
          [
           "Start your free trial\n\nIndex\n\nA accuracy, computing of, 168–171 algorithms categories of in ML, 5 co..."
          ],
          [
           "B\n\nBagging, 143\n\nbar chart\n\ndefined, 73\n\nplotting of, 73–77\n\nbar() function, 73\n\nbias, 141–144\n\nBool..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\PythonML-Lee.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\PythonML-Lee.txt, circle",
         "marker": {
          "color": "#FF6692",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\PythonML-Lee.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          10.116471,
          10.154308,
          14.604408,
          10.142573,
          -5.5603824,
          12.392945,
          10.2886095,
          -6.3731837,
          -7.249538,
          -7.278884,
          -5.9598827,
          10.558219,
          -6.152814,
          -6.120103,
          10.297151,
          9.240024,
          9.065007,
          8.825267,
          12.98118,
          8.482821,
          8.852725,
          0.7313536,
          14.490754,
          8.674153,
          8.27499,
          12.805697,
          6.963401,
          10.232183,
          9.986823,
          10.297361,
          9.215595,
          14.648316,
          10.479447,
          9.305294,
          9.688854,
          14.450939
         ],
         "xaxis": "x",
         "y": [
          -1.9498981,
          -2.1374843,
          -4.740616,
          -1.9798117,
          -7.626308,
          -3.4901285,
          -1.9210689,
          -4.828254,
          0.2586935,
          -0.17240968,
          -4.8969674,
          -1.8043973,
          3.0934339,
          3.702712,
          -1.8190658,
          -2.1787353,
          -1.735771,
          -0.79809487,
          -3.966977,
          -1.2262444,
          -0.7739516,
          5.056433,
          -4.7526126,
          -0.9834592,
          -1.0219281,
          -3.9318383,
          0.48413232,
          -0.85210025,
          -0.60424,
          -1.7307382,
          -0.34263977,
          -4.7757626,
          -1.8900574,
          -0.9510663,
          -1.1351265,
          -4.7298512
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Giving Computers the Ability to Learn from Data - Python Machine Learning - Third Edition [Book]\n\nSk..."
          ],
          [
           "Get Python Machine Learning - Third Edition now with the O’Reilly learning platform. O’Reilly member..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n2 Training Simple Machine Learning Algorithms for Classification\n\nIn this cha..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Insights reporting\n\nBlog\n\nContent sponsorship\n\nPython Machine Learning - Third Edition by Sebastian ..."
          ],
          [
           "Submit an RFP\n\nDiversity\n\nO’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\n..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Dealing with missing data\n\nIt is ...\n\nGet Python Machine Learning - Third Edition now with the O’Rei..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n5 Compressing Data via Dimensionality Reduction\n\nIn Chapter 4, Building Good ..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Insights reporting\n\nBlog\n\nContent sponsorship\n\nPython Machine Learning - Third Edition by Sebastian ..."
          ],
          [
           "Affiliate program\n\nSubmit an RFP\n\nDiversity\n\nO’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletter..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "Close\n\nApplying Machine Learning to Sentiment Analysis - Python Machine Learning - Third Edition [Bo..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n9 Embedding a Machine Learning Model into a Web Application\n\nIn the previous ..."
          ],
          [
           "Indonesia\n\nJapan\n\nDownload the O’Reilly App Take O’Reilly with you and learn anywhere, anytime on yo..."
          ],
          [
           "Insights reporting\n\nBlog\n\nContent sponsorship\n\nPython Machine Learning - Third Edition by Sebastian ..."
          ],
          [
           "O’Reilly for marketers\n\nSupport\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nl..."
          ],
          [
           "Sign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividuals\n\nFeatures\n\nAll fea..."
          ],
          [
           "Close\n\nImplementing a Multilayer Artificial Neural Network from Scratch - Python Machine Learning - ..."
          ],
          [
           "Gaining ...\n\nGet Python Machine Learning - Third Edition now with the O’Reilly learning platform. O’..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\n13 Parallelizing Neural Network Training with TensorFlow\n\nIn this chapter, we..."
          ],
          [
           "International\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJapan\n\nDownload the O’..."
          ],
          [
           "Certifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nContent sponso..."
          ],
          [
           "Close\n\nClassifying Images with Deep Convolutional Neural Networks - Python Machine Learning - Third ..."
          ],
          [
           "Convolution operations in one and two dimensions The building blocks of CNN architectures Implementi..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\n16 Modeling Sequential Data Using Recurrent Neural Networks\n\nIn the previous ..."
          ],
          [
           "International\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJapan\n\nDownload the O’..."
          ],
          [
           "Courses\n\nCertifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reporting\n\nBlog\n\nConte..."
          ],
          [
           "Close\n\nReinforcement Learning for Decision Making in Complex Environments - Python Machine Learning ..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\PythonML-RaschkaMirjalili.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\PythonML-RaschkaMirjalili.txt, circle",
         "marker": {
          "color": "#B6E880",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\PythonML-RaschkaMirjalili.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          9.703509,
          11.51019,
          10.611927,
          9.3398905,
          15.655226,
          10.282092,
          14.668321,
          8.923086,
          10.34255,
          10.26893,
          8.587737,
          15.52283,
          10.404835,
          14.282933,
          9.88444,
          7.9866037,
          10.750912,
          8.784363,
          15.479161,
          9.89024,
          14.560151,
          7.6535296,
          9.911835,
          13.331945,
          10.437952,
          10.071204,
          14.9095,
          10.211435,
          9.989444,
          9.949494,
          13.01438,
          9.779104,
          14.826877,
          9.9370775,
          8.819629,
          9.499658
         ],
         "xaxis": "x",
         "y": [
          -1.6617788,
          -2.6627247,
          -1.7550704,
          -0.8580563,
          -5.0076494,
          -1.333959,
          -4.7738647,
          -1.1151174,
          -1.959841,
          -1.6925077,
          -0.7135934,
          -4.9438996,
          -1.3525721,
          -4.651125,
          -1.1139961,
          -0.77212274,
          -1.8600867,
          -0.76929,
          -4.973299,
          -1.084431,
          -4.761715,
          -0.032273486,
          1.1483046,
          -4.1581,
          0.5887833,
          0.9403142,
          -4.8386574,
          0.5400407,
          0.9300442,
          1.1213952,
          -4.8132453,
          1.4175538,
          -4.836389,
          1.1709733,
          -0.17297685,
          -0.29621655
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "1. Probably Approximately Correct Software - Thoughtful Machine Learning with Python [Book]\n\nSkip to..."
          ],
          [
           "Start your free trial\n\nChapter 1. Probably Approximately Correct Software If you’ve ever flown on an..."
          ],
          [
           "The year 2014 saw the Heartbleed bug infection, which made many sites using SSL vulnerable. As a res..."
          ],
          [
           "SOLID SOLID is a framework that helps design better object-oriented code. In the same ways that the ..."
          ],
          [
           "Figure 1-1. A multi-tool like this has too many responsibilities\n\nOpen/Closed Principle The OCP, som..."
          ],
          [
           "Dependency Inversion Principle The DIP is a principle that guides us to depend on abstractions, not ..."
          ],
          [
           "Testing or TDD In the early days of aviation, pilots didn’t use checklists to test whether their air..."
          ],
          [
           "This led to the Agile Manifesto as well as the culture of testing and TDD, spearheaded by Kent Beck,..."
          ],
          [
           "Refactoring Refactoring is one of the hardest programming practices to explain to nonprogrammers, wh..."
          ],
          [
           "Technical debt in many cases arises through not writing tests or not following the SOLID principles...."
          ],
          [
           "Refactor your code to avoid a buildup of technical debt\n\nThe real question now is what makes the sof..."
          ],
          [
           "Writing the Right Software with Machine Learning In The Knowledge-Creating Company, Nonaka and Takeu..."
          ],
          [
           "The issue with inductive reasoning, though, is that you can only feed the algorithm data that you kn..."
          ],
          [
           "Hidden feedback loops Having built-in hidden features in model OCP\n\nUndeclared consumers/visibility ..."
          ],
          [
           "SRP In machine learning code, one of the biggest challenges for people to realize is that the code a..."
          ],
          [
           "OCP Recall that the OCP is about opening classes for extension but not modification. One way this ma..."
          ],
          [
           "LSP Not a lot of people talk about the LSP anymore because many programmers are advocating for compo..."
          ],
          [
           "ISP The ISP is the notion that a client-specific interface is better than a general purpose one. In ..."
          ],
          [
           "Many times this just isn’t the case. Take for instance the price of a stock; in the morning it might..."
          ],
          [
           "DIP The Dependency Inversion Principle is about limiting our buildups of data and making code more f..."
          ],
          [
           "Machine Learning Code Is Complex but Not Impossible At times, machine learning code can be difficult..."
          ],
          [
           "TDD: Scientific Method 2.0 Every true scientist is a dreamer and a skeptic. Daring to put a person o..."
          ],
          [
           "The Plan for the Book This book will cover a lot of ground with machine learning, but by the end you..."
          ],
          [
           "Get Thoughtful Machine Learning with Python now with the O’Reilly learning platform. O’Reilly member..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 2. A Quick Introduction to Machine Learning You’ve picked up this boo..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 3. K-Nearest Neighbors Have you ever bought a house before? If you’re..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 4. Naive Bayesian Classification Remember how email was several years..."
          ],
          [
           "Using Bayes’ Theorem to Find Fraudulent Orders Imagine you’re running an online store and lately you..."
          ],
          [
           "Conditional Probabilities Most people understand what we mean by the probability of something happen..."
          ],
          [
           "set(a) | set(b) #=> [1,2,3,4,5] Finally, the probability of A given B looks as follows in Python: a ..."
          ],
          [
           "r\n\nd\n\n)\n\n=\n\nP(Fraud∩Giftcard) P(Giftcard)\n\nNow this works if you know the actual probability of Frau..."
          ],
          [
           "P\n\n(\n\nF\n\nr\n\na\n\nu\n\nd\n\n∣\n\nG\n\ni\n\nf\n\nt\n\nc\n\na\n\nr\n\nd\n\n)\n\n=\n\nP(Giftcard∣Fraud)P(Fraud) P(Giftcard)\n\nRemembe..."
          ],
          [
           ")\n\n=\n\n60%\n\n10% 10%\n\n=\n\n60\n\n%\n\nThe beauty of this is that your work on measuring fraudulent orders is..."
          ],
          [
           "P\n\n(\n\nA\n\n∩\n\nB\n\n)\n\n=\n\nP\n\n(\n\nB\n\n|\n\nA\n\n)\n\nP\n\n(\n\nA\n\n)\n\n. This is assuming these events are not mutually ..."
          ],
          [
           ",\n\nA 2\n\n,\n\n⋯\n\n,\n\nA n\n\n1\n\n)\n\nThis expanded version is useful in trying to solve our problem by feedin..."
          ],
          [
           "s\n\n)\n\n=\n\nP(Giftcard,Promos∣Fraud)P(Fraud) P(Giftcard,Promos)\n\nLet’s ignore the denominator for now, ..."
          ],
          [
           "G\n\n|\n\nF\n\n)\n\nP\n\n(\n\nP\n\n|\n\nF\n\n,\n\nG\n\n)\n\nNow at this point we have a conundrum: how do you measure the pr..."
          ],
          [
           "i\n\nf\n\nt\n\nc\n\na\n\nr\n\nd\n\n∣\n\nF\n\nr\n\na\n\nu\n\nd\n\n)\n\nP\n\n(\n\nP\n\nr\n\no\n\nm\n\no\n\n∣\n\nF\n\nr\n\na\n\nu\n\nd\n\n)\n\nThis would be pr..."
          ],
          [
           "a\n\nu\n\nd\n\n)\n\nP\n\n(\n\nG\n\ni\n\nf\n\nt\n\nc\n\na\n\nr\n\nd\n\n∣\n\nF\n\nr\n\na\n\nu\n\nd\n\n)\n\nP\n\n(\n\nP\n\nr\n\no\n\nm\n\no\n\n∣\n\nF\n\nr\n\na\n\nu\n\nd..."
          ],
          [
           "Multiple promos used\n\n50%\n\n30%\n\nProbability of class\n\n10%\n\n90%\n\nAt this point, you can use this info..."
          ],
          [
           "Pseudocount There is one big challenge with a Naive Bayesian Classifier, and that is the introductio..."
          ],
          [
           "0\n\nPrince\n\n75%\n\n15%\n\nNigeria\n\n85%\n\n10%\n\nNow let’s assume we want to calculate a score for ham or spa..."
          ],
          [
           "What the classes look like interacting with each other\n\nA good data source\n\nA tokenization model\n\nAn..."
          ],
          [
           "EmailObject The EmailObject class has one responsibility, which is to parse an incoming email messag..."
          ],
          [
           "class TestPlaintextEmailObject(unittest.TestCase):\n\nCLRF = \"\\n\\n\"\n\ndef setUp(self): self.plain_file ..."
          ],
          [
           "Any method that is prefixed with test_ will be treated as a test to be run.\n\nsetUp(self) is a specia..."
          ],
          [
           "not isinstance(a,b)\n\nDo note that we will not use all of these methods; they are listed here for fut..."
          ],
          [
           "@staticmethod def _single_body(part): \"\"\" Get text from part. :param part: email.Message :return: st..."
          ],
          [
           "expected = BeautifulSoup(body, 'html.parser').text\n\nactual_body = self.html_email.body()\n\nself.asser..."
          ],
          [
           "if content_type == 'text/html': return BeautifulSoup(body, 'html.parser').text elif content_type == ..."
          ],
          [
           "class TestTokenizer(unittest.TestCase): def setUp(self): self.string = \"this is a test of the emerge..."
          ],
          [
           "return re.findall(\"\\w+\", string.lower())\n\n@staticmethod\n\ndef unique_tokenizer(string):\n\nreturn set(T..."
          ],
          [
           "Storing training data\n\nBuilding a Bayesian classifier\n\nError minimization through cross\n\nvalidation\n..."
          ],
          [
           "def test_multiple_categories(self): categories = self.trainer.categories expected = set([k for k, v ..."
          ],
          [
           "def test_counts_all_at_zero(self): for cat in ['_all', 'spam', 'ham', 'scram']: self.assertEqual(sel..."
          ],
          [
           "B\n\n)\n\n= P(B∣A i )P(A i ) ∑ j P(B∣A j )P(A j )\n\nBut because we’re being naive about this, we’ve disti..."
          ],
          [
           "W n\n\n∣\n\nS\n\np\n\na\n\nm\n\n)\n\nwhich is then divided by some normalizing constant, Z. Our goal now is to bui..."
          ],
          [
           "\"\"\"\n\nCalculates score\n\n:param email: EmailObject\n\n:return: float number\n\n\"\"\"\n\nself.train()\n\ncat_tota..."
          ],
          [
           "def test_adds_up_to_one(self): trainer = self.trainer scores = list(trainer.normalized_score(self.em..."
          ],
          [
           "normalized = {cat: (aggregate / scoresum) \\ for cat, aggregate in score.items()} return normalized\n\n..."
          ],
          [
           "def preference(self): return sorted(self.categories, key=lambda cat: self.total_for(cat)) Now that w..."
          ],
          [
           "def classify(self, email):\n\nscore = self.score(email)\n\nmax_score = 0.0\n\npreference = self.preference..."
          ],
          [
           "Minimizing false positives Up until this point, our goal with making models has been to minimize err..."
          ],
          [
           "from spam_trainer import SpamTrainer\n\nfrom email_object import EmailObject\n\nprint(\"Cross Validation\"..."
          ],
          [
           "with io.open(file, 'rb') as eml_file: emails.append(EmailObject(eml_file, category=label))\n\nprint(\"D..."
          ],
          [
           "validate(trainer, emails) Last, we can analyze the other direction of the cross-validation (i.e., va..."
          ],
          [
           "Email count\n\nWord count\n\nProbability of email\n\nProbability of word\n\nSpam\n\n1,378\n\n231,472\n\n31.8%\n\n36...."
          ],
          [
           "About O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nCommunity partners\n\nAffi..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 5. Decision Trees and Random Forests Every day we make decisions. Eve..."
          ],
          [
           "When ...\n\nGet Thoughtful Machine Learning with Python now with the O’Reilly learning platform. O’Rei..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 6. Hidden Markov Models Intuition informs much of what we do: for exa..."
          ],
          [
           "Figure ...\n\nGet Thoughtful Machine Learning with Python now with the O’Reilly learning platform. O’R..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Start your free trial\n\nChapter 7. Support Vector Machines In this chapter, we will set out to solve ..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 8. Neural Networks Humans are amazing pattern matchers. When we come ..."
          ],
          [
           "Close\n\nCheck it out now on O’Reilly Dive in for free with a 10-day trial of the O’Reilly learning pl..."
          ],
          [
           "Start your free trial\n\nChapter 9. Clustering Up until this point we have been solving problems of fi..."
          ],
          [
           "Don’t leave empty-handed Get Mark Richards’s Software Architecture Patterns ebook to better understa..."
          ],
          [
           "Feature selection\n\nFeature transformation\n\nEnsemble learning\n\nBootstrapping\n\nI’ll outline the benefi..."
          ],
          [
           "Press releases\n\nMedia coverage\n\nCommunity partners\n\nAffiliate program\n\nSubmit an RFP\n\nDiversity\n\nO’R..."
          ],
          [
           "Close\n\n11. Putting It Together: Conclusion - Thoughtful Machine Learning with Python [Book]\n\nSkip to..."
          ],
          [
           "Start your free trial\n\nChapter 11. Putting It Together: Conclusion Well, here we are! The end of the..."
          ],
          [
           "Supervised Supervised learning is the most common machine learning category. This is functional appr..."
          ],
          [
           "Watch on your big screen View all O’Reilly videos, Superstream events, and Meet the Expert sessions ..."
          ],
          [
           "Blog\n\nContent sponsorship\n\nThoughtful Machine Learning with Python by Matthew Kirk\n\nBuy on Amazon\n\nB..."
          ],
          [
           "aggregation (see bagging)Brown Corpus, Part-of-Speech Tagging with the Brown Corpus-How to Make This..."
          ],
          [
           "International\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJapan\n\nDownload the O’..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\ThoughtfulML-Kirk.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\ThoughtfulML-Kirk.txt, circle",
         "marker": {
          "color": "#FF97FF",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\ThoughtfulML-Kirk.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          10.967469,
          7.0581994,
          7.039274,
          6.882726,
          6.6931567,
          6.8017654,
          7.0084867,
          6.965249,
          6.9185576,
          6.968915,
          6.7937136,
          8.157026,
          6.9795265,
          6.65618,
          6.6845975,
          6.5412526,
          6.5768886,
          6.7154055,
          6.591915,
          6.7272844,
          8.19054,
          8.470722,
          8.763816,
          10.7075615,
          12.974162,
          8.525342,
          10.879842,
          5.8148017,
          12.885345,
          6.193071,
          5.3820148,
          5.410719,
          5.422288,
          5.37832,
          5.344113,
          5.398425,
          5.422536,
          5.4322424,
          5.3794537,
          5.380972,
          5.595939,
          5.3747807,
          5.3716726,
          5.875104,
          5.788044,
          5.1196795,
          4.357375,
          4.318901,
          4.1682534,
          4.53413,
          4.6667185,
          4.4115458,
          4.937348,
          4.38001,
          4.8286257,
          4.3527374,
          4.170466,
          4.544779,
          5.553238,
          4.1424766,
          4.112435,
          4.1181293,
          4.267877,
          4.326941,
          4.918189,
          4.728622,
          4.486812,
          4.482909,
          4.3479786,
          5.86493,
          14.577127,
          10.798967,
          7.334944,
          10.833072,
          12.886341,
          6.575824,
          10.49247,
          12.985304,
          8.649096,
          10.837532,
          9.799091,
          10.843898,
          6.9703345,
          12.514286,
          6.3890877,
          14.584757,
          10.702722,
          8.223171,
          8.512828,
          12.949457,
          10.303595,
          6.6031117,
          15.045413
         ],
         "xaxis": "x",
         "y": [
          -1.599125,
          2.6703777,
          2.6444209,
          2.739097,
          2.798953,
          2.726644,
          2.9481032,
          2.6996622,
          2.7874458,
          2.8396194,
          2.5662978,
          0.5716794,
          2.209343,
          2.7097135,
          2.4614534,
          2.3350015,
          2.542907,
          2.5401542,
          2.354071,
          2.501335,
          0.28124997,
          0.36531997,
          -0.3260714,
          -1.9885446,
          -4.5072303,
          -0.030872852,
          -1.6105406,
          1.2410479,
          -4.443137,
          -0.95357,
          -2.8828313,
          -2.880687,
          -2.8425694,
          -2.8959806,
          -2.9729137,
          -2.7795515,
          -2.6496701,
          -2.747877,
          -2.849861,
          -2.9213324,
          -1.7035424,
          -2.9148488,
          -2.8630319,
          -0.91316235,
          -0.8595239,
          -0.8772422,
          -1.0601618,
          -1.2588501,
          -1.4130982,
          -1.3069139,
          -1.2219647,
          -1.170203,
          -1.1169269,
          -1.391844,
          -1.1247022,
          -0.9232654,
          -0.9330802,
          -0.98541516,
          -1.8066677,
          -0.99360603,
          -0.98633206,
          -1.1078618,
          -0.92668176,
          -0.9849259,
          -0.7464927,
          -0.8440398,
          -0.97277176,
          -0.9139993,
          -0.49398556,
          -0.93969005,
          -4.768484,
          -1.4164026,
          5.62964,
          -1.5250479,
          -4.538586,
          -0.09121577,
          -1.1859533,
          -4.5789204,
          -0.81016713,
          -1.5145264,
          1.1611129,
          -1.4365472,
          0.5791599,
          -3.9012084,
          2.077061,
          -4.773937,
          -1.2680742,
          0.046395563,
          -0.5133075,
          -4.245362,
          -1.7294859,
          -0.19849563,
          -4.887967
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "okay hello welcome to uh week 11's lecture uh it's been a little while since we\n\ntalked about some o..."
          ],
          [
           "just as a review here what we've got is uh uh this is our typical\n\nkind of you know well anyway mach..."
          ],
          [
           "just based off the training set we can do that all right we can basically detect our error rate thin..."
          ],
          [
           "just building something in isolation what's it going to look like when it's actually working out the..."
          ],
          [
           "in a classification standpoint all right so we're doing all classification here i'll talk about regr..."
          ],
          [
           "potential threat to a system might be a one right that's a positive outcome that we positively ident..."
          ],
          [
           "okay all right all right so\n\nlet's work through an example we're talking here about intruder fraud d..."
          ],
          [
           "this is data point x right the likelihood\n\nprobability of that particular data point being spam is 5..."
          ],
          [
           "on positive and negative classification i don't think i need to read through all this let's just loo..."
          ],
          [
           "right is that because our threshold is so low right is that we\n\nhave no tolerance for potential frau..."
          ],
          [
           "according to what problem you might have right you might adjust that threshold measure right\n\nmaybe ..."
          ],
          [
           "predict true positives how often are we right okay not that good okay all right so\n\nnot so good here..."
          ],
          [
           "positive and false positive rate and those just become data points on a axis you just graph them\n\non..."
          ],
          [
           "it's much more kind of oriented towards this balance between false positives\n\nand true positives oh ..."
          ],
          [
           "is sensitivity all right we talked about that um okay\n\nuh and this is just one minus specificity all..."
          ],
          [
           "then penalizing you if you're not doing that well so i would i would certainly consider that\n\nespeci..."
          ],
          [
           "of one can be expected you know your case when our model gives us less than a forty percent\n\nprobabi..."
          ],
          [
           "know that's not super useful but it is really good for multi-class models\n\nall right and it and it w..."
          ],
          [
           "amongst all three of these all right so almost perfect agreement right so if we assume here we do a\n..."
          ],
          [
           "basically just the detection rate but in multi-class samples it works really well right so you can s..."
          ],
          [
           "the standard ones that i think a lot of people are familiar with mean squared error right that's jus..."
          ],
          [
           "one does all right is it just normalizes all right that root mean squared error\n\nby dividing it by t..."
          ],
          [
           "that's not quite as bad right so it helps put that into context that's what this does here it's all ..."
          ],
          [
           "all right that is the data grows all right it's not heavily dependent on a large number of covariate..."
          ],
          [
           "is under fit so here we have high bias okay and low variance\n\nso that's what we see down here all ri..."
          ],
          [
           "it right it probably goes out to this second rim all right but it's not that far off\n\nsomething like..."
          ],
          [
           "discussing here all right but it also kind of is an extension all right of that all right so i just\n..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\Week7-lecture.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\Week7-lecture.txt, circle",
         "marker": {
          "color": "#FECB52",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\Week7-lecture.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          9.726963,
          6.898117,
          6.798519,
          7.4900417,
          7.96643,
          7.999041,
          7.725066,
          8.014421,
          8.031182,
          7.8950863,
          7.8747873,
          7.992269,
          7.954438,
          7.9523425,
          8.10436,
          7.653448,
          7.8670487,
          7.557868,
          7.9387336,
          7.580413,
          7.0448256,
          6.434842,
          5.70005,
          4.6373587,
          5.5029798,
          7.2796683,
          6.893246
         ],
         "xaxis": "x",
         "y": [
          -0.33920774,
          4.680975,
          4.404171,
          4.9946904,
          4.9219294,
          4.906274,
          4.991185,
          4.9074335,
          4.9991746,
          5.1713576,
          4.9389954,
          4.9509745,
          4.965258,
          4.9906135,
          4.937266,
          4.836888,
          5.04771,
          5.3578825,
          5.1469927,
          5.0458364,
          5.6401877,
          5.374066,
          4.3043203,
          4.150982,
          4.2770643,
          4.734206,
          3.2984478
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "okay all right so let me pop this up here\n\nbigger i can do that there we go all right so we've been ..."
          ],
          [
           "have a leaf node or terminal node kind of the same thing it has one node coming in one edge and then..."
          ],
          [
           "of classifying setosa right that's remember that's a type of flower\n\nthat we have there does such a ..."
          ],
          [
           "to be able to decide uh how to classify our target variable all right all right so\n\nyou know dependi..."
          ],
          [
           "here you know it might be that you know a certain person you know fifty percent will go on uh on\n\na ..."
          ],
          [
           "example to maybe a perfect classification of whether they will go on to the second date or not right..."
          ],
          [
           "whether someone will go on a second date or not all right okay all right\n\nso decision trees are hier..."
          ],
          [
           "predestined right you could have a couple of variables that are incredibly good at predicting these ..."
          ],
          [
           "individual node those individual internal leaves okay all right\n\nand it will consider every possible..."
          ],
          [
           "related to basically to information gain which is the key component to kind of\n\nunderstand how decis..."
          ],
          [
           "some pretty weighty advantages right it is simple to understand and interpret through data visualiza..."
          ],
          [
           "we'll be using to use uh use these methods in the wrong circumstances all right they do have\n\nlike a..."
          ],
          [
           "this is why you know a single decision tree depending on how good or bad your data is can be very\n\nu..."
          ],
          [
           "but until we get there we have to understand what one tree is doing before we start building forests..."
          ],
          [
           "right so we're thinking about basically this is our equation in\n\npractice here just this portion of ..."
          ],
          [
           "clumsy through that all right the idea here is that information gain is basically going to be right ..."
          ],
          [
           "what we see here is that if the answer is yes all right that two of these uh\n\ntwo of these dots stop..."
          ],
          [
           "we're gonna take the average of these two numbers right so the average of 0.8\n\n0.0 all right and we'..."
          ],
          [
           "right and then we just subtract it from one and so we get 0.54\n\nall right okay so that would basical..."
          ],
          [
           "side of the uh side of the equation okay so let's take a look at another\n\nanother example here all r..."
          ],
          [
           "variable here sunny so that resulted in one yes all right all right\n\nand uh two nodes two nodes all ..."
          ],
          [
           "going to be 0 right okay and then we're going to subtract it by 1. so we're going to get all right 0..."
          ],
          [
           "perfectly terrible example all right so here what we see is we have perfect disagreement okay\n\nregar..."
          ],
          [
           "the same idea about net gain all right so pi in this equation just represents\n\nthe probability that ..."
          ],
          [
           "we see is you know kind of a a genie index here we're subtracting this from one that's\n\nbasically po..."
          ],
          [
           "mean squared error is how it's done if you were doing um if we were doing a continuous\n\nreducing bas..."
          ],
          [
           "kind of a pure split between this is this is pregnant and\n\nthat's the other way around sorry not pre..."
          ],
          [
           "at least you know 10 data points in every node all right so that would avoid kind of\n\nover spitting ..."
          ],
          [
           "are available all right are ones that have not been used uh anywhere higher all right\n\ninside the sp..."
          ],
          [
           "just stop there because uh you know the decision space is pretty low all right\n\nokay so the we talke..."
          ],
          [
           "anyway that's that that's there's let's assume that there's 24 dots here or something like that and ..."
          ],
          [
           "uh we talked about that a little bit we're gonna talk much more about that next week but that's basi..."
          ],
          [
           "visualization and they're intuitive so they can be useful for all those all those types of reasons b..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\Week9-lecture.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\Week9-lecture.txt, circle",
         "marker": {
          "color": "#636efa",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\Week9-lecture.txt, circle",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          6.8968067,
          6.910238,
          7.104217,
          7.037078,
          7.2521954,
          7.217295,
          6.9681244,
          7.086814,
          6.9709487,
          6.85108,
          6.8198385,
          6.3041,
          6.8026605,
          6.9214277,
          7.346378,
          7.3491654,
          7.4315844,
          7.1807995,
          7.3495154,
          7.1658854,
          7.4032016,
          7.425766,
          7.4967194,
          7.360331,
          7.267328,
          7.0505524,
          6.9204373,
          6.782606,
          7.0554147,
          6.7466187,
          6.0905995,
          6.7333503,
          6.8190627
         ],
         "xaxis": "x",
         "y": [
          5.672343,
          5.68294,
          5.708534,
          5.4810424,
          5.9136252,
          5.872376,
          5.797585,
          5.9094286,
          5.8865905,
          5.73035,
          5.6259604,
          4.8054905,
          5.447177,
          5.788184,
          6.275918,
          6.26254,
          6.203223,
          6.2810555,
          6.333238,
          6.244336,
          6.3272057,
          6.2683015,
          6.2198224,
          6.2751055,
          6.303298,
          6.002126,
          5.563491,
          5.3650885,
          5.815214,
          4.9745593,
          4.2099056,
          5.4950566,
          3.6323886
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "How do I use pandas?"
          ]
         ],
         "hovertemplate": "source=User query<br>symbol=star<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "User query, star",
         "marker": {
          "color": "black",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           100
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "diamond"
         },
         "mode": "markers",
         "name": "User query, star",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          -5.793454
         ],
         "xaxis": "x",
         "y": [
          -4.92701
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 700,
        "legend": {
         "itemsizing": "constant",
         "title": {
          "text": "<b>Chunk source</b>"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "<b>2D Projection of Chunk Embeddings via PaCMAP</b>"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# vistualize pca projection\n",
    "\n",
    "df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"x\": documents_projected[x, 0],\n",
    "            \"y\": documents_projected[x, 1],\n",
    "            \"source\": db.docstore.search(i).metadata[\"source\"],\n",
    "            \"extract\": db.docstore.search(i).page_content[:100] + \"...\",\n",
    "            \"symbol\": \"circle\",\n",
    "            \"size_col\": 4,\n",
    "        }\n",
    "        for x, i in enumerate(list(db.index_to_docstore_id.values()))\n",
    "    ]\n",
    "    + [\n",
    "        {\n",
    "            \"x\": documents_projected[-1, 0],\n",
    "            \"y\": documents_projected[-1, 1],\n",
    "            \"source\": \"User query\",\n",
    "            \"extract\": user_query,\n",
    "            \"size_col\": 100,\n",
    "            \"symbol\": \"star\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Visualize the embedding\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"source\",\n",
    "    hover_data=\"extract\",\n",
    "    size=\"size_col\",\n",
    "    symbol=\"symbol\",\n",
    "    color_discrete_map={\"User query\": \"black\"},\n",
    "    width=1000,\n",
    "    height=700,\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(opacity=1, line=dict(width=0, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "fig.update_layout(\n",
    "    legend_title_text=\"<b>Chunk source</b>\",\n",
    "    title=\"<b>2D Projection of Chunk Embeddings via PaCMAP</b>\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RAG bot\n",
    "\n",
    "import openai\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "api_key = os.getenv('OPEN_AI_KEY')\n",
    "\n",
    "class RagBot:\n",
    "\n",
    "    def __init__(self, retriever, model: str = \"gpt-3.5-turbo\"):\n",
    "        self._retriever = retriever\n",
    "        # Wrapping the client instruments the LLM\n",
    "        self._client = wrap_openai(openai.Client(api_key=api_key))\n",
    "        self._model = model\n",
    "\n",
    "    @traceable()\n",
    "    def retrieve_docs(self, question):\n",
    "        return self._retriever.invoke(question)\n",
    "\n",
    "    @traceable()\n",
    "    def invoke_llm(self, question, docs):\n",
    "        response = self._client.chat.completions.create(\n",
    "            model=self._model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful AI teaching assistant with expertise in Machine Learning.\"\n",
    "                    \" Use the following docs to produce a solution to the user question.\"\n",
    "                    \"If you do not know the answer, respond with \\'Couldn't tell ya\\' \\n\\n\"\n",
    "                    f\"## Docs\\n\\n{docs}\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Evaluators will expect \"answer\" and \"contexts\"\n",
    "        return {\n",
    "            \"answer\": response.choices[0].message.content,\n",
    "            \"contexts\": [doc for doc in docs],\n",
    "        }\n",
    "\n",
    "    @traceable()\n",
    "    def get_answer(self, question: str):\n",
    "        docs = self.retrieve_docs(question)\n",
    "        return self.invoke_llm(question, docs)\n",
    "\n",
    "rag_bot = RagBot(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To plot a decision boundary, you can follow these general steps based on the provided documentation:\\n\\n1. **Determine the Boundary**: First, you need to determine the decision boundary as per your machine learning model.\\n   \\n2. **Create Grid**: Create a grid to evaluate the model. This grid should cover the range of values for your data points.\\n   \\n3. **Make Predictions**: Use the model to predict the classes or values for the grid points.\\n   \\n4. **Plot the Boundary**: Finally, plot the decision boundary along with optional support vectors to visualize the model's classification. You can use contour plots or color plots to represent the boundary.\\n\\nThe specific code to achieve this will depend on the machine learning model you're using. The key functions involved are `decision_function` or `predict` to get the boundary, and plotting functions like `contour`, `contourf`, or scatter plots to visualize it.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_bot.get_answer(\"How do I plot a decision boundary?\")\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To plot a decision boundary, you can follow these general steps based on the provided documentation:\n",
      "\n",
      "1. **Determine the Boundary**: First, you need to determine the decision boundary as per your machine learning model.\n",
      "   \n",
      "2. **Create Grid**: Create a grid to evaluate the model. This grid should cover the range of values for your data points.\n",
      "   \n",
      "3. **Make Predictions**: Use the model to predict the classes or values for the grid points.\n",
      "   \n",
      "4. **Plot the Boundary**: Finally, plot the decision boundary along with optional support vectors to visualize the model's classification. You can use contour plots or color plots to represent the boundary.\n",
      "\n",
      "The specific code to achieve this will depend on the machine learning model you're using. The key functions involved are `decision_function` or `predict` to get the boundary, and plotting functions like `contour`, `contourf`, or scatter plots to visualize it.\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt\n",
      "RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt\n",
      "RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt\n",
      "RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt\n"
     ]
    }
   ],
   "source": [
    "for source in response['contexts']:\n",
    "    print(source.metadata['source'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
